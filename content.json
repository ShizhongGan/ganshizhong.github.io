{"meta":{"title":"钟声","subtitle":"甘士忠个人博客","description":"Sharing is meaningful","author":"甘士忠","url":"http://shizhonggan.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2021-10-28T06:55:59.894Z","updated":"2021-10-28T06:55:59.894Z","comments":false,"path":"/404.html","permalink":"http://shizhonggan.github.io/404.html","excerpt":"","text":""},{"title":"About","date":"2021-10-28T06:55:59.910Z","updated":"2021-10-28T06:55:59.910Z","comments":false,"path":"about/index.html","permalink":"http://shizhonggan.github.io/about/index.html","excerpt":"","text":""},{"title":"分类","date":"2021-10-28T06:55:59.911Z","updated":"2021-10-28T06:55:59.911Z","comments":false,"path":"categories/index.html","permalink":"http://shizhonggan.github.io/categories/index.html","excerpt":"","text":""},{"title":"书单","date":"2021-10-28T06:55:59.910Z","updated":"2021-10-28T06:55:59.910Z","comments":false,"path":"books/index.html","permalink":"http://shizhonggan.github.io/books/index.html","excerpt":"","text":""},{"title":"阅读","date":"2021-10-28T06:55:59.913Z","updated":"2021-10-28T06:55:59.913Z","comments":false,"path":"reading/index.html","permalink":"http://shizhonggan.github.io/reading/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2021-10-28T06:55:59.913Z","updated":"2021-10-28T06:55:59.913Z","comments":true,"path":"links/index.html","permalink":"http://shizhonggan.github.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2021-10-28T06:55:59.913Z","updated":"2021-10-28T06:55:59.913Z","comments":false,"path":"repository/index.html","permalink":"http://shizhonggan.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2021-10-28T06:55:59.914Z","updated":"2021-10-28T06:55:59.914Z","comments":false,"path":"tags/index.html","permalink":"http://shizhonggan.github.io/tags/index.html","excerpt":"","text":""},{"title":"","date":"2021-10-28T06:55:59.912Z","updated":"2021-10-28T06:55:59.912Z","comments":true,"path":"cv/weddingmusic/musiclist.html","permalink":"http://shizhonggan.github.io/cv/weddingmusic/musiclist.html","excerpt":"","text":"婚礼歌单 流程 歌曲 暖场歌曲 《Marry You》 Bruno Mars 《Lucky》 Lenka 《Could This Be love》 victoria acosta 《Nothing’s Gonna Change My Love For You》 Westlife 《Sugar》 Maroon 5 《Everybody》 Ingrid Michaelson 《Love You Like the Movies》 Anthem Lights 《我结婚了》 钟嘉欣 《暖暖》 梁静茹 《有点甜》 汪苏泷 BY2 《今天我要嫁给你》 蔡依林 《小酒窝》 林俊杰 蔡卓妍 《A Little Love》 冯曦妤 《I’m Yours》 Jason Mraz 主持人独白 《Canon In D》 (Piano)The O’Neill Brothers 新郎入场 《Can’t Stop Love》 Darin 新娘和父亲入场 《Perfect》 MADILYN 新郎走向新娘 《You Are The Reason》 Calum Scott 交接仪式 《Love Song For #1》 Corrinne May 新郎和新娘一起步入舞台 《婚礼》 Motive蓝吉 介绍新人 《婚礼》 Motive蓝吉 爱的宣言 《NaNa’s Theme》 吴俊斌 交换戒指&amp;拥吻 《How Long Will Love You》 Ellie Goulding 兄弟团姐妹团上台 《I Really Like You》 Carly Rae Jepsen 抛花球 《Beautiful Day》 Jamie Grace 父母上台 《Wedding Bell》 DEPAPEPE 父母致辞 《白昼之夜》 林隆璇 退场音乐 《Marry You》 Bruno Mars 暖场音乐循环播放 英文歌曲下载中文歌曲下载"},{"title":"","date":"2021-12-10T09:19:12.356Z","updated":"2021-12-10T09:19:12.356Z","comments":false,"path":"cv/20210521_update/index.html","permalink":"http://shizhonggan.github.io/cv/20210521_update/index.html","excerpt":"","text":"甘士忠 https://shizhongan.github.io 15822523657 gan_shizhong@163.com Experience北京光环新网科技股份有限公司 2019.6 -云计算研发工程师主要负责云平台的代码维护、SDN应用、自动化运维以及云上相关项目的技术研发。 维护公司云平台前后端的代码，解决客户云资源使用过程中存在的问题； 日常基于paramiko模块编写脚本，批量处理AWS云镜像文件，完成云服务器资源的调查取证；Ansible部署Zabbix监控和Elastic Stack日志分析系统； 基于celery模块和redis数据库，解决邮箱服务器并发问题； SDN网络的学习与应用；参加苏州移动研发中心移动云贵州节点建设，要负责ceph对象存储部署、云平台环境自动化检测、neutron网络测试等。泰康集团 2019.3 - 2019.4 NLP语音算法实习生基于注意力机制的LSTM的保单审核评级分类 准确率94.5% 新加坡南洋理工大学计算机学院[交流] 2017.7 - 2019.1研究助理主要任务： 海量数据处理，新加坡Open-street-map的百万条数据处理，企业的GPS海量数据处理，基于概率矩阵分解的缺失值插补； 在Linux系统与Docker容器平台下，实现基于隐马尔可夫模型的GPS数据与地图匹配； 基于LSTM深度学习网络，完成交通流量预测分析； 基于多种机器学习分类算法完成交通工具特征识别； 基于GAN网络的数据生成、分布学习。 Education天津工业大学 2016.9 -2019.4 计算机工程学院 研究助理[交流] 天津工业大学 2016.9 -2019.4 信息与通信工程 研究生 天津商业大学 2012.9 - 2016.6 数学与应用数学 本科 Publications高光谱图像地物识别甘士忠, 肖志涛, 陈雷, 南瑞杰. 基于高阶非线性模型的多目标高光谱图像解混算法. 红外与激光工程. 2019. [PDF] 陈雷, 甘士忠, 孙茜. 基于回溯优化的非线性高光谱图像解混. 红外与激光工程. 2017. [PDF] 混合语音信号提取陈雷, 甘士忠,张立毅,王光艳. 基于样条插值与人工蜂群优化的非线性盲源分离算法. 通信学报. 2017. [PDF] Honors &amp; Awards第十三届中国研究生电子设计竞赛 二等奖 2018第十二届中国研究生电子设计竞赛 二等奖 2017美国数学建模竞赛 三等奖 2015中国大学生数学建模竞赛 国家二等奖、天津市一等奖 2014 Teaching 工作中主要使用Python：基于Django的web开发；基于Paramiko模块的批量处理服务器资源；基于Celery分布式任务调度；Tensorflow, Pytorch深度学习库; OpenCV库的使用; Nampy, Pandas, Spicy等数值矩阵计算;基于Request, Selenium, beautifulsoup网络爬虫。 熟悉Linux系统命令 掌握Ansible, Elastic Stack, Zabbix, gitlab 等自动化运维相关工具的使用和集群化部署 熟悉Openstack开发与部署，后端和前端的代码维护 ServiceIEEE ACCESS 邀请审稿人 2019Research Experiences for Undergraduates in NTU 2017.7 - 2019.1 /* table th:first-of-type { width: 20%; } table th:nth-of-type(2) { width: 30%; } table th:nth-of-type(3) { width: 50%; } */ /* http://meyerweb.com/eric/tools/css/reset/ v2.0 | 20110126 License: none (public domain) */ /* html, */ article body, article main, article div, article span, article applet, article object, article iframe, article h1, article h2, article h3, article h4, article h5, article h6, article p, article blockquote, article pre, article a, article abbr, article acronym, article address, article big, article cite, article code, article del, article dfn, article em, article img, article ins, article kbd, article q, article s, article samp, article small, article strike, article strong, article sub, article sup, article tt, article var, article b, article u, article i, article center, article dl, article dt, article dd, article ol, article ul, article li, article fieldset, article form, article label, article legend, article table, article caption, article tbody, article tfoot, article thead, article tr, article th, article td, article article, article aside, article canvas, article details, article embed, article figure, article figcaption, article footer, /* article header, */ article hgroup, article menu, article nav, article output, article ruby, article section, article summary, article time, article mark, article audio, article video { margin: 0; padding: 0; border: 0; font-size: 100%; font: inherit; vertical-align: baseline; } /* HTML5 display-role reset for older browsers */ article article, article aside, article details, article figcaption, article figure, article footer, article header, article hgroup, article menu, article nav, article section { display: block; } article body { line-height: 1; } article ol, article ul { list-style: none; } article blockquote, article q { quotes: none; } article blockquote:before, article blockquote:after, article q:before, article q:after { content: \"\"; content: none; } article table { border-collapse: collapse; border-spacing: 0; } article br { margin-bottom: 0em; /* 设定 与下面间距1个字符， 1em也可以设为16px等 */ } /* end of reset */ article pre { display: block; font-family: monospace; white-space: pre; margin: 1em 0px; } article{ font: normal normal 400; font-size: 120%; line-height: 1.5em; /*also written as... font: normal normal 400 100%/1.5em;*/ font-family: \"Helvetica\", sans-serif; margin: 0.5in 0.5in 0.5in 0.5in; /* margin-top: 1em; margin-left: 1em; */ } article strong { font-weight: bold; } p strong { font-weight: bold; } article em { font-style: italic; } article h1 { font-family: \"Avenir Next\", sans-serif; text-align: center; /* font-size: 50pt; */ font-size: 300%; font-weight: lighter; position: relative; line-height: 1.2em; position: relative; /* left: 28%; */ } h1 strong { font-weight: normal !important; line-height: 1em; } /* Section headers */ article h2 { font-family: \"Avenir Next\", sans-serif; /* font-size: 20pt; */ font-size: 200%; text-align: center; font-weight: normal; display: flex; /* line-height: 1.5em; */ margin-top: 0.7em; margin-bottom: 0.5em; width: 100%; } article h2:after { border-bottom: 1.7px dashed #d3d3d3; /* height: 0.8em; */ margin-left: 10px; content: \"\"; flex: 1; } h3 strong { /* line-height: 2.5em; */ } article h3 { margin-top: 10px; } article code { font-family: \"Palatino\"; font-style: italic; float: right; } article li:before { content: \"-\"; position: relative; left: -0.5em; } article li { /*second line indent*/ padding-left: 2.25em; text-indent: -1.25em; /*color: #777;*/ } #contact-info { text-align: center; position: relative; font-weight: lighter; color: #ccc; /* font-family: Menlo,monospace,sans-serif; */ font-size: 80%; } article #contact-info a { text-decoration: none; } article a { text-decoration: none; color: rgb(20, 116, 151); } article hr { visibility: hidden; height: 0mm; }"},{"title":"","date":"2021-12-10T03:34:55.954Z","updated":"2021-12-10T03:34:55.954Z","comments":false,"path":"cv/20210521_update/en/index.html","permalink":"http://shizhonggan.github.io/cv/20210521_update/en/index.html","excerpt":"","text":"Shizhong GAN shizhongan.github.io 15822523657 gan_shizhong@163.com EducationCarnegie Mellon University 2018.9 - Ph.D. in Software Engineering Co-advised by Ken Koedinger and Josh Sunshine Columbia University 2016.9 - 2018.5 B.S. in Computer Science, Magna Cum Laude Vision, Graphics track Dickinson College 2013.9 - 2016.5 B.S. in Computer Science, Summa Cum Laude Computer Science Departmental Honors PublicationsPenrose: From Mathematical Notation to Beautiful DiagramsKatherine Ye, Wode Ni, Max Krieger, Dor Ma’ayan, Joshua Sunshine, Jonathan Aldrich, and Keenan Crane.ACM Transactions on Graphics (SIGGRAPH’20).[PDF][BibTeX][www][repo] How Domain Experts Create Conceptual Diagrams and Implications for Tool DesignDor Ma’ayan*, Wode Ni*, Katherine Ye, Chinmay Kulkarni, and Joshua Sunshine. Best Paper Honourable MentionIn Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI’20).[PDF][BibTeX] Defining Visual Narratives for Mathematics DeclarativelyMax Krieger, Wode Ni, and Joshua Sunshine.Evaluation and Usability of Programming Languages and Tools (PLATEAU 2019), co-located with UIST.[PDF][slides] Designing Declarative Language Tutorials: a Guided and Individualized ApproachAnael Kuperwajs Cohen, Wode Ni, and Joshua Sunshine.Evaluation and Usability of Programming Languages and Tools (PLATEAU 2019), co-located with UIST.[PDF][slides] Substance and Style: domain-specific languages for mathematical diagramsWode Ni*, Katherine Ye*, Joshua Sunshine, Jonathan Aldrich, and Keenan Crane. Domain-Specific Language Design and Implementation (DSLDI 2017), co-located with SPLASH.[PDF][slides][www][repo] Whiteboard Scanning Using Super-ResolutionWode Ni.Dickinson College Honors Theses. Paper 221.[PDF] ExperienceMicrosoft Research 2020.5 -Research Intern Carnegie Mellon University, Research Experiences for Undergraduate 2017.5 - 2017.8Research AssistantPenrose is a system that automatically visualizes mathematics using two domain-specific languages: Substance and Style. Co-advised by Jonathan Aldrich, Keenan Crane, Joshua Sunshine, and Katherine Ye, I designed and implemented the Style language, and extended the Substance language to support functions and logically quantified statements. Columbia University, Computer Graphics and User Interfaces Lab 2017.1 - 2017.5Research AssistantWorked with prof. Steven Feiner, on Cyber Affordance Visualization in Augumented Reality project. Developed a Microsoft Hololens application that visualizes the Columbia campus in AR environment. AsiaInfo 2015.6 - 2015.8Software Engineering InternWorked on server-side web applications and server deployment tools. MentoringMax Krieger (CMU, independent research &amp; REUSE) CMU, 2018 - NowCourtney Miller (New College of Florida, REUSE) CMU, 2019Anael Kuperwajs Cohen (Macalester College, REUSE) CMU, 2019 Honors &amp; AwardsCHI’20 Best Paper Honourable Mention Award CMU, 2020Phi Beta Kappa Dickinson, 2018Excellence in Computer Science Award Columbia, 2018Travel Award PL Mentoring Workshop (PLMW) SPLASH, 2018Tau Beta Pi, Engineering Honor Society Columbia, 2017Computer Science Departmental Honors Dickinson, 2016Pi Mu Epsilon, Mathematics Honor Society Dickinson, 2016Upsilon Pi Epsilon, Computer Science Honor Society Dickinson, 2016Alpha Lambda Delta, First year Honor Society Dickinson, 2013John Montgomery Scholarship Dickinson, 2013 TeachingTeaching Assistant, Programming Languages and Translators (COMS 4115) Columbia, 2017 - 2018Teaching Assistant, Introduction to Java II (COMP 132) Dickinson, 2016Peer Tutor, Data Structures and Problem Solving (COMP 232) Dickinson, 2016Computer Lab Consultant Dickinson, 2014 - 2016 ServiceReviewer CHI 2021Research Experiences for Undergraduates in Software Engineering Admission Committee CMU, 2019 - 2020 /* table th:first-of-type { width: 20%; } table th:nth-of-type(2) { width: 30%; } table th:nth-of-type(3) { width: 50%; } */ /* http://meyerweb.com/eric/tools/css/reset/ v2.0 | 20110126 License: none (public domain) */ /* html, */ article body, article main, article div, article span, article applet, article object, article iframe, article h1, article h2, article h3, article h4, article h5, article h6, article p, article blockquote, article pre, article a, article abbr, article acronym, article address, article big, article cite, article code, article del, article dfn, article em, article img, article ins, article kbd, article q, article s, article samp, article small, article strike, article strong, article sub, article sup, article tt, article var, article b, article u, article i, article center, article dl, article dt, article dd, article ol, article ul, article li, article fieldset, article form, article label, article legend, article table, article caption, article tbody, article tfoot, article thead, article tr, article th, article td, article article, article aside, article canvas, article details, article embed, article figure, article figcaption, article footer, /* article header, */ article hgroup, article menu, article nav, article output, article ruby, article section, article summary, article time, article mark, article audio, article video { margin: 0; padding: 0; border: 0; font-size: 100%; font: inherit; vertical-align: baseline; } /* HTML5 display-role reset for older browsers */ article article, article aside, article details, article figcaption, article figure, article footer, article header, article hgroup, article menu, article nav, article section { display: block; } article body { line-height: 1; } article ol, article ul { list-style: none; } article blockquote, article q { quotes: none; } article blockquote:before, article blockquote:after, article q:before, article q:after { content: \"\"; content: none; } article table { border-collapse: collapse; border-spacing: 0; } article br { margin-bottom: 0em; /* 设定 与下面间距1个字符， 1em也可以设为16px等 */ } /* end of reset */ article pre { display: block; font-family: monospace; white-space: pre; margin: 1em 0px; } article{ font: normal normal 400; font-size: 120%; line-height: 1.5em; /*also written as... font: normal normal 400 100%/1.5em;*/ font-family: \"Helvetica\", sans-serif; margin: 0.5in 0.5in 0.5in 0.5in; /* margin-top: 1em; margin-left: 1em; */ } article strong { font-weight: bold; } p strong { font-weight: bold; } article em { font-style: italic; } article h1 { font-family: \"Avenir Next\", sans-serif; text-align: center; /* font-size: 50pt; */ font-size: 300%; font-weight: lighter; position: relative; line-height: 1.2em; position: relative; /* left: 28%; */ } h1 strong { font-weight: normal !important; line-height: 1em; } /* Section headers */ article h2 { font-family: \"Avenir Next\", sans-serif; /* font-size: 20pt; */ font-size: 200%; text-align: center; font-weight: normal; display: flex; /* line-height: 1.5em; */ margin-top: 0.7em; margin-bottom: 0.5em; width: 100%; } article h2:after { border-bottom: 1.7px dashed #d3d3d3; /* height: 0.8em; */ margin-left: 10px; content: \"\"; flex: 1; } h3 strong { /* line-height: 2.5em; */ } article h3 { margin-top: 10px; } article code { font-family: \"Palatino\"; font-style: italic; float: right; } article li:before { content: \"-\"; position: relative; left: -0.5em; } article li { /*second line indent*/ padding-left: 2.25em; text-indent: -1.25em; /*color: #777;*/ } #contact-info { text-align: center; position: relative; font-weight: lighter; color: #ccc; /* font-family: Menlo,monospace,sans-serif; */ font-size: 80%; } article #contact-info a { text-decoration: none; } article a { text-decoration: none; color: rgb(20, 116, 151); } article hr { visibility: hidden; height: 0mm; }"}],"posts":[{"title":"Linux 常用命令","slug":"Linux/command","date":"2021-11-29T02:24:04.000Z","updated":"2021-11-29T05:47:44.269Z","comments":true,"path":"2021/11/29/Linux/command/","link":"","permalink":"http://shizhonggan.github.io/2021/11/29/Linux/command/","excerpt":"","text":"wc -l 统计行数ansible-doc -l |wc -l # 统计ansible模块个数","categories":[{"name":"Linux","slug":"Linux","permalink":"http://shizhonggan.github.io/categories/Linux/"}],"tags":[{"name":"Shell commands","slug":"Shell-commands","permalink":"http://shizhonggan.github.io/tags/Shell-commands/"}]},{"title":"Beats信息采集","slug":"ELK/Beats","date":"2021-11-01T02:03:04.000Z","updated":"2021-11-11T02:24:20.282Z","comments":true,"path":"2021/11/01/ELK/Beats/","link":"","permalink":"http://shizhonggan.github.io/2021/11/01/ELK/Beats/","excerpt":"","text":"介绍官网 FilebeatFilebeat是一个轻量级的日志采集器 当面对成百上千、甚至成千上万的服务器、虚拟机和容器生成的日志时，采用ssh十分麻烦。而Filebeat 可以提供一种轻量型方法，用于转发和汇总日志与文件，让简单的事情不再繁杂。 启动Filebeat后， 打开Logs UI, 直接在Kibana中观看对您的文件进行tail操作的过程。通过搜索栏按照服务、应用程序、主机、数据中心或者其他条件筛选，以跟踪您的全部汇总日志中的异常行为。 安装1234curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.15.1-linux-x86_64.tar.gztar xzvf filebeat-7.15.1-linux-x86_64.tar.gzmv filebeat-7.15.1-linux-x86_64 /filebeat 运行1234567891011121314cd filebeatvim gszbeat.yml # 创建配置文件#### 内容如下filebeat.inputs: # filebeat input输入- type: stdin # 标准输入 enabled: true # 启用标准输入setup.template.settings: index.number_of_shards: 3 # 指定下载数output.console: # 控制台输出 pretty: true # 启用美化功能 enable: true#####################################./filebeat -e -c gszbeat.yml # 启动chmod go-w /home/ec2-user/test/filebeat/gszbeat.yml # 若报错执行此命令 然后我们在控制台输入hello，就能看到我们会有一个json的输出，是通过读取到我们控制台的内容后输出的。 读取文件1234567891011121314151617vim gszbeat-log.yml # 创建配置文件#### 内容如下filebeat.inputs:- type: log enabled: true paths: - /home/ec2-user/test/filebeattest/*.logsetup.template.settings: index.number_of_shards: 2output.console: pretty: true enable: true#####################################./filebeat -e -c gszbeat.yml # 启动cd /home/ec2-user/test/filebeattest/ # 执行如下操作，会立刻读取更新的内容，并输出到控制台echo &quot;ganshizhong&quot; &gt;&gt; a.log 自定义字段123456789101112131415161718192021vim gszbeat-log.yml # 创建配置文件#### 内容如下filebeat.inputs:- type: log enabled: true paths: - /home/ec2-user/test/filebeattest/*.log tags:[&quot;web&quot;,&quot;test&quot;] #添加自定义tag，便于后续的处理 fields: # 添加自定义字段 from: test-web fields_under_root: true #true为添加到根节点，false为添加到子节点中setup.template.settings: index.number_of_shards: 2output.console: pretty: true enable: true#####################################./filebeat -e -c gszbeat.yml # 启动cd /home/ec2-user/test/filebeattest/ # 执行如下操作，会立刻读取更新的内容，并输出到控制台echo &quot;ganshizhong&quot; &gt;&gt; a.log 输出到Elasticsearch1234567891011121314151617181920vim gszbeat-log.yml # 创建配置文件#### 内容如下filebeat.inputs:- type: log enabled: true paths: - /home/ec2-user/test/filebeattest/*.log tags:[&quot;web&quot;,&quot;test&quot;] #添加自定义tag，便于后续的处理 fields: # 添加自定义字段 from: test-web fields_under_root: true #true为添加到根节点，false为添加到子节点中setup.template.settings: index.number_of_shards: 2output.elasticsearch: hosts: [&quot;127.0.0.1:9200&quot;]#####################################./filebeat -e -c gszbeat.yml # 启动cd /home/ec2-user/test/filebeattest/ # 执行如下操作，会立刻读取更新的内容，并输出到控制台echo &quot;ganshizhong&quot; &gt;&gt; a.log Filebeat工作原理Filebeat主要由下面几个组件组成： harvester、prospector 、input harvester 负责读取单个文件的内容 harvester逐行读取每个文件（一行一行读取），并把这些内容发送到输出 每个文件启动一个harvester，并且harvester负责打开和关闭这些文件，这就意味着harvester运行时文件描述符保持着打开的状态。 在harvester正在读取文件内容的时候，文件被删除或者重命名了，那么Filebeat就会续读这个文件，这就会造成一个问题，就是只要负责这个文件的harvester没用关闭，那么磁盘空间就不会被释放，默认情况下，Filebeat保存问价你打开直到close_inactive到达 prospector prospector负责管理harvester并找到所有要读取的文件来源 如果输入类型为日志，则查找器将查找路径匹配的所有文件，并为每个文件启动一个harvester Filebeat目前支持两种prospector类型：log和stdin Filebeat如何保持文件的状态 Filebeat保存每个文件的状态并经常将状态刷新到磁盘上的注册文件中 该状态用于记住harvester正在读取的最后偏移量，并确保发送所有日志行。 如果输出（例如ElasticSearch或Logstash）无法访问，Filebeat会跟踪最后发送的行，并在输出再次可以用时继续读取文件。 在Filebeat运行时，每个prospector内存中也会保存的文件状态信息，当重新启动Filebat时，将使用注册文件的数量来重建文件状态，Filebeat将每个harvester在从保存的最后偏移量继续读取 文件状态记录在data/registry文件中 input 一个input负责管理harvester，并找到所有要读取的源 如果input类型是log，则input查找驱动器上与已定义的glob路径匹配的所有文件，并为每个文件启动一个harvester 每个input都在自己的Go例程中运行 下面的例子配置Filebeat从所有匹配指定的glob模式的文件中读取行 12345filebeat.inputs:- type: log paths: - /var/log/*.log - /var/path2/*.log 启动命令123456./filebeat -e -c mogublog-es.yml./filebeat -e -c mogublog-es.yml -d &quot;publish&quot;## 参数说明-e: 输出到标准输出，默认输出到syslog和logs下-c：指定配置文件-d：输出debug信息 Module 日志数据处理前面要想实现日志数据的读取以及处理都是自己手动配置的，其实，在Filebeat中，有大量的Module，可以简化我们的配置，直接就可以使用，如下： 12345678910111213./filebeat modules list## 显示如下：Enabled:nginxDisabled:...kafkakibanamongodbmysqlredis... 12./filebeat modules enable nginx # 启动./filebeat modules disable nginx # 禁用 12345678910111213141516171819202122232425## 启用nginx后，进行配置cd modules.d/grep -Ev &#x27;*#|^$&#x27; nginx.yml## 输出，然后修改如下：- module: nginx access: enabled: true var.paths: [&quot;/home/ec2-user/program/gitlab/logs/nginx/*.log&quot;] error: enabled: true var.paths: [&quot;/home/ec2-user/program/gitlab/logs/nginx/*.log&quot;] ingress_controller: enabled: falsecd ..vi nginx.yml # 新建配置文件，内容如下#filebeat.inputs:setup.template.settings: index.number_of_shards: 3output.elasticsearch: hosts: [&quot;127.0.0.1:9200&quot;]filebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: false s Metricbeat用于从系统和服务搜集指标。Matricbeat能够以一种轻量型的方式，输送各种系统和服务统计数据，从CPU到内存，从Redis到Nginx，不一而足。 定期收集操作系统或应用程序的指标数据 存储到Elasticsearch中，进行实施的分析 Metricbeat组成Metricbeat有2部分组成，一部分是Module，另一个部分为Metricset Module 收集的对象：如 MySQL、Redis、Nginx、操作系统等 Metricset 收集指标的集合：如 cpu、memory，network等 安装123456789curl -L -O https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-7.15.1-linux-arm64.tar.gztar xzvf filebeat-7.15.1-linux-x86_64.tar.gzwget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -sudo apt-get install apt-transport-httpsecho &quot;deb https://artifacts.elastic.co/packages/7.x/apt stable main&quot; | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list # 貌似不用修改x,也可自动下载7.15.1，默认最新的sudo systemctl enable metricbeat# If your system does not use systemd then run:# sudo update-rc.d metricbeat defaults 95 10 配置123456789101112131415161718192021grep -Ev &quot;^*#|^$&quot; metricbeat.yml### 返回metricbeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: falsesetup.template.settings: index.number_of_shards: 1 index.codec: best_compressionsetup.kibana:output.elasticsearch: # hosts: [&quot;localhost:9200&quot;]# 修改 hosts: [&quot;119.255.249.177:9200&quot;]processors: - add_host_metadata: ~ - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~sed -i &#x27;s#hosts: \\[&quot;localhost:9200&quot;\\]#hosts: [&quot;119.255.249.177:9200&quot;]#&#x27; metricbeat.yml./metricbeat -e Nginx Module123456789101112131415161718192021222324#开启Nginx Module，#在nginx中，需要开启状态查询，才能查询到指标数据。#重新编译nginx./configure --prefix=/usr/local/nginx --with-http_stub_status_modulemakemake install./nginx -V #查询版本信息nginx version: nginx/1.11.6built by gcc 4.4.7 20120313 (Red Hat 4.4.7-23) (GCC)configure arguments: --prefix=/usr/local/nginx --with-http_stub_status_module#配置nginxvim nginx.conflocation /nginx-status &#123; stub_status on; access_log off;&#125;# 重启nginx./nginx -s reload### 测试： 119.255.x.x/nginx-status 结果说明： Active connections：正在处理的活动连接数 server accepts handled requests 第一个 server 表示Nginx启动到现在共处理了9个连接 第二个 accepts 表示Nginx启动到现在共成功创建 9 次握手 第三个 handled requests 表示总共处理了 21 次请求 请求丢失数 = 握手数 - 连接数 ，可以看出目前为止没有丢失请求 Reading: 0 Writing: 1 Waiting: 1 Reading：Nginx 读取到客户端的 Header 信息数 Writing：Nginx 返回给客户端 Header 信息数 Waiting：Nginx 已经处理完正在等候下一次请求指令的驻留链接（开启keep-alive的情况下，这个值等于 Active - (Reading+Writing)） 1234567891011121314151617181920212223242526配置nginx module#启用redis module./metricbeat modules enable nginx#修改redis module配置vim modules.d/nginx.yml#### 然后修改下面的信息# Module: nginx# Docs: https://www.elastic.co/guide/en/beats/metricbeat/6.5/metricbeat-modulenginx.html - module: nginx#metricsets:# - stubstatus period: 10s# Nginx hosts hosts: [&quot;http://127.0.0.1&quot;]# Path to server status. Default server-status server_status_path: &quot;nginx-status&quot;#username: &quot;user&quot;#password: &quot;secret&quot;修改完成后，启动nginx#启动./metricbeat -e 更多Module使用参见官方文档：https://www.elastic.co/guide/en/beats/metricbeat/current/metricbeat-modules.html https://www.cnblogs.com/cjsblog/p/9495024.html","categories":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/tags/ELK/"},{"name":"Nginx","slug":"Nginx","permalink":"http://shizhonggan.github.io/tags/Nginx/"}]},{"title":"Kibana数据可视化","slug":"ELK/Kibana","date":"2021-11-01T02:03:04.000Z","updated":"2021-11-17T07:14:37.167Z","comments":true,"path":"2021/11/01/ELK/Kibana/","link":"","permalink":"http://shizhonggan.github.io/2021/11/01/ELK/Kibana/","excerpt":"","text":"介绍Kibana 是一款开源的数据分析和可视化平台，它是 Elastic Stack 成员之一，设计用于和 Elasticsearch 协作。您可以使用 Kibana 对 Elasticsearch 索引中的数据进行搜索、查看、交互操作。您可以很方便的利用图表、表格及地图对数据进行多元化的分析和呈现。 官网：https://www.elastic.co/cn/kibana 安装1234567891011# Create a file called kibana.repo in the /etc/yum.repos.d/ directory for RedHat based distributionssudo echo &quot;[kibana-7.15.1]name=Kibana repository for 7.15.1 packagesbaseurl=https://artifacts.elastic.co/packages/7.15.1/yumgpgcheck=1gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearchenabled=1autorefresh=1type=rpm-md&quot; &gt; /etc/yum.repos.d/kibana.reposudo yum install kibana 123456docker network create elasticdocker pull docker.elastic.co/elasticsearch/elasticsearch:7.15.2docker run --name es01-test --net elastic -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; docker.elastic.co/elasticsearch/elasticsearch:7.15.2docker pull docker.elastic.co/kibana/kibana:7.15.1docker run --name kib01-test --net elastic -p 5601:5601 -e &quot;ELASTICSEARCH_HOSTS=http://119.255.249.177:9200&quot; docker.elastic.co/kibana/kibana:7.15.1 1234567891011121314# 解压tar -zxvf kibana-7.15.1-linux-x86_64.tar.gz# 重命名mv kibana-7.15.1-linux-x86_64 kibana## 然后在进入kibana目录，找到config文件夹下的kibana.yml进行配置的修改grep -Ev &quot;^#|^$&quot; kibana.yml## 输出如下server.host: &quot;0.0.0.0&quot; #对外暴露服务的地址elasticsearch.hosts: [&quot;http://192.168.0.8:9200&quot;,&quot;http://192.168.0.13:9200&quot;] #配置Elasticsearchsed -i &#x27;s#\\#server.host: &quot;localhost&quot;#server.host: &quot;0.0.0.0&quot;#&#x27; kibana.ymlsed -i &#x27;s#\\#elasticsearch.hosts: \\[&quot;http://localhost:9200&quot;\\]#elasticsearch.hosts: \\[&quot;http://192.168.0.8:9200&quot;,&quot;http://192.168.0.13:9200&quot;\\]#&#x27; kibana.yml Metricbeat 仪表盘现在将Metricbeat的数据展示在Kibana中，首先需要修改我们的MetricBeat配置 1234567#修改metricbeat配置setup.kibana: host: &quot;192.168.40.133:5601&quot; #安装仪表盘到Kibana【需要确保Kibana在正常运行，这个过程可能会有些耗时】./metricbeat setup --dashboards./metricbeat -e 然后到kibana页面下，找到刚刚安装的仪表盘**[Metricbeat System] Host overview ECS**, 得到如下界面 Nginx 指标仪表盘首先打开nginx状态；然后到kibana页面下，找到仪表盘**[Metricbeat Nginx] Overview**, Nginx 日志仪表盘我们可以和刚刚Metricbeat的仪表盘一样，也可以将filebeat收集的日志记录，推送到Kibana中 首先我们需要修改filebeat的 kibana-nginx.yml配置文件 12345678910filebeat.inputs:setup.template.settings: index.number_of_shards: 1output.elasticsearch: hosts: [&quot;119.255.249.177:9200&quot;]filebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: falsesetup.kibana: host: &quot;119.254.169.244:5601&quot; 然后按照仪表盘 1./filebeat -c kibana-nginx.yml setup 安装成功显示如下： 然后我们启动filebeat即可 1./filebeat -e -c kibana-nginx.yml 自定义图标Visualize 里设置，然后可以在Dashboard里导入。 开发者工具","categories":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/tags/ELK/"},{"name":"Nginx","slug":"Nginx","permalink":"http://shizhonggan.github.io/tags/Nginx/"}]},{"title":"Logstash","slug":"ELK/Logstash","date":"2021-11-01T02:03:04.000Z","updated":"2021-11-17T09:48:15.853Z","comments":true,"path":"2021/11/01/ELK/Logstash/","link":"","permalink":"http://shizhonggan.github.io/2021/11/01/ELK/Logstash/","excerpt":"","text":"介绍Logstash是一个开源的服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到最喜欢的存储库中（我们的存储库当然是ElasticSearch） Logstash充当数据处理的需求，当我们的数据需要处理的时候，会将它发送到Logstash进行处理，否则直接送到ElasticSearch中 安装部署12345678#检查jdk环境，要求jdk1.8+java -version#解压安装包tar -xvf logstash-7.9.1.tar.gz#第一个logstash示例bin/logstash -e &#x27;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123;&#125; &#125;&#x27; 其实原来的logstash的作用，就是为了做数据的采集，但是因为logstash的速度比较慢，所以后面使用beats来代替了Logstash，当我们使用上面的命令进行启动的时候，就可以发现了，因为logstash使用java写的，首先需要启动虚拟机，完成启动后，输入hello即可得到输出结果，如下图所示： 配置详解Logstash配置有三个部分，如下： 123456789input &#123; #输入stdin &#123; ... &#125; #标准输入&#125;filter &#123; #过滤，对数据进行分割、截取等处理...&#125;output &#123; #输出stdout &#123; ... &#125; #标准输出&#125; 输入 采集各种样式、大小和来源的数据，数据往往以各种各样的形式，或分散或集中地存在于很多系统中。 Logstash 支持各种输入选择 ，可以在同一时间从众多常用来源捕捉事件。能够以连续的流式传输方式，轻松地从您的日志、指标、Web 应用、数据存储以及各种 AWS 服务采集数据。 过滤 实时解析和转换数据 数据从源传输到存储库的过程中，Logstash 过滤器能够解析各个事件，识别已命名的字段以构建结构，并将它们转换成通用格式，以便更轻松、更快速地分析和实现商业价值。 输出 Logstash 提供众多输出选择，您可以将数据发送到您要指定的地方，并且能够灵活地解锁众多下游用例。 读取自定义日志Filebeat读取了nginx的日志，如果是自定义结构的日志，就需要读取处理后才能使用，所以，这个时候就需要使用Logstash了，因为Logstash有着强大的处理能力，可以应对各种各样的场景。 日志结构12019-03-15 21:21:21|ERROR|1 读取数据出错|参数：id=1002 可以看到，日志中的内容是使用“|”进行分割的，使用，我们在处理的时候，也需要对数据做分割处理。 编写配置文件 12345678910111213141516171819202122vim test-pipeline.conf## 然后添加如下内容input &#123; file &#123; path =&gt; &quot;/home/ec2-user/test/testlog/app.log&quot; ## 不能用相对路径 start_position =&gt; &quot;beginning&quot; &#125;&#125;filter &#123; mutate &#123; split =&gt; &#123;&quot;message&quot;=&gt;&quot;|&quot;&#125; &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125;&#125;# 启动./bin/logstash -f mogublog-pipeline.conf## 然后我们就插入我们的测试数据echo &quot;2019-03-15 21:21:21|ERROR|读取数据出错|参数：id=1002&quot; &gt;&gt; app.log 然后我们就可以看到logstash就会捕获到刚刚我们插入的数据，同时我们的数据也被分割了 结果如下： 输出到Elasticsearch修改配置文件，将我们的日志记录输出到ElasticSearch中 12345678910111213141516input &#123; file &#123; path =&gt; &quot;/soft/beats/logs/app.log&quot; start_position =&gt; &quot;beginning&quot; &#125;&#125;filter &#123; mutate &#123; split =&gt; &#123;&quot;message&quot;=&gt;&quot;|&quot;&#125; &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;119.255.249.177:9200&quot;] &#125;&#125;","categories":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/tags/ELK/"},{"name":"Logstash","slug":"Logstash","permalink":"http://shizhonggan.github.io/tags/Logstash/"}]},{"title":"Nginx日志分析系统","slug":"ELK/NgixLog","date":"2021-11-01T02:03:04.000Z","updated":"2021-11-09T09:07:35.103Z","comments":true,"path":"2021/11/01/ELK/NgixLog/","link":"","permalink":"http://shizhonggan.github.io/2021/11/01/ELK/NgixLog/","excerpt":"","text":"项目需求Nginx是一款非常优秀的web服务器，往往nginx服务会作为项目的访问入口，那么，nginx的性能保障就变得非常重要了，如果nginx的运行出现了问题就会对项目有较大的影响，所以，我们需要对nginx的运行有监控措施，实时掌握nginx的运行情况，那就需要收集nginx的运行指标和分析nginx的运行日志了。 业务流程 说明： 通过Beats采集Nginx的指标数据和日志数据 Beats采集到数据后发送到Elasticsearch中 Kibana读取数据进行分析 用户通过Kibana进行查看分析报表 Nginx部署安装123456789101112## 官网下载地址 http://nginx.org/download/## ubuntu 安装sudo apt install nginx # 80端口, 此处不要与gitlab的nginx冲突tail -f /var/log/nginx/access.logtail -f gitlab/logs/nginx/gitlab_access.log## centos 源码安装tar -xvf nginx-xxxx.tar.gzyum -y install pcre-devel zlib-devel./configuremake installcd /usr/local/nginx/sbin/./nginx centos安装Nginx参考 filebeat安装与使用参 1234567891011121314151617vim best-nginx.yml # 创建配置文件#### 内容如下filebeat.inputs:- type: log enabled: true paths: - /home/ec2-user/program/gitlab/logs/nginx/*.log tags:[&quot;nginx&quot;] fields_under_root: falsesetup.template.settings: index.number_of_shards: 3output.elasticsearch: hosts: [&quot;127.0.0.1:9200&quot;]#####################################./filebeat -e -c gszbeat.yml # 启动echo &quot;ganshizhong&quot; &gt;&gt; a.log","categories":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/tags/ELK/"},{"name":"Nginx","slug":"Nginx","permalink":"http://shizhonggan.github.io/tags/Nginx/"}]},{"title":"MYSQL游标使用方法","slug":"SQL/mysql_cursor","date":"2021-10-28T06:55:59.909Z","updated":"2021-10-28T06:55:59.909Z","comments":true,"path":"2021/10/28/SQL/mysql_cursor/","link":"","permalink":"http://shizhonggan.github.io/2021/10/28/SQL/mysql_cursor/","excerpt":"","text":"游标游标的特性 不敏感：数据库可以选择不复制结果集 只读 不滚动：游标只能向一方向前进，并且不可以跳过任何一行数据 游标的优点 游标是针对行操作的，对从数据库中 select 查询得到的结果集的 每一行可以 进行分开的独立的相同或者不相同的操作，是一种分离的思想。 游标的缺点 性能不高 只能一行一行操作 使用游标会产生死锁，造成内存开销大 游标的适用场景 存储过程 函数 触发器 事件游标使用方法游标五步法： 一、声明一个游标: DECLARE cursor_name CURSOR FOR select_statement 这个语句声明一个游标。也可以在子程序中定义多个游标，一个块中的每一个游标必须命名唯一。声明游标后也是单条操作的。 二、打开定义的游标: OPEN cursor_name 这个语句打开先前声明的游标。 三、获得下一行数据: FETCH cursor_name INTO var_name [, var_name] … 这个语句用指定的打开游标读取下一行（如果有下一行的话），并且前进游标指针至该行。 四、需要执行的语句(增删改查):这里视具体情况而定 五、释放游标: CLOSE cursor_name 这个语句关闭先前打开的游标，注意，用完后必须关闭。 123456789101112131415161718192021222324DROP PROCEDURE UpdateImgURL;/***游标***/CREATE PROCEDURE UpdateImgURL()BEGIN -- 遍历数据结束标志DECLARE Done INT DEFAULT 0;DECLARE Imgurl CHAR(255) DEFAULT &quot;&quot;;-- 游标DECLARE RS CURSOR FOR SELECT imgurl FROM weixin_linkface_userinfo ;-- 异常处理DECLARE CONTINUE HANDLER FOR SQLSTATE &#x27;02000&#x27; SET Done = 1;-- 打开游标OPEN RS;FETCH NEXT FROM RS INTO Imgurl;REPEATIF NOT Done THEN/**update 表名 set 字段名=REPLACE (字段名,&#x27;原来的值&#x27;,&#x27;要修改的值&#x27;) where 条件 **/END IF;FETCH NEXT FROM RS INTO Imgurl;UNTIL Done END REPEAT;CLOSE rs;END/**执行存储过程**/CALL UpdateImgURL 1234567891011121314151617181920BEGIN DECLARE no_more_record INT DEFAULT 0; DECLARE pID BIGINT(20); DECLARE pValue DECIMAL(15,5); DECLARE cur_record CURSOR FOR SELECT colA, colB from tableABC; /*首先这里对游标进行定义*/ DECLARE CONTINUE HANDLER FOR NOT FOUND SET no_more_record = 1; /*这个是个条件处理,针对NOT FOUND的条件,当没有记录时赋值为1*/ OPEN cur_record; /*接着使用OPEN打开游标*/ FETCH cur_record INTO pID, pValue; /*把第一行数据写入变量中,游标也随之指向了记录的第一行*/ WHILE no_more_record != 1 DO INSERT INTO testTable(ID, Value) VALUES (pID, pValue); FETCH cur_record INTO pID, pValue; END WHILE; CLOSE cur_record; /*用完后记得用CLOSE把资源释放掉*/END","categories":[{"name":"SQL","slug":"SQL","permalink":"http://shizhonggan.github.io/categories/SQL/"}],"tags":[{"name":"游标","slug":"游标","permalink":"http://shizhonggan.github.io/tags/%E6%B8%B8%E6%A0%87/"}]},{"title":"Elastic Stack(01)--Elasticsearch安装","slug":"ELK/ElasticSearch01","date":"2021-10-11T02:03:04.000Z","updated":"2021-10-28T06:55:59.900Z","comments":true,"path":"2021/10/11/ELK/ElasticSearch01/","link":"","permalink":"http://shizhonggan.github.io/2021/10/11/ELK/ElasticSearch01/","excerpt":"","text":"Elastic Stack 简介如果你没有听说过Elastic Stack，那你一定听说过ELK，实际上ELK是三款软件的简称，分别是Elasticsearch、 Logstash、Kibana组成，在发展的过程中，又有新成员Beats的加入，所以就形成了Elastic Stack。所以说，ELK是旧的称呼，Elastic Stack是新的名字。 Beats 采集一切数据 Filebeat 日志文件 Metricbeat 服务指标 Winlogbeat Win事件日志 Packetbeat 网络流量 健康检查 elasticsearch 核心存储和检索引擎。 基于java，是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。 logstash 高吞吐量数据处理引擎 基于java，是一个开源的用于收集,分析和存储日志的工具。 kibana 数据可视化 基于nodejs，也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的Web 界面，可以汇总、分析和搜索重要数据日志。 Beats是elastic公司开源的一款采集系统监控数据的代理agent，是在被监控服务器上以客户端形式运行的数据收集器的统称，可以直接把数据发送给Elasticsearch或者通过Logstash发送给Elasticsearch，然后进行后续的数据分析活动。Beats由如下组成: Packetbeat：是一个网络数据包分析器，用于监控、收集网络流量信息，Packetbeat嗅探服务器之间的流量，解析应用层协议，并关联到消息的处理，其支 持ICMP (v4 and v6)、DNS、HTTP、Mysql、PostgreSQL、Redis、MongoDB、Memcache等协议； Filebeat：用于监控、收集服务器日志文件，其已取代 logstash forwarder； Metricbeat：可定期获取外部系统的监控指标信息，其可以监控、收集 Apache、HAProxy、MongoDB MySQL、Nginx、PostgreSQL、Redis、System、Zookeeper等服务； Winlogbeat:用于监控、手机Windows系统的日志信息 Beats和Logstash其实都可以进行数据的采集，但是目前主流的是使用Beats进行数据采集，然后使用 Logstash进行数据的分割处理等，早期没有Beats的时候，使用的就是Logstash进行数据的采集。 Elasticsearch 安装centos7 云主机先打开9200端口 68端口 单机版安装1234567891011121314151617181920212223242526272829# 添加新用户useradd elsearch# 创建一个目录，存放下载的软件mkdir /itcastcd /itcastmkdir es # 将软件安装到这个目录chown elsearch:elsearch /itcast/ -R# 进入，然后通过xftp工具，将刚刚下载的文件拖动到该目录下cd /soft# 解压缩tar -zxvf elasticsearch-7.15.0-linux-x86_64.tar.gz -C esvi config/elasticsearch.yml network.host: 192.168.0.1 #0.0.0.0#在Elasticsearch中如果，network.host不是localhost或者127.0.0.1的话，就会认为是生产环境，会对环境的要求比较高，我们的测试环境不一定能够满足，一般情况下需要修改2处配置，如下：vi config/jvm.options -Xms256m # 内存128M，根据机器修改 -Xmx256mvi /etc/sysctl.conf # root用户操作 vm.max_map_count=655360sysctl -p # root用户下，使生效su - elsearch # 切换用户cd bin./elasticsearch 或 ./elasticsearch -d #后台系统 123456789101112131415# 报错一：bootstrap check failure [1] of [2]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535]## 解决方法vi /etc/security/limits.conf # root用户修改，且用户退出后重新登录生效 * soft nofile 65536 * hard nofile 131072 * soft nproc 2048 * hard nproc 65535# 报错二：bootstrap check failure [2] of [2]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configuredERROR: Elasticsearch did not exit normally - check the logs at /itcast/es/elasticsearch-7.15.0/logs/elasticsearch.log## 解决方法vi config/elasticsearch.yml # 取消注释，并保留一个节点 node.name: node-1 cluster.initial_master_nodes: [&quot;node-1] 更多错误参见： https://gitee.com/moxi159753/LearningNotes/tree/master/ElasticStack/1_ElasticSearch%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%AE%89%E8%A3%85 成功安装后访问如下地址，如图所示： ElasticSearchHead可视化工具由于ES官方没有给ES提供可视化管理工具，仅仅是提供了后台的服务，elasticsearch-head是一个为ES开发的一个页面客户端工具，其源码托管于Github，地址为 传送门 head提供了以下安装方式 源码安装，通过npm run start启动（不推荐） 通过docker安装（推荐） 通过chrome插件安装（推荐, 需翻墙） 通过ES的plugin方式安装（不推荐） Dcoker方式安装1234567891011121314151617## 在另外一台安装docker的云主机部署的，随意哪里都行#拉取镜像docker pull mobz/elasticsearch-head:5#创建容器docker create --name elasticsearch-head -p 9100:9100 mobz/elasticsearch-head:5docker network create --subnet=10.0.30.0/24 --opt com.docker.network.driver.mtu=1450 docker-gszdocker create --name elasticsearch-head --net docker-gsz --ip 10.0.30.11 -p 9100:9100 mobz/elasticsearch-head:5#启动容器docker start elasticsearch-head## 注意： 由于前后端分离开发，所以会存在跨域问题，需要在服务端做CORS的配置，如下：vim elasticsearch.ymlhttp.cors.enabled: true http.cors.allow-origin: &quot;*&quot; 成功安装并连接如下图所示： 通过Chrome插件安装打开chrome的应用商店，即可安装（该方法不需要修改配置文件） https://chrome.google.com/webstore/detail/elasticsearch-head/ffmkiejjmecolpfloofpjologoblkegm 报错问题解决1. 使用 Elasticsearch Head 查看“数据浏览”时，右侧不出数据，使用浏览器F12查看后，发现 406 Not Acceptable 错误12345678cd _site/vi vendor.js ##修改两处将 6886行 contentType: &quot;application/x-www-form-urlencoded&quot; 修改为 contentType: &quot;application/json;charset=UTF-8&quot;然后再将 7574行 var inspectData = s.contentType === &quot;application/x-www-form-urlencoded&quot; &amp;&amp; 修改为 var inspectData = s.contentType === &quot;application/json;charset=UTF-8&quot; &amp;&amp;## 具体步骤，由于容器中安装不了编辑器sed -i &#x27;s#var inspectData = s.contentType === &quot;application/x-www-form-urlencoded&quot;#var inspectData = s.contentType === &quot;application/json;charset=UTF-8&quot;#&#x27; vendor.jssed -i &#x27;s#contentType: &quot;application/x-www-form-urlencoded&quot;#contentType: &quot;application/json;charset=UTF-8&quot;#&#x27; vendor.js","categories":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/tags/ELK/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://shizhonggan.github.io/tags/Elasticsearch/"}]},{"title":"Elastic Stack(02)--Elasticsearch基本概念","slug":"ELK/ElasticSearch02","date":"2021-10-11T02:03:04.000Z","updated":"2021-10-29T09:25:15.673Z","comments":true,"path":"2021/10/11/ELK/ElasticSearch02/","link":"","permalink":"http://shizhonggan.github.io/2021/10/11/ELK/ElasticSearch02/","excerpt":"","text":"数据格式Elasticsearch 是面向文档型数据库，一条数据在这里就是一个文档。采用倒排索引。 Elasticsearch Index(索引) Type(类型，没这个概念了) Documents(文档) Fields(字段) MySQL DataBase(数据库) Table(表) Row(行) Column(列) 索引 索引（index）是Elasticsearch对逻辑数据的逻辑存储，所以它可以分为更小的部分。 可以把索引看成关系型数据库的表，索引的结构是为快速有效的全文索引准备的，特别是它不存储原始值。 Elasticsearch可以把索引存放在一台机器或者分散在多台服务器上，每个索引有一或多个分片（shard），每个分片可以有多个副本（replica）。 文档 存储在Elasticsearch中的主要实体叫文档（document）。用关系型数据库来类比的话，一个文档相当于数据库表中的一行记录。 Elasticsearch和MongoDB中的文档类似，都可以有不同的结构，但Elasticsearch的文档中，相同字段必须有相同类型。 文档由多个字段组成，每个字段可能多次出现在一个文档里，这样的字段叫多值字段（multivalued）。 每个字段的类型，可以是文本、数值、日期等。字段类型也可以是复杂类型，一个字段包含其他子文档或者数组。 映射 所有文档写进索引之前都会先进行分析，如何将输入的文本分割为词条、哪些词条又会被过滤，这种行为叫做 映射（mapping）。一般由用户自己定义规则。 文档类型 在Elasticsearch中，一个索引对象可以存储很多不同用途的对象。例如，一个博客应用程序可以保存文章和评 论。 每个文档可以有不同的结构。 不同的文档类型不能为相同的属性设置不同的类型。例如，在同一索引中的所有文档类型中，一个叫title的字段必须具有相同的类型。 RESTful API 在Elasticsearch中，提供了功能丰富的RESTful API的操作，包括基本的CRUD、创建索引、删除索引等操作。 创建非结构化索引在Lucene中，创建索引是需要定义字段名称以及字段的类型的，在Elasticsearch中提供了非结构化的索引，就是不需要创建索引结构，即可写入数据到索引中，实际上在Elasticsearch底层会进行结构化操作，此操作对用户是透明的。 索引操作 DSL搜索： Elasticsearch提供丰富且灵活的查询语言叫做DSL查询(Query DSL),它允许你构建更加复杂、强大的查询。 DSL(Domain Specific Language特定领域语言)以JSON请求体的形式出现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// 1. 创建索引,PUT有幂等性，所以不可以用POSTPUT http://127.0.0.0.1:9200/shopping// BODY raw json 请求参数可以设置如下，不设置默认 &#123;&quot;settings&quot;: &#123;&quot;index&quot;: &#123;&quot;number_of_shards&quot;: &quot;2&quot;,&quot;number_of_replicas&quot;: &quot;0&quot;&#125;&#125;&#125; // shards分片数 replicas副本数 &#123; # 返回结果 &quot;acknowledged&quot;: true, &quot;shards_acknowledged&quot;: true, &quot;index&quot;: &quot;shopping&quot; &#125;// 2. 获取索引信息GET http://127.0.0.0.1:9200/shopping DELETE http://127.0.0.0.1:9200/shopping # 删除索引GET http://127.0.0.1:9200/_cat/indices?v#_cat 表示查看的意思， indices 表示索引，所以整体含义就是查看当前 ES服务器中的所有索引，就好像 MySQL 中的 show tables// health status index uuid pri rep docs.count docs.deleted store.size pri.store.size green open .geoip_databases F2VtNo9NTMS-B18XqvCcaA 1 0 41 52 51mb 51mb green open test 0gFXqM0qQJ61S5e2iTk45A 2 0 0 0 416b 416b yellow open shopping m_9bLGjIToCSCYF1VhHSng 1 1 0 0 208b 208b// 3. 创建文档 POST POST http://127.0.0.0.1:9200/shopping/_doc # 会随机生成ID,所以不能用PUTPUT/POST http://127.0.0.0.1:9200/shopping/_doc/1001 # 设置ID, 该方式可以用PUTPUT/POST http://127.0.0.0.1:9200/shopping/_create/1001 # create功能同上 &#123;&quot;title&quot;:&quot;小米手机&quot;,&quot;category&quot;:&quot;小米&quot;,&quot;images&quot;:&quot;http://www.gulixueyuan.com/xm.jpg&quot;,&quot;price&quot;:3999.00&#125; &#123;//返回结果 &quot;_index&quot;: &quot;shopping&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;PoxKeHwBU1XQD5ffmuP9&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;_seq_no&quot;: 0, &quot;_primary_term&quot;: 1&#125;// 4. 文档查询 主键查询 全量查询GET http://127.0.0.0.1:9200/shopping/_doc/1002GET http://127.0.0.0.1:9200/shopping/_search #获取全部// 5. 修改PUT/POST http://127.0.0.0.1:9200/shopping/_doc/1001 # 全量覆盖, &#123;&quot;title&quot;:&quot;小米手机&quot;,&quot;images&quot;:&quot;http://www.gulixueyuan.com/xm.jpg&quot;,&quot;price&quot;:4999.00&#125;POST http://127.0.0.0.1:9200/shopping/_update/1001 # 局部更新 &#123;&quot;doc&quot;:&#123;&quot;title&quot;: &quot;华为手机&quot;&#125;&#125;// 6. 条件查询 分页查询 查询排序GET http://127.0.0.0.1:9200/shopping/_search?q=category:小米 # 这种方式不好，q是query GET http://127.0.0.0.1:9200/shopping/_search &#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;category&quot;:&quot;小米&quot;&#125;&#125;&#125; # 条件查询 &#123;&quot;query&quot;:&#123;&quot;match_all&quot;:&#123;&#125;&#125;&#125; # 全量查询 &#123;&quot;query&quot;:&#123;&quot;match_all&quot;:&#123;&#125;&#125;, &quot;from&quot;: 0, // 从第0开始，(页码-1)*每页数据条数 &quot;size&quot;: 2, // 每页显示2条 &quot;_source&quot;: [&quot;titile&quot;], // 指定显示的内容 &quot;sort&quot;:&#123; &quot;price&quot;:&#123; &quot;order&quot;: &quot;desc&quot; // 降序 &#125; &#125; &#125; # 全量查询 1234567891011// 7. 多条件查询 范围查询 过滤查询GET http://127.0.0.0.1:9200/shopping/_search # must 多个条件同时满足 &#123;&quot;query&quot;:&#123;&quot;bool&quot;:&#123;&quot;must&quot;:[&#123;&quot;match&quot;:&#123;&quot;category&quot;:&quot;小米&quot;&#125;&#125;, &#123;&quot;match&quot;:&#123;&quot;proce&quot;:&quot;1999.00&quot;&#125;&#125;], &quot;filter&quot;:&#123;&quot;range&quot;:&#123;&quot;price&quot;:&#123;&quot;gt&quot;:5000&#125;&#125;&#125;, &#125;&#125;&#125; #should 或 &#123;&quot;query&quot;:&#123;&quot;bool&quot;:&#123;&quot;should&quot;:[&#123;&quot;match&quot;:&#123;&quot;category&quot;:&quot;小米&quot;&#125;&#125;, &#123;&quot;match&quot;:&#123;&quot;category&quot;:&quot;华为&quot;&#125;&#125;], &#125;&#125;&#125; bool 查询可以用来合并多个条件查询结果的布尔逻辑，它包含一下操作符： must :: 多个查询条件的完全匹配,相当于 and 。 must_not :: 多个查询条件的相反匹配，相当于 not 。 should :: 至少有一个查询条件匹配, 相当于 or 。 gt : 大于 gte:: 大于等于 lt : 小于 lte: 小于等于 查询和过滤的对比 一条过滤语句会询问每个文档的字段值是否包含着特定值。 查询语句会询问每个文档的字段值与特定值的匹配程度如何。 一条查询语句会计算每个文档与查询语句的相关性，会给出一个相关性评分 _score，并且 按照相关性对匹 配到的文档进行排序。 这种评分方式非常适用于一个没有完全配置结果的全文本搜索。 一个简单的文档列表，快速匹配运算并存入内存是十分方便的， 每个文档仅需要1个字节。这些缓存的过滤结果集与后续请求的结合使用是非常高效的。 查询语句不仅要查找相匹配的文档，还需要计算每个文档的相关性，所以一般来说查询语句要比 过滤语句更耗时，并且查询结果也不可缓存。 123456// 8. 全文检索 完全匹配 高亮查询GET http://127.0.0.0.1:9200/shopping/_search &#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;category&quot;:&quot;小华&quot;&#125;&#125;&#125; # 以此查询会同时返回“小米”和“华为” &#123;&quot;query&quot;:&#123;&quot;match_phrase&quot;:&#123;&quot;category&quot;:&quot;小米&quot;&#125;&#125;, &quot;highlight&quot;:&#123;&quot;fields&quot;:&#123;&quot;category&quot;:&#123;&#125;&#125;&#125; # 对 &quot;category&quot;字段高亮显示 &#125; # 完全匹配 1234567891011121314151617181920// 9. 聚合查询GET http://127.0.0.0.1:9200/shopping/_search &#123;&quot;aggs&quot;:&#123; //聚合操作 &quot;price_group&quot;:&#123; //名称，随便起 &quot;terms&quot;:&#123; //分组 &quot;field&quot;:&quot;price&quot; //分组字段 &#125; &#125; &#125;, &quot;size&quot;:0 //原始数据不显示 &#125; &#123;&quot;aggs&quot;:&#123; //聚合操作 &quot;price_avg&quot;:&#123; //名称，随便起 &quot;avg&quot;:&#123; //平均值 &quot;field&quot;:&quot;price&quot; //分组字段 &#125; &#125; &#125;, &quot;size&quot;:0 //原始数据不显示 &#125; 有了索引库，等于有了数据库中的 database。接下来就需要建索引库(index)中的映射了，类似于数据库(database)中的表结构(table)。创建数据库表需要设置字段名称，类型，长度，约束等；索引库也一样，需要知道这个类型下有哪些字段，每个字段有哪些约束信息，这就叫做映射(mapping)。 123456789101112131415161718192021// 9. 映射关系PUT http://127.0.0.1:9200/user //先创建索引 userPUT http://127.0.0.1:9200/user/_mapping //创建映射&#123; &quot;properties&quot;:&#123; &quot;name&quot;:&#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: true &#125;, &quot;sex&quot;:&#123; &quot;type&quot;: &quot;keyword&quot;, //查询的时候必须完全匹配 &quot;index&quot;: true &#125;, &quot;tel&quot;:&#123; &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: false //不能被索引查询 &#125; &#125;&#125;PUT http://127.0.0.1:9200/user/_create/1001&#123;&quot;name&quot;:&quot;小米&quot;,&quot;sex&quot;:&quot;男的&quot;,&quot;tel&quot;:&quot;1111&quot;&#125; tring类型在ElasticSearch 旧版本中使用较多，从ElasticSearch 5.x开始不再支持string，由text和 keyword类型替代。 text 类型，当一个字段是要被全文搜索的，比如Email内容、产品描述，应该使用text类型。设置text类型 以后，字段内容会被分析，在生成倒排索引以前，字符串会被分析器分成一个一个词项。text类型的字段 不用于排序，很少用于聚合。 keyword类型适用于索引结构化的字段，比如email地址、主机名、状态码和标签。如果字段需要进行过 滤(比如查找已发布博客中status属性为published的文章)、排序、聚合。keyword类型的字段只能通过精 确值搜索到。 增加数据后，进行数据查询，可以发现对sex必须完全匹配才能查询，对于tel字段不能被查询 12// 10. 判断文档是否存在HEAD http://127.0.0.1:9200/user/1009 //返回状态码 12345678910111213141516// 11. 批量操作POST http://127.0.0.1:9200/user/_mget //_mget 批量获取数据 &#123;&quot;ids&quot;:[&quot;1001&quot;,&quot;1003&quot;]&#125;post http://127.0.0.1:9200/user/_bulk //_bulk 批零插入、修改、删除操作 &#123;action: &#123;metada&#125;&#125; //create delete &#123;request body&#125; ... &#123;&quot;create&quot;:&#123;&quot;_index&quot;:&quot;user&quot;,&quot;_id&quot;:2001&#125;&#125; &#123;&quot;name&quot;:&quot;name1&quot;,&quot;tel&quot;:&quot;1111&quot;,&quot;sex&quot;: &quot;男&quot;&#125; &#123;&quot;create&quot;:&#123;&quot;_index&quot;:&quot;user&quot;,&quot;_id&quot;:2002&#125;&#125; &#123;&quot;name&quot;:&quot;name2&quot;,&quot;tel&quot;:&quot;1111&quot;,&quot;sex&quot;: &quot;男&quot;&#125; &#123;&quot;create&quot;:&#123;&quot;_index&quot;:&quot;user&quot;,&quot;_id&quot;:2003&#125;&#125; &#123;&quot;name&quot;:&quot;name3&quot;,&quot;tel&quot;:&quot;1111&quot;,&quot;sex&quot;: &quot;男&quot;&#125; &#123;&quot;delete&quot;:&#123;&quot;_index&quot;:&quot;user&quot;,&quot;_id&quot;:2001&#125;&#125; &#123;&quot;delete&quot;:&#123;&quot;_index&quot;:&quot;user&quot;,&quot;_id&quot;:2002&#125;&#125; &#123;&quot;delete&quot;:&#123;&quot;_index&quot;:&quot;user&quot;,&quot;_id&quot;:2003&#125;&#125; _bulk批量处理报错The bulk request must be terminated by a newline，在JSON数据最后回车换行，代码中可以，主要是最后一行要换行 其他操作就类似了。一次请求多少性能最高？ 整个批量请求需要被加载到接受我们请求节点的内存里，所以请求越大，给其它请求可用的内存就越小。有一 个最佳的bulk请求大小。超过这个大小，性能不再提升而且可能降低。 最佳大小，当然并不是一个固定的数字。它完全取决于你的硬件、你文档的大小和复杂度以及索引和搜索的负 载。 幸运的是，这个最佳点(sweetspot)还是容易找到的：试着批量索引标准的文档，随着大小的增长，当性能开始 降低，说明你每个批次的大小太大了。开始的数量可以在1000~5000个文档之间，如果你的文档非常大，可以使用较小的批次。 通常着眼于你请求批次的物理大小是非常有用的。一千个1kB的文档和一千个1MB的文档大不相同。一个好的 批次最好保持在5-15MB大小间。 12345678// 12. 结构化查询&#123; &quot;query&quot;:&#123; &quot;term&quot;&#123; // 精确匹配；terms多个条件匹配 range范围查询结构gt等使用； exits文章中是否包含; match 全文本查询，结构化非结构化数据都可以查； bool，参照上面条件查询 ... &#125; &#125;&#125; 分词分词就是指将一个文本转化成一系列单词的过程，也叫文本分析，在Elasticsearch中称之为Analysis。 指定分词器进行分词 1234567891011121314151617181920212223POST /_analyze &#123;//输入参数 &quot;analyzer&quot;:&quot;standard&quot;, &quot;text&quot;:&quot;hello world&quot; &#125; &#123;//返回结果 &quot;tokens&quot;: [ &#123; &quot;token&quot;: &quot;hello&quot;, &quot;start_offset&quot;: 0, &quot;end_offset&quot;: 5, &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot;: 0 &#125;, &#123; &quot;token&quot;: &quot;world&quot;, &quot;start_offset&quot;: 6, &quot;end_offset&quot;: 11, &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot;: 1 &#125; ] &#125; 中文分词难点 中文分词的难点在于，在汉语中没有明显的词汇分界点，如在英语中，空格可以作为分隔符，如果分隔不正确就会造成歧义。如： 我/爱/炒肉丝 我/爱/炒/肉丝 常用中文分词器，IK、jieba、THULAC等，推荐使用IK分词器。 IK Analyzer是一个开源的，基于java语言开发的轻量级的中文分词工具包。从2006年12月推出1.0版开始，IKAnalyzer已经推出了3个大版本。最初，它是以开源项目Luence为应用主体的，结合词典分词和文法分析算法的中文分词组件。新版本的IK Analyzer 3.0则发展为面向Java的公用分词组件，独立于Lucene项目，同时提供了对Lucene的默认优化实现。 采用了特有的“正向迭代最细粒度切分算法“，具有80万字/秒的高速处理能力 采用了多子处理器分析模式，支持：英文字母（IP地址、Email、URL）、数字（日期，常用中文数量词，罗马数字，科学计数法），中文词汇（姓名、地名处理）等分词处理。 优化的词典存储，更小的内存占用。 IK分词器 Elasticsearch插件地址：https://github.com/medcl/elasticsearch-analysis-ik 安装分词器首先下载到最新的ik分词器：下载地址:https://github.com/medcl/elasticsearch-analysis-ik/releases/tag/v7.9.1 注意版本匹配，否则报错：[ERROR][o.e.b.ElasticsearchUncaughtExceptionHandler] [node-1] uncaught exception in thread [main]org.elasticsearch.bootstrap.StartupException: java.lang.IllegalArgumentException: Plugin [analysis-ik] was built for Elasticsearch version 7.9.1 but version 7.15.0 is running 下载完成后，使用xftp工具，拷贝到服务器上 1234567#安装方法：将下载到的 es/plugins/ik 目录下mkdir es/plugins/ik#解压unzip elasticsearch-analysis-ik-7.9.1.zip#重启ps aux |grep elasticsearch # 查询进程先kill./bin/elasticsearch -d 123456789#### 报错：[ERROR][o.e.b.ElasticsearchUncaughtExceptionHandler] [node-1] fatal error in thread [elasticsearch[node-1][system_read][T#2]], exitingjava.lang.OutOfMemoryError: Java heap spacefatal error in thread [elasticsearch[node-1][system_read][T#2]], exitingjava.lang.OutOfMemoryError: Java heap space# 解决方法vi config/jvm.options -Xms128m # 改大 256m -Xmx128m 1234567891011121314151617181920212223242526272829303132333435363738394041424344POST http://127.0.0.1:9200/_analyze &#123;//输入参数 &quot;analyzer&quot;:&quot;ik_max_word&quot;, //默认分词器 standard ,返回&#123;&quot;我&quot;,&quot;是&quot;,&quot;中&quot;,&quot;国&quot;,&quot;人&quot;&#125;，效果不好 &quot;text&quot;:&quot;我是中国人&quot; &#125; &#123;//返回结果 &quot;tokens&quot;: [ &#123; &quot;token&quot;: &quot;我&quot;, &quot;start_offset&quot;: 0, &quot;end_offset&quot;: 1, &quot;type&quot;: &quot;CN_CHAR&quot;, &quot;position&quot;: 0 &#125;, &#123; &quot;token&quot;: &quot;是&quot;, &quot;start_offset&quot;: 1, &quot;end_offset&quot;: 2, &quot;type&quot;: &quot;CN_CHAR&quot;, &quot;position&quot;: 1 &#125;, &#123; &quot;token&quot;: &quot;中国人&quot;, &quot;start_offset&quot;: 2, &quot;end_offset&quot;: 5, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 2 &#125;, &#123; &quot;token&quot;: &quot;中国&quot;, &quot;start_offset&quot;: 2, &quot;end_offset&quot;: 4, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 3 &#125;, &#123; &quot;token&quot;: &quot;国人&quot;, &quot;start_offset&quot;: 3, &quot;end_offset&quot;: 5, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 4 &#125; ]&#125; 全文搜索全文搜索两个最重要的方面是： 相关性（Relevance） 它是评价查询与其结果间的相关程度，并根据这种相关程度对结果排名的一种能力，这 种计算方式可以是 TF/IDF 方法、地理位置邻近、模糊相似，或其他的某些算法。 分词（Analysis） 它是将文本块转换为有区别的、规范化的 token 的一个过程，目的是为了创建倒排索引以及查询倒排索引。 ES 7.4 默认不在支持指定索引类型，默认索引类型是_doc 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// 创建索引PUT http://127.0.0.1:9200/itcast?include_type_name=true&#123; &quot;settings&quot;:&#123; &quot;index&quot;:&#123; &quot;number_of_shards&quot;:&quot;1&quot;, &quot;number_of_replicas&quot;:&quot;0&quot; &#125; &#125;, &quot;mappings&quot;:&#123; &quot;person&quot;:&#123; &quot;properties&quot;:&#123; &quot;name&quot;:&#123; &quot;type&quot;:&quot;text&quot; &#125;, &quot;age&quot;:&#123; &quot;type&quot;:&quot;integer&quot; &#125;, &quot;mail&quot;:&#123; &quot;type&quot;:&quot;keyword&quot; &#125;, &quot;hobby&quot;:&#123; &quot;type&quot;:&quot;text&quot;, &quot;analyzer&quot;:&quot;ik_max_word&quot; // 指定分词器 &#125; &#125; &#125; &#125;&#125;// 插入数据POST http://127.0.0.1:9200/itcast/_bulk&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;itcast&quot;,&quot;_type&quot;:&quot;person&quot;&#125;&#125;&#123;&quot;name&quot;:&quot;张三&quot;,&quot;age&quot;: 20,&quot;mail&quot;: &quot;111@qq.com&quot;,&quot;hobby&quot;:&quot;羽毛球、乒乓球、足球&quot;&#125;&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;itcast&quot;,&quot;_type&quot;:&quot;person&quot;&#125;&#125;&#123;&quot;name&quot;:&quot;李四&quot;,&quot;age&quot;: 21,&quot;mail&quot;: &quot;222@qq.com&quot;,&quot;hobby&quot;:&quot;羽毛球、乒乓球、足球、篮球&quot;&#125;&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;itcast&quot;,&quot;_type&quot;:&quot;person&quot;&#125;&#125;&#123;&quot;name&quot;:&quot;王五&quot;,&quot;age&quot;: 22,&quot;mail&quot;: &quot;333@qq.com&quot;,&quot;hobby&quot;:&quot;羽毛球、篮球、游泳、听音乐&quot;&#125;&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;itcast&quot;,&quot;_type&quot;:&quot;person&quot;&#125;&#125;&#123;&quot;name&quot;:&quot;赵六&quot;,&quot;age&quot;: 23,&quot;mail&quot;: &quot;444@qq.com&quot;,&quot;hobby&quot;:&quot;跑步、游泳、篮球&quot;&#125;&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;itcast&quot;,&quot;_type&quot;:&quot;person&quot;&#125;&#125;&#123;&quot;name&quot;:&quot;孙七&quot;,&quot;age&quot;: 24,&quot;mail&quot;: &quot;555@qq.com&quot;,&quot;hobby&quot;:&quot;听音乐、看电影、羽毛球&quot;&#125;// 单词搜索POST http://127.0.0.1:9200/itcast/person/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&quot;音乐&quot; &#125; &#125;, &quot;highlight&quot;:&#123; &quot;fields&quot;:&#123; &quot;hobby&quot;:&#123;&#125; &#125; &#125;&#125; 过程说明： 检查字段类型 爱好 hobby 字段是一个 text 类型（ 指定了IK分词器），这意味着查询字符串本身也应该被分词。 分析查询字符串 。 将查询的字符串 “音乐” 传入IK分词器中，输出的结果是单个项 音乐。因为只有一个单词项，所以 match 查询执行的是单个底层 term 查询。 查找匹配文档 。 用 term 查询在倒排索引中查找 “音乐” 然后获取一组包含该项的文档，本例的结果是文档：3 、5 。 为每个文档评分 。 用 term 查询计算每个文档相关度评分 _score ，这是种将 词频（term frequency，即词 “音乐” 在相关文档的hobby 字段中出现的频率）和 反向文档频率（inverse document frequency，即词 “音乐” 在所有文档的hobby 字段中出现的频率），以及字段的长度（即字段越短相关度越高）相结合的计算方式。 12345678910111213141516//多次搜索POST http://127.0.0.1:9200/itcast/person/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&quot;音乐 篮球&quot; &#125; &#125;, &quot;highlight&quot;:&#123; &quot;fields&quot;:&#123; &quot;hobby&quot;:&#123; &#125; &#125; &#125;&#125; 结果返回的“或”的关系，包含了“音乐”、“篮球”的数据都已经被搜索到了。如果想搜索的是既包含“音乐”又包含“篮球”的用户，在Elasticsearch中，可以指定词之间的逻辑关系，如下: 12345678910111213141516POST http://127.0.0.1:9200/itcast/person/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&quot;音乐 篮球&quot; &quot;operator&quot;:&quot;and&quot; &#125; &#125;, &quot;highlight&quot;:&#123; &quot;fields&quot;:&#123; &quot;hobby&quot;:&#123; &#125; &#125; &#125;&#125; 前面我们测试了“OR” 和 “AND”搜索，这是两个极端，其实在实际场景中，并不会选取这2个极端，更有可能是选取这种，或者说，只需要符合一定的相似度就可以查询到数据，在Elasticsearch中也支持这样的查询，通过 minimum_should_match来指定匹配度，如：70%； 123456789101112131415161718192021222324252627282930313233343536373839404142434445&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&#123; &quot;query&quot;:&quot;游泳 羽毛球&quot;, &quot;minimum_should_match&quot;:&quot;80%&quot; &#125; &#125; &#125;, &quot;highlight&quot;: &#123; &quot;fields&quot;: &#123; &quot;hobby&quot;: &#123;&#125; &#125; &#125;&#125;#结果：省略显示&quot;hits&quot;: &#123;&quot;total&quot;: 4, #相似度为80%的情况下，查询到4条数据&quot;max_score&quot;: 1.621458,&quot;hits&quot;: [&#125;#设置40%进行测试：&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&#123; &quot;query&quot;:&quot;游泳 羽毛球&quot;, &quot;minimum_should_match&quot;:&quot;40%&quot; &#125; &#125; &#125;, &quot;highlight&quot;: &#123; &quot;fields&quot;: &#123; &quot;hobby&quot;: &#123;&#125; &#125; &#125;&#125;#结果：&quot;hits&quot;: &#123;&quot;total&quot;: 5, #相似度为40%的情况下，查询到5条数据&quot;max_score&quot;: 1.621458,&quot;hits&quot;: [&#125; 相似度应该多少合适，需要在实际的需求中进行反复测试，才可得到合理的值。 1234567891011121314151617181920212223242526272829303132// 组合搜索POST http://127.0.0.1:9200/itcast/person/_search&#123; &quot;query&quot;:&#123; &quot;bool&quot;:&#123; &quot;must&quot;:&#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&quot;篮球&quot; &#125; &#125;, &quot;must_not&quot;:&#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&quot;音乐&quot; &#125; &#125;, &quot;should&quot;:[ &#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&quot;游泳&quot; &#125; &#125; ] &#125; &#125;, &quot;highlight&quot;:&#123; &quot;fields&quot;:&#123; &quot;hobby&quot;:&#123; &#125; &#125; &#125;&#125; 评分的计算规则 bool 查询会为每个文档计算相关度评分_score ， 再将所有匹配的 must 和 should 语句的分数_score 求和，最后除以 must 和 should 语句的总数。 默认情况下，should中的内容不是必须匹配的，如果查询语句中没有must，那么就会至少匹配其中一个。当然了，也可以通过minimum_should_match参数进行控制，该值可以是数字也可以的百分比。 1234567891011121314151617181920212223242526272829303132POST http://127.0.0.1:9200/itcast/person/_search&#123; &quot;query&quot;:&#123; &quot;bool&quot;:&#123; &quot;should&quot;:[ &#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&quot;游泳&quot; &#125; &#125;, &#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&quot;篮球&quot; &#125; &#125;, &#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&quot;音乐&quot; &#125; &#125; ], &quot;minimum_should_match&quot;:2 //意思是should中的三个词，至少要满足2个。 &#125; &#125;, &quot;highlight&quot;:&#123; &quot;fields&quot;:&#123; &quot;hobby&quot;:&#123; &#125; &#125; &#125;&#125; 有些时候，我们可能需要对某些词增加权重来影响该条数据的得分。如下： 搜索关键字为“游泳篮球”，如果结果中包含了“音乐”权重为10，包含了“跑步”权重为2。 1234567891011121314151617181920212223242526272829303132333435363738394041// 加权重 搜索POST http://127.0.0.1:9200/itcast/person/_search&#123; &quot;query&quot;:&#123; &quot;bool&quot;:&#123; &quot;must&quot;:&#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&#123; &quot;query&quot;:&quot;游泳篮球&quot;, &quot;operator&quot;:&quot;and&quot; &#125; &#125; &#125;, &quot;should&quot;:[ &#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&#123; &quot;query&quot;:&quot;音乐&quot;, &quot;boost&quot;:10 &#125; &#125; &#125;, &#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&#123; &quot;query&quot;:&quot;跑步&quot;, &quot;boost&quot;:2 &#125; &#125; &#125; ] &#125; &#125;, &quot;highlight&quot;:&#123; &quot;fields&quot;:&#123; &quot;hobby&quot;:&#123; &#125; &#125; &#125;&#125; ElasticSearch集群集群节点ELasticsearch的集群是由多个节点组成的，通过cluster.name设置集群名称，并且用于区分其它的集群，每个节点通过node.name指定节点的名称。 在Elasticsearch中，节点的类型主要有4种： master节点 配置文件中node.master属性为true(默认为true)，就有资格被选为master节点。master节点用于控制整个集群的操作。比如创建或删除索引，管理其它非master节点等。 data节点 配置文件中node.data属性为true(默认为true)，就有资格被设置成data节点。data节点主要用于执行数据相关的操作。比如文档的CRUD。 客户端节点 配置文件中node.master属性和node.data属性均为false。 该节点不能作为master节点，也不能作为data节点。 可以作为客户端节点，用于响应用户的请求，把请求转发到其他节点 部落节点 当一个节点配置tribe.*的时候，它是一个特殊的客户端，它可以连接多个集群，在所有连接的集群上执行 搜索和其他操作。 搭建集群123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#启动3个虚拟机，分别在3台虚拟机上部署安装Elasticsearchmkdir /itcast/es-cluster## 此处将单节点的安装文件拷贝过来，并删除数据文件cp es/elasticsearch-7.15.0/ ../es-cluster/ -Rcd /itcast/es-cluster/elasticsearch-7.15.0/datarm -rf *cd /itcast/es-cluster/elasticsearch-7.15.0/logrm -rf *#分发到其它机器scp -r es-cluster elsearch@192.168.40.134:/itcast#node01的配置：cluster.name: es-itcast-clusternode.name: node01node.master: truenode.data: truenetwork.host: 0.0.0.0http.port: 9200discovery.zen.ping.unicast.hosts: [&quot;192.168.40.133&quot;,&quot;192.168.40.134&quot;,&quot;192.168.40.135&quot;] # 发现集群的广播的地址 旧版本discovery.seed_hosts: [&quot;192.168.0.8&quot;,&quot;192.168.0.13&quot;] # 新版本，改其一即可cluster.initial_master_nodes: [&quot;node01&quot;，&quot;node02&quot;] # 新版本修改# 最小节点数discovery.zen.minimum_master_nodes: 2 # 新版本没有此选项，暂不修改添加# 跨域专用，最开始已经修改过了，此处不用修改，可以用echo 追加方式改http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;cat elasticsearch.yml |grep \\#cluster.name:cat elasticsearch.yml |grep node.name:cat elasticsearch.yml |grep network.host # 不需要改cat elasticsearch.yml |grep http.port # 不需要修改cat elasticsearch.yml |grep \\#discoverycat elasticsearch.yml |grep cluster.initial_master_nodes: sed -i &#x27;s#\\#cluster.name: my-application#cluster.name: es-itcast-cluster#&#x27; elasticsearch.ymlsed -i &#x27;s#node.name: node-1#node.name: node01#&#x27; elasticsearch.ymlsed -i &#x27;s#node.name: node01#node.name: node01\\nnode.master: true\\nnode.data: true#&#x27; elasticsearch.yml # 可以跟上面合并sed -i &#x27;s#\\#discovery.seed_hosts: \\[&quot;host1&quot;, &quot;host2&quot;\\]#discovery.seed_hosts: \\[&quot;192.168.0.8&quot;,&quot;192.168.0.13&quot;\\]#&#x27; elasticsearch.ymlsed -i &#x27;s#cluster.initial_master_nodes: \\[&quot;node-1&quot;\\]#cluster.initial_master_nodes: \\[&quot;node01&quot;，&quot;node02&quot;\\]#&#x27; elasticsearch.yml#node02的配置：grep -Ev &#x27;^#|^$&#x27; elasticsearch.yml cluster.name: es-itcast-cluster node.name: node02 node.master: false node.data: true network.host: 0.0.0.0 http.port: 9200 discovery.seed_hosts: [&quot;192.168.0.8&quot;,&quot;192.168.0.13&quot;] # 新版本，改其一即可 cluster.initial_master_nodes: [&quot;node01&quot;,&quot;node02&quot;] # 新版本修改 http.cors.enabled: true http.cors.allow-origin: &quot;*&quot;sed -i &#x27;s#\\#cluster.name: my-application#cluster.name: es-itcast-cluster#&#x27; elasticsearch.ymlsed -i &#x27;s#node.name: node-1#node.name: node02\\nnode.master: false\\nnode.data: true#&#x27; elasticsearch.ymlsed -i &#x27;s#\\#discovery.seed_hosts: \\[&quot;host1&quot;, &quot;host2&quot;\\]#discovery.seed_hosts: \\[&quot;192.168.0.8&quot;,&quot;192.168.0.13&quot;\\]#&#x27; elasticsearch.ymlsed -i &#x27;s#cluster.initial_master_nodes: \\[&quot;node-1&quot;\\]#cluster.initial_master_nodes: \\[&quot;node01&quot;,&quot;node02&quot;\\]#&#x27; elasticsearch.yml#node03的配置：,暂时没做三节点cluster.name: es-itcast-clusternode.name: node02node.master: falsenode.data: truenetwork.host: 0.0.0.0http.port: 9200discovery.zen.ping.unicast.hosts: [&quot;192.168.40.133&quot;,&quot;192.168.40.134&quot;,&quot;192.168.40.135&quot;]discovery.zen.minimum_master_nodes: 2http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;#分别启动3个节点./elasticsearch 打开elasticsearch_head前端，创建test索引，分片书为5，副本数为1，如下图所示，其中细边框是粗边框的副本： 12//查询集群状态GET http://127.0.0.1:9200/_cluster/health 集群状态的三种颜色 颜色 意义 green 所有主要分片和复制分片都可用 yellow 所有主要分片可以，但不是所有复制分片可用 red 不是所有的主要分片都可用 分片和副本为了将数据添加到Elasticsearch，我们需要索引(index)——一个存储关联数据的地方。实际上，索引只是一个用来指向一个或多个分片(shards)的“逻辑命名空间(logical namespace)”. 一个分片(shard)是一个最小级别“工作单元(worker unit)”,它只是保存了索引中所有数据的一部分。 我们需要知道是分片就是一个Lucene实例，并且它本身就是一个完整的搜索引擎。应用程序不会和它直接通 信。 分片可以是主分片(primary shard)或者是复制分片(replica shard)。 索引中的每个文档属于一个单独的主分片，所以主分片的数量决定了索引最多能存储多少数据。 复制分片只是主分片的一个副本，它可以防止硬件故障导致的数据丢失，同时可以提供读请求，比如搜索或者从别的shard取回文档。 当索引创建完成的时候，主分片的数量就固定了，但是复制分片的数量可以随时调整。 如果有个节点，分片均匀分配到三个节点，让其中一个节点宕机，集群状态先变黄，经过一段时间，宕机的节点不再显示，(如果主节点宕机，主节点将重新选举产生)，集群恢复到绿色 分布式文档存储问题： 集群保存文档时，文档该存储到哪个节点？随机还是轮询？如果读取又该如何查找？ elasticsearch采用计算的方式来确定存储到哪个节点，计算公式如下： 1shard = hash(routing) % number_of_primary_shards 式中：routing值是一个任意字符串，它默认是”_id”，也可以自定义；routing字符串通过哈希函数生一个数字；这个routing字符串通过哈希函数生成一个数字，然后除以主切片的数量后得到余数(remainder),该余数就是特定文档所在的分片，这也是创建主分片后，不能修改的原因。 分布式文档读写新建、索引和删除请求都是写（write）操作，它们必须在主分片上成功完成才能复制分片上 下面我们罗列在主分片和复制分片上成功新建、索引或删除一个文档必要的顺序步骤： 客户端给Node 1 发送新建、索引或删除请求。 节点使用文档的_id 确定文档属于分片0 。它转发请求到Node 3 ，分片0 位于这个节点上。 Node 3 在主分片上执行请求，如果成功，它转发请求到相应的位于Node 1 和Node 2 的复制节点上。当所有 的复制节点报告成功， Node 3 报告成功到请求的节点，请求的节点再报告给客户端。 客户端接收到成功响应的时候，文档的修改已经被应用于主分片和所有的复制分片。你的修改生效了。 分布式文档搜索（单个文档）文档能够从主分片或任意一个复制分片被检索。 下面我们罗列在主分片或复制分片上检索一个文档必要的顺序步骤： 客户端给Node 1 发送get请求。 节点使用文档的_id 确定文档属于分片0 。分片0 对应的复制分片在三个节点上都有。此时，它转发请求到 Node 2 。 Node 2 返回文档(document)给Node 1 然后返回给客户端。对于读请求，为了平衡负载，请求节点会为每个请求选择不同的分片——它会循环所有分片副本。可能的情况是，一个被索引的文档已经存在于主分片上却还没来得及同步到复制分片上。这时复制分片会报告文档未找到，主分片会成功返回文档。一旦索引请求成功返回给用户，文档则在主分片和复制分片都是可用的。 分布式文档全文搜索搜索，分为2个阶段， 搜索（query） 取回（fetch） 搜索（query）查询阶段包含以下三步： 客户端发送一个search（搜索） 请求给Node 3 , Node 3 创建了一个长度为from+size 的空优先级队 Node 3 转发这个搜索请求到索引中每个分片的原本或副本。每个分片在本地执行这个查询并且结果将结果到 一个大小为from+size 的有序本地优先队列里去。 每个分片返回document的ID和它优先队列里的所有document的排序值给协调节点Node 3 。Node 3 把这些 值合并到自己的优先队列里产生全局排序结果。 取回（fetch）分发阶段由以下步骤构成： 协调节点辨别出哪个document需要取回，并且向相关分片发出GET 请求。 每个分片加载document并且根据需要丰富（enrich）它们，然后再将document返回协调节点。 一旦所有的document都被取回，协调节点会将结果返回给客户端。","categories":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/tags/ELK/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://shizhonggan.github.io/tags/Elasticsearch/"}]},{"title":"Python 自动化运维(4)--Zabbix","slug":"DevOps/Zabbix","date":"2021-09-27T03:03:04.000Z","updated":"2021-10-28T06:55:59.898Z","comments":true,"path":"2021/09/27/DevOps/Zabbix/","link":"","permalink":"http://shizhonggan.github.io/2021/09/27/DevOps/Zabbix/","excerpt":"","text":"基础设施监控 基础设施监控 服务器温度、风扇转速 ipmitool命令 存储监控(df,fdisk,iotop) cpu (lscpu, uptime, top, htop, glances) 内存情况 (free) 网络(iftop) 应用监控 mysql redis nginx php-fpm python 安全监控 nginx+lua编要给WAF通过kibana可以图形化站式不同的攻击类型统计 用户登录数，passwd文件变化，本地所有文件改动 网络监控 端口，IDC带宽网络流量，网络流入流出速率，网络入/出流量，网络使用率，SMTP, POP3 完善理想的监控系统特点 监控系统能够自定义监控内容，自己通过脚本采集所需的数据 数据存入到数据库，日后对该数据进行分析计算 监控系统可以简易，快速的部署到服务器 数据可视化只管清晰 异常警告通知 可以定义复杂度告警逻辑，做到监控项之间的关联警告，例如程序之间的依赖检测，而不是之单独检测某个指标 警告可以确认响应，让运维组内的人知道已经有人处理警告问题 报警方式可以字定义，如短信，邮件，以及微信，钉钉等 告警内容可以字定义，能够写入一些简单的饭呢西，便于运维人员只管了解数据，否则还得去服务器查看 报警后，可以预处理一些任务，如自我修复，重启，采集数据 协同工作 监控系统有强大的API，提供给研发同学调用或其他系统调用 监控数据开发性，数据结构主流，便于分析 监控可视化可以建议的插件使用，而非复杂的JS文件 zabbix优点 支持自定义监控脚本，提供需要输出的值即可 zabbix存储的数据库表结构稍有复杂但是逻辑清晰 zabbix存在模板概念，可以方便的将一组监控进行部署 每一个item就是监控项，可以看到历史记录，且web界面友好 zabbix有强大的Trigger(触发器)定义规则，可以定义复杂的报警逻辑 zabbix提供了ack报警确认机制 zabbix支持邮件，短信，微信等告警 zabbix在触发告警后，可以远程执行系统命令 zabbix有原生的php绘图模块 zabbix5.0 安装 5.0版本要求php版本最低7.2.0，对php扩展组件版本也有要求,具体参见【官方文档】 准备机器，环境初始化 123456ifconfig eth0 |awk &#x27;NR==2&#123;print $2&#125;&#x27; # 输出IP,如果没有制表符，则第二列不好输出## 关闭防火墙systemctl disable --now firewalldgetenforce # 查看是否关闭iptables -L # 查看流量是否允许过来free -m # 内存大点，至少两个G, 4G最好 获取zabbix的下载源 12345678rpm -Uvh https://mirrors.aliyun.com/zabbix/zabbix/5.0/rhel/7/x86_64/zabbix-release-5.0-1.el7.noarch.rpm # 获得镜像源ls /etc/yum.repos.d/ # 可以查看到zabbix.repo文件## 修改zabbix.repo的镜像源为阿里的sed -i &#x27;s#http://repo.zabbix.com#https://mirrors.aliyun.com/zabbix#&#x27; /etc/yum.repos.d/zabbix.repo[zabbix-frontend]...enabled=1 # 0改为1， 官方文档给的 清空缓存，安装zabbix server和 agent 1234yum clean all yum makecacheyum install zabbix-server-mysql zabbix-agent -y 安装software collections, 便于后续安装高版本的php, yum默认安装5.4过低。SCL(Software Colletions) 可以让你在同一个操作系统上安装和使用多个版本的软件，而不会影响系统的安装包。软件包会安装在/opt/rh目录下。为了避免系统广泛冲突， /opt/rh包安装在目录中。例如，这允许你在centOS 7安装python3.5,而不会删除或干扰/etc/opt/rh/软件包的所有配置文件都存储在目录中，SCL包提供了定义使用所包含应用程序所需的环境变量的shell脚本。 1yum install centos-release-scl -y 安装前端环境 1yum install zabbix-web-mysql-scl zabbix-apache-conf-scl -y 安装zabbix所需的数据库 1yum install mariadb-server -y 配置数据库，设置开机启动 12345678910111213141516systemctl enable --now mariadb## 初始化数据库systemctl status mariadb # 先查看状态netstat -tunlp # 查看3306端口mysql_secure_installation # 初始化Enter current password for root (enter for none):OK, successfully used password, moving on...Set root password? [Y/n] yRemove anonymous users? [Y/n] yDisallow root login remotely? [Y/n] nRemove test database and access to it? [Y/n] yReload privilege tables now? [Y/n] y#################mysql -uroot -p1234 #成功登录 添加数据库用户，以及zabbix所需的数据库信息 1234create database zabbix character set utf8 collate utf8_bin; # 创建数据库create user zabbix@localhost identified by &#x27;1234&#x27;; # 创建用户grant all privileges on zabbix.* to zabbix@localhost; # 授权zabbix数据库下的所有表给zabbix这个用户flush privileges; # 刷新 使用zabbix-mysql命令导入数据库信息 123456789ls /usr/share/doc/zabbix-server-mysql*/create.sql.gz # 先查看以下 /usr/share/doc/zabbix-server-mysql-5.0.15/create.sql.gz ## mysql -u用户名 -p 数据库名zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbixmysql -uzabbix -p1234 # 登录查看show databases;use zabbix;show tables; # 可以查看很多表 修改zabbix server配置文件，修改数据库密码 12345678910vi /etc/zabbix/zabbix_server.conf### Option: DBPassword# Database password.# Comment this line if no password is used.## Mandatory: no# Default:DBPassword=1234################grep &#x27;^DBPass&#x27; /etc/zabbix/zabbix_server.conf # 查看是否修改成功 修改php配置文件 12vi /etc/opt/rh/rh-php72/php-fpm.d/zabbix.conf php_value[date.timezone] = Asia/Shanghai # 修改时区，取消注释 启动zabbix相关服务器 12systemctl restart zabbix-server zabbix-agent httpd rh-php72-php-fpmsystemctl enable zabbix-server zabbix-agent httpd rh-php72-php-fpm 登录访问web 网址: ip/zabbix 用户：Admin 密码：zabbix zabbix客户端部署zabbix5.0版本 agent2新版本采用golang语言开发，性能更高 由于是go语言开发，部署很方便，与之前的程序部署形式不一样 agent2 默认10050端口，客户端的端口。两个版本不能共存 旧版本客户端，zabbix-agent go语言新版本， zabbix-agent2 12345678910111213141516171819202122232425262728293031323334353637383940414243################# centosgetenforce # 查看防火墙是否关闭# 1. 时间同步yum install ntpdate -yntpdate -u ntp.aliyun.com# 2. 时区统一mv /etc/localtime&#123;,.bak&#125;ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime# 3. 安装zabbix agent2,rpm -Uvh https://mirrors.aliyun.com/zabbix/zabbix/5.0/rhel/7/x86_64/zabbix-release-5.0-1.el7.noarch.rpm # 获得镜像源sed -i &#x27;s#http://repo.zabbix.com#https://mirrors.aliyun.com/zabbix#&#x27; /etc/yum.repos.d/zabbix.repo #修改zabbix.repo的镜像源为阿里的yum install zabbix-agent2 -y # 安装agent2# 4. 查看配置文件和启动命令vi /etc/zabbix/zabbix_agent2.confls -l /usr/sbin/zabbix_agent2# 5. 启动客户端systemctl enable --now zabbix-agent2netstat -tnlp |grep zabbix # 查看端口# 修改配置文件hostnamectl set-hostname agent1 # 修改主机名grep -Ev &#x27;^#|^$&#x27; /etc/zabbix/zabbix_agent2.conf # 查看过滤掉注释和空行的配置文件cat /var/run/zabbix/zabbix_agent2.pid # 查看进程号ps -ef |grep zabbix # 看进程号是否一致vi /etc/zabbix/zabbix_agent2.conf PidFile=/var/run/zabbix/zabbix_agent2.pid LogFile=/var/log/zabbix/zabbix_agent2.log LogFileSize=0 Server=127.0.0.1 # 192.168.0.8 ServerActive=127.0.0.1 # 192.168.0.8 Hostname=agent1 # zbx-agent01 Include=/etc/zabbix/zabbix_agent2.d/*.conf ControlSocket=/tmp/agent.sock# 7. 重启agent2systemctl restart zabbix-agent2#################### ubuntusudo ufw status 验证 zabbix-agent2的连通性123# 1. 在服务端上通过命令主动获取数据yum install zabbix-get -y # 可以主动去客户端拿数据zabbix_get -s &#x27;192.168.0.13&#x27; -p 10050 -k &#x27;agent.ping&#x27; zabbix-server web 乱码问题12yum install wqy-microhei-fonts -y\\cp /usr/share/fonts/wqy-microhei/wqy-microhei.ttc /usr/share/fonts/dejavu/DejaVuSans.ttf 自定义监控内容例1 自定义监控服务器登录人数，限制登陆人数不超过三个 命令行方法1234567891011121314151617##################### 客户端操作# 1. 明确要执行的linux命令who | wc -l# 2. 手动创建zabbix的配置文件，用于定义key/etc/zabbix/zabbix_agent2.conf# 3. 创建配置文件，内容如下cd /etc/zabbix/zabbix_agentd.d/vi getusernum.confUserParameter=login.user,who|wc -l# 重启systemctl restart zabbix-agent2systemctl status zabbix-agent2######################## 服务端操作# 检查 zabbix_get -s &#x27;192.168.0.13&#x27; -p 10050 -k &#x27;login.user&#x27; # 可以看到返回值 web页面添加zabbix-server的自定义监控模板 创建模板 ： 名称Template Login User Number 创建应用集 创建监控项，自定义item，具体想监控的内容 创建触发器，当监控获取到值的时候，进行触发器比较、判断，决定是否报警 创建图像 将具体的主机和该模板连接，关联 邮件报警全网监控方案自动快速添加主机，思路 克隆监控模板 自动注册和自动发现 使用zabbix的api接口，利用curl语言，或者开发自己的变成脚本如python等 1curl -i -X POST -H &#x27;Content-Type:application/json&#x27; -d&#x27;&#123;&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;method&quot;:&quot;user.login&quot;,&quot;params&quot;:&#123;&quot;user&quot;:&quot;Admin&quot;,&quot;password&quot;:&quot;zabbix&quot;&#125;,&quot;auth&quot;:null,&quot;id&quot;:0&#125;&#x27; &quot;http://119.255.249.177/zabbix/api_jsonrpc.php&quot; 监控实施方案 硬件监控 应用服务监控 rsync服务监控 监控服务器的873端口是否存活 有关端口的监控，使用zabbix自带的key net.tcp.port[,873] 进行数据推拉，检测效果 监控NFC服务是否正常 通过key检测111端口 net.tcp.port[,111] showmount -e ip | wc -l 监控mysql数据库是否正常 通过端口 net.tcp.port[,3306] zabbix自带mysql监控模板，直接添加主板和mysql的主机关联即可 web 服务监控 net.tcp.port[,80] zabbix也提供了web服务器的监控模板 监控服务的具体方案12345678910111213141516# 端口检测的命令, 结合grep查看端口是否存活netstat sslsof## 例如：netstat -tunlp|grep httpdzabbix_get -s &#x27;127.0.0.1&#x27; -p 10050 -k &#x27;net.tcp.port[,80]&#x27; pkill httpd # 关闭进程，再查看# 查询进程信息ps# 通过客户端连接## 1. curl 查询web服务器## 2. mysql，用mysql语句连接验证## 3. 缓存数据库服务，数据读写验证 自动发现（被动）与自动注册（主动）主机1234567891011121314151617181920212223# 1. 准备一台机器,安装好agent2systemctl is-active zabbix-agent2 # 检查是否安装好# 2. 配置host解析ip zabbix_server_nameip zabbix_agent_name###### 自动发现模式【配置-自动发现，然后通过动作选项加入主机】【略】###### 自动注册模式# 3. 修改配置文件grep -Ev &#x27;^#|^$&#x27; /etc/zabbix/zabbix_agent2.confPidFile=/var/run/zabbix/zabbix_agentd.pidLogFile=/var/log/zabbix-agent/zabbix_agentd.logLogFileSize=0Server=119.255.249.177ServerActive=119.255.249.177Hostname=ganHostnameItem=system.hostname # 多设置的一项Include=/etc/zabbix/zabbix_agentd.conf.d/*.conf# 4. 验证连通性telnet 119.254.169.244 10050zabbix_get -s &#x27;119.254.169.244&#x27; -p 10050 -k &#x27;agent.ping&#x27;# 配置-动作-创建动作-修改条件-操作添加主机-添加主机群主-添加链接到模板 分布式监控12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364# 环境准备119.255.243.31 zabbix-proxy119.254.173.203 zabbix-agent2# 关闭防火墙iptables -Lgetenforcesystemctl stop zabbix-agent2netstat -tunlp# 自动发现与自动注册功能关闭# zabbix-server 已经安装无需变动# 准备好客户端机器，agent2机器# 配置代理服务器，并且部署数据库，用于存储agent2发来的数据，最终发给zabbix-server# ubuntu16 不支持zabbix5.0# wget https://repo.zabbix.com/zabbix/5.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_5.0-1+bionic_all.deb# sudo dpkg -i zabbix-release_5.0-1+bionic_all.deb# sudo sed -i.bak &#x27;s#http://repo.zabbix.com#https://mirrors.aliyun.com/zabbix#&#x27; /etc/apt/sources.list.d/zabbix.list # apt update# apt upgradesudo apt install zabbix-proxy-mysql zabbix-get -y # get可能安装不上，就不安装了apt-get install mariadb-server python-pymysqlservice mysql restartvi /etc/mysql/my.cnf [mysqld] collation-server = utf8_unicode_ci init-connect=&#x27;SET NAMES utf8&#x27; character-set-server = utf8mysql_secure_installation # 加强MariaDB的安全设置：create database zabbix_proxy character set utf8 collate utf8_bin;create user zabbix@localhost identified by &#x27;1234&#x27;;grant all privileges on zabbix_proxy.* to zabbix@localhost; # 授权zabbix数据库下的所有表给zabbix这个用户grant all on zabbix_proxy.* to &#x27;zabbix&#x27;@&#x27;localhost&#x27; identified by &#x27;zabbix&#x27; with grant option; # 如果报错用该命令flush privileges; # 刷新# 导入数据dpkg -L zabbix-proxy-mysql # 查看安装过程中数据库的位置 /usr/share/zabbix-proxy-mysql/schema.sql.gzzcat /usr/share/zabbix-proxy-mysql/schema.sql.gz | mysql -uzabbix -p zabbix_proxy# 修改配置文件vi /etc/zabbix/zabbix_proxy.confsed -i.ori &#x27;162a DBPassword=zabbix&#x27; /etc/zabbix/zabbix_proxy.conf # 修改162行,并做了.ori的备份文件sed -i &#x27;s#Server=127.0.0.1#Server=119.255.249.177#&#x27; /etc/zabbix/zabbix_proxy.confsed -i &#x27;s#Hostname=Zabbix proxy#Hostname=ryu#&#x27; /etc/zabbix/zabbix_proxy.conf# 检查代理服务器配置文件grep &#x27;^[a-Z]&#x27; /etc/zabbix/zabbix_proxy.conf Server=119.255.249.177 Hostname=ryu # 代理服务器名 LogFile=/var/log/zabbix-proxy/zabbix_proxy.log PidFile=/var/run/zabbix/zabbix_proxy.pid DBName=zabbix_proxy DBUser=zabbix DBPassword=zabbix FpingLocation=/usr/bin/fping Fping6Location=/usr/bin/fping6 Include=/etc/zabbix/zabbix_proxy.conf.d/*.conf# 启动service zabbix-proxy status# 在服务端添加代理服务器","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/tags/DevOps/"},{"name":"zabbix","slug":"zabbix","permalink":"http://shizhonggan.github.io/tags/zabbix/"}]},{"title":"Python 自动化运维(3)--Nagios使用","slug":"DevOps/Nagios3","date":"2021-09-18T03:03:04.000Z","updated":"2021-10-28T06:55:59.897Z","comments":true,"path":"2021/09/18/DevOps/Nagios3/","link":"","permalink":"http://shizhonggan.github.io/2021/09/18/DevOps/Nagios3/","excerpt":"","text":"添加一个监控主机 编辑 /usr/local/nagios/etc/objects/contacts.cfg 增加报警联系人信息1. 编辑 /usr/local/nagios/etc/objects/templates.cfg 增加报警策略信息 编辑 /usr/local/nagios/etc/objects/localhost.cfg 增加被监控主机信息 检测配置文件是否正确12/etc/init.d/nagios restart # 重新启动nagios -v /etc/nagios/nagios.cfg # 检查配置文件 配置文件有错的启动： Running configuration check… CONFIG ERROR! Restart aborted. Check your Nagios configuration 检测配置文件： nagios -v /etc/nagios/nagios.cfg 客户端安装nagios 在被监控的机器上安装nagios: yum install nagios 启动nrpe: systemctl start nagios 客户端进程nrpenrpe主要是用来搜集主机相关信息 在被监控的机器上安装nrpe: yum install nrpe 启动nrpe: systemctl start nrpe 修改 /usr/local/nagios/etc/cgi.cfg 配置里的use_authentication 为0 重启nagios: systemctl restart nagios 图形化工具nagios只显示当前状态，图形显示很差，可以用以下工具 nagiosQL 图形化配置管理工具 pnp4nagios 监控信息图标工具 nagiosgraph 监控信息图标工具 插件下载 https://exchange.nagios.org/ 插件使用 编辑command.cfg, 增加一个command 在hosts文件中使用这个command","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/tags/DevOps/"},{"name":"Nagios","slug":"Nagios","permalink":"http://shizhonggan.github.io/tags/Nagios/"}]},{"title":"Python 自动化运维(3)--Nagios配置","slug":"DevOps/Nagios2","date":"2021-09-18T03:03:04.000Z","updated":"2021-10-28T06:55:59.897Z","comments":true,"path":"2021/09/18/DevOps/Nagios2/","link":"","permalink":"http://shizhonggan.github.io/2021/09/18/DevOps/Nagios2/","excerpt":"","text":"Nagios配置文件 nagios.cfg 主配置文件,进程运行状态的配置文件，其他配置文件主要是基于此配置文件选择 cgi.cfg 控制cgi访问的配置文件，网络访问协议,web访问配置 resource.cfg 资源文件，在此文件中定义的变量可以再其他配置文件中引用 objects/*.cfg 监控相关的配置文件,用于定义nagios对象 commands.cfg 定义命令的配置文件，可以被其他文件应用 contacts.cfg 定义联系人和联系人组，用于接收警报消息 localhosts.cfg 定义监控本机的配置文件，不局限于local,可以是其配置文件 printer.cfg 定义打印机配置文件默认不启用 switch.cfg 监控路由器的配置文件，默认不启用 templates.cfg 模板配置文件 timeperiods.cfg 定义监控时间段的配置文件 windows.cfg 监控windows主机的一个配置文件模板，默认不启用 Nagios主配置文件对象配置文件模块： 定义主机、主机组、联系人、联系人组、服务等 cfg_file指明配置文件分开定义 Nagios将会读取并处理所有这些配置文件 对象配置文件 #cfg_dir=/usr/local/nagios/etc/servers #cfg_dir=/usr/local/nagios/etc/printers #cfg_dir=/usr/local/nagios/etc/switches #cfg_dir=/usr/local/nagios/etc/routers 对象缓存文件这些选项将决定当Nagios启动或重启时，对象定义将被缓存在什么地方。CGI将从这个对象文件中读取对象的定义，而不是在之前的对象配置文件路径中去找。这样做是为了避免修改Nagios配置文件后引起的不一致问题。 状态文件这个文件保存着目前检测到的服务和主机数据信息。这个文件当中的内容是被CGI读取并处理的，而它也是每次Nagios重新启动的时候被删除。 status_file=/var/log/nagios/stauts.dat Nagios进程运行用户和用户组 nagios_user = nagios nagios_nagios = nagios 外部命令行 check_external_commands = 1 , 这个选项允许用户指定是否Nagios应对外部的命令进行检查 command_check_interval = 15s , 外部命令检查时间间隔 command_file=/var/log/nagios/rw/nagios.cmd , 这事Nagios用力啊检查外部命令请求的文件。这个文件同样也是用户操作提交于CGI命令写入的地。 external_command_buffer_slot = 4096 , 外部命令缓冲 运行文件 downtime_file=/var/log/nagios/downtime.dat, 这是Nagios用来记录主机和服务故障停机时间数据的文件 lock_file=/var/run/nagios.pid , 设定Nagios的PID文件 temp_file=/var/log/nagios/nagios.tmp , 设定临时文件的路径 日志 log_file : 设定Nagios的主日志文件的路径(需修改，负责会出现权限问题) log_rotation_method : 写主日志记录是的循环记录方式 log_archive_path : 设定日志归档路径 use_syslog : 默认设定Nagios信息加入系统日志 log_notifications : 默认设定Nagios的通知是记录的 log_service_retries: 默认设定记录服务重启信息 log_host_retries : 默认设定记录主机重启信息 log_event_handlers : 默认启用记录事件处理程序信息 log_initial_states : 默认不记录初始化状态信息(最好开启) log_external_commands : 默认设定记录外部命令信息 log_passive_checks : 默认设定记录被动检查信息 主服务间内部检查之间延时的方式 service_inter_check_delay_method : 默认设定服务间检查间隔采用smart算法 值n表示none,不做任何延迟 值d表示dump, 表示在两个相邻的检查之间做1s的延迟 值s表示smart, 表示默认精简方式安排延迟 值x.xx表示动手定制每相邻的检查之间固定的x.xx秒延迟","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/tags/DevOps/"},{"name":"Nagios","slug":"Nagios","permalink":"http://shizhonggan.github.io/tags/Nagios/"}]},{"title":"Python 自动化运维(2)","slug":"DevOps/SaltStack","date":"2021-09-16T03:03:04.000Z","updated":"2021-10-28T06:55:59.898Z","comments":true,"path":"2021/09/16/DevOps/SaltStack/","link":"","permalink":"http://shizhonggan.github.io/2021/09/16/DevOps/SaltStack/","excerpt":"","text":"SaltStack概念 一个配置管理系统，能够维护预定义状态的远程节点 一个分布式远程执行系统，用来在远程节点上执行命令和查询数据 SaltStack特点 简单(相对于Puppet) 并行执行 基于成熟技术(ZeroMQ, AES) Python API 灵活开放 SaltStack服务架构 Master – 负责管理所有节点(可以有多个) Minion – 节点服务(客户端) ZeroMQ – 通信服务 AES – 数据加密方法 SaltStack 缺点 需要单独安装客户端 安全隐患大 ZeroMQ 简述ZeroMQ以嵌入式网络变成库的形式实现了一个并行开发框架，能够提供进程内、进程间、网络和广播方式的消息信道，并支持扇出、发布-订阅、任务分发、请求/相应等通信模式。【入门不需要深入了解】","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/tags/DevOps/"}]},{"title":"JumpServer堡垒机","slug":"DevOps/JumpServer","date":"2021-09-16T03:03:04.000Z","updated":"2021-11-24T03:20:22.290Z","comments":true,"path":"2021/09/16/DevOps/JumpServer/","link":"","permalink":"http://shizhonggan.github.io/2021/09/16/DevOps/JumpServer/","excerpt":"","text":"介绍身份认证Authentication账号管理Accout授权控制Authorization审计AuditJumpServer安全提示JumpServer高可用部署","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"}],"tags":[{"name":"JumpServer","slug":"JumpServer","permalink":"http://shizhonggan.github.io/tags/JumpServer/"}]},{"title":"Python 自动化运维(3)--Nagios安装","slug":"DevOps/Nagios","date":"2021-09-15T03:03:04.000Z","updated":"2021-10-28T06:55:59.897Z","comments":true,"path":"2021/09/15/DevOps/Nagios/","link":"","permalink":"http://shizhonggan.github.io/2021/09/15/DevOps/Nagios/","excerpt":"","text":"Nagios一款免费的开源IT基础设施监控系统，其功能强大，灵活性强，能够监控windows、linux、VMware和Unix主机状态，交换机、路由器等网络设置等。 结构上分为两个部分： 核心功能 轻量化 插件 Nagios特性 监控网络服务(HTTP,) 监控主机资源(CPU负载、CPU使用率、进程状态等) 主动通知 web页面（发现异常报警功能） 可扩展 Nagios优点 轻量级，架构简单 容易部署 文档健全 灵活、全面（插件安装方便，可随时安装卸载，即插即用） Nagios 缺点 修改配置麻烦(只能改配置文件，不能再web页面改) 太灵活、学习成本高 监控报警缺乏历史数据(可以通过插件解决 ) 严重依赖外部插件 Nagios 原理简而言之，主机给客户机发了指令，让客户机收集相关信息，客户机把信息收集后发送给主机。 通信过程： Nagios执行安装在它里面的check_nrpe插件，并告诉check_nrpe去检测哪些服务。 Nagios执行安装在它里面的check_nrpe插件，并告诉check_nrpe去检测哪些服务 NRPE运行本地的各种插件区检测本地的服务和状态(check_disk,..etc) 最后，NRPE把检测的结果传给主机端的check_nrpe,check_nrpe再把结果送到Nagios状态队列中。 Nagios依次读取队列中的信息，再把结果显示出来。 Nagios 安装12345678910111213cd /etc/yum.repos.d/mv CentOS-Base.repo CentOS-Base.repo.bakwget http://mirrors.163.com/.help/CentOS7-Base-163.repoyum makecacheyum -y update# Install the required packagesyum install gcc glibc glibc-common wget gd gd-devel perl postfix unzip zip httpd php # php安装后可访问web页面# Download and Install Nagios Corecd /tmpwget https://assets.nagios.com/downloads/nagioscore/releases/nagios-4.4.3.tar.gztar xzf nagios-4.4.3.tar.gz./configure 12345678910111213141516171819useradd nagiosgroupadd nagcmdusermod -a -G nagcmd nagiosusermod -a -G nagcmd apache # 得安装httpd才有./configure --with-nagios-group=nagios --with-command-group=nagcmdmake allmake installmake install-init# Next, run the following command to install the Nagios sample configuration filesmake install-config# To, install the initialization script which can be used to manage your Nagios service, run the following commandmake install-daemoninit# Run the following command to install and configure the external command file to make Nagios Core to work from the command line:make install-commandmode# The following command will install the Apache web server configuration filesmake install-webconf# After all the installations are complete, restart your apache service with:systemctl restart httpd 1234567891011121314151617181920212223242526# Create nagiosadmin User Accounthtpasswd -c /usr/local/nagios/etc/htpasswd.users nagiosadmin #password 1234####### Install Nagios Plugins ######yum install gcc glibc glibc-common make gettext automake autoconf wget openssl-devel net-snmp net-snmp-utils epel-release perl-Net-SNMP wget https://nagios-plugins.org/download/nagios-plugins-2.2.1.tar.gztar -zxvf nagios-plugins-2.2.1.tar.gzcd /tmp/nagios-plugins-2.2.1/# Compile and install the Nagios plugins../configure --with-nagios-user=nagios --with-nagios-group=nagiosmakemake install# 最后将 Nagios 和 Apache 设置为开机启动，并重启 Nagios 服务以使配置修改内容生效，最后打开防火墙，放行HTTP服务：systemctl enable nagiossystemctl enable httpdsystemctl restart nagiosfirewall-cmd --add-service=http --zone=public --permanentfirewall-cmd --reload# Accessing Nagios Core/usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/nagios.cfgsystemctl start nagioshttp://119.255.249.177/nagios/ 参考： https://linuxhostsupport.com/blog/how-to-install-nagios-core-on-centos-7/ https://www.itzgeek.com/how-tos/linux/centos-how-tos/monitor-centos-7-rhel-7-using-nagios-4-0-7.html","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/tags/DevOps/"},{"name":"Nagios","slug":"Nagios","permalink":"http://shizhonggan.github.io/tags/Nagios/"}]},{"title":"Python 自动化运维(1)","slug":"DevOps/Ansible","date":"2021-09-12T03:03:04.000Z","updated":"2021-11-23T07:24:52.033Z","comments":true,"path":"2021/09/12/DevOps/Ansible/","link":"","permalink":"http://shizhonggan.github.io/2021/09/12/DevOps/Ansible/","excerpt":"","text":"介绍运维自动化是一组将静态的设备结构转化为根据IT服务需求动态弹性响应的策略，目的就是实现IT运维的质量，降低成本。 优点：高效利、平台化、标准化、流程化 自动化运维工具： 部署类： jenkins 环境类： ansible 监控类： ngios 运维包括：监控、持续集成、运维等 运维自动化设计思想： 管理体系化、工作流程化、人员专业化、任务自动化（环境定义自动化、部署自动化、监控自动化） 关心的问题：自动化、易实现、跨平台、轻量级 缺点： 数据无法共享、无法主动式发现问题[不能预测]、部署成本高、标准不统一 云运维： 资源数据共享、主动发现问题、统一标准、批量推送成本低 ansibleAnsible是一个自动化管理IT资源的工具 功能： 系统环境配置 安装软件 持续集成 热回滚 优点： 无客户端 推送式 丰富module 基于YAML的Playbook 商业化支持 缺点： 效率低、易挂起，串行的， 与其他软件对比： Ansible教程准备环境 pyhon setuptools 参考:https://www.cnblogs.com/effortsing/p/10012070.html 快速安装： 12345678sudo apt install python-setuptoolssudo apt install python3-pippython3 -m pip install ansible ## 这个方式好，能产生ansible.cfgsudo apt-get install -y python-software-properties software-properties-commonsudo add-apt-repository -y ppa:ansible/ansible; sudo apt-get updatesudo apt-get install -y ansible Ansible源码安装, 主要是因为自定义了系统、软件环境 获取源码 解压源码 进入目录 运行source ./hacking/env-setup Ansible系统源安装: Centos yum install ansible Ubuntu apt-get install software-prperties-common apt-get-repository ppa:ansible/ansible apt-get update apt-get install ansible ansible是基于ssh通信的，所以不需要后台起服务 Ansible配置文件路径 export ANSIBLE_CONFIG # 首先，Ansible命令会检查环境变量，及这个环境变量将指向的配置文件 ./ansible.cfg # 其次，将会检查当前目录下的ansible.cfg配置文件 ~/.ansible.cfg # 再次，将会检查当前用户home目录下的.ansible.cfg配置文件 /etc/ansible/ansible.cfg # 最后，将会检查在用软件包管理工具安装Ansible时自动产生的配置文件 如果以上目录都没有，则自己新建，只能有一个配置文件，不然会被覆盖 AnsibleAnsible命令格式： ansible all -m ping ansible 命令主题： ansible/ansible-playbook 被操作的目标机器的正则表达式： all 指定使用的模块： -m ping （command shell 命令） 传入参数: -a 传入的参数，例：ansible all -a ‘ls’ 命令详解：|optional arguments|detail||-|-|-a | 指定传入模块的参数-C -D | 两个一起使用，检查hosts规则文件的修改-l | 限制匹配规则的主机数-list-hosts | 显示所有匹配规则的主机数-m -M | 指定所用的模块和模块路径–syntax-check | 检查语法-v | 显示详细日志 添加一台主机 编辑/etc/ansible/hosts, 如果没有可以手动添加，其他位置创建也可以 添加本地public SSH key 到目标机器的authorized_keys 添加本机的密钥到Ansible 运行ansible all -m ping 测试添加是否成功 Inventory（分组） Patterns ( ) Ad-Hoc () Playbook 是一种简单的配置管理系统与多机器部署系统的基础。与现有的其他系统有不同之处，且非常适合于复杂应用的部署。 Playbooks可用于声明配置，更强大的地方在于，playbooks中以编排有序的执行过程，甚至于做到在多组机器间，来回有序的执行带别指定的步骤，且可以同步或异步的发起任务。 Ansible APIAPI提供的功能： 调用Ansible模块 引入Ansible runner库 初始化runner对象， 传入相关参数 运行runner对象的runner函数 12345678import ansible.runnerrunner = ansible.runner.Runner( module_name = &#x27;ping&#x27;, module_args = &#x27;&#x27;, # 参数 pattern = &#x27;web*&#x27;, # 匹配的机器 forks = 10, # 进程数)datastructure = runner.run() ansible2.0版本前后，差异很大，以上示例不适用于2.0后，以下是Ansible2.0 API使用方法 定义一个结果对象 初始化ansible节点对象 初始化结果对象 创建一个任务 1# 后续学 开发动态的Inventory数据源 更好的控制playbook等功能的运行 编写ansible module 字定义Ansible Plugin","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/tags/DevOps/"},{"name":"Ansilbe","slug":"Ansilbe","permalink":"http://shizhonggan.github.io/tags/Ansilbe/"}]},{"title":"Django RESTful API 学习笔记","slug":"Python/django_RESTful","date":"2021-09-07T08:36:04.000Z","updated":"2021-10-28T06:55:59.903Z","comments":true,"path":"2021/09/07/Python/django_RESTful/","link":"","permalink":"http://shizhonggan.github.io/2021/09/07/Python/django_RESTful/","excerpt":"","text":"https://www.bilibili.com/video/BV1k5411p7Kp?p=3&amp;spm_id_from=pageDriver 1 web应用模式 前后端分离 juery – ajax vue – axios 前后端不分离，后端渲染好页面或重定向到其他页面 2 RESTful风格统一了CURD, 增删改查。REST(Representational State Transfer) 设计方法： 域名 专属域名 https://api.xxx.com https://xxx.com/api/ 版本 版本号放入域名https://xxx.com/api/1.0/foo 放入HTTP头部信息中，Accept: vnd.example-com.foo+json; version=1.0 路径 资源作为网址，只能是名词，不能有动词，往往与数据库的表明对应 https://xxx.api/1.0/books/name API的mincing应使用附属 HTTP动词 GET(SELECT) POST(CREATE) PUT(UPDATE) DELETE(DELETE) PATCH(UPDATE)局部更新 HEAD 元数据 OPTIONS 无害请求 过滤信息(Filtering) 状态码(Status Codes) 错误处理 返回结果json格式 3 RESTful案例","categories":[{"name":"Django","slug":"Django","permalink":"http://shizhonggan.github.io/categories/Django/"}],"tags":[{"name":"Django","slug":"Django","permalink":"http://shizhonggan.github.io/tags/Django/"},{"name":"RESTful API","slug":"RESTful-API","permalink":"http://shizhonggan.github.io/tags/RESTful-API/"}]},{"title":"opendaylight下发流表--想象不到的坑(1)","slug":"SDN/odl_error1","date":"2021-08-17T09:07:04.000Z","updated":"2021-10-28T06:55:59.907Z","comments":true,"path":"2021/08/17/SDN/odl_error1/","link":"","permalink":"http://shizhonggan.github.io/2021/08/17/SDN/odl_error1/","excerpt":"","text":"这两天在云平台部署了Carbon版本的opendaylight, 通过界面下发流表过程中，万万没想到遇到了这样的坑，如下图所示。 讲道理，在填入正确的node id之后（table id 在openflow1.0版本设置为0），即可展开flow list，填写相关参数，然后发送请求。然而，如图上所示，无法展开，没有展开按钮，没有网上各种资料所说的”+”图标。于是，反反复复、一步一步、仔仔细细地检查了各个操作步骤是否准确，貌似并没有什么错误。 这两天用谷歌搜索也不能解决问题，遍读官方文档也没有解决方法，苦苦盯着屏幕开始自我怀疑，是我环境没有部署好？是我操作不当？是我对网络的理解不够深刻？是我对计算机一窍不通？。。。。。。 正当放弃的时候，突然灵光一现，我把鼠标轻轻地挪到了flow list 圆圈A后方这个位置，如下图所示，鼠标放在红色的箭头位置时，上方突然跳出一个add list iterm，这不就是我苦苦寻找的东西么！ 至此，这个隐藏的按钮终于被找到了，问题也就解决了。点击展开如下，flow[0]后的删除按钮也无法显示，显然这是软件的问题。 下图是其他平台正常界面显示结果，如下所示，红色框框中的图标按钮是我这几天苦苦追寻的东西。此坑完结。。。。。 问题解决了，原因找到了，坑了我两天的问题，绝对不能这样放过，必须深究一下本质原因，查看界面html源码如下面三张图所示。先找到这个位置所需要的icon，找到icon对应的位置，发现该位置下貌似没有所需要的icon。这几天胸口郁结之气终于散了！","categories":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/categories/SDN/"}],"tags":[{"name":"OpenDaylight","slug":"OpenDaylight","permalink":"http://shizhonggan.github.io/tags/OpenDaylight/"},{"name":"那些坑","slug":"那些坑","permalink":"http://shizhonggan.github.io/tags/%E9%82%A3%E4%BA%9B%E5%9D%91/"}]},{"title":"Mininet MAC地址学习","slug":"SDN/mininet02","date":"2021-08-12T05:07:04.000Z","updated":"2021-10-28T06:55:59.907Z","comments":true,"path":"2021/08/12/SDN/mininet02/","link":"","permalink":"http://shizhonggan.github.io/2021/08/12/SDN/mininet02/","excerpt":"","text":"MAC地址学习MAC地址是识别LAN节点的标识。MAC对设备（通常是网卡）接口是全球统一的，MAC地址为48bit，用12个十六进制数表示。前6个十六进制数字由IEEE管理，用来识别生产商或者厂商，构成组织唯一识别符（OUI， Organization Unique Identifier）。后6个包括网卡序列号，或者特定硬件厂商的设定值。对于一个网卡来说，MAC地址是它的物理地址，是不可变的，而IP地址是它对应的逻辑地址，是可以更改的。在交换机中有一张记录局域网主机MAC地址与交换机接口对应关系的表，交换机根据这张表负责将数据帧传输到指定的主机上。交换机在接收到数据帧以后，首先将数据帧中的源MAC地址和对应的接口记录到MAC表中，接着检查自己的MAC表中是否有数据帧中目标MAC地址的信息，如果有，则根据MAC表中记录的对应接口将数据帧发送出去（也就是单播），如果没有，则将该数据帧从非接收口发送出去（也就是广播）。 实验12345678910111213141516171819202122232425262728293031323334353637$ sudo mn --topo linear --mac --switch ovsk --controller=none # 没有指定控制器，交换机中没有流表的存在，无法进行转发操作，主机h1和h2无法通信。mininet&gt; pingall # 此时无法ping通*** Ping: testing ping reachabilityh1 -&gt; Xh2 -&gt; X*** Results: 100% dropped (0/2 received)$ sudo ovs-ofctl dump-flows s1 # 也无流表存在NXST_FLOW reply (xid=0x4):mininet&gt; nodesavailable nodes are:h1 h2 s1 s2mininet&gt; neth1 h1-eth0:s1-eth1h2 h2-eth0:s2-eth1s1 lo: s1-eth1:h1-eth0 s1-eth2:s2-eth2s2 lo: s2-eth1:h2-eth0 s2-eth2:s1-eth2mininet&gt; dump&lt;Host h1: h1-eth0:10.0.0.1 pid=7448&gt;&lt;Host h2: h2-eth0:10.0.0.2 pid=7451&gt;&lt;OVSSwitch s1: lo:127.0.0.1,s1-eth1:None,s1-eth2:None pid=7457&gt;&lt;OVSSwitch s2: lo:127.0.0.1,s2-eth1:None,s2-eth2:None pid=7460&gt;$ sudo ovs-vsctl del-fail-mode s1 # 打开交换机s1的二层，执行该命令后s1变成普通的二层交换机$ sudo ovs-vsctl del-fail-mode s2 # 同上mininet&gt; h1 ping h2 # 执行上述步骤，即可ping通PING 10.0.0.2 (10.0.0.2) 56(84) bytes of data.64 bytes from 10.0.0.2: icmp_seq=1 ttl=64 time=0.750 ms64 bytes from 10.0.0.2: icmp_seq=2 ttl=64 time=0.038 ms64 bytes from 10.0.0.2: icmp_seq=3 ttl=64 time=0.044 ms$ sudo ovs-ofctl dump-flows s1 # 可以看到两条数据帧转发表，这表明交换机已进行过MAC地址学习NXST_FLOW reply (xid=0x4): cookie=0x0, duration=63.612s, table=0, n_packets=10, n_bytes=756, idle_age=48, priority=0 actions=NORMAL$ sudo ovs-ofctl dump-flows s2NXST_FLOW reply (xid=0x4): cookie=0x0, duration=64.392s, table=0, n_packets=10, n_bytes=756, idle_age=51, priority=0 actions=NORMAL","categories":[{"name":"Mininet","slug":"Mininet","permalink":"http://shizhonggan.github.io/categories/Mininet/"}],"tags":[{"name":"网络架构","slug":"网络架构","permalink":"http://shizhonggan.github.io/tags/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/"},{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/tags/SDN/"},{"name":"OVS","slug":"OVS","permalink":"http://shizhonggan.github.io/tags/OVS/"}]},{"title":"Ansible学习笔记","slug":"Ansible/install","date":"2021-08-12T02:24:04.000Z","updated":"2021-12-09T09:00:47.814Z","comments":true,"path":"2021/08/12/Ansible/install/","link":"","permalink":"http://shizhonggan.github.io/2021/08/12/Ansible/install/","excerpt":"","text":"参考资料 https://www.w3cschool.cn/automate_with_ansible/ https://www.bilibili.com/video/BV18t411f7CN?from=search&amp;seid=5997156070713703834&amp;spm_id_from=333.337.0.0 运维自动化发展历程及技术应用本地部署(On-Premises) -&gt; 基础设施即服务(IaaS) -&gt; 平台即服务(PaaS) -&gt; 软件即服务(SaaS) 自动化运维应用场景 文件传输 命令执行 应用部署 配置管理 任务流编排 企业实际应用场景分析 1 Dev开发环境 使用者：程序员 功能：程序员开发软件，测试BUG的环境 管理者：程序员 2 测试环境 使用者：QA测试工程师 功能：测试经过Dev环境测试通过的软件的功能 管理者：运维 说明：测试环境往往有多套,测试环境满足测试功能即可，不宜过多 1、测试人员希望测试环境有多套,公司的产品多产品线并发，即多个版本，意味着多个版本同步测试 2、通常测试环境有多少套和产品线数量保持一样 3 发布环境：代码发布机，有些公司为堡垒机（安全屏障） 使用者：运维 功能：发布代码至生产环境 管理者：运维（有经验） 发布机：往往需要有2台（主备） 4 生产环境 使用者：运维，少数情况开放权限给核心开发人员，极少数公司将权限完全 开放给开发人员并其维护 功能：对用户提供公司产品的服务 5 管理者：只能是运维 生产环境服务器数量：一般比较多，且应用非常重要。往往需要自动工具协助部署配置应用 6 灰度环境（生产环境的一部分） 使用者：运维 功能：在全量发布代码前将代码的功能面向少量精准用户发布的环境,可基于主机或用户执行灰度发布 案例：共100台生产服务器，先发布其中的10台服务器，这10台服务器就是灰度服务器 管理者：运维 灰度环境：往往该版本功能变更较大，为保险起见特意先让一部分用户优化体验该功能，待这部分用户使用没有重大问题的时候，再全量发布至所有服务器 程序发布 程序发布要求： 不能导致系统故障或造成系统完全不可用 不能影响用户体验 预发布验证： 新版本的代码先发布到服务器（跟线上环境配置完全相同，只是未接入到调度器） 灰度发布： 基于主机，用户，业务 发布路径： /webapp/tuangou /webapp/tuangou-1.1 /webapp/tuangou-1.2 发布过程：在调度器上下线一批主机(标记为maintanance状态) –&gt; 关闭服务 –&gt; 部署新版本的应用程序 --&gt; 启动服务 --&gt; 在调度器上启用这一批服务器 自动化灰度发布：脚本、发布平台 常用自动化运维工具 Ansible：python，Agentless，中小型应用环境，使用ssh协议 Saltstack：python，一般需部署agent(麻烦)，执行效率更高 Puppet：ruby, 功能强大，配置复杂，重型,适合大型环境，需要agent端配合 Fabric：python，agentless Chef：ruby，国内应用少 Cfengine func 可以ansible部署saltstack；ansible无主无从架构，开箱即用，用完即扔。 运维自动化场景： 操作系统预备自动化：PXE, Kickstart, Cobbler 配置自动化: Ansible 监控自动化: 系统与应用监控: Zabbix 日志监控: ELK 代码持续继承与代码持续发布自动化: git, Docker, Jenkins, github Ansible 特性 模块化：调用特定的模块，完成特定任务 Paramiko（python对ssh的实现），PyYAML，Jinja2（模板语言）三个关键模块 支持自定义模块 基于Python语言实现 部署简单，基于python和SSH(默认已安装)，agentless= 安全，基于OpenSSH 支持playbook编排任务 幂等性：一个任务执行1遍和执行n遍效果一样，不因重复执行带来意外情况 无需代理不依赖PKI（无需ssl） 可使用任何编程语言写模块 YAML格式，编排任务，支持丰富的数据结构 较强大的多层解决方案 Ansible主要组成部分 ANSIBLE PLAYBOOKS：任务剧本（任务集），编排定义Ansible任务集的配置文件， 由Ansible顺序依次执行，通常是JSON格式的YML文件 INVENTORY：Ansible管理主机的清单 /etc/anaible/hosts MODULES： Ansible执行命令的功能模块，多数为内置核心模块，也可自定义 PLUGINS： 模块功能的补充，如连接类型插件、循环插件、变量插件、过滤插件等，该功能不常用 API： 供第三方程序调用的应用程序编程接口 ANSIBLE： 组合INVENTORY、API、MODULES、PLUGINS的绿框，可以理解为是ansible命令工具，其为核心执行工具 Ansible命令执行来源： USER，普通用户，即SYSTEM ADMINISTRATOR CMDB（配置管理数据库） API 调用 PUBLIC/PRIVATE CLOUD API调用 (公有私有云的API接口调用) USER-&gt; Ansible Playbook -&gt; Ansibile​利用ansible实现管理的方式： Ad-Hoc 即ansible单条命令，主要用于临时命令使用场景 Ansible-playbook 主要用于长期规划好的，大型项目的场景，需要有前期的规划过程 Ansible-playbook（剧本）执行过程 将已有编排好的任务集写入Ansible-Playbook 通过ansible-playbook命令分拆任务集至逐条ansible命令，按预定规则逐条执行​Ansible主要操作对象 HOSTS主机 NETWORKING网络设备​注意事项: 执行ansible的主机一般称为主控端，中控，master或堡垒机 主控端Python版本需要2.6或以上 被控端Python版本小于2.4需要安装python-simplejson 被控端如开启SELinux需要安装libselinux-python windows不能做为主控端 ansible不是服务,不会一直启动,只是需要的时候启动安装 12345678910111213141516171819202122232425262728293031323334353637383940## rpm包安装: EPEL源yum -y install epel-releaseyum install ansible## 编译安装:yum -y install python-jinja2 PyYAML python-paramiko python-babelpython-cryptotar xf ansible-1.5.4.tar.gzcd ansible-1.5.4python setup.py buildpython setup.py installmkdir /etc/ansiblecp -r examples/* /etc/ansible## Git方式:git clone git://github.com/ansible/ansible.git --recursivecd ./ansiblesource ./hacking/env-setup## pip安装： pip是安装Python包的管理器，类似yumyum install python-pip python-develyum install gcc glibc-devel zibl-devel rpm-bulid openssl-develpip install --upgrade pippip install ansible --upgrade## 确认安装：[root@master ec2-user]# ansible --versionansible 2.9.25 config file = /etc/ansible/ansible.cfg configured module search path = [u&#x27;/root/.ansible/plugins/modules&#x27;, u&#x27;/usr/share/ansible/plugins/modules&#x27;] ansible python module location = /usr/lib/python2.7/site-packages/ansible executable location = /bin/ansible python version = 2.7.5 (default, Nov 16 2020, 22:23:17) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)][ec2-user@master ~]$ file /usr/bin/ansible/usr/bin/ansible: symbolic link to `/usr/bin/ansible-2.7&#x27;[ec2-user@master ~]$ ll /usr/bin/ansiblelrwxrwxrwx 1 root root 20 Nov 18 16:29 /usr/bin/ansible -&gt; /usr/bin/ansible-2.7 相关文件1234567891011121314rpm -ql ansible |less # 查看详细路径## 配置文件/etc/ansible/ansible.cfg # 主配置文件,配置ansible工作特性(一般无需修改)/etc/ansible/hosts # 主机清单(将被管理的主机放到此文件)/etc/ansible/roles/ # 存放角色的目录​## 程序/usr/bin/ansible # 主程序，临时命令执行工具/usr/bin/ansible-doc # 查看配置文档，模块功能查看工具/usr/bin/ansible-galaxy # 下载/上传优秀代码或Roles模块的官网平台/usr/bin/ansible-playbook # 定制自动化任务，编排剧本工具/usr/bin/ansible-pull # 远程执行命令的工具/usr/bin/ansible-vault # 文件加密工具/usr/bin/ansible-console # 基于Console界面与用户交互的执行工具 Ansible 简单应用案例使用ansible ping 模块实现测试主机互通性集群免密登录方法： shell写个循环 密码设置相同，然后-k 登录即可 12345678## 第一步：实现多主机间免密登录# 在ansible controller 生成密钥ssh-keygen -t rsa -f /root/.ssh/id_rsa -N &#x27;&#x27; # -N 免密操作ssh-copy-id IP # 同用户下操作## 第二部：修改/etc/ansible/hosts文件，添加需要操作的主机## 第三步：使用ping模块ansible all -m ping # 如果有hosts文件，首先识别该文件，其他host无效 在使用ansible连接之前，必须首先登录一下，保持know_hosts有连接记录，负责无法连接 ansible的ping不是基于ssh协议的 报错: ssh免密登录设置无法生效，具体如下： 123456789101112131415161718ssh 192.169.0.13 -v # 可查看具体报错原因##### 返回如下############## debug1: key_load_public: No such file or directorydebug1: identity file /home/ec2-user/.ssh/id_rsa-cert type -1...debug1: No valid Key exchange contextdebug1: Next authentication method: gssapi-with-micdebug1: Unspecified GSS failure. Minor code may provide more informationNo Kerberos credentials available (default cache: KEYRING:persistent:1000)debug1: Unspecified GSS failure. Minor code may provide more informationNo Kerberos credentials available (default cache: KEYRING:persistent:1000)################### 解决方法如下，修改文件权限su ec2-userchmod 700 /home/ec2-user/chmod 700 /home/ec2-user/.sshchmod 644 /home/ec2-user/.ssh/authorized_keyschmod 600 /home/ec2-user/.ssh/id_rsa 使用ansible cron 模块实现配置多主机时间同步12345678910111213141516171819202122232425262728## 第一步：选择时钟源服务器- 国内建议使用阿里时钟源 time1.aliyun.com- 国际建议使用微软时钟源 time.windows.com# ntpdate -u ntp.aliyun.com# mv /etc/localtime&#123;,.bak&#125;# ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime## 第二步：cron模块应用sudo yum install ntpdate -yansible 主机清单IP或分组名称 -m 模块 -a &quot;参数&quot;ansible 192.168.0.15 -m cron -a &#x27;name=&quot;test cron1&quot; job=&quot;sudo ntpdate ntp.aliyun.com&quot; minute=0 hour=*/1&#x27; # 每一小时更新一次 192.168.0.15 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot; &#125;, &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;test cron1&quot; ] &#125;## 远程主机查看结果crontab -lansible 192.168.0.15 -m command -a &#x27;crontab -l&#x27; 192.168.0.15 | CHANGED | rc=0 &gt;&gt; #Ansible: test cron1 0 */1 * * * sudo ntpdate ntp.aliyun.com 使用ansible copy 模块实现多主机配置文件同步1234## 第一步：准备本地域名解析文件119.255.249.177## 第二部：copy模块应用ansible 192.168.0.15 -m copy -a &quot;src=/etc/hosts dest=/etc/hosts&quot; 如果需要root权限，可以在root用户下执行操作，同时确保主机开启rootssh登录，方式如下：【此处是不成熟的解决办法，采用ansible -b参数，可以在连接后切换到root用户下】 12345678910111213141516## 开启rootssh登录最近使用这个工具，普通用户可以登录root用户不可以登录。将vi /etc/ssh/sshd_config按照下述配置解决问题修改sshd配置文件：vi /etc/ssh/sshd_configPermitRootLogin yesPubkeyAuthentication noPasswordAuthentication yesUseLogin yes## 两者命令都可以查看 是否开启cat /etc/ssh/sshd_config |grep PermitRootLogin |grep -Ev &#x27;^#&#x27;grep -Ev &#x27;^#|^$&#x27; /etc/ssh/sshd_config |grep PermitRootLoginsudo sed -i &quot;s#PermitRootLogin no#PermitRootLogin yes#&quot; /etc/ssh/sshd_configansible all -m command -a &#x27;sudo cat /etc/ssh/sshd_config |grep PermitRootLogin |grep -Ev &quot;^#&quot;&#x27;ansible all -m command -a &#x27;sudo sed -i &quot;s#PermitRootLogin no#PermitRootLogin yes#&quot; /etc/ssh/sshd_config&#x27; Ansible 配置文件Ansible 配置文件/etc/ansible/ansible.cfg （一般保持默认） 1234567891011121314151617vim /etc/ansible/ansible.cfg[defaults]#inventory = /etc/ansible/hosts # 主机列表配置文件#library = /usr/share/my_modules/ # 库文件存放目录#remote_tmp = $HOME/.ansible/tmp # 临时py命令文件存放在远程主机目录#local_tmp = $HOME/.ansible/tmp # 本机的临时命令执行目录 #forks = 5 # 默认并发数,同时可以执行5次#sudo_user = root # 默认sudo 用户#ask_sudo_pass = True # 每次执行ansible命令是否询问ssh密码#ask_pass = True # 每次执行ansible命令是否询问ssh口令#remote_port = 22 # 远程主机的端口号(默认22)## 建议优化项： host_key_checking = False # 检查对应服务器的host_key，建议取消注释log_path=/var/log/ansible.log # 日志文件,建议取消注释module_name = command # 默认模块 Ansible命令123456789101112131415Ansible系列命令 ansible ansible-doc ansible-playbook ansible-vault ansible-console ansible-galaxy ansible-pullansible-doc: 显示模块帮助 ansible-doc [options] [module...] -a 显示所有模块的文档 -l, --list 列出可用模块 -s, --snippet 显示指定模块的playbook片段(简化版,便于查找语法)示例： ansible-doc -l 列出所有模块 ansible-doc ping 查看指定模块帮助用法 ansible-doc -s ping 查看指定模块帮助用法 ansible 命令ansible通过ssh实现配置管理、应用部署、任务执行等功能，建议配置ansible端能基于密钥认证的方式联系各被管理节点 1234567891011121314151617181920212223242526ansible &lt;host-pattern&gt; [-m module_name] [-a args]ansible +被管理的主机(ALL) +模块 +参数 --version 显示版本 -m module 指定模块，默认为command -v **详细过程 –vv -vvv更详细** --list-hosts 显示主机列表，可简写 --list -k, --ask-pass 提示输入ssh连接密码,默认Key验证 -C, --check 检查，并不执行 -T, --timeout&#x3D;TIMEOUT 执行命令的超时时间,默认10s -u, --user&#x3D;REMOTE_USER 执行远程执行的用户 -b, --become 代替旧版的sudo切换 --become-user&#x3D;USERNAME 指定sudo的runas用户,默认为root -K, --ask-become-pass 提示输入sudo时的口令ansible all --list 列出所有主机ping模块: 探测网络中被管理主机是否能够正常使用 走ssh协议 如果对方主机网络正常,返回pongansible-doc -s ping 查看ping模块的语法 检测所有主机的网络状态1&gt; 默认情况下连接被管理的主机是ssh基于key验证,如果没有配置key,权限将会被拒绝 因此需要指定以谁的身份连接,输入用户密码,必须保证被管理主机用户密码一致 ansible all -m ping -k2&gt; 或者实现基于key验证 将公钥ssh-copy-id到被管理的主机上 , 实现免密登录 ansible all -m ping ansible的Host-pattern12345678910111213141516171819202122匹配主机的列表 All ：表示所有Inventory中的所有主机 ansible all –m ping * :通配符 ansible &quot;*&quot; -m ping (*表示所有主机) ansible 192.168.1.* -m ping ansible &quot;*srvs&quot; -m ping 或关系 &quot;:&quot; ansible &quot;websrvs:appsrvs&quot; -m ping ansible “192.168.1.10:192.168.1.20” -m ping 逻辑与 &quot;:&amp;&quot; ansible &quot;websrvs:&amp;dbsrvs&quot; –m ping 在websrvs组并且在dbsrvs组中的主机 逻辑非 &quot;:!&quot; ansible &#x27;websrvs:!dbsrvs&#x27; –m ping 在websrvs组，但不在dbsrvs组中的主机 注意：此处为单引号 综合逻辑 ansible &#x27;websrvs:dbsrvs:&amp;appsrvs:!ftpsrvs&#x27; –m ping 正则表达式 ansible &quot;websrvs:&amp;dbsrvs&quot; –m ping ansible &quot;~(web|db).*\\.magedu\\.com&quot; –m ping ansible命令执行过程 加载自己的配置文件 默认/etc/ansible/ansible.cfg 加载自己对应的模块文件，如command 通过ansible将模块或命令生成对应的临时py文件，并将该文件传输至远程服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件 给文件+x执行 执行并返回结果 删除临时py文件，sleep 0退出 执行状态： 绿色：执行成功并且不需要做改变的操作 黄色：执行成功并且对目标主机做变更 红色：执行失败 Ansible常用模块详解模块文档：https://docs.ansible.com/ansible/latest/modules/modules_by_category.html command在远程主机执行命令，默认模块，可忽略-m选项 123456789101112ansible all -m command -a &#x27;service vsftpd start&#x27;ansible all -m command -a &#x27;echo adong |passwd --stdin 123456&#x27;ansible all -a &quot;removes=/home/aa/tt cat /home/aa/tt&quot; -b # remove表示如果不存在该文件，则不执行，反之执行ansible all -a &quot;creates=/home/aa/tt df -h&quot; -b # creates表示如果存在该文件，则不执行，反之执行ansible all -a &quot;chdir=/home/aa/ cat tt&quot; # chdir 表示切换到该目录下之后执行命令ansible all -a &quot;/data/f1.sh&quot; -b # 此处.sh脚本开头必须有“#!/bin/bash”，得规范## 创建一个账号ansible all -a &quot;useradd test1&quot; -b ansible all -a &quot;getent passwd test1&quot; # 查看用户是否存在ansible all -m shell -a &quot;echo magedu|passwd --stdin test1&quot; # 添加口令才能登陆，不能成功ansible all -m shell -a &quot;echo $HOSTNAME&quot; ## 此命令不支持 $VARNAME &lt; &gt; | ; &amp; * 等特殊符号,用shell模块实现 注意：ubuntu和centos的命令不尽一样，所以以下命令能在centos上运行成功，再ubuntu上不一定能成功 Shell和command相似，用shell执行命令,上述无法执行的命令可以通过该模块执行。因此，使用shell模块即可。同时，针对不同的应用场景，尽量采用相应的模块进行处理，例如，“rm -rf /file” 删除文件命令可以采用 file 模块进行处理。 1234567891011ansible all -m shell -a &#x27;getenforce&#x27; 查看SELINUX状态ansible all -m shell -a &quot;sed -i &#x27;s/SELINUX=.*/SELINUX=disabled&#x27; /etc/selinux/config&quot;ansible all -m shell -a &#x27;echo magedu|passwd --stdin test1&#x27; 调用bash执行命令 类似 cat /tmp/stanley.md | awk -F&#x27;|&#x27; &#x27;&#123;print $1,$2&#125;&#x27; &amp;&gt; /tmp/example.txt 这些复杂命令，即使使用shell也可能会失败， 解决办法：写到脚本时，copy到远程执行，再把需要的结果拉回执行命令的机器 修改配置文件,使shell作为默认模块 vim /etc/ansible/ansible.cfg module_name = shell Script在远程主机上运行ansible服务器上的脚本 1ansible all -m script -a /data/test.sh Copy从主控端复制文件到远程主机 src : 源文件 指定拷贝文件的本地路径 (如果有/ 则拷贝目录内容,比拷贝目录本身) dest: 指定目标路径 mode: 设置权限 backup: 备份源文件 content: 代替src 指定本机文件内容,生成目标主机文件 12ansible all -m copy -a &quot;src=/root/test1.sh dest=/tmp/test2.sh owner=root mode=600 backup=yes&quot; # 如果目标存在，默认覆盖，此处指定先备份ansible all -m copy -a &quot;content=&#x27;test content\\nxxx&#x27; dest=/tmp/test.txt&quot; # 指定内容，直接生成目标文件 Fetch从远程主机提取文件至主控端，copy相反，目前不支持目录,可以先打包,再提取文件 File：设置文件属性 path: 要管理的文件路径 (强制添加) recurse: 递归,文件夹要用递归 src: 创建硬链接,软链接时,指定源目标,配合’state=link’ ‘state=hard’ 设置软链接,硬链接 state: 状态 absent 缺席,删除 12345678910ansible all -m fetch -a &#x27;src=/root/test.sh dest=/data/scripts&#x27; # 会生成每个被管理主机不同编号的目录,不会发生文件名冲突 ## 对于抓多个文件，可以先压缩，再抓取ansible all -m shell -a &#x27;tar jxvf test.tar.gz /root/test.sh&#x27;ansible all -m fetch -a &#x27;src=/root/test.tar.gz dest=/data/&#x27;ansible all -m file -a &#x27;path=/app/test.txt state=touch&#x27; 创建文件ansible all -m file -a &quot;path=/data/testdir state=directory&quot; 创建目录ansible all -m file -a &quot;path=/data/testdir state=absent&quot; 删除ansible all -m file -a &quot;path=/root/test.sh owner=wang mode=755&quot; 设置权限755ansible all -m file -a &#x27;src=/data/testfile dest=/data/testfile-link state=link&#x27; 创建软链接 unarchive：解包解压缩，有两种用法：1、将ansible主机上的压缩包传到远程主机后解压缩至特定目录，设置copy=yes.2、将远程主机上的某个压缩包解压缩到指定路径下，设置copy=no 常见参数： copy：默认为yes，当copy=yes，拷贝的文件是从ansible主机复制到远程主机上，如果设置为copy=no，会在远程主机上寻找src源文件 src： 源路径，可以是ansible主机上的路径，也可以是远程主机上的路径，如果是远程主机上的路径，则需要设置copy=no dest：远程主机上的目标路径 mode：设置解压缩后的文件权限 123ansible all -m unarchive -a &#x27;src=foo.tgz dest=/var/lib/foo&#x27; #默认copy为yes ,将本机目录文件解压到目标主机对应目录下ansible all -m unarchive -a &#x27;src=/tmp/foo.zip dest=/data copy=no mode=0777&#x27; # 解压被管理主机的foo.zip到data目录下, 并设置权限777ansible all -m unarchive -a &#x27;src=https://example.com/example.zip dest=/data copy=no&#x27; Archive：打包压缩 path: 指定路径 dest: 指定目标文件 format: 指定打包格式 owner: 指定所属者 mode: 设置权限 1ansible all -m archive -a &#39;path&#x3D;&#x2F;etc&#x2F;sysconfig dest&#x3D;&#x2F;data&#x2F;sysconfig.tar.bz2 format&#x3D;bz2 owner&#x3D;wang mode&#x3D;0777&#39; #将远程主机目录打包 Hostname：管理主机名12ansible group -m hostname -a &quot;name=app.adong.com&quot; 更改一组的主机名ansible 192.168.38.103 -m hostname -a &quot;name=app2.adong.com&quot; 更改单个主机名 Cron：计划任务1234## 支持时间：minute,hour,day,month,weekdayansible all -m cron -a &#x27;minute=*/5 job=&quot;/usr/sbin/ntpdate 172.16.0.1 &amp;&gt;/dev/null&quot; name=Synctime&#x27; # 创建任务ansible all -m cron -a &#x27;state=absent name=Synctime&#x27; # 删除任务ansible all -m cron -a &#x27;minute=*/10 job=&quot;/usr/sbin/ntpdate 172.30.0.100&quot; name=synctime disabled=true&#x27; #注释任务,不在生效，必须有 name, job,disabled=&quot;true/yes/false/no&quot; 三个参数 Yum：管理包1234567ansible all -m yum -a &#x27;list=httpd&#x27; # 查看程序列表ansible all -m yum -a &#x27;name=httpd state=present&#x27; # 安装ansible all -m yum -a &#x27;name=httpd,vsftpd state=absent&#x27; # 删除 可以同时安装多个程序包ansible all -m copy -a &#x27;src=/data/software.rpm dest=/dir/&#x27; # 拷贝软件ansible all -m yum -a &#x27;name=dstat update_cache=yes&#x27; # 避免缓存造成的影响ansible all -m yum -a &#x27;name=/dir/software.rpm disable_gpg_check=yes&#x27; # Service：管理服务1234ansible all -m service -a &#x27;name=httpd state=stopped&#x27; 停止服务ansible all -m service -a &#x27;name=httpd state=started enabled=yes&#x27; 启动服务,并设为开机自启ansible all -m service -a &#x27;name=httpd state=reloaded&#x27; 重新加载ansible all -m service -a &#x27;name=httpd state=restarted&#x27; 重启服务 User：管理用户 home 指定家目录路径 system 指定系统账号 group 指定组 remove 清除账户 shell 指定shell类型 12345678910ansible all -m user -a &#x27;name=nginx shell=/sbin/nologin system=yes home=/var/nginx groups=root,bin uid=80 comment=&quot;nginx service&quot;&#x27; # 源码编译都需要创建用户，yum安装的就自动创建了ansible all -m user -a &#x27;name=nginx state=absent remove=yes&#x27; # 删除用户ansible all -a &#x27;ls /var/ -l&#x27; # 查看用户目录已经被删除ansible all -a &#x27;getent passwd nginx&#x27; # 账号也删除了ansible all -m user -a &#x27;name=user1 comment=&quot;test user&quot; uid=2048 home=/app/user1 group=root&#x27;ansible all -m user -a &#x27;name=sysuser1 system=yes home=/app/sysuser1&#x27;ansible all -m user -a &#x27;name=user1 state=absent remove=yes&#x27; 清空用户所有数据ansible all -m user -a &#x27;name=app uid=88 system=yes home=/app groups=root shell=/sbin/nologin password=&quot;$1$zfVojmPy$ZILcvxnXljvTI2PhP2Iqv1&quot;&#x27; 创建用户ansible all -m user -a &#x27;name=app state=absent&#x27; 不会删除家目录 安装mkpasswd yum insatll expect mkpasswd 生成口令 openssl passwd -1 生成加密口令 删除用户及家目录等数据 Group：管理组12ansible all -m group -a &quot;name=testgroup system=yes&quot; 创建组ansible all -m group -a &quot;name=testgroup state=absent&quot; 删除组 Ansible系列命令ansible-galaxy 连接 https://galaxy.ansible.com 下载相应的roles(角色) 列出所有已安装的galaxy ansible-galaxy list 安装galaxy ansible-galaxy install geerlingguy.redis 删除galaxy ansible-galaxy remove geerlingguy.redis ansible-pull 推送命令至远程，效率无限提升，对运维要求较高 ansible-playbook 可以引用按照标准的yml语言写的脚本 执行playbook 1234567891011### 示例：ansible-playbook hello.ymlcat hello.yml#hello world yml file##################### 开始--- # 标准格式，可以没有，表示开始- hosts: internal remote_user: ec2-user tasks: - name: hello world command: /usr/bin/wall hello world################### 结束 ansible-vault (了解) 1234567### 功能：管理加密解密yml文件ansible-vault [create|decrypt|edit|encrypt|rekey|view]ansible-vault encrypt hello.yml 加密ansible-vault view hello.yml 查看ansible-vault edit hello.yml 编辑加密文件ansible-vault rekey hello.yml 修改口令ansible-vault create new.yml 创建新文件 Ansible-console：2.0+新增，可交互执行命令，支持tab (了解) 123456789[ec2-user@master ~]$ ansible-consoleWelcome to the ansible console.Type help or ? to list commands.ec2-user@all (3)[f:5]$ cd internal # 切换组ec2-user@internal (2)[f:5]$ forks 10 # 设置并发数ec2-user@internal (2)[f:10]$ list # 看主机清单ec2-user@internal (2)[f:10]$ ? 或 help # 列出所有内置命令，模块ec2-user@internal (2)[f:10]$ command hostname playbook playbook是由一个或多个”play”组成的列表 play的主要功能在于将预定义的一组主机，装扮成事先通过ansible中的task定义好的角色。Task实际是调用ansible的一个module，将多个play组织在一个playbook中，即可以让它们联合起来，按事先编排的机制执行预定义的动作 Playbook采用YAML语言编写 YAML语法简介Ansible","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://shizhonggan.github.io/categories/Ansible/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://shizhonggan.github.io/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"Mininet安装与使用问题","slug":"SDN/mininet01","date":"2021-08-12T02:24:04.000Z","updated":"2021-10-28T06:55:59.907Z","comments":true,"path":"2021/08/12/SDN/mininet01/","link":"","permalink":"http://shizhonggan.github.io/2021/08/12/SDN/mininet01/","excerpt":"","text":"安装12345678910111213141516# 升级pip3,避免后续安装报错吗，高版本的pip放弃了对2.7和3.5版本的支持，因此需要降级wget https://bootstrap.pypa.io/pip/3.5/get-pip.pypython3 get-pip.py git clone git://github.com/mininet/mininetcd mininet git tag # list available versionsgit checkout -b mininet-2.3.0 2.3.0 # cd ..mininet/util/install.sh -s mydir -amininet/util/install.sh [options] -a 全部安装 -nfv 仅安装mininet, OpenFlow, OVS -s mydir 将source/build放在指定目录 指定python版本Mininet 2.3.0 及更高版本支持 Python 3 和 Python 2 12sudo PYTHON=python2 mininet/util/install.sh -n # install Python 2 Mininetsudo PYTHON=python3 mininet/util/install.sh -n # install Python 3 Mininet 查看mininet对应的python版本 1234echo py sys.version | sudo mn -v output mininet&gt; 3.5.2 (default, Jan 26 2021, 13:30:48) [GCC 5.4.0 20160609] mininet&gt; 可能存在的报错通过mininet面板设计拓扑，保存为py脚本时会报错，如下所示： 1234567mininet&gt; Exception in Tkinter callbackTraceback (most recent call last): File &quot;/usr/lib/python3.5/tkinter/__init__.py&quot;, line 1553, in __call__ return self.func(*args) File &quot;miniedit.py&quot;, line 1707, in exportScript f.write(&quot;#!/usr/bin/env python\\n&quot;)TypeError: a bytes-like object is required, not &#x27;str&#x27; 只需修改miniedit.py脚本的第1702行，f=open(“fileName”,”wb”) 改成 f=open(“fileName”,”w”) 连接远程控制器，没有流表初次安装使用mininet启动基本拓扑，都会生成默认流表，网络时全连通的。但在后续的使用过程中，对流表进行添加、删除等操作，会导致再次启动新的默认网络拓扑不再有默认的全连通网络。此时，需要手动添加 123456789101112131415## 为所有交换机添加端口1和端口2的操作---两个交换机公共操作dpctl add-flow in_port=1,actions=output:2 dpctl add-flow in_port=2,actions=output:1## 为交换机之间端口提供交互---只操作s1(因为只有s1有端口3)sh ovs-ofctl add-flow s1 in_port=1,actions=output:2,3sh ovs-ofctl add-flow s1 in_port=3,actions=output:1,2sh ovs-ofctl add-flow s1 in_port=2,actions=output:1,3## mininet命令mininet&gt; dpctl add-flow in_port=1,actions=output:2,3mininet&gt; dpctl add-flow in_port=2,actions=output:1,3mininet&gt; dpctl add-flow in_port=3,actions=output:1,2## 为交换机2添加丢弃流表，使得两个交换机不可通信（在前面互通基础上实现）mininet&gt; sh ovs-ofctl del-flows s2 in_port=1 删除原有流表mininet&gt; sh ovs-ofctl add-flow s2 in_port=1,actions=drop 添加丢弃流表 MININET OpenFlow13协议支持问题Steps to Reproduce: set OpenFlow protocol to 1.3 on bridge br0 (done during boot in OpenShift) 12# ovs-vsctl set bridge br0 protocols=OpenFlow13# sudo mn --switch=ovs,protocols=OpenFlow13 # 启动网络之前提前设置协议参数 try to dump flows 1# ovs-ofctl dump-flows br0 123456789101112## 报错Actual results:2015-11-04T17:45:56Z|00001|vconn|WARN|unix:/var/run/openvswitch/br0.mgmt: version negotiation failed (we support version 0x01, peer supports version 0x04)ovs-ofctl: br0: failed to connect to socket (Broken pipe)Expected results:OFPST_FLOW reply (OF1.3) (xid=0x2): cookie=0x0, duration=1299.155s, table=0, n_packets=0, n_bytes=0, dl_src=01:00:00:00:00:00/01:00:00:00:00:00 actions=drop ...Additional info:this currently works when specifying the version 1# ovs-ofctl dump-flows br0 --protocols=OpenFlow13 原因： ovs-ofctl allows you to set many protocols on the command line, like –protocols=OpenFlow10,OpenFlow13. That will work for bridges that only support OpenFlow13. The problem with using any version by default is that mod-flow has different semantics depending on the version. So, instead of behaving differently whenever you use ovs-ofctl mod-flow, the tool defaults to OpenFlow10 only. Why not use an alias like ovs-ofctl13=’ovs-ofctl –protocols=OpenFlow13’? 个人总结：即使采用 mn –protocols=OpenFlow10,OpenFlow13 这种方式也会出现上述报错问。可以先不指定协议直接启动一个网络拓扑，此时OpenFlow协议默认的1.0。然后再mininet命令行中输入命令进行协议修改，如： mininet&gt; dpctl dump-flows -O OpenFlow13 。","categories":[{"name":"Mininet","slug":"Mininet","permalink":"http://shizhonggan.github.io/categories/Mininet/"}],"tags":[{"name":"网络架构","slug":"网络架构","permalink":"http://shizhonggan.github.io/tags/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/"},{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/tags/SDN/"},{"name":"OVS","slug":"OVS","permalink":"http://shizhonggan.github.io/tags/OVS/"}]},{"title":"网络技术基础知识[持续更新]","slug":"SDN/basicnetwork","date":"2021-07-01T08:18:00.000Z","updated":"2021-10-28T06:55:59.907Z","comments":true,"path":"2021/07/01/SDN/basicnetwork/","link":"","permalink":"http://shizhonggan.github.io/2021/07/01/SDN/basicnetwork/","excerpt":"","text":"IPv4192.168.1.1 由32位点分十进制表示，如下图所示： IP地址由两部分组成： 网络ID和主机ID 网络ID：用于区分不同的子网 主机ID：用于区分同一子网得不同主机 掩码：用于区分网络ID和主机ID,前24位是1可以表示为/24,如下图所示： 使用方法： 网络地址 All Hosts=0广播地址 All Hosts=1主机地址数量 2^n-2(n=32-掩码)&lt;网络地址+1，广播地址-1&gt; IPv4即将枯竭，解决方法： VLSM可变长子网掩码 私网IP NAT 最终解决方法IPv6 例题：10.102.22.9/22 网络地址：10.102.20.0 广播地址：10.102.23.255 主机地址范围：&lt;10.102.20.1, 10.102.23.254&gt; 5G 技术特点网络通信包括：无线通信（wifi, 2G-5G） 和 有线通信（双绞线, 光纤等）。由于不同的传播介质，有线的通信能力远远大于无线通信。 光速=波长×频率 5G特点 高频段（毫米波）：频率越高，越趋向直线传播，传输过程衰减越大，覆盖范围越小，成本越高 微基站：辐射更小，天线长度与波长成正比（天线长度 = 波长/10~波长/4），因此5G天线非常小。可以实现MASSIVE MIMO，5G天线阵列可以实现。 波束赋形，将光源聚集到一个设备上的技术。波束赋形的物理学原理，其实就是波的干涉现象。百度百科上定义如下：频率相同的两列波叠加，使某些区域的振动加强，某些区域的振动减弱，而且振动加强的区域和振动减弱的区域相互隔开。 D2D(device to device)以往信令包和数据包都是通过基站，5G是信令包通过基站数据再设备中间互相传输。 BGP协议[学了还是不懂啥玩意]基本概念BGP概述 外部网关协议 使用TCP作为传输层协议 支持CIDR 增量更新 路径矢量路由协议 无环路 路由策略丰富 可防止路由震荡 易于扩展 自治系统AS: 由同一个技术管理机构管理、使用统一选路策略的一些路由器的集合。 工作原理-报文类型 Open报文： 协商BGP参数 Update报文： 交换路由信息 Keepalive报文：保持邻居关系 Notification报文：差错通知 Route-Refresh报文：用于改变路由策略后请求对等体重新发送路由信息 工作原理-状态机 视频学习链接 SDN Underlay 与 OverlayUnderlay: 现实的物理基础层网络设备。-数据中心基础转发架构的网络。 以太网最初设计的时候就是一个分布式的网络架构，没有中心控制节点，网络中的节点通过协议传递学习网络的可达性信息。 underlay就是数据中心场景的基础物理设施，保证任何两个点路由可达，其中包含了传统的网络技术。 Overlay: 一个基于物理网络之上构建的逻辑网络。 verlay是在网络技术领域指的是一种网络架构上叠加的虚拟化技术模式，Overlay网络也是一个网络，不过是建立在Underlay网络之上的网络。 overlay网络节点通过虚拟或者逻辑链路进行通信，其实现基于ip技术的基础网络为主。 Overlay网络技术多种多样，一般采用TRILL、VxLan、GRE、NVGRE等隧道技术。 underlay和overlay是互相独立的，其中underlay为overlay提供基础承载； underlya和overlay是相对而言的，谁为对方提供基础网络架构，谁就是underlay，相反另外的一方则为overlay； 提到overlay是近几年数据中心为网络兴起的概念，但是对于传统网络而言实际上早一些类似概念。 传统网络：l2vpn、l3vpn、qinq、macinmac等隧道技术就是传统的overlay网络技术；数据中心网络：以vxlan、gre、nvgre、trill等新兴隧道技术为基础构建出来的vpc网络；2 当前网络架构主流技术对比flexe是一种在ip传送网借鉴otn网络的一种无ip交换的更快的1层网络技术，可以理解成把多个节点调度打通看做一根光纤，无ip交换自然更快；mpls和sr这些基于二三层之间的隧道技术，个人理解可以理解成逻辑接口，提供的是一个跨多个节点的专线管道；vxlan、gre、nvgre、trill是基于ip技术打造新兴隧道技术，本质而言，他们对于每个具体的设备仍然是一个逻辑接口；数据中心场景下基于vxlan、gre等不同底层承载新建的逻辑网络，也就是我们常说的vpc网络，是真正意义的逻辑network；l2vpn和l3vpn网路构建出来的也是一个逻辑network,通常承载在mpls的运营商传统网络场景，但是sdwan的出现改变了这一个格局。 路由器硬件设计要考虑八个方面： FIB表容量 协议特性 高可靠性 快速收敛 QOS 吞吐量 低功耗 带宽 RFC1925: Good, fast, cheap, pick any two, but you can’t have all three 网络传输中的三张表，MAC地址表、ARP缓存表以及路由表 路由表：目的地址、网络掩码、下一条ip地址、出接口、优先级、cost路由开销 arp表：ip地址、对应的mac地址、ip地址类型 mac表：mac地址、出端口 详细参考：https://www.cnblogs.com/dapaitou2006/p/6391472.html","categories":[{"name":"网络","slug":"网络","permalink":"http://shizhonggan.github.io/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://shizhonggan.github.io/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"软件定义网络（SDN）学习笔记(6)--Floodlight","slug":"SDN/SDN07_Floodlight","date":"2021-06-03T05:11:04.000Z","updated":"2021-10-28T06:55:59.906Z","comments":true,"path":"2021/06/03/SDN/SDN07_Floodlight/","link":"","permalink":"http://shizhonggan.github.io/2021/06/03/SDN/SDN07_Floodlight/","excerpt":"","text":"安装123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051## 通用版本java 卸载dpkg -l |grep -i jdkapt-get purge openjdk*apt-get purge icedtea-* openjdk-*## 安装1（此方法不行）sudo apt-get install build-essential ant python-devsudo add-apt-repository ppa:webupd8team/javasudo apt-get updatesudo apt-get install oracle-java8-installer## 安装2sudo mkdir /usr/lib/jvmsudo tar -zxvf jdk-8u181-linux-x64.tar.gz -C /usr/lib/jvm# sudo vim ~/.bashrcsudo vim /etc/profile #set oracle jdk environment export JAVA_HOME=/home/ec2-user/jdk/jdk1.8.0_211 ## 这里要注意目录要换成自己解压的jdk 目录 export JRE_HOME=$&#123;JAVA_HOME&#125;/jre export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH source /etc/profile ## 设置默认jdk(可不操作)sudo update-alternatives --install /usr/bin/java java /usr/lib/jvm/jdk1.8.0_181/bin/java 300 sudo update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/jdk1.8.0_181/bin/javac 300 sudo update-alternatives --install /usr/bin/jar jar /usr/lib/jvm/jdk1.8.0_181/bin/jar 300 sudo update-alternatives --install /usr/bin/javah javah /usr/lib/jvm/jdk1.8.0_181/bin/javah 300 sudo update-alternatives --install /usr/bin/javap javap /usr/lib/jvm/jdk1.8.0_181/bin/javap 300## 执行sudo update-alternatives --config java## 检查java -versionjavac -version## Floodlightsudo apt-get install build-essential default-jdk ant python-devsudo apt-get install gitgit clone -b v1.1 git://github.com/floodlight/floodlight.git cd floodlight# git pull origin master # git submodule init # git submodule update antant eclipse## 启动java -jar target/floodlight.jar","categories":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/categories/SDN/"}],"tags":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/tags/SDN/"},{"name":"Floodlight","slug":"Floodlight","permalink":"http://shizhonggan.github.io/tags/Floodlight/"}]},{"title":"软件定义网络（SDN）学习笔记(5)--OpenDaylight控制器","slug":"SDN/SDN05_OpenDaylight","date":"2021-05-31T05:11:04.000Z","updated":"2021-10-28T06:55:59.906Z","comments":true,"path":"2021/05/31/SDN/SDN05_OpenDaylight/","link":"","permalink":"http://shizhonggan.github.io/2021/05/31/SDN/SDN05_OpenDaylight/","excerpt":"","text":"SDN学习目录 SDN学习笔记(0)–wireshark抓包分析 SDN学习笔记(1)–iPerf和Netperf性能测试 SDN学习笔记(2)–Scapy交互式数据处理与Postman HTTP请求测试 SDN学习笔记(3)–OVS系统架构 SDN学习笔记(5)–OpenDaylight控制器 1 OpenDaylight介绍控制器是给交换机下发流表的设备，最常见的控制器是OpenDaylight，简称ODL，下面首先安装一个ODL控制器，看看控制器给交换机下发的原汁原味的流表是怎么样的。 心得：控制器还是属ODL好安装啊…界面丰富，新手上路不需要担心太多东西，就是软件太大。 2 ODL控制器安装123456789101112131415161718192021222324252627282930313233343536## 安装JAVAapt install openjdk-8-jdk## 配置环境vim /etc/environment # 进入环境变量配置文件，在第二行加入java的环境变量。 JAVA_HOME=&quot;/usr/lib/jvm/java-8-openjdk-amd64&quot;## 下载ODL编译好的文件wget https://nexus.opendaylight.org/content/groups/public/org/opendaylight/integration/distribution-karaf/0.6.4-Carbon/distribution-karaf-0.6.4-Carbon.tar.gz## 解压文件tar zvxf distribution-karaf-0.6.4-Carbon.tar.gz## 配置文件/etc/org.apache.karaf.management.cfg # Host for RMI registry rmiRegistryHost = 0.0.0.0 # Port number for RMI server connection rmiServerPort = 44444 # Host for RMI server rmiServerHost = 0.0.0.0## tmux 启动 odltmux unset TMOUT./bin/karaffeature:install odl-l2switch-switch-ui odl-openflowplugin-flow-services-ui odl-mdsal-apidocs odl-dluxapps-applications odl-faas-all## 上面就行，下面这个或许也可以，同时要遵守顺序feature:install odl-restconffeature:install odl-l2switch-switchfeature:install odl-openflowplugin-allfeature:install odl-dlux-allfeature:install odl-mdsal-allfeature:install odl-adsal-northbound ODL命令： 1234567log:display|more # 控制台查看日志feature:list # 列出所有组件feature:list -i # 列出已经安装的feature:list -i|grep odl-restconf # 确认某个组件安装# rm -rf data # 删除data目录，并# ./bin/karaf clean # 清除组件重新进入karaf控制台 验证OpenDaylight基本功能 12# mn --controller=remote,ip=119.255.243.31,port=6633mininet&gt;pingall 登录web界面，查看是否有拓扑http://:8181/index.html 用户名：admin 密码：admin 下发流表YANG UI是OpenDaylight中一款基于DLUX的应用，旨在简化、激励应用的开发与测试。YANG UI通过动态封装、调用YANG模型和相关REST APIs，生成并展示一个简单的UI界面。开发人员可以通过API请求获取交换机信息，并且以JSON格式展示。YANG UI主要面向上层应用开发，为应用开发人员提供了很多相关工具，有效的节约了开发人员的时间。 OpenFlow1.0协议处理数据包的流程相对简单，因为1.0版本只支持单流表。交换机接收到数据包后解析数据包，数据包解析后就开始匹配，从table 0 开始匹配，如果匹配成功则对该数据包执行相应的动作，更新相应的计数器。如果没有找到匹配项则将数据包交给控制器。 OpenFlow1.3协议支持多流表匹配，即一个交换机只会有多个流表，因此数据包处理过程相对复杂。首先解析进入设备的报文，然后从table 0开始匹配，按照优先级高低依次匹配该流表中的流表项，一个报文在一个流表中只会匹配上一条流表项。通常根据报文的类型，报文头的字段例如源MAC地址、目的MAC地址、源IP地址、目的IP地址等进行匹配，大部分匹配还支持掩码进行更精确、灵活的匹配。也可以通过报文的入端口或元数据信息来进行报文的匹配，一个流表项中可以同时存在多个匹配项，一个报文需要同时匹配流表项中所有匹配项才能匹配该流表项。报文匹配按照现有的报文字段进行，比如前一个流表通过apply actions改变了该报文的某个字段，则下一个表项按修改后的字段进行匹配。如果匹配成功，则按照指令集里的动作更新动作集，或更新报文/匹配集字段，或更新元数据和计数器。根据指令是否继续前往下一个流表，不继续则终止匹配流程执行动作集，如果指令要求继续前往下一个流表则继续匹配，下一个流表的ID需要比当前流表ID大。当报文匹配失败了，如果存在无匹配流表项（table miss）就按照该表项执行指令，一般是将报文转发给控制器、丢弃或转发给其他流表。如果没有table miss表项则默认丢弃该报文。 YANG UI是OpenDaylight中一款基于DLUX的应用，旨在简化、激励应用的开发与测试。YANG UI通过动态封装、调用YANG模型和相关REST APIs，生成并展示一个简单的UI界面。开发人员可以通过API请求获取交换机信息，并且以JSON格式展示。YANG UI主要面向上层应用开发，为应用开发人员提供了很多相关工具，有效的节约了开发人员的时间。 OpenFlow1.0协议处理数据包的流程相对简单，因为1.0版本只支持单流表。交换机接收到数据包后解析数据包，数据包解析后就开始匹配，从table 0 开始匹配，如果匹配成功则对该数据包执行相应的动作，更新相应的计数器。如果没有找到匹配项则将数据包交给控制器。 OpenFlow1.3协议支持多流表匹配，即一个交换机只会有多个流表，因此数据包处理过程相对复杂。首先解析进入设备的报文，然后从table 0开始匹配，按照优先级高低依次匹配该流表中的流表项，一个报文在一个流表中只会匹配上一条流表项。通常根据报文的类型，报文头的字段例如源MAC地址、目的MAC地址、源IP地址、目的IP地址等进行匹配，大部分匹配还支持掩码进行更精确、灵活的匹配。也可以通过报文的入端口或元数据信息来进行报文的匹配，一个流表项中可以同时存在多个匹配项，一个报文需要同时匹配流表项中所有匹配项才能匹配该流表项。报文匹配按照现有的报文字段进行，比如前一个流表通过apply actions改变了该报文的某个字段，则下一个表项按修改后的字段进行匹配。如果匹配成功，则按照指令集里的动作更新动作集，或更新报文/匹配集字段，或更新元数据和计数器。根据指令是否继续前往下一个流表，不继续则终止匹配流程执行动作集，如果指令要求继续前往下一个流表则继续匹配，下一个流表的ID需要比当前流表ID大。当报文匹配失败了，如果存在无匹配流表项（table miss）就按照该表项执行指令，一般是将报文转发给控制器、丢弃或转发给其他流表。如果没有table miss表项则默认丢弃该报文。 在Open vSwitch中，流表项作为ovs-ofctl的参数，采用“字段=值”的格式。如果有多个字段，可以用逗号分开，一些常见字段如下： 字段名称 说明 in_port=port 传递数据包的端口的OpenFlow端口编号 dl_vlan=vlan 数据包的VLAN Tag值，范围是0-4095，0xffff代表不包含VLAN Tag的数据包 dl_src=&lt;MAC&gt; dl_dst= &lt;MAC&gt; 匹配源或者目标的MAC地址 01:00:00:00:00:00/01:00:00:00:00:00 代表广播地址 00:00:00:00:00:00/01:00:00:00:00:00 代表单播地址 dl_type=ethertype 匹配以太网协议类型，其中： dl_type=0x0800 代表IPv4协议； dl_type=0x086dd 代表IPv6协议； dl_type=0x0806 代表ARP协议； nw_src=ip[/netmask] nw_dst=ip[/netmask] 当 dl_typ=0x0800 时，匹配源或者目标的IPv4地址，可以使IP地址或者域名 table=number 指定要使用的流表的编号，范围是0-254。在不指定的情况下，默认值为0。通过使用流表编号，可以创建或者修改多个Table中的Flow。 步骤一 通过miniedit.py 快速设计网络拓扑，并保存为topo1_1_3.py文件，如下图所示 步骤二 python3 topo1_1_3.py 执行文件，打开opendaylight web页面，可查看网络拓扑图如下所示 单机左侧，可查看Nodes 节点信息， Node id在下发流表过程中需要。点击Node Connectors可查看具体节点连接信息 展开“opendaylight-inventory rev.2013-08-19”,选择“config-&gt;nodes-&gt;node{id}-&gt;table{id}-&gt;flow{id}” 参数填写 “match&gt;ethernet-match&gt;ethernet-type”, 填写”type”为”0x0800”; “layer-3-match”选择”ipv4=match”使用IP匹配; 展开”layer-3-match”填写源IP地址和目的IP地址，如下图： “instuctions”后单击添加，选择”apply-actions-case”; “apply-actions”后单击添加，选择“drop-action-case”; 以上两个order都设置为0，如下图所示： 设置”priority”为27, “idle-timeout”为0, “hard-timeout”为0, “cookie”为100000000, “table_id”为0，如下图所示： 选择PUT，点击Send, 若发送成功，如下图所示： 执行命令查看流表 1sudo ovs-ofctl dump-flows s1 登录主机h1，执行如下命令向主机h2、h3发送数据包，测试连通性： 123scapy&gt;&gt;&gt; result,unanswered=sr(IP(dst=&quot;10.0.0.2&quot;,ttl=(3,10))/ICMP())&gt;&gt;&gt; result,unanswered=sr(IP(dst=&quot;10.0.0.3&quot;,ttl=(3,10))/ICMP()) 12scapy&gt;&gt;&gt; result,unanswered=sr(IP(dst=&quot;10.0.0.1&quot;,ttl=(3,10))/ICMP()) 12# ovs-ofctl del-flows s1 dl_type=0x0800,nw_src=10.0.0.1,nw_dst=10.0.0.2 # 删除下发的流表# ovs-ofctl dump-flows s1 # 可以查看流表已被删除","categories":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/categories/SDN/"}],"tags":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/tags/SDN/"},{"name":"OVS","slug":"OVS","permalink":"http://shizhonggan.github.io/tags/OVS/"},{"name":"OpenDaylight","slug":"OpenDaylight","permalink":"http://shizhonggan.github.io/tags/OpenDaylight/"}]},{"title":"AWS云平台SDK boto3(python)--自动化创建实例、创建挂载卷以及远程操作","slug":"Python/aws_boto3_paramiko","date":"2021-05-26T00:36:04.000Z","updated":"2021-10-28T06:55:59.903Z","comments":true,"path":"2021/05/26/Python/aws_boto3_paramiko/","link":"","permalink":"http://shizhonggan.github.io/2021/05/26/Python/aws_boto3_paramiko/","excerpt":"","text":"1 介绍Boto3是AWS python版的SDK，可以向python开发者在编写程序过程中使用Amazon S3和 Amazon EC2等服务。 Boto提供了简单的面向对象的API和基本的AWS相关服务。Boto3是最新版本，老版本例如boto2不建议使用。 这篇文章介绍了如何在本地windows环境下，进行AWS云服务的一些基本操作，例如创建实例创建、卷创建和挂载、资源状态查询、资源使用后的清理回收，以及通过paramiko远程操作实例。 2 安装环境 安装AWS CLI(Command Line Interface)AWS命令行接口(CLI)是一个统一的工具来管理的AWS服务。只需下载并完成配置，便可以从命令行控制多个AWS服务，并通过脚本实现对AWS云服务的自动化操作。 下载链接：https://aws.amazon.com/cli/ 可参考 https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html#guide-configuration 主要配置修改： 12345678## 修改 ~/.aws/credentials[default]aws_access_key_id = YOUR_KEY # 你的aws_secret_access_key = YOUR_SECRET## 修改 ~/.aws/config[default]region=cn-north-1a # 安装Boto3 12## python3pip install boto3 3 基本命令3.1 操作流程基本操作流程示例： 创建实例 查询实例状态 创建卷 查看卷状态 若实例与卷均已创建完成并可以使用，挂载卷到已创建的云主机 资源使用完毕，清理回收3.2 客户端和资源 boto3.client(“ec2”) 该命令主要可以进行EC2客户端的一些基本操作。例如：关联、挂载、创建、查询，取消、删除、修改等。 boto3.resource(“ec2”) 该命令主要可以进行EC2云服务中的各类资源的相关操作。该命令与client有交集的部分也有独立的一部分。 3.3 控制AWS代码123456789101112131415161718192021222324252627282930313233343536373839404142434445import boto3# 先调用以下两个ec2 = boto3.client(&quot;ec2&quot;) ec2_resource = boto3.resource(&quot;ec2&quot;) ## 创建实例，返回的是实例的详细信息createInstance = ec2_resource.create_instances( Placement=&#123; &quot;AvailabilityZone&quot;: &quot;cn-north-1b&quot;, &#125;, ImageId=&quot;ami-0c52e2685c7218558&quot;, # 可先从AWS console上查看 InstanceType=&quot;t2.micro&quot;, MaxCount=1, # 可同时创建多个, MinCount=1, KeyName=&quot;gsz&quot;, # 实现创建好的key pairs)instanceID = createInstance[0].id # 从返回的数据中得到实例的ID## 状态查询,是为了等待创建成功，状态可使用情况下进行下一步操作instance_state = ec2_resource.Instance(instanceID).state[&quot;Name&quot;] # 根据实例ID查询状态## 创建卷，此处貌似&quot;ec2&quot;和&quot;ec2_resource&quot;都具有创建卷的方法snap2vol = ec2.create_volume( AvailabilityZone= &quot;cn-north-1b&quot;, # 要与创建的实例相同 Encrypted=True, Size = 100, # 单位GiBs SnapshotId = &quot;snap-096b5af48e45fe262&quot; # 通过某个快照ID创建，如无则为常规卷)## 挂载卷volID = create_vol[&#x27;VolumeId&#x27;] # 获取卷IDattach_vol2 = ec2.attach_volume( ice=Device2, # 挂载路径 /dev/sdf InstanceId=InstanceID, # 实例ID VolumeId=volID, #卷ID)attach_state = ec2_resource.Volume(datavolID).attachments[0][&#x27;State&#x27;]## 删除资源instance = ec2_resource.Instance(instanceID)instance.terminate()volume = ec2_resource.Volume(vol_id)volume.delete() 3.4 远程操作云主机123456789101112131415161718import paramiko## 实例化SSHClinetsshc = paramiko.SSHClient()sshc.set_missing_host_key_policy(paramiko.AutoAddPolicy())sshc.connect(host, username=username,port=port,pkey=key)## 传文件sftp = sshc.open_sftp()localfile1 = &quot;path to your locoal file&quot;remotepath1 = &quot;path/file.name&quot;sftp.put(localfile1, remotepath1)sftp.close()commands = [ &quot;shell command list&quot;]for command in commands: stdin, stdout, stderr = sshc.exec_command(command) 参考资料Paramiko: https://www.cnblogs.com/xiao-apple36/p/9144092.html Boto3: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ec2.html#ec2","categories":[{"name":"AWS","slug":"AWS","permalink":"http://shizhonggan.github.io/categories/AWS/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://shizhonggan.github.io/tags/AWS/"},{"name":"boto3","slug":"boto3","permalink":"http://shizhonggan.github.io/tags/boto3/"},{"name":"paramiko","slug":"paramiko","permalink":"http://shizhonggan.github.io/tags/paramiko/"}]},{"title":"Paramiko执行后台命令报错","slug":"Python/paramiko","date":"2021-05-20T01:39:04.000Z","updated":"2021-10-28T06:55:59.903Z","comments":true,"path":"2021/05/20/Python/paramiko/","link":"","permalink":"http://shizhonggan.github.io/2021/05/20/Python/paramiko/","excerpt":"","text":"1. 报错关键字 paramiko Exception ignored in: &lt;function BufferedFile.__del__ at 0x000001E62C28A048&gt; TypeError: ‘NoneType’ object is not callable 2. 代码12345import paramikosshc = paramiko.SSHClient()sshc.set_missing_host_key_policy(paramiko.AutoAddPolicy())sshc.connect(host, username=username,port=port,pkey=key)stdin1, stdout1, stderr1 = sshc.exec_command(&quot;setsid ...(省略)... &amp;&quot;) setsid是linux系统命令，如果再window下写的代码此处必然无法运行。可以先将setsid相关代码通过sshc.open_sftp()上传到服务端，然后通过sshc.exec_command(“python setsid.py”)运行脚本。 nohup 与 setsid 区别参考：http://www.tang-lei.com/2019/03/04/linux-nohup-setsid-使用区别/ nohup nohup命令的功能就是使用当前进程忽略hangup信号，从而继续执行。默认的标准输入输出都会被重定向到当前目录下的nohup.out文件里。一般我们配置在命令的末尾加上 &amp; 来配合使用。 可以通过 &gt;filename 2&gt;&amp;1 来重定向默认的输入输出, 如：”nohup minio server :9001 /mnt/test/ &gt; /var/log/minio_test.log 2&gt;&amp;1 &amp;”, 通过jobs 可以看到该进程的父进程是当前shell的进程号 作用说明：进程在后台执行；忽略hangup信号；重定向日志输出 &amp; &amp; 代表后台运行程序。如果终端退出，则该进程会结束。通常配合nohup和setsid使用 setsid setsid 就是set session id 的意思。表示该命令运行的进程是一个新的session。因此其父进程不属于当前终端。实际上setsid运行的进程，其父进程id(ppid)为1(init进程的id)。 如：”setsid minion server :9001 /mnt/test/ &gt; /var/log/minio_test.log &amp;”。注意：setsid输出重定向必须手动指定。 结论 由于nohup的父进程与当前的worker有关，当我们Ctrl+C的时候，也会把其给kill掉。而setsid的父进程是init,所以当我们退出worker的时候，并不会kill掉该服务 3. 输出123456789Exception ignored in: &lt;function BufferedFile.__del__ at 0x000001E62C28A048&gt;Traceback (most recent call last): File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paramiko\\file.py&quot;, line 66, in __del__ File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paramiko\\channel.py&quot;, line 1392, in close File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paramiko\\channel.py&quot;, line 991, in shutdown_write File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paramiko\\channel.py&quot;, line 963, in shutdown File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paramiko\\channel.py&quot;, line 1246, in _send_eof File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paramiko\\message.py&quot;, line 232, in add_intTypeError: &#x27;NoneType&#x27; object is not callable 报错原因 windows回车和linux回车存在差异,如下图是windows的回车，二linux不是。 nohup &amp; 命令执行完没有完全退出 shell命令存在错误 4. 解决方法1234567891011121314151617181920212223## main.pyimport paramikosshc = paramiko.SSHClient()sshc.set_missing_host_key_policy(paramiko.AutoAddPolicy())sshc.connect(host, username=username,port=port,pkey=key)sftp = sshc.open_sftp()localfile = &quot;cmd.py&quot;remotepath = &quot;/path/cmd.py&quot;sftp.put(localfile, remotepath)stdin, stdout1, stderr = sshc.exec_command(&quot;python &quot;+&quot;cmd.py&quot;) sshc.close()## cmd.pyimport osimport sysSnapID = &quot;snap-096b5af48e45fe262&quot;datapath = &quot;/mnt/snap/8572302701/hda/data.gz.aes&quot;opensslcmd = os.popen( # 此处选用os.popen，主要是怀疑paramiko存在问题&quot;setsid ...(your shell commands)... &amp;&quot;)# 此处可以多添加几个无用命令sys.exit() 将代码最后添加一个sys.exit()程序恢复正常,其实主要ssh返回的结果缓冲释放过快未读完，就产生报错了。也有说，加一个sleep 1秒也可以解决。 也可能是shell脚本问题，需仔细检查;windows于linux 回车差异需要注意。","categories":[{"name":"运维","slug":"运维","permalink":"http://shizhonggan.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/tags/DevOps/"},{"name":"paramiko","slug":"paramiko","permalink":"http://shizhonggan.github.io/tags/paramiko/"},{"name":"python","slug":"python","permalink":"http://shizhonggan.github.io/tags/python/"}]},{"title":"学术论文免费下载方法","slug":"Tips/PaperDownload","date":"2021-05-18T13:44:23.000Z","updated":"2021-10-28T06:55:59.909Z","comments":true,"path":"2021/05/18/Tips/PaperDownload/","link":"","permalink":"http://shizhonggan.github.io/2021/05/18/Tips/PaperDownload/","excerpt":"","text":"本文仅测试了IEEE论文的下载，亲测有效。 打开网址scihubtw.tw，网站如下： IEEE搜索你需要下载的文章，打开文章所在页面如下图所示，其中红色框内的链接和DOI编号都可以在SCI-HUB中搜索，然后即可下载。 温馨提示：SCI-HUB网址会经常变更，需要多加留意啊~","categories":[{"name":"Tips","slug":"Tips","permalink":"http://shizhonggan.github.io/categories/Tips/"}],"tags":[]},{"title":"Docker 常用命令方法","slug":"Docker/basic_method","date":"2021-04-28T03:03:04.000Z","updated":"2021-10-28T06:55:59.899Z","comments":true,"path":"2021/04/28/Docker/basic_method/","link":"","permalink":"http://shizhonggan.github.io/2021/04/28/Docker/basic_method/","excerpt":"","text":"镜像搜索、拉取和使用123456docker search ubuntudocker pull ubuntudocker run -it --name test ubuntu /bin/bashdocker start testdocker restart testdocker stop test 将容器保存为镜像，便于重复使用12345apt-get install net-toolsapt-get install -y inetutils-pingapt-get install iproute2docker commit -a &quot;作者名&quot; -m &quot;镜像描述&quot; 容器ID 新镜像命名docker commit -a &quot;paxton&quot; -m &quot;ubuntu with modified apt source.list&quot; ovs1 mdubuntu 自定义网络 docker的网络通信基于安装时新建的docker0网桥，可以与外网，本虚拟机以及其他虚拟机通信 在两台虚拟机上创建自定义网络，并为新建容器分配自定义网络下的ip地址，两台虚拟机分配不同网段，配置操作如下： 虚拟机1-ip：192.168.255.129 容器网段 10.0.30.0/24 容器ip：10.0.30.10 虚拟机1操作如下： 创建自定义网络，ifconfig可发现多出一个网桥 123456## h0docker network create --subnet=10.0.30.0/24 --opt com.docker.network.driver.mtu=1450 docker-br0 docker run -itd --net docker-br0 --ip 10.0.30.10 --name h0 mdubuntu /bin/bash## h1docker network create --subnet=10.0.50.0/24 --opt com.docker.network.driver.mtu=1450 docker-br1 docker run -itd --net docker-br1 --ip 10.0.50.10 --name h1 ubuntu /bin/bash 此时，新建的两个虚拟机相互无法ping通。可以通过增加路由的方式解决： 1234ip route show # 查看一下当前路由docker network connect docker-br0 h1 # 将h1加入到h0所在的自定义网络docker-br0中，进入h1可ping通h0，h0不可ping通h1 https://www.cnblogs.com/tengj/p/5357879.htmlhttps://blog.csdn.net/Silvester123/article/details/80867168","categories":[{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/tags/Docker/"}]},{"title":"Docker 容器内网络无法连接","slug":"Docker/netdisconnected","date":"2021-04-27T08:09:04.000Z","updated":"2021-10-28T06:55:59.900Z","comments":true,"path":"2021/04/27/Docker/netdisconnected/","link":"","permalink":"http://shizhonggan.github.io/2021/04/27/Docker/netdisconnected/","excerpt":"","text":"操作系统ubuntu16docker 参照官方教程安装最新版本 问题描述最近迷恋上了docker，因为官方提供的ubuntu镜像只有64M!!!十分轻便。然而基于该镜像生成的容器无法联网，参见下面代码错误，然后试了试其它镜像，依旧无法联网。 12345678910111213141516171819202122root@gan# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEubuntu latest a2a15febcdf3 7 days ago 64.2MBroot@e6a2c5bec004:/# apt updateErr:1 http://security.ubuntu.com/ubuntu bionic-security InRelease Connection failed [IP: 91.189.88.162 80]Err:2 http://archive.ubuntu.com/ubuntu bionic InRelease Connection failed [IP: 91.189.88.149 80]Err:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease Connection failed [IP: 91.189.88.24 80]Err:4 http://archive.ubuntu.com/ubuntu bionic-backports InRelease Connection failed [IP: 91.189.88.149 80]Reading package lists... DoneBuilding dependency treeReading state information... DoneAll packages are up to date.W: Failed to fetch http://archive.ubuntu.com/ubuntu/dists/bionic/InRelease Conn ection failed [IP: 91.189.88.149 80]W: Failed to fetch http://archive.ubuntu.com/ubuntu/dists/bionic-updates/InRelea se Connection failed [IP: 91.189.88.24 80]W: Failed to fetch http://archive.ubuntu.com/ubuntu/dists/bionic-backports/InRel ease Connection failed [IP: 91.189.88.149 80]W: Failed to fetch http://security.ubuntu.com/ubuntu/dists/bionic-security/InRel ease Connection failed [IP: 91.189.88.162 80]W: Some index files failed to download. They have been ignored, or old ones used instead. 解决办法例如：Docker容器内不能联网的6种解决方案stack overflow中的高分回复 Docker apt-get update fails中文这六种解决方法，不要轻易动用，除非你之前做过大量的网络设置，负责这些问题基本不会出现。 第一步：首先查看docker虚拟网卡，查看mtu值，如果是1500(默认，或者更大)，则需要修改为1450或者更小，/etc/docker/daemon.json 。此外，可以在daemon.json中修改镜像的存储路径，以免占用太多的系统内存；修改mtu值便可以联网了；dns根据情况修改，可以不加吧。12345678910111213141516171819202122232425262728293031root@gan:/etc/docker# ifconfigdocker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1450 inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255 inet6 fe80::42:7eff:fee3:87ab prefixlen 64 scopeid 0x20&lt;link&gt; ether 02:42:7e:e3:87:ab txqueuelen 0 (Ethernet) RX packets 4518 bytes 281479 (281.4 KB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 5733 bytes 17386562 (17.3 MB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0root@gan# vim /etc/docker/daemon.json&#123; &quot;data-root&quot;: &quot;/home/ec2-user/software/docker-data&quot;, &quot;storage-driver&quot;: &quot;overlay2&quot;, &quot;mtu&quot;: 1450, &quot;dns&quot;: [&quot;you_server_dns&quot;,&quot;8.8.8.8&quot;]&#125;##启动 systemctl start docker## 守护进程重启sudo systemctl daemon-reload## 重启docker服务sudo systemctl restart docker## 关闭dockersudo systemctl stop docker## 重启docker服务sudo service docker restart## 关闭dockersudo service docker stop 第二步：再按照其它方法慢慢修改吧总结有时候搜索不到答案，就细致读一下官方文档，按照官方文档操作一般不会遇到问题，否则就是这个软件的BUG了。 MTU [百度百科]通信术语 最大传输单元（Maximum Transmission Unit，MTU）是指一种通信协议的某一层上面所能通过的最大数据包大小（以字节为单位）。最大传输单元这个参数通常与通信接口有关（网络接口卡、串口等）。 因为协议数据单元的包头和包尾的长度是固定的，MTU越大，则一个协议数据单元的承载的有效数据就越长，通信效率也越高。MTU越大，传送相同的用户数据所需的数据包个数也越低。 MTU也不是越大越好，因为MTU越大， 传送一个数据包的延迟也越大；并且MTU越大，数据包中 bit位发生错误的概率也越大。 MTU越大，通信效率越高而传输延迟增大，所以要权衡通信效率和传输延迟选择合适的MTU。","categories":[{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/tags/Docker/"}]},{"title":"Ubuntu安装Docker与最常用配置","slug":"Docker/docker_install","date":"2021-04-26T02:54:04.000Z","updated":"2021-10-28T06:55:59.899Z","comments":true,"path":"2021/04/26/Docker/docker_install/","link":"","permalink":"http://shizhonggan.github.io/2021/04/26/Docker/docker_install/","excerpt":"","text":"1 docker 介绍Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源。 Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。 容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低。 Docker 从 17.03 版本之后分为 CE（Community Edition: 社区版） 和 EE（Enterprise Edition: 企业版），我们用社区版就可以了。 Docker的应用场景 Web 应用的自动化打包和发布。 自动化测试和持续集成、发布。 在服务型环境中部署和调整数据库或其他的后台应用。 从头编译或者扩展现有的 OpenShift 或 Cloud Foundry 平台来搭建自己的 PaaS 环境。 Docker 的优点 Docker 是一个用于开发，交付和运行应用程序的开放平台。Docker 使您能够将应用程序与基础架构分开，从而可以快速交付软件。借助 Docker，您可以与管理应用程序相同的方式来管理基础架构。通过利用 Docker 的方法来快速交付，测试和部署代码，您可以大大减少编写代码和在生产环境中运行代码之间的延迟。 快速，一致地交付您的应用程序 Docker 允许开发人员使用您提供的应用程序或服务的本地容器在标准化环境中工作，从而简化了开发的生命周期。 容器非常适合持续集成和持续交付（CI / CD）工作流程，请考虑以下示例方案： 您的开发人员在本地编写代码，并使用 Docker 容器与同事共享他们的工作。 他们使用 Docker 将其应用程序推送到测试环境中，并执行自动或手动测试。 当开发人员发现错误时，他们可以在开发环境中对其进行修复，然后将其重新部署到测试环境中，以进行测试和验证。 测试完成后，将修补程序推送给生产环境，就像将更新的镜像推送到生产环境一样简单。 响应式部署和扩展 Docker 是基于容器的平台，允许高度可移植的工作负载。Docker 容器可以在开发人员的本机上，数据中心的物理或虚拟机上，云服务上或混合环境中运行。 Docker 的可移植性和轻量级的特性，还可以使您轻松地完成动态管理的工作负担，并根据业务需求指示，实时扩展或拆除应用程序和服务。 在同一硬件上运行更多工作负载 Docker 轻巧快速。它为基于虚拟机管理程序的虚拟机提供了可行、经济、高效的替代方案，因此您可以利用更多的计算能力来实现业务目标。Docker 非常适合于高密度环境以及中小型部署，而您可以用更少的资源做更多的事情。 安装ubuntu16.04安装成功；ubuntu14.04安装失败【各种报错啊，有耐心的可以慢慢去解决】。 123456789101112131415161718192021$ sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak$ sudo rm /etc/apt/sources.list$ sudo vi /etc/apt/sources.listecho \\&quot;deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse&quot; \\&gt;&gt; /etc/apt/sources.list$ sudo apt-get update$ sudo apt-get upgrade 12$ sudo apt-get remove docker docker-engine docker.io containerd runc # 如果存在旧版本地docker产品先卸载$ Install using the repository1234567$ sudo apt-get update$ sudo apt-get install apt-transport-https ca-certificates curl gnupg lsb-release$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg$ sudo apt-key fingerprint 0EBFCD88$ echo \\ &quot;deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null INSTALL DOCKER CE123$ sudo apt-get update$ sudo apt-get install docker-ce docker-ce-cli containerd.io$ sudo docker run hello-world docker 更改工作存储路径【可选操作】1$ sudo systemctl stop docker Runtime directory and storage driver You may want to control the disk space used for Docker images, containers, and volumes by moving it to a separate partition.To accomplish this, set the following flags in the daemon.json file:1234&#123; &quot;data-root&quot;: &quot;/mnt/docker-data&quot;, ## 修改成你自己的目录 &quot;storage-driver&quot;: &quot;overlay2&quot;&#125; 12$ sudo service docker start # 重启$ sudo systemctl start docker Docker 更改容器日志文件大小【可选操作】 docker容器的日志文件会不断挤占系统资源内存，因此需要限定docker日志文件大小，实现docker日志定期处理，具体方法如下： 123456789# 查看文件夹子文件所占内存大小du -h --max-depth=1 /home/ec2-user/dirname/# vim /etc/docker/daemon.json &#123; &quot;log-driver&quot;:&quot;json-file&quot;, &quot;log-opts&quot;: &#123;&quot;max-size&quot;:&quot;500m&quot;, &quot;max-file&quot;:&quot;1&quot;&#125; # max-size=500m，意味着一个容器日志大小上限是500M，max-file=3，意味着一个容器有三个日志，分别是id+.json、id+1.json、id+2.json。&#125; ## 重启docker守护进程 # systemctl daemon-reload 、# systemctl restart docker","categories":[{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/tags/Docker/"}]},{"title":"面向对象编程(python)","slug":"Python/ObjectOrientedPrograming","date":"2021-04-26T02:54:04.000Z","updated":"2021-10-28T06:55:59.903Z","comments":true,"path":"2021/04/26/Python/ObjectOrientedPrograming/","link":"","permalink":"http://shizhonggan.github.io/2021/04/26/Python/ObjectOrientedPrograming/","excerpt":"","text":"与面向过程相比，面向对象优缺点如下： 优点：易维护、易复用、易扩展，由于面向对象有封装、继承、多态性的特性，可以设计出低耦合的系统，使系统 更加灵活、更加易于维护 数据抽象的概念可以在保持外部接口不变的情况下改变内部实现，从而减少甚至避免对外界的干扰； 通过继承大幅减少冗余的代码，并可以方便地扩展现有代码，提高编码效率，也减低了出错概率，降低软件维护的难度； 结合面向对象分析、面向对象设计，允许将问题域中的对象直接映射到程序中，减少软件开发过程中中间环节的转换过程； 通过对对象的辨别、划分可以将软件系统分割为若干相对独立的部分，在一定程度上更便于控制软件复杂度； 以对象为中心的设计可以帮助开发人员从静态（属性）和动态（方法）两个方面把握问题，从而更好地实现系统； 通过对象的聚合、联合可以在保证封装与抽象的原则下实现对象在内在结构以及外在功能上的扩充，从而实现对象由低到高的升级。 缺点：性能比面向过程低 自己写","categories":[{"name":"Python","slug":"Python","permalink":"http://shizhonggan.github.io/categories/Python/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://shizhonggan.github.io/tags/OOP/"}]},{"title":"软件定义网络（SDN）学习笔记(3)--OVS系统架构","slug":"SDN/SDN03_ovs","date":"2021-04-21T13:31:04.000Z","updated":"2021-10-28T06:55:59.905Z","comments":true,"path":"2021/04/21/SDN/SDN03_ovs/","link":"","permalink":"http://shizhonggan.github.io/2021/04/21/SDN/SDN03_ovs/","excerpt":"","text":"SDN学习目录 SDN学习笔记(0)–wireshark抓包分析 SDN学习笔记(1)–iPerf和Netperf性能测试 SDN学习笔记(2)–Scapy交互式数据处理与Postman HTTP请求测试 SDN学习笔记(3)–OVS系统架构 SDN学习笔记(5)–OpenDaylight控制器 1 基本概念1.1 交换机交换机（Switch）是一种在通信系统中完成信息交换功能的设备。它可以为接入交换机的任意两个网络节点提供独享的电信号通路。最常见的交换机是以太网交换机。其他常见的还有电话语音交换机、光纤交换机等。目前，二层交换技术发展比较成熟，二层交换机（Layer 2 switches）是指只支持OSI第二层（数据链路层）交换技术的交换机。 1.2 工作原理交换机拥有一条很高带宽的背部总线和内部交换矩阵。交换机的所有的端口都挂接在这条背部总线上，控制电路收到数据包以后，处理端口会查找内存中的地址对照表以确定目的MAC（网卡的硬件地址）的NIC（网卡）挂接在哪个端口上，通过内部交换矩阵迅速将数据包传送到目的端口，目的MAC若不存在，广播到所有的端口，接收端口回应后交换机会“学习”新的MAC地址，并把它添加入内部MAC地址表中，并刷新CAM表，表中有MAC地址，对应的端口号，端口所属的VLAN信息，交换机在二层转发数据时根据CAM表查找出端口。使用交换机也可以把网络“分段”，通过对照IP地址表，交换机只允许必要的网络流量通过交换机。通过交换机的过滤和转发，可以有效的减少冲突域，但不能划分广播域。交换机在同一时刻可进行多个端口对之间的数据传输。每一端口都可视为独立的网段，连接在其上的网络设备独自享有全部的带宽，无须同其他设备竞争使用。当节点A向节点D发送数据时，节点B可同时向节点C发送数据，而且这两个传输都享有网络的全部带宽，有着自己的虚拟连接。 1.3 作用与功能交换机的常见功能如下： MAC地址学习：以太网交换机了解每一端口相连设备的MAC地址，并将地址同相应的端口映射起来存放在交换机缓存中的MAC地址表中。 转发/过滤：当一个数据帧的目的地址在MAC地址表中有映射时，它被转发到连接目的节点的端口而不是所有端口（如该数据帧为广播/组播帧则转发至所有端口）。 消除回路：当交换机包括一个冗余回路时，以太网交换机通过生成树协议避免回路的产生，同时允许存在后备路径。 2 Open vSwitch (OVS)在网络中，交换机和桥概念类似，Open vSwitch是一个虚拟交换软件，也就是说，Open vSwitch实现了网桥的功能。学习Open vSwitch的第一步要弄清楚网桥的概念。网桥是连接两个局域网的设备，工作在数据链路层，根据MAC地址来转发帧。在Open vSwitch中创建一个网桥后，此时网络功能不受影响，但是会产生一个虚拟网卡，之所以会产生一个虚拟网卡，是为了实现接下来的网桥（交换机）功能。有了这个网桥以后，还需要为这个网桥增加端口（port），一个端口就是一个物理网卡，当网卡加入到这个网桥之后，其工作方式就和普通交换机的一个端口的工作方式类似了。以下是一个网桥的具体信息： Open vSwitch（OVS）是一个高质量的、多层虚拟交换机。OVS遵循开源Apache2.0许可，通过可编程扩展，OVS可以实现大规模网络的自动化（配置、管理、维护），同时支持现有标准管理接口和协议（比如NetFlow、sFlow、SPAN、RSPAN、CLI、LACP、802.1ag等）。此外OVS支持多种Linux虚拟化技术，包括Xen/XenServer，KVM，和VirtualBox等。虽然是虚拟交换机，但是其工作原理与物理交换机类似。在虚拟交换机的实现中，其两端分别连接着物理网卡和多块虚拟网卡，同时虚拟交换机内部会维护一张映射表，根据MAC地址寻找对应的虚拟机链路进而完成数据转发。 OVS交换机有两种工作模式 一种为SDN交换机，另一种为普通交换机。作为SDN交换机时，显示Fail_mode为Secure，在这种模式下OVS交换机需要控制器发送转发规则，指挥交换机去工作 作为普通交换机时，显示Fail_mode是Standalone。其和物理交换机工作模式一样，记录端口号和MAC地址的对应关系，基于对应关系转发数据帧。交换机默认状态是SDN交换机。 OVS 架构分为三个部分: 内核空间：包含了流表（Flow Table）和Datapath模块（类似于网桥，主要负责对数据分组进行操作）。 用户空间：运行着OVS的守护进程(Open vSwitch Daemon, vswitchd)和数据库(Open vSwitch Database, ovsdb)，他们是ovs的核心功能模块。 vswitchd类似于OVS的心脏，维持OVS的声明周期。可以配置一系列特性： 基于MAC地址学习的二层交换 支持IEEE802.1Q VLAN sFlow监测 连接OpenFlow控制器 通过Netlink协议与内核模块Datapath直接通信 ovsdb相当于OVS的大脑，存储OVS的配置信息和数据流信息。 配置管理层：包括ovs-dpctl, ovs-ofctl, ovs-appctl, ovs-vsctl和ovsdb-tool等，主要用于和vswitchd,ovsdb之间进行交互操作以及ovs的安装配置和部署 3. OVS安装使用OVS可以运行在任何基于Linux的虚拟化平台，包括KVM, VirtualBox, Xen等，其代码都是基于C编写，所以易于移植到其他环境。安装有两种方法：一种通过二进制文件安装apt-get；另外一种是源码安装。 3.1 ovs安装docker 安装参见【Ubuntu安装Docker与最常用配置】 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950docker pull ubuntudocker run -it --name ovs1 ubuntu /bin/bash apt install pythonapt install python-pipwget https://www.openvswitch.org/releases/openvswitch-2.13.3.tar.gz参考：https://www.cnblogs.com/goldsunshine/p/10331606.htmlapt list --upgradable # 查看可以升级的包apt install pythonapt install python-pip wget https://www.openvswitch.org/releases/openvswitch-2.13.3.tar.gztar -zxf openvswitch-2.13.3.tar.gz## 以下需root用户下执行./configuremake make installmake modules_install /sbin/modprobe openvswitch export PATH=$PATH:/usr/local/share/openvswitch/scriptsovs-ctl start export PATH=$PATH:/usr/local/share/openvswitch/scriptsovs-ctl --no-ovs-vswitchd startexport PATH=$PATH:/usr/local/share/openvswitch/scriptsovs-ctl --no--ovsdb-server startmkdir -p /usr/local/etc/openvswitchovsdb-tool create /usr/local/etc/openvswitch/conf.db \\ vswitchd/vswitch.ovsschemamkdir -p /usr/local/var/run/openvswitchovsdb-server --remote=punix:/usr/local/var/run/openvswitch/db.sock \\ --remote=db:Open_vSwitch,Open_vSwitch,manager_options \\ --private-key=db:Open_vSwitch,SSL,private_key \\ --certificate=db:Open_vSwitch,SSL,certificate \\ --bootstrap-ca-cert=db:Open_vSwitch,SSL,ca_cert \\ --pidfile --detach --log-fileovs-vsctl --no-wait initovs-vswitchd --pidfile --detach --log-file note:进入容器后，若发现无法联网请参见文章【Docker容器内网络无法连接】 3.2 ovs-vsctl 命令使用ovs-ovsctl命令是对交换机上网桥和端口等信息进行配置的命令。获取或者更改ovs-vswitchd的配置信息，此工具操作的时候会更新ovsdb-server中的数据库。下面的操作需要连接控制器，控制器的安装可以参考【OpenDaylight安装】 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950## 查看网桥ovs-vsctl show393b60ce-7d82-41e0-bd78-2aa47e54c8d5 ovs_version: &quot;2.13.3&quot;## 添加网桥ovs-vsctl add-br br-test393b60ce-7d82-41e0-bd78-2aa47e54c8d5 Bridge br-test Port br-test Interface br-test type: internal ovs_version: &quot;2.13.3&quot;## 绑定网卡，创建网桥后会默认创建同名的port，可以绑定机器存在的网卡ovs-vsctl add-port br-test ens8393b60ce-7d82-41e0-bd78-2aa47e54c8d5 Bridge br-test Port ens8 Interface ens8 Port br-test Interface br-test type: internal ovs_version: &quot;2.13.3&quot;## 删除port绑定的网卡ovs-vsctl del-port br-test ens8## 删除网桥ovs-vsctl add-br br-test## 网桥连接控制器ovs-vsctl set-controller br-test tcp:x.x.x.x:6633## 设置协议,否则web界面无法显示ovs-vsctl set bridge br-test protocols=OpenFlow10393b60ce-7d82-41e0-bd78-2aa47e54c8d5 Bridge br-test Controller &quot;tcp:x.x.x.x:6633&quot; is_connected: true Port ens8 Interface ens8 Port br-test Interface br-test type: internal ovs_version: &quot;2.13.3&quot;## 网桥端开连接控制器ovs-vsctl del-controller br-test ovs连接控制器成功后，可在opendaylight界面看到： ovs连接本地docker容器后，可以在OpenDaylight界面看到： 12345678910## 查看docker容器的网卡物理地址docker exec -it h0 bashroot@8cfaf3984bdf:/# ifconfigeth0 flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1450 inet 10.0.50.10 netmask 255.255.255.0 broadcast 10.0.50.255 ether 02:42:0a:00:32:0a txqueuelen 0 (Ethernet) RX packets 2873 bytes 319842 (319.8 KB) RX errors 0 dropped 2736 overruns 0 frame 0 TX packets 29 bytes 1666 (1.6 KB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ovs连接容器方法有诸多坑存在，将单独整理一篇文章讲解 上面说到，创建桥的时候会创建一个和桥名字一样的接口，并自动作为该桥的一个端口，那么这个虚拟接口的作用，一方面是可以作为交换机的管理端口，另一方面也是基于这个虚拟接口实现了桥的功能。Open vSwitch的内核模块实现了多个“数据路径”，每个都可以有多个vports。每个数据路径也通过关联流表（flow table）来设置操作，而这些流表中的流都是用户空间在报文头和元数据的基础上映射的关键信息，一般的操作都是将数据包转发到另一个vport。当一个数据包到达一个vport，内核模块所做的处理是提取其流的关键信息并在流表中查找这些关键信息，当有一个匹配的流时它执行对应的操作，如果没有匹配，它会将数据包送到用户空间的处理队列中，作为处理的一部分，用户空间可能会设置一个流用于以后碰到相同类型的数据包可以在内核中执行操作。ovs-vsctl关于网桥管理的常用命令如下： 命令 含义 init 初始化数据库（前提数据分组为空） show 打印数据库信息摘要 add-br BRIDGE 添加新的网桥 del-br BRIDGE 删除网桥 list-br 打印网桥摘要信息 list-ports BRIDGE 打印网桥中所有port摘要信息 add-port BRIDGE PORT 向网桥中添加端口 del-port [BRIDGE] PORT 删除网桥上的端口 get-controller BRIDGE 获取网桥的控制器信息 del-controller BRIDGE 删除网桥的控制器信息 set-controller BRIDGE TARGET 向网桥添加控制器 3.3 ovs-ofctl 命令使用ovs-ofctl 命令是对流表的操作，包括对流表的增，删，改，查等命令。简单来说流表类似于交换机的MAC地址表，路由器的路由表，是ovs交换机指挥流量转发的表。 OpenFlow是用于管理交换机流表的协议，ovs-ofctl是Open vSwitch提供的命令行工具。在没有配置OpenFlow控制器的模式下，用户可以使用ovs-ofctl命令通过OpenFlow协议连接Open vSwitch来创建、修改或删除Open vSwitch中的流表项，并对Open vSwitch的运行状况进行动态监控。ovs-ofctl关于流表管理的常用命令如下表所示： 对于add-flow、add-flows和mod-flows这3个命令，还需要指定要执行的动作actions=[target],[target]…，一个流规则中可能有多个动作，按照指定的先后顺序执行。常见的流表操作如下表所示 在OpenFlow白皮书中，Flow被定义为某个特定的网络流量。例如，一个TCP连接就是一个Flow，或者从某个IP地址发出来的数据包，都可以被认为是一个Flow。支持OpenFlow协议的交换机应该包括一个或多个流表，流表中的条目包含：数据包头的信息、匹配成功后要执行的指令和统计信息。当数据包进入OVS后，会将数据包和流表中的流表项进行匹配，如果发现了匹配的流表项，则执行该流表项中的指令集。相反，如果数据包在流表中没有发现任何匹配，OVS会通过控制通道把数据包发到OpenFlow控制器中。在OVS中，流表项作为ovs-ofctl的参数，采用如下的格式：字段=值，如果有多个字段，可以用逗号或空格分开，一些常用的字段列举如下表所示。","categories":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/categories/SDN/"}],"tags":[{"name":"网络架构","slug":"网络架构","permalink":"http://shizhonggan.github.io/tags/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/"},{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/tags/SDN/"},{"name":"OVS","slug":"OVS","permalink":"http://shizhonggan.github.io/tags/OVS/"}]},{"title":"软件定义网络（SDN）学习笔记(4)--Mininet","slug":"SDN/SDN04_Mininet","date":"2021-04-21T13:31:04.000Z","updated":"2021-10-28T06:55:59.906Z","comments":true,"path":"2021/04/21/SDN/SDN04_Mininet/","link":"","permalink":"http://shizhonggan.github.io/2021/04/21/SDN/SDN04_Mininet/","excerpt":"","text":"Mininet简洁Mininet是基于Linux C ontainer架构开发的一个进程虚拟化网络仿真工具，可以创建一个含有主机、交换机、控制器和链路的虚拟网络，其交换机支持OpenFlow，具有高度灵活的自定义软件定义网络。Mininet可以用一个命令在一台主机上（虚拟机、云或者本地）以秒级创建一个虚拟网络，并在上面运行真正的内核、交换机和应用程序代码。Mininet能实现如下功能： 为OpenFlow应用程序提供一个简单、便宜的网络测试平台 启用复杂的拓扑测试，无需连接物理网络 具有拓扑感知和OpenFlow感知的CLI，用于调试或运行网络范围的测试 支持任意自定义拓扑，主机数可达4096，并包括一组基本的参数化拓扑 提供用于网络创建和实验的可扩展Python API Miniedit可视化，直接在界面上编辑任意拓扑，生成python自定义拓扑脚本，使用Mininet可视化界面方便了用户自定义拓扑创建，为不熟悉python脚本的使用者创造了更简单的环境，界面直观，可操作性强。 Mininet 2.2.0+内置miniedit 。在mininet/examples下提供miniedit.py脚本，执行脚本后显示可视化界面，可自定义拓扑及配置属性。MiniEdit使用主要分三个步骤：Miniedit启动→自定义创建拓扑，设置设备信息→运行拓扑并生成拓扑脚本。 Mininet 安装与卸载123456789101112131415sudo apt-get updategit clone http://github.com/mininet/mininet.gitcd mininet ``cat INSTALL|morecd util/## 安装./install.sh -a## 检查是否成功mn --test pingall## 查看版本mn --version## 卸载sudo rm -rf /usr/local/bin/mn /usr/local/bin/mnexec /usr/local/lib/python*/*/*mininet* /usr/local/bin/ovs-* /usr/local/sbin/ovs-*sudo apt-get remove mininet 1234567891011121314151617181920# dpkg 报错 参考：https://www.bbsmax.com/A/MyJx7MvVzn/sudo mv /var/lib/dpkg/info/ /var/lib/dpkg/info_old/sudo mkdir /var/lib/dpkg/info/sudo apt-get updatesudo apt-get -f installsudo mv /var/lib/dpkg/info/* /var/lib/dpkg/info_old/sudo rm -rf /var/lib/dpkg/infosudo mv /var/lib/dpkg/info_old/ /var/lib/dpkg/info/sudo apt-get update sudo apt-get upgrade ## 或者 这个方法不行，但有说成功的... # https://blog.csdn.net/ljf_study/article/details/81591036sudo apt-get autoremovesudo apt-get --purge remove &amp;&amp; sudo apt-get autocleansudo apt-get -f installsudo apt-get updatesudo apt-get upgrade &amp;&amp; sudo apt-get dist-upgradesudo dpkg-reconfigure -asudo dpkg --configure -a Mininet拓朴构建与命令使用topo：用于指定网络拓扑，Mininet支持创建的网络拓扑为：minimal、single、linear和tree。 minimal：创建一个交换机和两个主机相连的简单拓扑。默认无—topo参数的情况下就是这样。其内部实现就是调用了single,2对应的函数。 single,n：设置一个交换机和n个主机相连的拓扑。 linear,n：创建n个交换机，每个交换机只连接一个主机，并且所有交换机成线型排列。 tree,depth=n,fanout=m：创建深度为n，每层树枝为m的树型拓扑。因此形成的拓扑的交换机个数为（mn-1）/（m-1），主机个数为mn。 –custom：在上述已有拓扑的基础上，Mininet支持自定义的拓扑，使用一个简单的Python API即可。—custom需和—topo一起使用，如mn —custom file.py -topo mytopo。 网络构建参数使用12345678910111213141516# 创建single拓扑sudo mn --topo=single,3exit # 退出 # 创建linear线性拓扑sudo mn --topo=linear,3# 创建tree树形拓扑，深度2，每个交换机下挂两个设备sudo mn --topo=tree,depth=2,fanout=2# 创建custom自定义拓扑cd /home/openlab/openlab/mininet/customsudo mn --custom topo-2sw-2host.py --topo mytopo#自定义（custom）拓扑指python编写文件file.py，执行此脚本即可创建定义的拓扑，—custom与—topo联用，在custom目录下存在topo-2sw-2host.py文件，本例调用此文件构建拓扑。## 设置交换机--switch=Switch # 默认ovsk，还包括user,ovsbr,ovsk,ivs和lxbr## 配置MAC地址， 内部交互命令使用1234567net # 显示链接信息nodes # 查看节点信息links # 查看链路健壮性信息pingall # 验证所有主机间通信并查看结果xterm h1 h2 # 开启xterm进入设备可视化操作界面exit # 退出mn -c # 清除释放Mininet构造配置的交换机及主机 可视化构建网络拓扑 启动 12cd mininet/examples # 进入该目录下sudo ./miniedit.py # 启动可视化界面 Miniedit拓扑建立：选择左侧的网络组件，在空白区域单击鼠标左键即可添加网络组件，可选择的组件主要有主机、OpenFlow交换机、传统交换机，传统路由器、链路、控制器。 Miniedit拓扑建立：选择左侧的网络组件，在空白区域单击鼠标左键即可添加网络组件，可选择的组件主要有主机、OpenFlow交换机、传统交换机，传统路由器、链路、控制器。 Miniedit全局配置：Miniedit左上角“Edit”中可以剪切删除设备，及对整个网络进行全局配置 Miniedit运行：点击左下角“run”，即可运行设置好的网络拓扑，同时在后台可以看到相应的配置信息。运行后对交换机、主机进行右击长按，可查看交换机的bridge信息及打开Host的终端 Miniedit保存脚本：miniedit设置好拓扑后，可通过选择File-Export Level 2 Script，将其保存为python脚本，默认在mininet/examples目录下，通过chmod给此脚本权限后，直接运行即可重现拓扑 Miniedit脚本执行 1234# 通过后台查看保存的sdnlab.py脚本文件，并给脚本赋予权限：chmod –R 777 sdnlab.py# 执行sdnlab.py脚本：./sdnlab.py Mininet 调用API扩展自定义拓扑123456789101112cd mininet/custom sudo mn --custom topo-2sw-2host.py --topo mytopo # 执行py net.addHost(&#x27;h3&#x27;) # 添加主机h3py net.addLink(s3,net.get(&#x27;h3&#x27;)) # 添加s3与h3之间的链路py s3.attach(&#x27;s3-eth3&#x27;) # s3添加接口py net.get(&#x27;h3&#x27;).cmd(&#x27;ifconfig h3-eth0 10.3&#x27;) # 配置h3的IP地址## 查看节点信息dumpnodes ## 检查连通性h1 ping h3pingall Mininet可视化构建网络拓扑1234## 报错 MoTTY X11 proxy: Unsupported authorisation protocol## 需要普通用户下执行cd mininet/mininet/examplessudo ./miniedit.py 在控制器上进行鼠标右击长按，选择Properties即可对控制器进行配置，如下所示 在交换机上进行鼠标右击长按，选择Properties即可对交换机进行配置，交换机属性需配置16位的DPID，如下所示: 在主机上进行鼠标右击长按，选择Properties即可对主机进行配置，主机属性需配置IP地址，如下所示。 也可对链路进行属性配置，主要配置带宽、时延、丢包率等，此项可配置亦可不配置，如下所示: Miniedit全局配置。Miniedit左上角“Edit”中可以剪切删除设备，及对整个网络进行全局配置，如下所示。 Miniedit运行。 单击左下角“run”，即可运行设置好的网络拓扑，同时在后台可以看到相应的配置信息。 运行后对交换机、主机进行右击长按，可查看交换机的bridge信息及打开Host的终端，交换机信息如下： Miniedit保存脚本。Miniedit设置好拓扑后，可通过选择“File &gt; Export Level 2 Script”，将其保存为python脚本，默认在mininet/examples目录下。 Miniedit脚本执行。 通过后台查看保存的sdnlab.py脚本文件，并给脚本赋予权限： 1sudo chmod -R 777 sdnlab.py Mininet流表应用1——手动添加流表创建拓扑12345678910111213141516171819202122232425262728vim ./custom/exper1.py#!/usr/bin/pythonfrom mininet.topo import Topofrom mininet.net import Mininetfrom mininet.node import RemoteControllerfrom mininet.link import TCLinkfrom mininet.util import dumpNodeConnectionsclass MyTopo( Topo ): &quot;Simple topology example.&quot; def __init__( self ): &quot;Create custom topo.&quot; # Initialize topology Topo.__init__( self ) # Add hosts and switches Host1 = self.addHost( &#x27;h1&#x27; ) Host2 = self.addHost( &#x27;h2&#x27; ) Host3 = self.addHost( &#x27;h3&#x27; ) Switch1 = self.addSwitch( &#x27;s1&#x27; ) Switch2 = self.addSwitch( &#x27;s2&#x27; ) # Add links self.addLink( Host1, Switch1 ) self.addLink( Host2, Switch1 ) self.addLink( Host3, Switch2 ) self.addLink( Switch1, Switch2 )topos = &#123; &#x27;mytopo&#x27;: ( lambda: MyTopo() ) &#125;## # 运行自定义脚本，并指定一个不存在的控制器，是交换机不受控制器控制sudo mn --custom exper1.py --topo mytopo --controller=remote,ip=127.0.0.1,port=6633 测试流表状态下的通信12345678910111213141516171819xterm h1 h2 h3 # 打开可视化终端dpctl dump-flows # 查看交换机的flow table信息，可以看到没有流表mininet&gt; dpctl dump-flows*** s1 -------------------------*** s2 -------------------------## 在主机h2中执行命令tcpdump -n -i h2-eth0抓取网卡h2-eth0上的数据包root@sdntest:~/mininet/custom# tcpdump -n -i h2-eth0tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on h2-eth0, link-type EN10MB (Ethernet), capture size 262144 bytes## 在主机h3中执行命令tcpdump -n -i h3-eth0抓取网卡h2-eth0上的数据包,结果同上## 在主机h1中执行如下命令分别ping主机h2和h3，结果如下：PING 10.0.0.2 (10.0.0.2) 56(84) bytes of data.From 10.0.0.1 icmp_seq=1 Destination Host UnreachableFrom 10.0.0.1 icmp_seq=2 Destination Host UnreachableFrom 10.0.0.1 icmp_seq=3 Destination Host Unreachable--- 10.0.0.2 ping statistics ---3 packets transmitted, 0 received, +3 errors, 100% packet loss, time 1999mspipe 3 添加流表并测试主机间的通信123456# 步骤1 执行如下命令添加交换机端口流表使主机h1和h2通信mininet&gt; dpctl add-flow in_port=1,actions=output:2dpctl add-flow in_port=2,actions=output:1# 步骤2 执行如下命令查看交换机流表，两条flow entry添加成功mininet&gt; dpctl dump-flows# 步骤3 在主机h1中执行如下命令分别ping主机h2和h3 可以看到主机h1成功ping通h2，且h3没收到任何ping包。原理解析：用dpctl对交换机添加flow，让交换机从s1-eth1这个端口接收到的所有traffic都从s1-eth2这个端口发出去。用dpctl给交换机添加双向流表，因为ping包除了echo request还有echo reply。所以还需要用dpctl对交换机添加flow，让交换机从s1-eth2这个端口接收到的所有traffic都从s1-eth1这个端口发出去。添加这两条flow后，h1能够ping通h2，但是并没有为h1和h3之间添加对应的端口流表，所以h1与h3不通。 添加协议流表使h1/h2通信1234567891011# 步骤1 执行如下命令删除之前通过端口添加的流表并查看流表，确保交换机flow table为空dpctl del-flowsdpctl dump-flows# 步骤2 执行如下命令添加两条traffic类型为IPv4（0x0800）协议相关的flow entry，并查看下发的流表。dpctl add-flow dl_type=0x0800,nw_dst=10.0.0.2,actions=output:2dpctl add-flow dl_type=0x0800,nw_dst=10.0.0.1,actions=output:1dpctl dump-flows# 步骤3 在主机h1中执行如下命令分别ping主机h2和h3ping -c 3 10.0.0.2ping -c 3 10.0.0.3# 步骤4 在主机h2和h3 上查看tcpdump抓包结果 原理解析：用dpctl对交换机添加flow，让交换机把所有EtherType为0x0800（IPv4）并且destiation IP为10.0.0.2的traffic从s1-eth2这个端口发出去。用dpctl对交换机添加flow，让交换机把所有EtherType为0x0800（IPv4）并且destiation IP为10.0.0.1的traffic从s1-eth1这个端口发出去。但处在同一网段下的主机，它们之间的交流是L2 forwarding，需要靠ARP来解析MAC地址，之前只匹配了0x0800(IPv4)协议，并没有匹配到0x0806(ARP)，这样当交换机收到h1的ARP包后，因为没有控制器，flow table里面也没有相应的flow告诉它如何转发这个ARP包，交换机只能将它丢弃，从而导致h1 ping h2失败，所以需要添加ARP协议的流表来使通信。 1234# 步骤5 执行命令添加ARP（0x0806）协议相关的流表，让交换机以NORMAL形式（即广播）将所有ARP包从各个端口广播出去dpctl add-flow dl_type=0x0806,actions=NORMALdpctl dump-flows## 然后 h1可以ping通h2 Mininet流表应用实战2123456789101112131415161718192021# 步骤1 登录OpenDaylight虚拟机，执行如下命令查看OpenDaylight的启动情况，端口监听情况如下所示netstat -anput|grep 6653netstat -anput|grep 8181./bin/karaffeature:install odl-l2switch-switch-ui odl-openflowplugin-flow-services-ui odl-mdsal-apidocs odl-dluxapps-applications odl-faas-allfeature:install odl-restconffeature:install odl-l2switch-switch-uifeature:install odl-openflowplugin-flow-services-uifeature:install odl-mdsal-apidocsfeature:install odl-dluxapps-applicationsfeature:install odl-faas-all# 步骤2 mininet虚拟机打开wireshark进行抓包，监听网卡anysudo wireshark# 步骤3 sudo mn --custom exper1.py --topo mytopo --controller=remote,ip=119.255.243.31,port=6633 --switch ovs,protocols=OpenFlow13 # 这个1.3协议得设置 不然总失败，或1.1# 步骤4 执行命令pingall验证Mininet中虚拟主机的连通性# 步骤5 执行命令dpctl dump-flows查看交换机上的流表 123error: ovs-ofctl：version negotiation failed (we support version 0x01, peer supports version 0x04) 查看ovs中的流表时报错。原因是ovs-ofctl dump-flows命令默认是1.0版本，需要在命令中指定OpenFlow版本sudo ovs-ofctl dump-flows -O OpenFlow13 s1 # ovs 12# 步骤6 停止Wireshark抓包并查看抓包结果，筛选出openflow_v4协议数据包，如下图# 步骤7 打开odl控制器可以看到拓扑图如下 OpenFlow协议解析 步骤1 首先发送HELLO消息，建立初始化连接，协商使用的OpenFlow协议版本。由下图可知，ODL与Mininet之间应用的是OpenFlow1.0版本协议。 步骤2 OpenFlow版本协商完成后，控制器发送一条features_request消息获取交换机的特性信息，包括交换机的ID（DPID）、缓冲区数量、端口及端口属性等等。相应的，交换机回复features_reply消息。ofpt_feature_reply数据包详情如下，交换机的DPID是数据通道独一无二的标识符。本实验中交换机缓冲区数量（n_buffers）为256，交换机支持的流表数量（n_tables）为254，交换机所支持的功能，如下所示。 步骤3 stats reply消息用于回应stats request信息，主要是交换机回应给控制器的状态信息 步骤4 当交换机收到数据包后查找流表无匹配项时，将数据包封装在packet_in消息发给控制器，由控制器通过packet_out消息下发决策，使发送和接收数据包的两主机间进行通信。 步骤5 flow mod消息涉及流表项的下发匹配信息，下图显示的是flow mod匹配项的类型信息。 Mininet 多数据中心网络拓扑流量带宽实验实验内容 通过Mininet模拟搭建基于不同数据中心的网络拓扑。 通过程序生成真实网络流量。 实验原理数据中心基础数据中心不仅是一个网络概念，还是一个服务概念，它构成了网络基础资源的一部分，提供了一种高端的数据传输服务和高速接入服务。数据中心提供给用户综合全面的解决方法，为政府上网、企业上网、企业IT管理提供专业服务，使企业和个人能够迅速借助网络开展业务，把精力集中在其核心业务策划和网站建设上，而减少IT方面的后顾之忧。 使用mininet中的iperf工具在网络中生成UDP流量，iperf客户端传送数据流到iperf的服务端，由服务端接收并记录相关信息。网络性能评估中一个巨大的挑战就是如何生成真实的网络流量，可以通过程序来创造人工的网络流量，通过建立测试环境来模拟真实的状况。此应用主要以数据中心网络为目标场景，在mininet仿真环境中尽可能地还原数据中心内部的真实流量情况。Mininet数据中心应用价值： 树状拓扑结构容错能力强 降低数据中心成本消耗 提供重新排列的全带宽无阻碍路径 提高带宽利用率 分析数据中心网络流量性能 为真实数据中心和仿真测试床提供有用信息 在mininet中进行自定义命令iperfmulti功能拓展主要分为4步： 修改mininet/net.py 修改mininet/cli.py 修改bin/mn 重新安装Mininet核心文件：~/mininet/util/install.sh -n 操作步骤一、编写网络测试程序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081## 执行命令sudo vi openlab/mininet/mininet/net.py打开net.py文件,添加定义iperf_single()函数，实现在两个主机间进行iperf udp测试，并且在server端记录，具体代码如下，建议将代码放置在“def iperf”下 def iperf_single( self,hosts=None, udpBw=&#x27;10M&#x27;, period=60, port=5001): &quot;&quot;&quot;Run iperf between two hosts using UDP. hosts: list of hosts; if None, uses opposite hosts returns: results two-element array of server and client speeds&quot;&quot;&quot; if not hosts: return else: assert len( hosts ) == 2 client, server = hosts filename = client.name[1:] + &#x27;.out&#x27; output( &#x27;*** Iperf: testing bandwidth between &#x27; ) output( &quot;%s and %s\\n&quot; % ( client.name, server.name ) ) iperfArgs = &#x27;iperf -u &#x27; bwArgs = &#x27;-b &#x27; + udpBw + &#x27; &#x27; print &quot;***start server***&quot; server.cmd( iperfArgs + &#x27;-s -i 1&#x27; + &#x27; &gt; /home/sdnlab/log/&#x27; + filename + &#x27;&amp;&#x27;) print &quot;***start client***&quot; client.cmd( iperfArgs + &#x27;-t &#x27;+ str(period) + &#x27; -c &#x27; + server.IP() + &#x27; &#x27; + bwArgs +&#x27; &gt; /home/sdnlab/log/&#x27; + &#x27;client&#x27; + filename +&#x27;&amp;&#x27;)## 添加自定义命令iperfmulti()函数，iperfmulti函数主要是实现依次为每一台主机随机选择另一台主机作为iperf的服务器端，通过调用iperf_single，自身以客户端身份按照指定参数发送UDP流，服务器生成的报告以重定向的方式输出到文件中，使用iperfmulti命令，主机随机地向另一台主机发起一条恒定带宽的UDP数据流。具体代码如下所示,建议将代码放置在“def iperf_single”下 def iperfMulti(self, bw, period=60): base_port = 5001 server_list = [] client_list = [h for h in self.hosts] host_list = [] host_list = [h for h in self.hosts] cli_outs = [] ser_outs = [] _len = len(host_list) for i in xrange(0, _len): client = host_list[i] server = client while( server == client ): server = random.choice(host_list) server_list.append(server) self.iperf_single(hosts = [client, server], udpBw=bw, period= period, port=base_port) sleep(.05) base_port += 1 sleep(period) print &quot;test has done&quot;## sudo vi openlab/mininet/mininet/cli.py,添加如下代码，注册iperfmulti命令 ## isReadable缩进有问题？ def isReadable( poller ): &quot;Check whether a Poll object has a readable fd.&quot; for fdmask in poller.poll( 0 ): mask = fdmask[ 1 ] if mask &amp; POLLIN: return True return False def do_iperfmulti( self, line ): &quot;&quot;&quot;Multi iperf UDP test between nodes&quot;&quot;&quot; args = line.split() if len(args) == 1: udpBw = args[ 0 ] self.mn.iperfMulti(udpBw) elif len(args) == 2: udpBw = args[ 0 ] period = args[ 1 ] err = False self.mn.iperfMulti(udpBw, float(period)) else: error(&#x27;invalid number of args: iperfmulti udpBw period\\n&#x27; + &#x27;udpBw examples: 1M 120\\n&#x27;)## 执行命令sudo vi openlab/mininet/bin/mn打开mn文件，在mn中加入iperfmulti可执行命令，如下所示TESTS = &#123; name: True for name in ( &#x27;pingall&#x27;, &#x27;pingpair&#x27;, &#x27;iperf&#x27;, &#x27;iperfudp&#x27;, &#x27;iperfmulti&#x27; ) &#125;ALTSPELLING = &#123; &#x27;pingall&#x27;: &#x27;pingAll&#x27;, &#x27;pingpair&#x27;: &#x27;pingPair&#x27;, &#x27;iperfudp&#x27;: &#x27;iperfUdp&#x27;,&#x27;iperfMulti&#x27;:&#x27;iperfMulti&#x27; &#125;## 执行如下命令，重新编译Mininet。$ cd openlab/mininet/util$./install.sh -n## sudo mn命令创建一个topo，查看是否存在iperfmulti命令，以此验证iperfmulti是否成功 二、构建多数据中心网络拓扑12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758## 执行如下命令，创建多数据中心拓扑创建脚本。$ cd /home/openlab/openlab/mininet/custom$ sudo vi fattree.py#!/usr/bin/python&quot;&quot;&quot;Custom topology exampleAdding the &#x27;topos&#x27; dict with a key/value pair to generate our newly definedtopology enables one to pass in &#x27;--topo=mytopo&#x27; from the command line.&quot;&quot;&quot;from mininet.topo import Topofrom mininet.net import Mininetfrom mininet.node import RemoteController,CPULimitedHostfrom mininet.link import TCLinkfrom mininet.util import dumpNodeConnectionsclass MyTopo( Topo ): &quot;Simple topology example.&quot; def __init__( self ): &quot;Create custom topo.&quot; # Initialize topology Topo.__init__( self ) L1 = 2 L2 = L1 * 2 L3 = L2 c = [] a = [] e = [] # add core ovs for i in range( L1 ): sw = self.addSwitch( &#x27;c&#123;&#125;&#x27;.format( i + 1 ) ) c.append( sw ) # add aggregation ovs for i in range( L2 ): sw = self.addSwitch( &#x27;a&#123;&#125;&#x27;.format( L1 + i + 1 ) ) a.append( sw ) # add edge ovs for i in range( L3 ): sw = self.addSwitch( &#x27;e&#123;&#125;&#x27;.format( L1 + L2 + i + 1 ) ) e.append( sw ) # add links between core and aggregation ovs for i in range( L1 ): sw1 = c[i] for sw2 in a[i/2::L1/2]: # self.addLink(sw2, sw1, bw=10, delay=&#x27;5ms&#x27;, loss=10, max_queue_size=1000, use_htb=True) self.addLink( sw2, sw1 ) # add links between aggregation and edge ovs for i in range( 0, L2, 2 ): for sw1 in a[i:i+2]: for sw2 in e[i:i+2]: self.addLink( sw2, sw1 ) #add hosts and its links with edge ovs count = 1 for sw1 in e: for i in range(2): host = self.addHost( &#x27;h&#123;&#125;&#x27;.format( count ) ) self.addLink( sw1, host ) count += 1topos = &#123; &#x27;mytopo&#x27;: ( lambda: MyTopo() ) &#125; Mininet创建网络拓扑的代码中，可以通过改变代码中定义的L1变量来设置核心交换机的数量，并通过添加额外的交换机和链路来构成更复杂的数据中心网络拓扑。随着边缘交换机的增加，主机个数也随之增长，利用Mininet的易用性和扩展性，可以创建基于多种数据中心场景下的网络拓扑，达到更好更全面的实验效果。说明：为方便用户实验，该段代码在/home/ftp/fattree.py文件中已预置。 12## 切换到Mininet主机，执行如下命令，启动Mininet，生成测试拓扑结构。sudo mn --custom fattree.py --topo mytopo --controller=remote,ip=119.255.243.31,port=6633 --switch ovs,protocols=OpenFlow13","categories":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/categories/SDN/"}],"tags":[{"name":"网络架构","slug":"网络架构","permalink":"http://shizhonggan.github.io/tags/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/"},{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/tags/SDN/"},{"name":"OVS","slug":"OVS","permalink":"http://shizhonggan.github.io/tags/OVS/"}]},{"title":"软件定义网络（SDN）学习笔记(3)--Scapy交互式数据处理与Postman HTTP请求测试","slug":"SDN/SDN02_Scapy_Postman","date":"2021-04-20T01:15:22.000Z","updated":"2021-10-28T06:55:59.905Z","comments":true,"path":"2021/04/20/SDN/SDN02_Scapy_Postman/","link":"","permalink":"http://shizhonggan.github.io/2021/04/20/SDN/SDN02_Scapy_Postman/","excerpt":"","text":"SDN学习目录 SDN学习笔记(0)–wireshark抓包分析 SDN学习笔记(1)–iPerf和Netperf性能测试 SDN学习笔记(2)–Scapy交互式数据处理与Postman HTTP请求测试 SDN学习笔记(3)–OVS系统架构 SDN学习笔记(5)–OpenDaylight控制器 ScapyScapy 是基于python编写的交互式数据包处理程序，使用pyhon解释器作为命令面板。可以用来发送、嗅探、解析和伪造网络数据包，通常用于网络攻击和测试。 Scapy 不仅可以实现扫描、路由跟踪、探测、单元测试、攻击和发现网络等传统功能，也可以代替hping、arpspoof、arp-sk、arping、p0f,实现部分Namp、Tcpdump和tshark的功能。 它能够伪造或解码大量的网络协议数据包，能够发送、捕捉、匹配请求和回复包等。 它还可以发送无效数据帧、诸如修改的802.11数据帧、在WEP熵解码加密通道(VOIP)、ARP缓存攻击(VLAN)等，这是其他工具无法完成的。 Scapy主要负责定义、发送和接收报文。 Postman 进行SDN流表下发任务Postman是google开发的一款强大的王爷调试、发送网页HTTP请求，并能运行测试用例的Chrome插件。","categories":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/categories/SDN/"}],"tags":[{"name":"Scapy","slug":"Scapy","permalink":"http://shizhonggan.github.io/tags/Scapy/"},{"name":"Postman","slug":"Postman","permalink":"http://shizhonggan.github.io/tags/Postman/"}]},{"title":"Spark学习(1)","slug":"BigData/Spark01","date":"2021-04-17T07:54:23.000Z","updated":"2021-10-28T06:55:59.896Z","comments":true,"path":"2021/04/17/BigData/Spark01/","link":"","permalink":"http://shizhonggan.github.io/2021/04/17/BigData/Spark01/","excerpt":"","text":"Spark是基于内存的运算，效率更高，语句更加简洁。 RDD 弹性分布式数据集，以实现通用性。 安装部署 运行环境与安装包不匹配的时候，就要对源代码进行编译或生成（SBT或Maven编译）。 make-distribution.sh option param –hadoop VERSION Hadoop版本号，默认1.0.4 –with-yarn 是否支持Hadoop YARN –with-hive 是否在Spark SQL中支持hive –skip-java-test 是否编译过程中略过java测试 –with-tachyon 是否支持文件系统Tachyon –tgz 在根目录生成spark-$VERSION-bin.tgz的部署包, 若无此参数则只生成dist目录 – name 在根目录生成spark-$VERSION-bin-$NAME.tgz的部署包，与–tgz组合使用 例如： 生成支持yarn、hadoop2.2.0的部署包： ./make-distribution.sh –hadoop 2.2.0 –with-yarn –tgz 生成支持yarn、hive的部署包 ./make-distribution.sh –hadoop 2.2.0 –with-yarn –with-hive –tgz Spark Standalone 集群部署 Java 的安装 ssh 无密码登录 Spark 安装包解压 Spark配置文件配置 文件 conf/slave hadoop1 hadoop2 hadoop3 文件 conf/spark-env.sh export SPARK_MASTER_IP=hadoop1 export SPARK_MASTER_PORT=7077 export SPARK_WORKER_CORES=1 export SPARK_WORKER_INSTANCES=1 export SPARK_MEMORY=3g Spark Standalone HA 部署 基于文件系统的HA[有问题] spark.deploy.recoveryMode 设置城FILESYSTEM spark.deploy.recoveryDirectory Spark保存恢复状态的目录 Spark-env.sh里对SPARK_DAEMON_JAVA_OPTS 设置 export SPARK_DAEMON_JAVA_OPTS=”-Dspark.deploy.recoverMode=FILESYSTEM -D spark.deploy.recoveryDirectory=/app/hadoop/spark/spark100/recovery” 基于zookeeper的HA 参考博客 spark.deploy.recoveryMode 设置成ZOOKEEPER spark.deploy.zookeeper.url ZooKeeper URL spark.deploy.zookeeper.dir Zookeeper保存恢复状态的目录，缺省为/spark spark-env里对SPARK_DAEMON_JAVA_OPTS设置 export SPARK_DAEMON_JAVA_OPTS=”-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=hadoop1:2181,hadoop2:2181,hadoop3:2181 -Dspark.deploy.zookeeper.dir=/spark” Spark Standalone 伪分布式部署Spark工具介绍 Spark 交互工具spark-shell Spark 应用程序部署工具spark-submit 参数说明 J 1","categories":[{"name":"BigData","slug":"BigData","permalink":"http://shizhonggan.github.io/categories/BigData/"}],"tags":[]},{"title":"Keras学习准备[待续...]","slug":"DeepLeaning/Keras/KerasBase","date":"2021-04-17T07:54:23.000Z","updated":"2021-10-28T06:55:59.896Z","comments":true,"path":"2021/04/17/DeepLeaning/Keras/KerasBase/","link":"","permalink":"http://shizhonggan.github.io/2021/04/17/DeepLeaning/Keras/KerasBase/","excerpt":"","text":"1. 安装12345pip install tensorflowpip install tensorflow-gpupip install keras## 其他pip install pydot pydot_ng vizgraph python3-tk matplotlib 2. 主要模型 MLP(多层感知机) 全连接网络，也成为深度前馈网络或前馈神经网络。常用于简单的逻辑和线性回归问题。处理序列数据和多维数据欠佳。 CNN(卷积神经网络) 主要应用与图像或视频的分类、分割和生成等。也可用于时序数据网络 RNN(循环神经网络) 主要应用于序列数据的预测 3. 代码流程3.1 加载数据集数据集常用MNIST手写体 3. MLP 数据集 MNIST手写体 代码：https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras","categories":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://shizhonggan.github.io/categories/Deep-Learning/"}],"tags":[]},{"title":"软件定义网络（SDN）学习笔记(1)--iPerf和Netperf性能测试","slug":"SDN/SDN01_iPerf_Netperf","date":"2021-04-15T08:15:22.000Z","updated":"2021-10-28T06:55:59.905Z","comments":true,"path":"2021/04/15/SDN/SDN01_iPerf_Netperf/","link":"","permalink":"http://shizhonggan.github.io/2021/04/15/SDN/SDN01_iPerf_Netperf/","excerpt":"","text":"SDN学习目录 SDN学习笔记(0)–wireshark抓包分析 SDN学习笔记(1)–iPerf和Netperf性能测试 SDN学习笔记(2)–Scapy交互式数据处理与Postman HTTP请求测试 SDN学习笔记(3)–OVS系统架构 SDN学习笔记(5)–OpenDaylight控制器 1. iPerf and NetperfiPerf是网络性能测试工具，可以测试主机之间的吞吐量。iPerf具有多种参数和特性，支持协议、定时、缓冲区等参数的配置调整，能够测试TCP/UDP的最大带宽、延迟抖动、数据包丢失等统计信息。iPerf基于Server/Client的工作模式,客户端向服务端发送一定量的数据，服务端统计并计算带宽、延时和抖动等信息。 命令格式： iperf [-s|-c host] [options] Netperf也是网络性能测试工具，主要用于测试TCP或UDP和Berkeley套接字接口的批量数据传输(Bulk Data Transfer)和请求/应答(Request/Reponse)性能。Netperf工具以Client/Server方式工作，服务端是netServer，用来侦听来自客户端的连接，客户端时NetPerf，用来向服务发起网络测试。在客户端与服务端之间，首先建立一个控制连接，传递有关测试配置的信息，以及测试的结果。在控制连接建立并传递了测试配置信息以后，客户端与服务之间建立一个测试连接，用于来回传递特殊的流量，已测试网络性能。 命令格式：netperf [global options] –[test-specific options] 2. 性能测试指标 网络吞吐量：单位时间内通过某个网络(信道或接口)的数据量，吞吐量受网络的带宽或网络的额定速率限制，单位bit/s 网络延时：一个数据包从用户的计算机发送到网站服务器，然后立即从网站服务器返回用户计算机的来回时间。影响网络演示的主要因素：路由的跳数和网络的流量。交换机延时(Latency)是指从交换机接收到数据包到开始向目的端口复制数据包之间的时间间隔。有许多因素会影响交换机演示大小，如转发技术等。 抖动：用于描述包在网络中的传输延时变化，抖动越小，说明网络质量越稳定、越好。 丢包率：理想状态下发送多少数据包就能接收到多少数据包。但由于信号衰减、网络质量等诸多因素的影响并不能达到理想状态。丢包率是指测试中多丢失的数据包数量占所有发送数据包的比率。 3. iPerf和Netperf比较 比较项 iPerf Netperf 支持多线程 是 是 可以设置服务器关闭之前保持的连接数 是 否 支持组播 是 否 支持除TCP,UDP之外的协议 否 是 支持IPv6 一定程度上 是 可以输出TCP MSS指 是 否 设置测试分组大小 否 是 支持多种测试范式 否 是 4. 测试命令4.1 iPerf一、TCP测试1234567## 主机一 10.0.0.8# iperf -s # 作为服务端## 主机二# iperf -c 10.0.0.8# iperf -c 10.0.0.8 -t 32 -i 8 # 测试时间32s,输出频率8s# iperf -c 10.0.0.8 -n 2000M -i 5 # 数据包为2000M,输出频率5s## 主机三 与主机二 分别执行上述命令，可以观察主机一的测试结果， 不同时段的带宽相差比较大 二、UDP测试123## 主机一 10.0.0.8 停止iPerf TCP服务# iperf -s -u # UDP测试# iperf -c 10.0.0.8 -u -b 2000M -i 5 -l 1380 # -b 2000M 2000Mbit/s发送速率， -i 5 表示输出频率5s -l 1380表示数据包的大小为1380个字节 note: 若发现Server接收不到Client 端发来的包，即没有任何输出，请检查是不是Client 端发的数据包大小大于Server端网卡设置的MTU值。当不设置-l的时候，Client端默认发送的数据包大小为1470. 4.2 Netperf一、TCP测试12345## 主机一# netserver -p 9991 # 指定端口## 主机二# netperf -H 10.0.0.8 -p 9991 # 缺省TCP批量传输，即 -t TCP_STREAM# netperf -H 10.0.0.8 -p 9991 -- -m 1024 二、UDP 测试1# netperf -t UDP_STREAM -H 10.0.0.8 -p 9991 -- -m 1024 note: 不同于iPerf, Netperf测试UDP数据包无需在服务器端指定参数，所以，不用重启服务器，只需要在客户端上加上 -t UDP_STREAM","categories":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/categories/SDN/"}],"tags":[{"name":"性能测试","slug":"性能测试","permalink":"http://shizhonggan.github.io/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"},{"name":"iPerf","slug":"iPerf","permalink":"http://shizhonggan.github.io/tags/iPerf/"},{"name":"Netperf","slug":"Netperf","permalink":"http://shizhonggan.github.io/tags/Netperf/"}]},{"title":"[阅读] Few-Shot Adversarial Domain Adaptation","slug":"Paper/Few-ShotAdversarialDomainAdaptation","date":"2021-04-14T13:54:23.000Z","updated":"2021-10-28T06:55:59.902Z","comments":true,"path":"2021/04/14/Paper/Few-ShotAdversarialDomainAdaptation/","link":"","permalink":"http://shizhonggan.github.io/2021/04/14/Paper/Few-ShotAdversarialDomainAdaptation/","excerpt":"","text":"参考资料： Github Code: https://github.com/Coolnesss/fada-pytorch[作者源程序] Github Code: https://github.com/xzsl/FewShotPapers[源程序，包含数据源，参考文献] http://blog.leanote.com/post/wuvin/1f36d3173608 https://blog.csdn.net/Adupanfei/article/details/85164925 https://github.com/topics/domain-adaptation","categories":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://shizhonggan.github.io/categories/Deep-Learning/"}],"tags":[{"name":"Few-shot Learning","slug":"Few-shot-Learning","permalink":"http://shizhonggan.github.io/tags/Few-shot-Learning/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"http://shizhonggan.github.io/tags/Semi-Supervised-Learning/"}]},{"title":"软件定义网络（SDN）学习笔记(0)--wireshark抓包分析","slug":"SDN/SDN00_wireshark","date":"2021-04-09T07:36:22.000Z","updated":"2021-10-28T06:55:59.904Z","comments":true,"path":"2021/04/09/SDN/SDN00_wireshark/","link":"","permalink":"http://shizhonggan.github.io/2021/04/09/SDN/SDN00_wireshark/","excerpt":"","text":"SDN学习目录 SDN学习笔记(0)–wireshark抓包分析 SDN学习笔记(1)–iPerf和Netperf性能测试 SDN学习笔记(2)–Scapy交互式数据处理与Postman HTTP请求测试 SDN学习笔记(3)–OVS系统架构 SDN学习笔记(5)–OpenDaylight控制器 简单网络命令1. ifconfigifconfig用于显示、设置、启动和停止网络设备。通过此命令能够显示出正在使用的计算机的IP地址、子网掩码和默认网关等。当网络环境发生改变时可通过此命令对网络进行相应的配置。ifconfig命令的格式和参数解释如下： 命令格式：ifconfig [网络设备] [参数] 命令参数如下表所示： 1234567891011121314151617181920212223242526272829303132333435# ifconfig # 查看网络设备信息eth0 Link encap:Ethernet HWaddr fa:16:3e:22:f1:7c inet addr:30.0.0.96 Bcast:30.0.0.255 Mask:255.255.255.0 inet6 addr: fe80::f816:3eff:fe22:f17c/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1450 Metric:1 RX packets:2402 errors:0 dropped:0 overruns:0 frame:0 TX packets:2390 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:190993 (190.9 KB) TX bytes:4116702 (4.1 MB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:16 errors:0 dropped:0 overruns:0 frame:0 TX packets:16 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:880 (880.0 B) TX bytes:880 (880.0 B)eth0表示第一块网卡。HWaddr表示网卡的物理地址即MAC地址。inet addr表示网卡的IPv4地址。inet6 addr表示网卡的IPv6地址。Bcast表示网卡的广播地址。Mask表示子网掩码地址。UP表示网卡开启状态。RUNNING表示网卡的网线被接上。MULTICAST表示支持组播。MTU表示最大传输单元。RX packets、TX packets表示接收、发送数据包情况统计。RX byte、TX bytes表示接收、发送数据字节数统计信息。lo表示主机的回环地址。一般是用来测试一个网络程序时又不想让局域网或外网的用户能够查看，只能在此台主机上运行和查看所用的网络接口，比如把httpd服务器指定到回坏地址后，在浏览器输入127.0.0.1就能看到你所架WEB网站，但只有您能看得到，局域网的其它主机或用户无从知道。# ifconfig eth0 down # 关闭网卡# ifconfig eth0 up # 开启网卡# ifconfig eth0 192.168.2.10 netmask 255.255.255.0 broadcast 192.168.2.255 # 配置IP地址等信息 note: 机器重启后，配置的IP地址就失效了，若想将配置信息永久地存的电脑里，需要修改网卡的配置文件。 2. pingping命令用于检查网络是否通畅和网络连接速度。简单地说，网络上的机器都有唯一确定的IP地址，给目标IP地址发送一个数据包，就会返回一个同样大小的数据包，根据返回的数据包可以确定目标主机是否存在，可以初步判断网络是否通畅以及连接速度等信息。根据数据包返回时间和丢包率，可以大致判断出网络是否稳定。Ping的返回异常信息有“Request Timed Out”、“Destination Net Unreachable”、“Bad IP address”和“Source quench received”：（1） Request Timed Out表示对方主机可以到达但是连接超时，这种情况通常是对方拒绝接收你发给它的数据包而造成的数据包丢失。原因可能是对方装有防火墙。（2） Destination Net Unreachable表示对方主机不存在或者没有跟对方建立连接。（3） Bad IP address表示可能没有连接到DNS服务器所以无法解析这个IP地址，也可能是IP地址不存在。（4） Source quench received表示对方或中途的服务器繁忙无法回应。说明：“destination host unreachable”和“time out”的区别：如果所经过的路由器的路由表中具有到达目标的路由，而目标因为其它原因不可到达，这时候会出现“time out”，如果路由表中连到达目标的路由都没有，那就会出现“destination host unreachable”。ping命令的格式和参数解释如下： 命令格式：ping [参数] [主机名或IP地址] 命令参数如下表所示： 12# ping 127.0.0.1 ## ping -c 5 www.xxx.com # -c 5表示在发送5个数据包后停止。 note1: ping本网网关或本网IP地址，可以检查硬件设备是否有问题，也可以检查本机与本地网络连接是否正常（在非局域网中这一步骤可以忽略）。 3. traceroute命令traceroute是用来显示源主机到目标主机之间所经过的网关的命令。traceroute命令用IP生存时间（TTL）字段和ICMP错误消息来确定从一个主机到网络上其他主机的路由。首先，traceroute发送一个TTL是1的IP数据包到目的地，当路径上的第一个路由器收到这个数据包时，TTL将会减1。此时，TTL变为0，所以该路由器会将此数据包丢掉，并返回一个ICMP time exceeded消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址）。traceroute收到这个消息后，便知道这个路由器存在于路径上，接着traceroute再发送一个TTL是2的数据包，继而发现第2个路由器。依此规律，traceroute每次将发送的数据包的TTL加1来发现下一个路由器，一直持续到某个数据包抵达目的地。当数据包到达目的地后，该主机则不会返回ICMP time exceeded消息，此时traceroute通过UDP数据包向不常见端口（30000以上）发送数据包，因此会收到ICMP port unreachable消息，故可判断到达目的地。traceroute命令的格式和参数解释如下： 命令格式：traceroute [参数] [主机] 命令参数如下表所示： 12345# sudo su# apt-get install traceroute # 安装# traceroute www.baidu.com # 追踪网络数据包的路由途径，执行结果如下图所示# traceroute -m 10 www.baidu.com # 设置路由追踪10条，即只发回通过10个网关的信息# traceroute -w 3 www.baidu.com # 把对外发探测包的等待响应时间设置为3秒 4. route命令route用于显示和操作IP路由表，它的主要作用是创建静态路由。在Linux系统中，设置路由通常是为了解决以下问题：Linux系统在一个局域网中，局域网中有一个网关，若要让机器访问Internet，那么就需要将网关的IP地址设置为Linux机器的默认路由。route命令的格式和参数解释如下： 命令格式：route [-f] [-p] [command] [destination] [mask netmask] [gateway] [metric] [if interface] 命令参数如下表所示: 12345678# routeopenlab@openlab:~/Desktop$ routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Ifacedefault 30.0.0.1 0.0.0.0 UG 0 0 0 eth0default 30.0.0.1 0.0.0.0 UG 100 0 0 eth030.0.0.0 * 255.255.255.0 U 0 0 0 eth0169.254.169.254 30.0.0.1 255.255.255.255 UGH 0 0 0 eth0 Destination：表示目标网段或主机。 Gateway：表示网关地址，“*”表示目标是本主机所属的网络，不需要路由。 Genmask：表示网络掩码。 Flags：表示标记。常用标记如下： U表示路由是活动的 H表示目标是一个主机 G表示路由指向网关 R表示恢复动态路由产生的表项 D表示由路由的后台程序动态地安装 M表示由路由的后台程序修改 ！表示拒绝路由。 Metric：表示路由距离，到达指定网络所需的中转数（Linux内核中没有使用）。 Ref：表示路由项引用次数（Linux内核中没有使用）。 Use：表示此路由项被路由软件查找的次数。 Iface：表示该路由表项对应的输出接口。123456# route add -net 224.0.0.0 netmask 240.0.0.0 dev eth0 # 添加网关# route del -net 224.0.0.0 netmask 240.0.0.0# route add -net 192.168.62.0 netmask 255.255.255.0 gw 192.168.1.1 # 添加一条路由(发往192.168.62这个网段的全部要经过网关192.168.1.1)# route del -net 192.168.122.0 netmask 255.255.255.0 # 删除一条路由 删除的时候不用写网关 5. IPip命令用来显示或操纵Linux主机的路由、网络设备、策略路由和隧道，是Linux下较新的功能强大的网络配置工具。它能够替代一些传统的网络管理工具，例如ifconfig、route等，使用权限为超级用户，ip命令的格式和参数解释如下： 命令格式：ip [OPTIONS] OBJECT [COMMAND [ARGUMENTS]] 命令参数：OPTIONS是一些修改ip行为或者改变其输出的选项。所有的选项都是以-字符开头，分为长、短两种形式。12345# ip link list # 查看网络设备的运行状态1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000 link/ether fa:16:3e:50:89:7f brd ff:ff:ff:ff:ff:ff lo表示主机的回环地址。 eth0表示第一块网卡。 UP表示网卡开启状态。 MULTICAST表示支持组播。 mtu表示最大传输单元。 link/ether表示MAC地址。12345678910111213# ip -s link list # 查看更加详细的网络设备信息1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 RX: bytes packets errors dropped overrun mcast 880 16 0 0 0 0 TX: bytes packets errors dropped carrier collsns 880 16 0 0 0 0 2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000 link/ether fa:16:3e:50:89:7f brd ff:ff:ff:ff:ff:ff RX: bytes packets errors dropped overrun mcast 378682 3605 0 0 0 0 TX: bytes packets errors dropped carrier collsns 2422264 2317 0 0 0 0 RX packets、TX packets表示接收、发送数据包情况统计。 RX bytes、TX bytes表示接收、发送数据字节数统计信息。1234# ip addr list # 查看ip信息# ip link set eth0 down # ip link list命令# ip link set eth0 up # 开启eth0网卡# route add default gw 30.0.1.1 # 设置网关 inet表示网卡的IPv4地址。 inet6表示网卡的IPv6地址。 note: 使用ip命令关闭网卡后，默认路由也被删除了，而使用ip命令启用网卡时，并不会配置路由，所以将无法ping通公网地址，故需要配置路由。 6. netstat命令netstat是一个监控TCP/IP网络的非常有用的命令，它可以显示路由表、实际的网络连接以及每一个网络接口设备的状态信息。它用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。另外它还能列出处于监听状态（即等待接入请求）的套接字。如果你想确认系统上的Web服务有没有起来，你可以查看80端口有没有打开。netstat命令的格式和参数解释如下： 命令格式：netstat [-acCeFghilMnNoprstuvVwx][-A&lt;网络类型&gt;][—ip] 命令参数如下表所示：1234# netstat -a # 查看所有端口信息# netstat -at # 查看TCP连接# netstat -l # 查看所有处于监听状态的Sockets# netstat -ap | grep ssh # 查看程序运行的端口 7. tcpdump命令tcpdump是根据使用者的定义对网络上的数据包进行截获的包分析工具。tcpdump凭借强大的功能和灵活的截取策略，成为类UNIX系统下用于网络分析和问题排查的首选工具。tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、网络或端口的过滤。 命令格式：tcpdump [ -adeflnNOpqStvx ] [ -c 数量 ] [ -F 文件名 ][ -i 网络接口 ] [ -r 文件名] [ -s snaplen ][ -T 类型 ] [ -w 文件名 ] [表达式 ] 命令参数： tcpdump命令常用参数如下： 123456# tcpdump -i eth0 # 进行抓包# ping www.xxxx.com # 在打开一个窗口进行网络请求,可看到抓包信息# tcpdump -i eth0 tcp port 80 # 抓取端口为80的TCP协议的数据信息# tcpdump-i eth0 tcp # 抓取TCP协议的数据信息，并访问网址：www.xxx.com# tcpdump -i eth0 -w tcpdump_package.pcap # 该命令作用是将tcupdump抓到的网络包保存到tcpdump_package.pcap文件中，命名规则为：文件名.pcap。# tcpdump -r tcpdump_package.pcap # 该命令作用是将保存在tcpdump_package.pacp中的抓包信息读取出来。 练习题下面（B）命令用于测试网络是否连通。 A. ifconfig B. ping C. ftp D. route 下列相关route命令的使用错误的是（B） A. 添加路由：route add-net 192.168.1.0 netmask - 255.255.255.0 gw 192.168.1.1 B. 删除路由：route del-net 192.168.1.0 C. 添加默认网关：route add default gw 192.168.120.240 D. 添加路由：route add-net 192.168.1.0/24 dev eth0 下面输出信息解释错误的是（D） A. HWaddr表示网卡的物理地址即MAC地址。 B. inet addr表示网卡的IP地址。 C. MTU表示最大传输单元。 D. RX packets、TX packets表示接收、发送数据字节数统计信息。 判断： 使用ifconfig命令配置主机信息后，信息将永久保存在电脑里。× 判断： traceroute -m 4 www.xxx.com表示只发回通过4个网关的信息。√ 下列关于ip命令理解错误的是（B） A. ip命令用来显示或操纵Linux主机的路由、网络设备、策略路由和隧道，它能够替代一些传统的网络管理工具，例如ifconfig、route等。 B. ip命令支持的操作有add、delete、show和link。 C. 可以使用ip addr add 192.168.17.30/24 dev eth0命令给主机配置IP地址。 D. 使用ip命令的neighbour选项，可以查看接入你所在的局域网的设备的MAC地址。 关于tcpdump命令理解错误的是（B） A. tcpdump支持对网络层、协议、主机、网络或端口的过滤。 B. tcpdump -i eth1 ‘((tcp) and (port 80) and ((dst host 192.168.1.254) or (dst host 192.168.1.200)))’，表示抓取所有经过eth1，目的地址是192.168.1.254和192.168.1.200，端口是80的TCP数据。 C. 不带任何选项的tcpdump，默认会抓取第一个网络接口，且只有将tcpdump进程终止才会停止抓包。 D. 表达式单元之间可以使用操作符” and / &amp;&amp; / or / || / not / ! “进行连接，从而组成复杂的条件表达式。 下面对netstat的输出结果理解正确的是（D） A. Active Internet connections表示TCP连接；Active UNIX domain sockets表示Unix域套接口。 B. State：表示连接状态，LISTENING表示正在侦听端口，等待建立连接。 C. Proto：表示使用的通信协议。 D. 以上均正确 判断： netstat是一个网络连接端扫描软件，用来扫描电脑上开放的端口，确定哪些服务运行在哪些端口，并且推断出计算机运行的操作系统。× 判断： 使用括号”()”可以改变tcpdump的表达式的优先级 √ Wireshark抓包分析工具Wireshark是一个免费开源的网络数据包分析软件。用于截取网络数据包并尽可能显示出最为详细的网络数据包数据。为了安全考虑，Wireshark只能查看封包，而不能修改封包的内容，或者发送封包。Wireshark能够对大部分局域网协议进行解析，具有界面简单、操作方便、实时显示捕获数据的优点。Wireshark不是入侵侦测系统，对于网络上的异常流量行为，Wireshark不会产生警示或是任何提示。然而，仔细分析Wireshark撷取的封包能够帮助使用者对于网络行为有更清楚的了解。Wireshark的用途很广，网络管理员可以使用Wireshark来检测网络问题，网络安全工程师可以使用Wireshark来检查资讯安全相关问题，开发者可以使用Wireshark来为新的通讯协议除错，普通使用者可以使用Wireshark来学习网络协议的相关知识。在使用Wireshark工具时，可以按如下流程进行： 确定Wireshark的位置。即在哪执行wireshark命令，如果没有一个正确的位置，启动Wireshark后会花费很长的时间捕获一些与自己无关的数据。 选择捕获接口。一般都是选择连接到Internet网络的接口，这样才可以捕获到与网络相关的数据。否则，捕获到的其它数据对自己也没有任何帮助。 使用捕获过滤器。通过设置捕获过滤器，可以避免产生过大的捕获文件。这样用户在分析数据时，也不会受其它数据干扰。而且，还可以为用户节约大量的时间。 使用显示过滤器。通常使用捕获过滤器过滤后的数据，往往还是很复杂。为了使过滤的数据包再更细致，此时使用显示过滤器进行过滤。 使用着色规则。通常使用显示过滤器过滤后的数据，都是有用的数据包。如果想更加突出的显示某个会话，可以使用着色规则高亮显示。 构建图表。如果用户想要更明显的看出一个网络中数据的变化情况，使用图表的形式可以很方便的展现数据分布情况。 重组数据。Wireshark的重组功能，可以重组一个会话中不同数据包的信息，或者是一个重组一个完整的图片或文件。由于传输的文件往往较大，所以信息分布在多个数据包中。为了能够查看到整个图片或文件，这时候就需要使用重组数据的方法来实现。环境 控制器：Ubuntu14.03桌面版,Floodlight1.0;CPU:1,内存:2GB,磁盘:20GB 交换机：Ubuntu14.03桌面版,OVS2.3.1;CPU:1,内存:2GB,磁盘:20GB 基本使用步骤12# apt-get install wireshark # root用户下安装$ sudo wireshark # 普通用户下打开wireshark主界面，这里权限的问题，root打不开，普通用户无法获得网卡 步骤 1 选择需要抓包的网卡Wireshark是捕获机器上的某一块网卡的网络包，当你的机器上有多块网卡的时候，你需要选择一个网卡，请按下面的方式选择网卡： 方式一：选择网卡“eth0”，单击开始按钮 方式二：1)在菜单栏选择”Capture -&gt; Interfaces”，进入选择网卡的页面;2)选择网卡“eth0”，单击“Start”，进入抓包页面 步骤 2 单击浏览器图标，打开浏览器，在浏览器上访问www.sina.com.cn，进行抓包步骤 3 单击红色停止按钮停止抓包，抓包结果如下图所示 图中四个区域分别为： 为DISPLAY FILTER（显示过滤器），显示过滤器用于查找捕捉记录中的内容。 为PACKET LIST PANE（封包列表），封包列表中显示所有已经捕获的封包。可以看到发送或接收方的MAC/IP地址、TCP/UDP端口号、协议或封包的内容。 为PACKET DETAILS PANE（封包详细信息）：这里显示的是在封包列表中被选中项目的详细信息。 为DISSECTOR PANE（16进制数据）：“解析器”在Wireshark中也被叫做“16进制数据查看面板”。这里显示的内容与“封包详细信息”中相同，只是改为以16进制的格式表述。 步骤 4 根据抓包结果，分析抓包数据 在封包列表部分选择一条TCP协议数据，如下图所示。 在封包列表部分选择一条TCP协议数据，如下图所示。 图中： Frame：表示物理层数据帧概况。 Ethernet II：表示数据链路层以太网帧头部信息。 Internet Protocol Version 4：表示互联网IP包头信息。 Transmission Control Protocol：表示传输层数据段头部信息，此处为TCP。 图中： 数据链路层显示有源MAC地址，目的MAC地址。 网络层IP的版本信息显示为IPv4。协议为TCP。源IP地址30.0.0.93即本机IP地址，目的IP地址10.168.16.15即远端服务器地址。 源端口为5901，目的端口为52356。 步骤 5 过滤报文信息 过滤源IP地址 如查找源地址为30.0.0.93的报文，则在过滤框中输入ip.src==30.0.0.93进行过滤 过滤目的IP地址 如查找目的地址为10.168.16.15的报文，则在过滤框中输入ip.dst==10.168.16.15进行过滤 过滤端口 如过滤52356端口，则在过滤框中输入tcp.port==52356||udp.port==52356 过滤协议 如过滤TCP的协议，则在过滤框中输入协议名tcp进行过滤 使用连接符and过滤。 过滤两种条件时，使用and连接，如过滤ip为30.0.0.93并且为TCP协议的报文，则在过滤框中输入ip.src==30.0.0.93 and tcp进行过滤，如下图所示。步骤 6 保存Wireshark抓包数据。 捕获的数据信息可以保存在文件中，这样就可以随时在Wireshark中打开此文件进行分析，而无需再次捕获同样的数据。关闭数据捕获屏幕或退出Wireshark时，系统会提示你保存信息 练习题下面关于Wireshark说法错误的是（D） A. 捕获过滤器用来过滤捕获的封包，以免捕获太多的记录。 B. 封包列表中显示所有已经捕获的封包。可以看到发送或接收方的MAC/IP地址、TCP/UDP端口号、协议或封包的内容。 C. 显示过滤器用来告诉Wireshark只显示那些符合过滤条件的数据包。 D. Wireshark能够对大部分局域网协议进行解析，能够查看、修改封包的内容，具有界面简单、操作方便、实时显示捕获数据的优点。 下面关于Wireshark的过滤表达式描述错误的是（B） A. 过滤ip为10.0.1.1并且为http协议的报文，表达式为：ip.src==10.0.1.1 and http。 B. 如果没有特别指明来源或目的地，则默认使用源地址进行过滤。 C. 否(“not”)具有最高的优先级，或(“or”)和与(“and”)具有相同的优先级，运算时从左至右进行。 D. 对目的地址为192.168.0.1的包的过滤，表达式为：ip.dst eq 192.168.0.1。 判断：封包列表的面板中显示：编号、时间戳、源地址、目标地址、协议、长度以及封包信息，不同的协议用了不同的颜色显示，也可以自己修改这些显示的颜色规则。 √ 判断：Wireshark的捕捉过滤器支持协议过滤和内容过滤。×","categories":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/categories/SDN/"}],"tags":[{"name":"性能测试","slug":"性能测试","permalink":"http://shizhonggan.github.io/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"},{"name":"网络","slug":"网络","permalink":"http://shizhonggan.github.io/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"Hexo markdown 插入图片解决方法","slug":"HexoStudy/HexoImageFile","date":"2021-04-07T12:41:21.000Z","updated":"2021-10-28T06:55:59.901Z","comments":true,"path":"2021/04/07/HexoStudy/HexoImageFile/","link":"","permalink":"http://shizhonggan.github.io/2021/04/07/HexoStudy/HexoImageFile/","excerpt":"","text":"前言官方解决办法： https://hexo.io/zh-cn/docs/asset-folders.html 我尝试了一下这个官方办法，并未成功。于是，不得不尝试大家推荐的“图床”办法。 “图床”即第三方存储图片的地方，并能支持http/https协议以提供图片访问链接。减轻本地服务器空间，加快图片打开速度。 提供图床的第三方网站众多。出于对安全、网站服务能力的考量，建议采用gitee 作为图片托管仓库。 具体方法 新建仓库 仓库下新建index.html，此时service 里便出现gitee pages功能 点击gitee pages进入设置，直接默认确定即可，然后出现该网页链接地址 url 克隆到本地,然后将你需要的图片放到该目录下 push到仓库 于是，可以通过url+path的方式访问图片 markdown可以直接使用 温馨提示1：图要加水印 温馨提示2：gitee每次更新都要进入service-&gt;gitee page-&gt;update","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://shizhonggan.github.io/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://shizhonggan.github.io/tags/Hexo/"},{"name":"前端","slug":"前端","permalink":"http://shizhonggan.github.io/tags/%E5%89%8D%E7%AB%AF/"}]},{"title":"Gitalk 评论登录出现403 解决方法","slug":"HexoStudy/Gitalk403Solution","date":"2021-04-07T11:22:12.000Z","updated":"2021-10-28T06:55:59.901Z","comments":true,"path":"2021/04/07/HexoStudy/Gitalk403Solution/","link":"","permalink":"http://shizhonggan.github.io/2021/04/07/HexoStudy/Gitalk403Solution/","excerpt":"","text":"起因网络受限 本篇文章参考：https://cuiqingcai.com/30010.html 问题二Related Issues not found Please contact @ShizhongGan to initialize the comment 解决方法 用代理啊 换其他的","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://shizhonggan.github.io/categories/Hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://shizhonggan.github.io/tags/hexo/"},{"name":"gitalk","slug":"gitalk","permalink":"http://shizhonggan.github.io/tags/gitalk/"}]},{"title":"vs code 实用扩展插件","slug":"Tips/vscode_tips","date":"2021-04-07T06:32:06.000Z","updated":"2021-10-28T06:55:59.910Z","comments":true,"path":"2021/04/07/Tips/vscode_tips/","link":"","permalink":"http://shizhonggan.github.io/2021/04/07/Tips/vscode_tips/","excerpt":"","text":"Angular 8 and TypeScript/HTML VS Code Snippets Awesome Flutter Snippets Chinese (Simplified) Language Pack for Visual Studio Code Code Runner Code Spell Checker Dart Docker Draw.io Integration Flutter Graphviz Interactive Preview HTML Boilerplate Jupyter LaTeX Workshop Live Server Markdown All in One Markdown Mind Map Preview Markdown PDF Markdown+Math Office Viewer open in browser PlantUML python reStructuredText","categories":[{"name":"Tips","slug":"Tips","permalink":"http://shizhonggan.github.io/categories/Tips/"}],"tags":[{"name":"vs code插件","slug":"vs-code插件","permalink":"http://shizhonggan.github.io/tags/vs-code%E6%8F%92%E4%BB%B6/"}]},{"title":"Gitee部署Hexo 博客","slug":"HexoStudy/HexoGiteeDeploy","date":"2021-04-07T01:21:46.000Z","updated":"2021-10-28T06:55:59.901Z","comments":true,"path":"2021/04/07/HexoStudy/HexoGiteeDeploy/","link":"","permalink":"http://shizhonggan.github.io/2021/04/07/HexoStudy/HexoGiteeDeploy/","excerpt":"","text":"前言由于网络限制，Github部署Hexo博客加载速度慢，因此建议采用gitee进行部署。 部署方法 注册gitee账号 新建公开仓库 访问地址不带二级目录设置：如果你想你的 pages 首页访问地址不带二级目录，如ipvb.gitee.io，你需要建立一个与自己个性地址同名的项目，如 gitee.com/ipvb 这个用户，想要创建一个自己的站点，但不想以子目录的方式访问，想以ipvb.oschina.io直接访问，那么他就可以创建一个名字为ipvb的项目 gitee.com/ipvb/ipvb 部署完成后，就可以以 ipvb.gitee.io 进行访问了。 设置hexo _config.yml文件，绑定该新建的仓库 hexo d部署 该仓库的service出现gitee page功能，点击进去默认确定即可 然后通过ipvb.gitee.io即可访问 温馨提示：每次hexo d部署完，都要进入gitee page功能中update，否则无法看到网页变化。github不需要。","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://shizhonggan.github.io/categories/Hexo/"}],"tags":[{"name":"Gitee","slug":"Gitee","permalink":"http://shizhonggan.github.io/tags/Gitee/"},{"name":"Hexo","slug":"Hexo","permalink":"http://shizhonggan.github.io/tags/Hexo/"}]},{"title":"Hexo 快速搭建静态博客","slug":"HexoStudy/HexoStudy","date":"2021-04-06T02:26:34.000Z","updated":"2021-10-28T06:55:59.902Z","comments":true,"path":"2021/04/06/HexoStudy/HexoStudy/","link":"","permalink":"http://shizhonggan.github.io/2021/04/06/HexoStudy/HexoStudy/","excerpt":"","text":"环境准备12# 设置npm环境npm config set registry https://registry.npm.taobao.org 1ssh-keygen -t rsa -C &quot;gan_shizhong@163.com&quot; 12345678910# install pluginnpm install hexo-wordcount --savenpm install hexo-generator-json-content --savenpm install hexo-generator-feed --savenpm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --savenpm install hexo-neat --save# npm install hexo-translate-title --save 12345安装Hexonpm install -g hexo-clinpm install hexonpm install hexo-deployer-git --save 发布文章1hexo new page &quot;文件名&quot;","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://shizhonggan.github.io/categories/Hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://shizhonggan.github.io/tags/hexo/"},{"name":"gitalk","slug":"gitalk","permalink":"http://shizhonggan.github.io/tags/gitalk/"},{"name":"前端","slug":"前端","permalink":"http://shizhonggan.github.io/tags/%E5%89%8D%E7%AB%AF/"}]}],"categories":[{"name":"Linux","slug":"Linux","permalink":"http://shizhonggan.github.io/categories/Linux/"},{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/categories/ELK/"},{"name":"SQL","slug":"SQL","permalink":"http://shizhonggan.github.io/categories/SQL/"},{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"},{"name":"Django","slug":"Django","permalink":"http://shizhonggan.github.io/categories/Django/"},{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/categories/SDN/"},{"name":"Mininet","slug":"Mininet","permalink":"http://shizhonggan.github.io/categories/Mininet/"},{"name":"Ansible","slug":"Ansible","permalink":"http://shizhonggan.github.io/categories/Ansible/"},{"name":"网络","slug":"网络","permalink":"http://shizhonggan.github.io/categories/%E7%BD%91%E7%BB%9C/"},{"name":"AWS","slug":"AWS","permalink":"http://shizhonggan.github.io/categories/AWS/"},{"name":"运维","slug":"运维","permalink":"http://shizhonggan.github.io/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Tips","slug":"Tips","permalink":"http://shizhonggan.github.io/categories/Tips/"},{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/categories/Docker/"},{"name":"Python","slug":"Python","permalink":"http://shizhonggan.github.io/categories/Python/"},{"name":"BigData","slug":"BigData","permalink":"http://shizhonggan.github.io/categories/BigData/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://shizhonggan.github.io/categories/Deep-Learning/"},{"name":"Hexo","slug":"Hexo","permalink":"http://shizhonggan.github.io/categories/Hexo/"}],"tags":[{"name":"Shell commands","slug":"Shell-commands","permalink":"http://shizhonggan.github.io/tags/Shell-commands/"},{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/tags/ELK/"},{"name":"Nginx","slug":"Nginx","permalink":"http://shizhonggan.github.io/tags/Nginx/"},{"name":"Logstash","slug":"Logstash","permalink":"http://shizhonggan.github.io/tags/Logstash/"},{"name":"游标","slug":"游标","permalink":"http://shizhonggan.github.io/tags/%E6%B8%B8%E6%A0%87/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://shizhonggan.github.io/tags/Elasticsearch/"},{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/tags/DevOps/"},{"name":"zabbix","slug":"zabbix","permalink":"http://shizhonggan.github.io/tags/zabbix/"},{"name":"Nagios","slug":"Nagios","permalink":"http://shizhonggan.github.io/tags/Nagios/"},{"name":"JumpServer","slug":"JumpServer","permalink":"http://shizhonggan.github.io/tags/JumpServer/"},{"name":"Ansilbe","slug":"Ansilbe","permalink":"http://shizhonggan.github.io/tags/Ansilbe/"},{"name":"Django","slug":"Django","permalink":"http://shizhonggan.github.io/tags/Django/"},{"name":"RESTful API","slug":"RESTful-API","permalink":"http://shizhonggan.github.io/tags/RESTful-API/"},{"name":"OpenDaylight","slug":"OpenDaylight","permalink":"http://shizhonggan.github.io/tags/OpenDaylight/"},{"name":"那些坑","slug":"那些坑","permalink":"http://shizhonggan.github.io/tags/%E9%82%A3%E4%BA%9B%E5%9D%91/"},{"name":"网络架构","slug":"网络架构","permalink":"http://shizhonggan.github.io/tags/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/"},{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/tags/SDN/"},{"name":"OVS","slug":"OVS","permalink":"http://shizhonggan.github.io/tags/OVS/"},{"name":"运维","slug":"运维","permalink":"http://shizhonggan.github.io/tags/%E8%BF%90%E7%BB%B4/"},{"name":"网络","slug":"网络","permalink":"http://shizhonggan.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Floodlight","slug":"Floodlight","permalink":"http://shizhonggan.github.io/tags/Floodlight/"},{"name":"AWS","slug":"AWS","permalink":"http://shizhonggan.github.io/tags/AWS/"},{"name":"boto3","slug":"boto3","permalink":"http://shizhonggan.github.io/tags/boto3/"},{"name":"paramiko","slug":"paramiko","permalink":"http://shizhonggan.github.io/tags/paramiko/"},{"name":"python","slug":"python","permalink":"http://shizhonggan.github.io/tags/python/"},{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/tags/Docker/"},{"name":"OOP","slug":"OOP","permalink":"http://shizhonggan.github.io/tags/OOP/"},{"name":"Scapy","slug":"Scapy","permalink":"http://shizhonggan.github.io/tags/Scapy/"},{"name":"Postman","slug":"Postman","permalink":"http://shizhonggan.github.io/tags/Postman/"},{"name":"性能测试","slug":"性能测试","permalink":"http://shizhonggan.github.io/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"},{"name":"iPerf","slug":"iPerf","permalink":"http://shizhonggan.github.io/tags/iPerf/"},{"name":"Netperf","slug":"Netperf","permalink":"http://shizhonggan.github.io/tags/Netperf/"},{"name":"Few-shot Learning","slug":"Few-shot-Learning","permalink":"http://shizhonggan.github.io/tags/Few-shot-Learning/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"http://shizhonggan.github.io/tags/Semi-Supervised-Learning/"},{"name":"Hexo","slug":"Hexo","permalink":"http://shizhonggan.github.io/tags/Hexo/"},{"name":"前端","slug":"前端","permalink":"http://shizhonggan.github.io/tags/%E5%89%8D%E7%AB%AF/"},{"name":"hexo","slug":"hexo","permalink":"http://shizhonggan.github.io/tags/hexo/"},{"name":"gitalk","slug":"gitalk","permalink":"http://shizhonggan.github.io/tags/gitalk/"},{"name":"vs code插件","slug":"vs-code插件","permalink":"http://shizhonggan.github.io/tags/vs-code%E6%8F%92%E4%BB%B6/"},{"name":"Gitee","slug":"Gitee","permalink":"http://shizhonggan.github.io/tags/Gitee/"}]}