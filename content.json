{"meta":{"title":"钟声","subtitle":"甘士忠个人博客","description":"Sharing is meaningful","author":"甘士忠","url":"http://shizhonggan.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2022-05-07T10:07:50.294Z","updated":"2022-05-07T10:07:50.294Z","comments":false,"path":"/404.html","permalink":"http://shizhonggan.github.io/404.html","excerpt":"","text":""},{"title":"About","date":"2022-05-07T10:07:50.330Z","updated":"2022-05-07T10:07:50.330Z","comments":false,"path":"about/index.html","permalink":"http://shizhonggan.github.io/about/index.html","excerpt":"","text":""},{"title":"书单","date":"2022-05-07T10:07:50.330Z","updated":"2022-05-07T10:07:50.330Z","comments":false,"path":"books/index.html","permalink":"http://shizhonggan.github.io/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2022-05-07T10:07:50.331Z","updated":"2022-05-07T10:07:50.331Z","comments":false,"path":"categories/index.html","permalink":"http://shizhonggan.github.io/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2022-05-07T10:07:50.334Z","updated":"2022-05-07T10:07:50.334Z","comments":true,"path":"links/index.html","permalink":"http://shizhonggan.github.io/links/index.html","excerpt":"","text":""},{"title":"阅读","date":"2022-05-07T10:07:50.334Z","updated":"2022-05-07T10:07:50.334Z","comments":false,"path":"reading/index.html","permalink":"http://shizhonggan.github.io/reading/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2022-05-07T10:07:50.335Z","updated":"2022-05-07T10:07:50.335Z","comments":false,"path":"repository/index.html","permalink":"http://shizhonggan.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-05-07T10:07:50.335Z","updated":"2022-05-07T10:07:50.335Z","comments":false,"path":"tags/index.html","permalink":"http://shizhonggan.github.io/tags/index.html","excerpt":"","text":""},{"title":"","date":"2022-05-07T10:07:50.333Z","updated":"2022-05-07T10:07:50.333Z","comments":false,"path":"cv/20211210_update/index.html","permalink":"http://shizhonggan.github.io/cv/20211210_update/index.html","excerpt":"","text":"甘士忠 https://shizhongan.github.io 15822523657 gan_shizhong@163.com Experience北京光环新网科技股份有限公司 2019.6 -云计算研发工程师 光环新网云光环云主要负责云平台的代码维护、SDN应用、自动化运维以及云上相关项目的技术研发。 集群状态与日志监控预警平台构建与应用 2021.6-2021.12 维护公司云平台前后端的代码，解决客户云资源使用过程中存在的问题；AWS云平台资源自动化取证 2021.3 - 2021.6 针对违规的AWS云平台用户，协助公安机关调查取证，基于paramiko模块自定义编写脚本，批量处理AWS云镜像文件，完成云服务器资源的调查取证;SDN网络虚拟化技术自研与应用 2021.1 - 2021.3 Ansible部署Zabbix监控和Elastic Stack日志分析系统；苏州移动研发中心移动云贵州节点部署实施 2020.10 - 2020.12 基于celery模块和redis数据库，解决邮箱服务器并发问题； 2020.6-2020.9 SDN网络的学习与应用；参加苏州移动研发中心移动云贵州节点建设，要负责ceph对象存储部署、云平台环境自动化检测、neutron网络测试等。泰康集团 2019.3 - 2019.4NLP语音算法实习生基于注意力机制的LSTM的保单审核评级分类 准确率94.5% 新加坡南洋理工大学计算机学院[交流] 2017.7 - 2019.1Research Assistant主要任务： 海量数据处理，新加坡Open-street-map的百万条数据处理，企业的GPS海量数据处理，基于概率矩阵分解的缺失值插补； 在Linux系统与Docker容器平台下，实现基于隐马尔可夫模型的GPS数据与地图匹配； 基于LSTM深度学习网络，完成交通流量预测分析； 基于多种机器学习分类算法完成交通工具特征识别； 基于GAN网络的数据生成、分布学习。 Education南洋理工大学 2016.9 -2019.4 计算机工程学院 研究助理[交流] 天津工业大学 2016.9 -2019.4 信息与通信工程 研究生 天津商业大学 2012.9 - 2016.6 数学与应用数学 本科 Publications高光谱图像地物识别甘士忠, 肖志涛, 陈雷, 南瑞杰. 基于高阶非线性模型的多目标高光谱图像解混算法. 红外与激光工程. 2019. [PDF] 陈雷, 甘士忠, 孙茜. 基于回溯优化的非线性高光谱图像解混. 红外与激光工程. 2017. [PDF] 混合语音信号提取陈雷, 甘士忠,张立毅,王光艳. 基于样条插值与人工蜂群优化的非线性盲源分离算法. 通信学报. 2017. [PDF] Honors &amp; Awards第十三届中国研究生电子设计竞赛 二等奖 2018第十二届中国研究生电子设计竞赛 二等奖 2017美国数学建模竞赛 三等奖 2015中国大学生数学建模竞赛 国家二等奖、天津市一等奖 2014 Teaching 工作中主要使用Python：基于Django的web开发；基于Paramiko模块的批量处理服务器资源；基于Celery分布式任务调度；Tensorflow, Pytorch深度学习库; OpenCV库的使用; Nampy, Pandas, Spicy等数值矩阵计算;基于Request, Selenium, beautifulsoup网络爬虫。 熟悉Linux系统命令, 计算机网络 掌握Ansible, Elastic Stack, Zabbix, gitlab docker等自动化运维相关工具的使用和集群化部署 熟悉Openstack开发与部署，后端和前端的代码维护 matlab ServiceIEEE ACCESS 邀请审稿人 2019Research Experiences for Undergraduates in NTU 2017.7 - 2019.1 /* table th:first-of-type { width: 20%; } table th:nth-of-type(2) { width: 30%; } table th:nth-of-type(3) { width: 50%; } */ /* http://meyerweb.com/eric/tools/css/reset/ v2.0 | 20110126 License: none (public domain) */ /* html, */ article body, article main, article div, article span, article applet, article object, article iframe, article h1, article h2, article h3, article h4, article h5, article h6, article p, article blockquote, article pre, article a, article abbr, article acronym, article address, article big, article cite, article code, article del, article dfn, article em, article img, article ins, article kbd, article q, article s, article samp, article small, article strike, article strong, article sub, article sup, article tt, article var, article b, article u, article i, article center, article dl, article dt, article dd, article ol, article ul, article li, article fieldset, article form, article label, article legend, article table, article caption, article tbody, article tfoot, article thead, article tr, article th, article td, article article, article aside, article canvas, article details, article embed, article figure, article figcaption, article footer, /* article header, */ article hgroup, article menu, article nav, article output, article ruby, article section, article summary, article time, article mark, article audio, article video { margin: 0; padding: 0; border: 0; font-size: 100%; font: inherit; vertical-align: baseline; } /* HTML5 display-role reset for older browsers */ article article, article aside, article details, article figcaption, article figure, article footer, article header, article hgroup, article menu, article nav, article section { display: block; } article body { line-height: 1; } article ol, article ul { list-style: none; } article blockquote, article q { quotes: none; } article blockquote:before, article blockquote:after, article q:before, article q:after { content: \"\"; content: none; } article table { border-collapse: collapse; border-spacing: 0; } article br { margin-bottom: 0em; /* 设定 与下面间距1个字符， 1em也可以设为16px等 */ } /* end of reset */ article pre { display: block; font-family: monospace; white-space: pre; margin: 1em 0px; } article{ font: normal normal 400; font-size: 120%; line-height: 1.5em; /*also written as... font: normal normal 400 100%/1.5em;*/ font-family: \"Helvetica\", sans-serif; margin: 0.5in 0.5in 0.5in 0.5in; /* margin-top: 1em; margin-left: 1em; */ } article strong { font-weight: bold; } p strong { font-weight: bold; } article em { font-style: italic; } article h1 { font-family: \"Avenir Next\", sans-serif; text-align: center; /* font-size: 50pt; */ font-size: 300%; font-weight: lighter; position: relative; line-height: 1.2em; position: relative; /* left: 28%; */ } h1 strong { font-weight: normal !important; line-height: 1em; } /* Section headers */ article h2 { font-family: \"Avenir Next\", sans-serif; /* font-size: 20pt; */ font-size: 200%; text-align: center; font-weight: normal; display: flex; /* line-height: 1.5em; */ margin-top: 0.7em; margin-bottom: 0.5em; width: 100%; } article h2:after { border-bottom: 1.7px dashed #d3d3d3; /* height: 0.8em; */ margin-left: 10px; content: \"\"; flex: 1; } h3 strong { /* line-height: 2.5em; */ } article h3 { margin-top: 10px; } article code { font-family: \"Palatino\"; font-style: italic; float: right; } article li:before { content: \"-\"; position: relative; left: -0.5em; } article li { /*second line indent*/ padding-left: 2.25em; text-indent: -1.25em; /*color: #777;*/ } #contact-info { text-align: center; position: relative; font-weight: lighter; color: #ccc; /* font-family: Menlo,monospace,sans-serif; */ font-size: 80%; } article #contact-info a { text-decoration: none; } article a { text-decoration: none; color: rgb(20, 116, 151); } article hr { visibility: hidden; height: 0mm; }"},{"title":"","date":"2022-05-07T10:07:50.333Z","updated":"2022-05-07T10:07:50.333Z","comments":true,"path":"cv/weddingmusic/musiclist.html","permalink":"http://shizhonggan.github.io/cv/weddingmusic/musiclist.html","excerpt":"","text":"婚礼歌单 流程 歌曲 暖场歌曲 《Marry You》 Bruno Mars 《Lucky》 Lenka 《Could This Be love》 victoria acosta 《Nothing’s Gonna Change My Love For You》 Westlife 《Sugar》 Maroon 5 《Everybody》 Ingrid Michaelson 《Love You Like the Movies》 Anthem Lights 《我结婚了》 钟嘉欣 《暖暖》 梁静茹 《有点甜》 汪苏泷 BY2 《今天我要嫁给你》 蔡依林 《小酒窝》 林俊杰 蔡卓妍 《A Little Love》 冯曦妤 《I’m Yours》 Jason Mraz 主持人独白 《Canon In D》 (Piano)The O’Neill Brothers 新郎入场 《Can’t Stop Love》 Darin 新娘和父亲入场 《Perfect》 MADILYN 新郎走向新娘 《You Are The Reason》 Calum Scott 交接仪式 《Love Song For #1》 Corrinne May 新郎和新娘一起步入舞台 《婚礼》 Motive蓝吉 介绍新人 《婚礼》 Motive蓝吉 爱的宣言 《NaNa’s Theme》 吴俊斌 交换戒指&amp;拥吻 《How Long Will Love You》 Ellie Goulding 兄弟团姐妹团上台 《I Really Like You》 Carly Rae Jepsen 抛花球 《Beautiful Day》 Jamie Grace 父母上台 《Wedding Bell》 DEPAPEPE 父母致辞 《白昼之夜》 林隆璇 退场音乐 《Marry You》 Bruno Mars 暖场音乐循环播放 英文歌曲下载中文歌曲下载"},{"title":"","date":"2022-05-07T10:07:50.332Z","updated":"2022-05-07T10:07:50.332Z","comments":false,"path":"cv/20211210_update/en/index.html","permalink":"http://shizhonggan.github.io/cv/20211210_update/en/index.html","excerpt":"","text":"Shizhong GAN shizhongan.github.io 15822523657 gan_shizhong@163.com EducationCarnegie Mellon University 2018.9 - Ph.D. in Software Engineering Co-advised by Ken Koedinger and Josh Sunshine Columbia University 2016.9 - 2018.5 B.S. in Computer Science, Magna Cum Laude Vision, Graphics track Dickinson College 2013.9 - 2016.5 B.S. in Computer Science, Summa Cum Laude Computer Science Departmental Honors PublicationsPenrose: From Mathematical Notation to Beautiful DiagramsKatherine Ye, Wode Ni, Max Krieger, Dor Ma’ayan, Joshua Sunshine, Jonathan Aldrich, and Keenan Crane.ACM Transactions on Graphics (SIGGRAPH’20).[PDF][BibTeX][www][repo] How Domain Experts Create Conceptual Diagrams and Implications for Tool DesignDor Ma’ayan*, Wode Ni*, Katherine Ye, Chinmay Kulkarni, and Joshua Sunshine. Best Paper Honourable MentionIn Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI’20).[PDF][BibTeX] Defining Visual Narratives for Mathematics DeclarativelyMax Krieger, Wode Ni, and Joshua Sunshine.Evaluation and Usability of Programming Languages and Tools (PLATEAU 2019), co-located with UIST.[PDF][slides] Designing Declarative Language Tutorials: a Guided and Individualized ApproachAnael Kuperwajs Cohen, Wode Ni, and Joshua Sunshine.Evaluation and Usability of Programming Languages and Tools (PLATEAU 2019), co-located with UIST.[PDF][slides] Substance and Style: domain-specific languages for mathematical diagramsWode Ni*, Katherine Ye*, Joshua Sunshine, Jonathan Aldrich, and Keenan Crane. Domain-Specific Language Design and Implementation (DSLDI 2017), co-located with SPLASH.[PDF][slides][www][repo] Whiteboard Scanning Using Super-ResolutionWode Ni.Dickinson College Honors Theses. Paper 221.[PDF] ExperienceMicrosoft Research 2020.5 -Research Intern Carnegie Mellon University, Research Experiences for Undergraduate 2017.5 - 2017.8Research AssistantPenrose is a system that automatically visualizes mathematics using two domain-specific languages: Substance and Style. Co-advised by Jonathan Aldrich, Keenan Crane, Joshua Sunshine, and Katherine Ye, I designed and implemented the Style language, and extended the Substance language to support functions and logically quantified statements. Columbia University, Computer Graphics and User Interfaces Lab 2017.1 - 2017.5Research AssistantWorked with prof. Steven Feiner, on Cyber Affordance Visualization in Augumented Reality project. Developed a Microsoft Hololens application that visualizes the Columbia campus in AR environment. AsiaInfo 2015.6 - 2015.8Software Engineering InternWorked on server-side web applications and server deployment tools. MentoringMax Krieger (CMU, independent research &amp; REUSE) CMU, 2018 - NowCourtney Miller (New College of Florida, REUSE) CMU, 2019Anael Kuperwajs Cohen (Macalester College, REUSE) CMU, 2019 Honors &amp; AwardsCHI’20 Best Paper Honourable Mention Award CMU, 2020Phi Beta Kappa Dickinson, 2018Excellence in Computer Science Award Columbia, 2018Travel Award PL Mentoring Workshop (PLMW) SPLASH, 2018Tau Beta Pi, Engineering Honor Society Columbia, 2017Computer Science Departmental Honors Dickinson, 2016Pi Mu Epsilon, Mathematics Honor Society Dickinson, 2016Upsilon Pi Epsilon, Computer Science Honor Society Dickinson, 2016Alpha Lambda Delta, First year Honor Society Dickinson, 2013John Montgomery Scholarship Dickinson, 2013 TeachingTeaching Assistant, Programming Languages and Translators (COMS 4115) Columbia, 2017 - 2018Teaching Assistant, Introduction to Java II (COMP 132) Dickinson, 2016Peer Tutor, Data Structures and Problem Solving (COMP 232) Dickinson, 2016Computer Lab Consultant Dickinson, 2014 - 2016 ServiceReviewer CHI 2021Research Experiences for Undergraduates in Software Engineering Admission Committee CMU, 2019 - 2020 /* table th:first-of-type { width: 20%; } table th:nth-of-type(2) { width: 30%; } table th:nth-of-type(3) { width: 50%; } */ /* http://meyerweb.com/eric/tools/css/reset/ v2.0 | 20110126 License: none (public domain) */ /* html, */ article body, article main, article div, article span, article applet, article object, article iframe, article h1, article h2, article h3, article h4, article h5, article h6, article p, article blockquote, article pre, article a, article abbr, article acronym, article address, article big, article cite, article code, article del, article dfn, article em, article img, article ins, article kbd, article q, article s, article samp, article small, article strike, article strong, article sub, article sup, article tt, article var, article b, article u, article i, article center, article dl, article dt, article dd, article ol, article ul, article li, article fieldset, article form, article label, article legend, article table, article caption, article tbody, article tfoot, article thead, article tr, article th, article td, article article, article aside, article canvas, article details, article embed, article figure, article figcaption, article footer, /* article header, */ article hgroup, article menu, article nav, article output, article ruby, article section, article summary, article time, article mark, article audio, article video { margin: 0; padding: 0; border: 0; font-size: 100%; font: inherit; vertical-align: baseline; } /* HTML5 display-role reset for older browsers */ article article, article aside, article details, article figcaption, article figure, article footer, article header, article hgroup, article menu, article nav, article section { display: block; } article body { line-height: 1; } article ol, article ul { list-style: none; } article blockquote, article q { quotes: none; } article blockquote:before, article blockquote:after, article q:before, article q:after { content: \"\"; content: none; } article table { border-collapse: collapse; border-spacing: 0; } article br { margin-bottom: 0em; /* 设定 与下面间距1个字符， 1em也可以设为16px等 */ } /* end of reset */ article pre { display: block; font-family: monospace; white-space: pre; margin: 1em 0px; } article{ font: normal normal 400; font-size: 120%; line-height: 1.5em; /*also written as... font: normal normal 400 100%/1.5em;*/ font-family: \"Helvetica\", sans-serif; margin: 0.5in 0.5in 0.5in 0.5in; /* margin-top: 1em; margin-left: 1em; */ } article strong { font-weight: bold; } p strong { font-weight: bold; } article em { font-style: italic; } article h1 { font-family: \"Avenir Next\", sans-serif; text-align: center; /* font-size: 50pt; */ font-size: 300%; font-weight: lighter; position: relative; line-height: 1.2em; position: relative; /* left: 28%; */ } h1 strong { font-weight: normal !important; line-height: 1em; } /* Section headers */ article h2 { font-family: \"Avenir Next\", sans-serif; /* font-size: 20pt; */ font-size: 200%; text-align: center; font-weight: normal; display: flex; /* line-height: 1.5em; */ margin-top: 0.7em; margin-bottom: 0.5em; width: 100%; } article h2:after { border-bottom: 1.7px dashed #d3d3d3; /* height: 0.8em; */ margin-left: 10px; content: \"\"; flex: 1; } h3 strong { /* line-height: 2.5em; */ } article h3 { margin-top: 10px; } article code { font-family: \"Palatino\"; font-style: italic; float: right; } article li:before { content: \"-\"; position: relative; left: -0.5em; } article li { /*second line indent*/ padding-left: 2.25em; text-indent: -1.25em; /*color: #777;*/ } #contact-info { text-align: center; position: relative; font-weight: lighter; color: #ccc; /* font-family: Menlo,monospace,sans-serif; */ font-size: 80%; } article #contact-info a { text-decoration: none; } article a { text-decoration: none; color: rgb(20, 116, 151); } article hr { visibility: hidden; height: 0mm; }"},{"title":"","date":"2022-05-07T10:07:50.333Z","updated":"2022-05-07T10:07:50.333Z","comments":false,"path":"cv/20211210_update/en/index1.html","permalink":"http://shizhonggan.github.io/cv/20211210_update/en/index1.html","excerpt":"","text":"Paxton GAN shizhongan.github.io 15822523657 gan_shizhong@163.com EducationCarnegie Mellon University 2018.9 - Ph.D. in Software Engineering Co-advised by Ken Koedinger and Josh Sunshine Columbia University 2016.9 - 2018.5 B.S. in Computer Science, Magna Cum Laude Vision, Graphics track Dickinson College 2013.9 - 2016.5 B.S. in Computer Science, Summa Cum Laude Computer Science Departmental Honors PublicationsPenrose: From Mathematical Notation to Beautiful DiagramsKatherine Ye, Wode Ni, Max Krieger, Dor Ma’ayan, Joshua Sunshine, Jonathan Aldrich, and Keenan Crane.ACM Transactions on Graphics (SIGGRAPH’20).[PDF][BibTeX][www][repo] How Domain Experts Create Conceptual Diagrams and Implications for Tool DesignDor Ma’ayan*, Wode Ni*, Katherine Ye, Chinmay Kulkarni, and Joshua Sunshine. Best Paper Honourable MentionIn Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI’20).[PDF][BibTeX] Defining Visual Narratives for Mathematics DeclarativelyMax Krieger, Wode Ni, and Joshua Sunshine.Evaluation and Usability of Programming Languages and Tools (PLATEAU 2019), co-located with UIST.[PDF][slides] Designing Declarative Language Tutorials: a Guided and Individualized ApproachAnael Kuperwajs Cohen, Wode Ni, and Joshua Sunshine.Evaluation and Usability of Programming Languages and Tools (PLATEAU 2019), co-located with UIST.[PDF][slides] Substance and Style: domain-specific languages for mathematical diagramsWode Ni*, Katherine Ye*, Joshua Sunshine, Jonathan Aldrich, and Keenan Crane. Domain-Specific Language Design and Implementation (DSLDI 2017), co-located with SPLASH.[PDF][slides][www][repo] Whiteboard Scanning Using Super-ResolutionWode Ni.Dickinson College Honors Theses. Paper 221.[PDF] ExperienceMicrosoft Research 2020.5 -Research Intern Carnegie Mellon University, Research Experiences for Undergraduate 2017.5 - 2017.8Research AssistantPenrose is a system that automatically visualizes mathematics using two domain-specific languages: Substance and Style. Co-advised by Jonathan Aldrich, Keenan Crane, Joshua Sunshine, and Katherine Ye, I designed and implemented the Style language, and extended the Substance language to support functions and logically quantified statements. Columbia University, Computer Graphics and User Interfaces Lab 2017.1 - 2017.5Research AssistantWorked with prof. Steven Feiner, on Cyber Affordance Visualization in Augumented Reality project. Developed a Microsoft Hololens application that visualizes the Columbia campus in AR environment. AsiaInfo 2015.6 - 2015.8Software Engineering InternWorked on server-side web applications and server deployment tools. MentoringMax Krieger (CMU, independent research &amp; REUSE) CMU, 2018 - NowCourtney Miller (New College of Florida, REUSE) CMU, 2019Anael Kuperwajs Cohen (Macalester College, REUSE) CMU, 2019 Honors &amp; AwardsCHI’20 Best Paper Honourable Mention Award CMU, 2020Phi Beta Kappa Dickinson, 2018Excellence in Computer Science Award Columbia, 2018Travel Award PL Mentoring Workshop (PLMW) SPLASH, 2018Tau Beta Pi, Engineering Honor Society Columbia, 2017Computer Science Departmental Honors Dickinson, 2016Pi Mu Epsilon, Mathematics Honor Society Dickinson, 2016Upsilon Pi Epsilon, Computer Science Honor Society Dickinson, 2016Alpha Lambda Delta, First year Honor Society Dickinson, 2013John Montgomery Scholarship Dickinson, 2013 TeachingTeaching Assistant, Programming Languages and Translators (COMS 4115) Columbia, 2017 - 2018Teaching Assistant, Introduction to Java II (COMP 132) Dickinson, 2016Peer Tutor, Data Structures and Problem Solving (COMP 232) Dickinson, 2016Computer Lab Consultant Dickinson, 2014 - 2016 ServiceReviewer CHI 2021Research Experiences for Undergraduates in Software Engineering Admission Committee CMU, 2019 - 2020 /* table th:first-of-type { width: 20%; } table th:nth-of-type(2) { width: 30%; } table th:nth-of-type(3) { width: 50%; } */ /* http://meyerweb.com/eric/tools/css/reset/ v2.0 | 20110126 License: none (public domain) */ /* html, */ article body, article main, article div, article span, article applet, article object, article iframe, article h1, article h2, article h3, article h4, article h5, article h6, article p, article blockquote, article pre, article a, article abbr, article acronym, article address, article big, article cite, article code, article del, article dfn, article em, article img, article ins, article kbd, article q, article s, article samp, article small, article strike, article strong, article sub, article sup, article tt, article var, article b, article u, article i, article center, article dl, article dt, article dd, article ol, article ul, article li, article fieldset, article form, article label, article legend, article table, article caption, article tbody, article tfoot, article thead, article tr, article th, article td, article article, article aside, article canvas, article details, article embed, article figure, article figcaption, article footer, /* article header, */ article hgroup, article menu, article nav, article output, article ruby, article section, article summary, article time, article mark, article audio, article video { margin: 0; padding: 0; border: 0; font-size: 100%; font: inherit; vertical-align: baseline; } /* HTML5 display-role reset for older browsers */ article article, article aside, article details, article figcaption, article figure, article footer, article header, article hgroup, article menu, article nav, article section { display: block; } article body { line-height: 1; } article ol, article ul { list-style: none; } article blockquote, article q { quotes: none; } article blockquote:before, article blockquote:after, article q:before, article q:after { content: \"\"; content: none; } article table { border-collapse: collapse; border-spacing: 0; } article br { margin-bottom: 0em; /* 设定 与下面间距1个字符， 1em也可以设为16px等 */ } /* end of reset */ article pre { display: block; font-family: monospace; white-space: pre; margin: 1em 0px; } article{ font: normal normal 400; font-size: 120%; line-height: 1.5em; /*also written as... font: normal normal 400 100%/1.5em;*/ font-family: \"Helvetica\", sans-serif; margin: 0.5in 0.5in 0.5in 0.5in; /* margin-top: 1em; margin-left: 1em; */ } article strong { font-weight: bold; } p strong { font-weight: bold; } article em { font-style: italic; } article h1 { font-family: \"Avenir Next\", sans-serif; text-align: center; /* font-size: 50pt; */ font-size: 300%; font-weight: lighter; position: relative; line-height: 1.2em; position: relative; /* left: 28%; */ } h1 strong { font-weight: normal !important; line-height: 1em; } /* Section headers */ article h2 { font-family: \"Avenir Next\", sans-serif; /* font-size: 20pt; */ font-size: 200%; text-align: center; font-weight: normal; display: flex; /* line-height: 1.5em; */ margin-top: 0.7em; margin-bottom: 0.5em; width: 100%; } article h2:after { border-bottom: 1.7px dashed #d3d3d3; /* height: 0.8em; */ margin-left: 10px; content: \"\"; flex: 1; } h3 strong { /* line-height: 2.5em; */ } article h3 { margin-top: 10px; } article code { font-family: \"Palatino\"; font-style: italic; float: right; } article li:before { content: \"-\"; position: relative; left: -0.5em; } article li { /*second line indent*/ padding-left: 2.25em; text-indent: -1.25em; /*color: #777;*/ } #contact-info { text-align: center; position: relative; font-weight: lighter; color: #ccc; /* font-family: Menlo,monospace,sans-serif; */ font-size: 80%; } article #contact-info a { text-decoration: none; } article a { text-decoration: none; color: rgb(20, 116, 151); } article hr { visibility: hidden; height: 0mm; }"}],"posts":[{"title":"Jupyter 远程服务器部署与使用","slug":"Python/Jupyter","date":"2022-10-13T02:46:43.040Z","updated":"2022-10-13T02:46:43.040Z","comments":true,"path":"2022/10/13/Python/Jupyter/","link":"","permalink":"http://shizhonggan.github.io/2022/10/13/Python/Jupyter/","excerpt":"","text":"部署12345678910111213141516171819202122232425262728293031pip3 install jupyter -i https://pypi.douban.com/simple/# 登陆服务器生成配置文件jupyter notebook --generate-configWriting default config to: /root/.jupyter/jupyter_notebook_config.py# 生成密码ipython3from notebook.auth import passwdpasswd()Enter password:Verify password:Out[2]: &#x27;argon2:$argon2id$v=19$m=10240,t=10,p=8$d7KY0z59c4W2D35oUhsfOQ$ksuiDsWhogYFfuNqUxSa5IpayeOQVecbROGoXceza/k&#x27;# 修改配置文件# 将ip设置为*，意味允许任何IP访问c.NotebookApp.ip = &#x27;*&#x27;# 这里的密码就是上边我们生成的那一串c.NotebookApp.password = &#x27;sha1:3c7ece6d01a3:aef0f9818ea49be2c2f2cc5f5a6228fd327ec00d&#x27;# 服务器上并没有浏览器可以供Jupyter打开c.NotebookApp.open_browser = False# 监听端口设置为8888或其他自己喜欢的端口c.NotebookApp.port = 8888# 我们可以修改jupyter的工作目录，也可以保持原样不变，如果修改的话，要保证这一目录已存在#c.MappingKernelManager.root_dir = &#x27;/root/jupyter_run&#x27;# 允许远程访问c.NotebookApp.allow_remote_access = Truejupyter notebook --ip=0.0.0.0 --no-browser --allow-rootnohup jupyter notebook --ip=0.0.0.0 --no-browser --allow-root &amp;","categories":[{"name":"Python","slug":"Python","permalink":"http://shizhonggan.github.io/categories/Python/"}],"tags":[{"name":"Jupyter","slug":"Jupyter","permalink":"http://shizhonggan.github.io/tags/Jupyter/"}]},{"title":"","slug":"DevOps/demo","date":"2022-10-13T02:46:42.893Z","updated":"2022-10-13T02:46:42.909Z","comments":true,"path":"2022/10/13/DevOps/demo/","link":"","permalink":"http://shizhonggan.github.io/2022/10/13/DevOps/demo/","excerpt":"","text":"This is a demo project required by SRE role.The candidate should be able to complete the project independently in two days and well document the procedure in a practical and well understanding way.It is not guaranteed that all tasks can be achieved as expected, in which circumstance, the candidate should trouble shoot the issue, conclude based on findings and document which/why/how. Task 0: Install a ubuntu 18.04 server 64-biteither in a physical machine or a virtual machine (choose any hypervisor like virtualbox, vmware workstation/fusion, kvm, hyper-v, …. )Use virtualbox as a quick start: https://www.virtualbox.org/http://releases.ubuntu.com/18.04/http://releases.ubuntu.com/18.04/ubuntu-18.04.5-live-server-amd64.iso https://segmentfault.com/a/1190000022468063 https://nsrc.org/workshops/2014/btnog/raw-attachment/wiki/Track2Agenda/ex-virtualbox-portforward-ssh.htm For virtualbox VM, use network NAT and forward required ports to host machine, like:22-&gt;22222 for ssh80-&gt;28080 for gitlab8081/8082-&gt;28081/28082 for go app31080/31081-&gt;31080/31081 for go app in k8s Task 1: Update systemssh to guest machine from host machine ($ ssh user@localhost -p 22222) and update the system to the latesthttps://help.ubuntu.com/18.04/serverguide/apt.htmlupgrade the kernel to the 18.04 latestNote: You may need to change the default apt repo to local to avoid network issue, like: # cat /etc/apt/sources.list deb http://mirrors.163.com/ubuntu bionic main restricted deb http://mirrors.163.com/ubuntu bionic-updates main restricted deb http://mirrors.163.com/ubuntu bionic universe deb http://mirrors.163.com/ubuntu bionic-updates universe deb http://mirrors.163.com/ubuntu bionic multiverse deb http://mirrors.163.com/ubuntu bionic-updates multiverse deb http://mirrors.163.com/ubuntu bionic-backports main restricted universe multiverse deb http://mirrors.163.com/ubuntu bionic-security main restricted deb http://mirrors.163.com/ubuntu bionic-security universe deb http://mirrors.163.com/ubuntu bionic-security multiverse 123456789101112131415mv /etc/apt/sources.list /etc/apt/sources.list.bakecho &#x27;deb http://mirrors.163.com/ubuntu bionic main restricteddeb http://mirrors.163.com/ubuntu bionic-updates main restricteddeb http://mirrors.163.com/ubuntu bionic universedeb http://mirrors.163.com/ubuntu bionic-updates universedeb http://mirrors.163.com/ubuntu bionic multiversedeb http://mirrors.163.com/ubuntu bionic-updates multiversedeb http://mirrors.163.com/ubuntu bionic-backports main restricted universe multiversedeb http://mirrors.163.com/ubuntu bionic-security main restricteddeb http://mirrors.163.com/ubuntu bionic-security universedeb http://mirrors.163.com/ubuntu bionic-security multiverse&#x27; &gt; /cat/etc/apt/sources.listsudo apt-get updatesudo apt-get upgrade Task 2: install gitlab-ce version in the hosthttps://about.gitlab.com/install/#ubuntu?version=ceExpect output: Gitlab is up and running at http://127.0.0.1 (no tls or FQDN required)Access it from host machine http://127.0.0.1:28080 参考：https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-gitlab-on-ubuntu-18-04 1234567sudo apt updatesudo apt install ca-certificates curl openssh-server postfixcurl -LO https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.shbash /tmp/script.deb.shapt install gitlab-ce Task 3: create a demo group/project in gitlabnamed demo/go-web-hello-world (demo is group name, go-web-hello-world is project name).Use golang to build a hello world web app (listen to 8081 port)Check-in the code to mainline (need to use git).https://golang.org/https://gowebexamples.com/hello-world/Expect source code at http://127.0.0.1:28080/demo/go-web-hello-world Task 4: build the app and expose ($ go run) the service to 28081 portExpect output from host machine:curl http://127.0.0.1:28081Go Web Hello World! Task 5: install dockerhttps://docs.docker.com/install/linux/docker-ce/ubuntu/Note: To avoid default docker repo access issue (could not pull images), you can add mirror registry like this: # cat /etc/docker/daemon.json { “registry-mirrors”: [“https://hub-mirror.c.163.com&quot;] } # systemctl daemon-reload # systemctl restart docker 1234567apt install ca-certificates curl gnupg lsb-releasemkdir -p /etc/apt/keyringscurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpgecho &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/nullapt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin Task 6: run the app in containerbuild a docker image ($ docker build) for the web app and run that in a container ($ docker run), expose the service to 28082 (-p)https://docs.docker.com/engine/reference/commandline/build/Check in the Dockerfile into gitlabExpect output from host machine:curl http://127.0.0.1:28082Go Web Hello World! 123456789101112131415161718192021222324252627282930313233343536package mainimport ( &quot;fmt&quot; &quot;net&#x2F;http&quot;)func main() &#123; http.HandleFunc(&quot;&#x2F;&quot;, func(w http.ResponseWriter, r *http.Request) &#123; fmt.Fprintf(w, &quot;\\n Go Web Hello World!\\n&quot;) &#125;) http.ListenAndServe(&quot;:8081&quot;, nil)&#125;# Create build stage based on buster imageFROM golang:alpine# Create working directory under &#x2F;appWORKDIR &quot;&#x2F;app&quot;# Install any required modules#RUN go mod download# Copy over Go source codeCOPY hello.go &#x2F;app&#x2F;hello.goRUN go build hello.go# Run the Go build and output binary under hello_go_http# Make sure to expose the port the HTTP server is usingEXPOSE 8082# Run the app binary when we run the containerENTRYPOINT [&quot;.&#x2F;hello&quot;]docker build -t goweb .docker run -d -p 8083:8082 --name goweb gowebdocker tag goweb ganshizhong&#x2F;go-web-hello-world:v0.1docker push ganshizhong&#x2F;go-web-hello-world:v0.1docker pull ganshizhong&#x2F;go-web-hello-world:v0.1 Error response from daemon: Get https://registry-1.docker.io/v2/: dial tcp: lookup registry-1.docker.io: Temporary failure in name resolutionQ：删除所有none镜像docker rmi docker images | grep &quot;&lt;none&gt;&quot; | awk &#39;&#123;print $3&#125;&#39;参考： https://blog.csdn.net/weixin_42581414/article/details/105954828 Task 7: push image to dockerhubtag the docker image using your_dockerhub_id/go-web-hello-world:v0.1 and push it to docker hub (https://hub.docker.com/)Expect output: https://hub.docker.com/repository/docker/your_dockerhub_id/go-web-hello-world Task 8: document the procedure in a MarkDown filecreate a README.md file in the gitlab repo and add the technical procedure above (0-7) in this file Task 9: install a single node Kubernetes cluster using kubeadmhttps://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/Check in the admin.conf file into the gitlab repo 12sudo apt-get updatesudo apt-get install -y apt-transport-https ca-certificates curl https://blog.csdn.net/qq_44895681/article/details/107413950 https://blog.csdn.net/H12590400327/article/details/103740602 https://www.jianshu.com/p/8e78e0abddf9 https://blog.csdn.net/weixin_43168190/article/details/107227626 https://www.cnblogs.com/dream397/p/13814166.html https://www.quwenqing.com/archives/1899.html 12kubeadm init --image-repository=registry.aliyuncs.com/google_containers Task 10: deploy the hello world containerin the kubernetes above and expose the service to nodePort 31080Expect output:curl http://127.0.0.1:31080Go Web Hello World!Check in the deployment yaml file or the command line into the gitlab repo https://galaxyyao.github.io/2019/06/24/%E5%AE%B9%E5%99%A8-8-Kubernetes%E5%AE%9E%E6%88%98-k8s%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B9%8BNode-Pod%E4%B8%8EDeployment/ https://kubernetes.io/zh-cn/docs/reference/kubectl/cheatsheet/ https://kubernetes.io/zh-cn/docs/tasks/debug/debug-application/_print/ 1234567891011121314kubectl get nodes # 节点，相当于一台容器kubectl describe node &#x27;node-name&#x27;kubectl kubectl run myweb --image=ganshizhong/go-web-hello-world:v0.1 --port=8082 -o yaml &gt; goweb.ymalkubectl expose deployment goweb --port=31080 --target-port=8082kubectl rollout restart deployment gowebkubectl edit svc -n kkubernetes-dashboard 12345678910111213141516171819202122232425262728293031apiVersion: v1kind: Servicemetadata: creationTimestamp: &quot;2022-09-16T02:38:43Z&quot; labels: app: goweb name: goweb namespace: default resourceVersion: &quot;30824&quot; uid: a9c5fab5-3c4a-49b7-bb80-cdbb58e72e3dspec: clusterIP: 10.111.191.86 clusterIPs: - 10.111.191.86 externalTrafficPolicy: Cluster internalTrafficPolicy: Cluster ipFamilies: - IPv4 ipFamilyPolicy: SingleStack ports: - nodePort: 51828 port: 31080 protocol: TCP targetPort: 8082 selector: app: goweb sessionAffinity: None type: NodePort # 将&#96;ClusterIP&#96;替换为 &#96;NodePort&#96; 会自动产生一个nodePort端口，修改即可status: loadBalancer: &#123;&#125; Task 11: install kubernetes dashboardand expose the service to nodeport 31081https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/Expect output: https://127.0.0.1:31081 (asking for token) Task 12: generate token for dashboard login in task 11figure out how to generate token to login to the dashboard and publish the procedure to the gitlab. 123https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.mdkubectl -n kubernetes-dashboard create token admin-user Task 13: publish your workpush all files/procedures in your local gitlab repo to remote github repo (e.g. https://github.com/your_github_id/go-web-hello-world)if this is for an interview session, please send it to &#x62;&#111;&#46;&#99;&#x75;&#105;&#64;&#101;&#114;&#x69;&#99;&#115;&#115;&#x6f;&#x6e;&#x2e;&#x63;&#111;&#109;, no later than two calendar days after the interview. 123456789101112131415161718192021222324252627apiVersion: apps&#x2F;v1kind: Deploymentmetadata: name: my-go-appspec: replicas: 3 selector: matchLabels: app: my-go-app template: metadata: labels: app: my-go-app spec: containers: - name: go-app-container image: registry.cn-shanghai.aliyuncs.com&#x2F;your_hubname_xxxx&#x2F;servertest:1.0.0 imagePullPolicy: IfNotPresent resources: limits: memory: &quot;512Mi&quot; cpu: &quot;500m&quot; requests: memory: &quot;64Mi&quot; cpu: &quot;100m&quot; ports: - containerPort: 8000 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869apiVersion: v1kind: Podmetadata: creationTimestamp: &quot;2022-09-16T02:06:39Z&quot; labels: run: deplyment name: deplyment namespace: default resourceVersion: &quot;13869&quot; uid: b6f661e5-a718-4774-bfcb-5921e5058d04spec: containers: - args: - myweb image: ganshizhong&#x2F;go-web-hello-world:v0.1 imagePullPolicy: IfNotPresent name: deplyment ports: - containerPort: 8082 protocol: TCP resources: &#123;&#125; terminationMessagePath: &#x2F;dev&#x2F;termination-log terminationMessagePolicy: File volumeMounts: - mountPath: &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount name: kube-api-access-dglgf readOnly: true dnsPolicy: ClusterFirst enableServiceLinks: true preemptionPolicy: PreemptLowerPriority priority: 0 restartPolicy: Always schedulerName: default-scheduler securityContext: &#123;&#125; serviceAccount: default serviceAccountName: default terminationGracePeriodSeconds: 30 tolerations: - effect: NoExecute key: node.kubernetes.io&#x2F;not-ready operator: Exists tolerationSeconds: 300 - effect: NoExecute key: node.kubernetes.io&#x2F;unreachable operator: Exists tolerationSeconds: 300 volumes: - name: kube-api-access-dglgf projected: defaultMode: 420 sources: - serviceAccountToken: expirationSeconds: 3607 path: token - configMap: items: - key: ca.crt path: ca.crt name: kube-root-ca.crt - downwardAPI: items: - fieldRef: apiVersion: v1 fieldPath: metadata.namespace path: namespacestatus: phase: Pending qosClass: BestEffort 报错1234567891011单节点，preemption: 0/1 nodes are available: 1 Preemption is not helpful for schedulinghttps://www.cnblogs.com/fat-girl-spring/p/14538991.htmlroot@demo:/home/gsz# kubectl describe node demo |grep TaintTaints: node-role.kubernetes.io/control-plane:NoScheduleroot@demo:/home/gsz# kubectl taint node demo node-role.kubernetes.io/control-plane:NoSchedule-node/demo untaintedroot@demo:/home/gsz# kubectl describe node demo |grep TaintTaints: &lt;none&gt;","categories":[],"tags":[]},{"title":"Linux IO Multiplexing, Select vs Poll vs Epoll","slug":"Linux/IO_multiplexing","date":"2022-09-26T07:39:04.000Z","updated":"2022-10-13T02:46:42.940Z","comments":true,"path":"2022/09/26/Linux/IO_multiplexing/","link":"","permalink":"http://shizhonggan.github.io/2022/09/26/Linux/IO_multiplexing/","excerpt":"","text":"介绍One basic concept of Linux (actually Unix) is the rule that everything in Unix/Linux is a file. Each process has a table of file descriptors that point to files, sockets, devices and other operating system objects. Typical system that works with many IO sources has an initializaion phase and then enter some kind of standby mode – wait for any client to send request and response it. Simple solution is to create a thread (or process) for each client , block on read until a request is sent and write a response. This is working ok with a small amount of clients but if we want to scale it to hundred of clients, creating a thread for each client is a bad idea. File Descriptor:A file descriptor is a number that uniquely identifies an open file in a computer’s operating system. It describes a data resource, and how that resource may be accessed. When a program asks to open a file — or another data resource, like a network socket — the kernel: Grants access. Creates an entry in the global file table. Provides the software with the location of that entry. The descriptor is identified by a unique non-negative integer, such as 0, 12, or 567. At least one file descriptor exists for every open file on the system. File descriptors were first used in Unix, and are used by modern operating systems including Linux, macOS, and BSD. In Microsoft Windows, file descriptors are known as file handles. When a process makes a successful request to open a file, the kernel returns a file descriptor which points to an entry in the kernel’s global file table. The file table entry contains information such as the inode of the file, byte offset, and the access restrictions for that data stream (read-only, write-only, etc.). On a Unix-like operating system, the first three file descriptors, by default, are STDIN (standard input), STDOUT (standard output), and STDERR (standard error). Name File descriptor Description Abbreviation Standard input 0 The default data stream for input, for example in a command pipeline. In the terminal, this defaults to keyboard input from the user. stdin Standard output 1 The default data stream for output, for example when a command prints text. In the terminal, this defaults to the user’s screen. stdout Standard error 2 The default data stream for output that relates to an error occurring. In the terminal, this defaults to the user’s screen. stderr 1find / -name &#x27;*something*&#x27; 2&gt;/dev/null The errors sent to /dev/null, and are not displayed. IO MultiplexingThe solution is to use a kernel mechanism for polling over a set of file descriptors. There are 3 options you can use in Linux: select(2) poll(2) epoll All the above methods serve the same idea, create a set of file descriptors , tell the kernel what would you like to do with each file descriptor (read, write, ..) and use one thread to block on one function call until at least one file descriptor requested operation available Select System CallThe select( ) system call provides a mechanism for implementing synchronous multiplexing I/O sh int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); A call to select( ) will block until the given file descriptors are ready to perform I/O, or until an optionally specified timeout has elapsed The watched file descriptors are broken into three sets: File descriptors listed in the readfds set are watched to see if data is available for reading. File descriptors listed in the writefds set are watched to see if a write operation will complete without blocking. File descriptors in the exceptfds set are watched to see if an exception has occurred, or if out-of-band data is available (these states apply only to sockets). Select – summary: We need to build each set before each call The function check any bit up to the higher number – O(n) We need to iterate over the file descriptors to check if it exists on the set returned from select The main advantage of select is the fact that it is very portable – every unix like OS has it Poll system callUnlike select(), with its inefficient three bitmask-based sets of file descriptors, poll( ) employs a single array of nfds pollfd structures. the prototype is simpler: 1int poll (struct pollfd *fds, unsigned int nfds, int timeout); 参考https://devarea.com/linux-io-multiplexing-select-vs-poll-vs-epoll/#.Yxb5AHZBxD8 File descriptor：https://www.computerhope.com/jargon/f/file-descriptor.htm#:~:text=A%20file%20descriptor%20is%20a,Grants%20access. epoll python example:http://scotdoyle.com/python-epoll-howto.html select, poll, epoll:https://jvns.ca/blog/2017/06/03/async-io-on-linux--select--poll--and-epoll/","categories":[{"name":"Linux","slug":"Linux","permalink":"http://shizhonggan.github.io/categories/Linux/"}],"tags":[{"name":"io multiplexing","slug":"io-multiplexing","permalink":"http://shizhonggan.github.io/tags/io-multiplexing/"},{"name":"select","slug":"select","permalink":"http://shizhonggan.github.io/tags/select/"},{"name":"poll","slug":"poll","permalink":"http://shizhonggan.github.io/tags/poll/"},{"name":"epoll","slug":"epoll","permalink":"http://shizhonggan.github.io/tags/epoll/"}]},{"title":"基于React 后台系统开发","slug":"NetworkSecurityPrj/react_admin","date":"2022-09-22T06:22:12.000Z","updated":"2022-10-13T02:46:42.987Z","comments":true,"path":"2022/09/22/NetworkSecurityPrj/react_admin/","link":"","permalink":"http://shizhonggan.github.io/2022/09/22/NetworkSecurityPrj/react_admin/","excerpt":"","text":"设置12345678910yarn create react-app test-admincd test-admin/yarn add react-admin ra-data-json-server prop-typesyarn start## 我采用如下方法，与上面一样npm install -g create-react-appcreate-react-app my-appcd my-app/npm add react-admin ra-data-json-server prop-typesnpm start 1234567891011121314151617 npm start Starts the development server. npm run build Bundles the app into static files for production. npm test Starts the test runner. npm run eject Removes this tool and copies build dependencies, configuration files and scripts into the app directory. If you do this, you can’t go back!We suggest that you begin by typing: cd test-admin npm start 与API建立连接vi src/App.js 12345678910// in src/App.jsimport * as React from &quot;react&quot;;import &#123; Admin &#125; from &#x27;react-admin&#x27;;import jsonServerProvider from &#x27;ra-data-json-server&#x27;;const dataProvider = jsonServerProvider(&#x27;https://jsonplaceholder.typicode.com&#x27;);const App = () =&gt; &lt;Admin dataProvider=&#123;dataProvider&#125; /&gt;;export default App; 参考https://marmelab.com/react-admin/Tutorial.html https://codesandbox.io/examples/package/ant-design-pro 文件夹结构： https://pro.ant.design/zh-CN/docs/folder","categories":[{"name":"React","slug":"React","permalink":"http://shizhonggan.github.io/categories/React/"}],"tags":[{"name":"React","slug":"React","permalink":"http://shizhonggan.github.io/tags/React/"}]},{"title":"python进阶知识点","slug":"Python/advance_tip","date":"2022-08-30T05:39:04.000Z","updated":"2022-10-13T02:46:43.056Z","comments":true,"path":"2022/08/30/Python/advance_tip/","link":"","permalink":"http://shizhonggan.github.io/2022/08/30/Python/advance_tip/","excerpt":"","text":"1. 关键字is 和 == 的区别 作用在于比较两个变量是否指向了同一个对象，is所比较的是对象，而==比较的是对象所指代的值 12345a = &#x27;hello world&#x27;b = &#x27;hello world&#x27;c = a[:]print(id(a), id(b), id(c)) # 都指向同一个对象 ,1706679966576 1706679966576 1706679966576print(a==b, a is b, a is c) # 都为True, True True True 123456&gt;&gt;&gt; a = &#x27;hello world&#x27;&gt;&gt;&gt; b = &#x27;hello world&#x27;&gt;&gt;&gt; print(a==b)True&gt;&gt;&gt; print(a is b)False 2. 深拷贝和浅拷贝 深拷贝指的是复制内容，单独开辟一个内存，浅拷贝指的是两个变量同时指向一个内存ID。 12345678910import copya = [1,2,3,4,5]b = a #浅拷贝，a,b同时指向一个id,当其中一个修改时，另外一个也会被修改。c = copy.deepcopy(a) #深拷贝，c单独开辟一个id,用来存储和a一样的内容。d =a[:] #这样也是深拷贝。e = copy.copy(a) # 当拷贝内容是可变类型时，那么就会进行深拷贝，如果是不可变类型时，那么就会进行浅拷贝f = (1,3)g = copy.copy(f)print(id(a),id(b),id(c),id(d),id(e),id(f),id(g)) # 1706683021760 1706683021760 1706683112832 1706683111872 1706683034368 1706679894144 1706679894144 3. 私有化和Property 我们可以使用@property装饰器来创建只读属性，@property装饰器会将方法转换为相同名称的只读属性,可以与所定义的属性配合使用，这样可以防止属性被修改。 Python 代码遵循统一的访问原则，公认的原则包括： 直接暴露实例变量，应当是foo.x = 0, 而不是 foo.set_x(0) if you need to wrap the accesses inside methods, for whatever reason, use @property, which preserves the access semantics. That is, foo.x = 0 now invokes foo.set_x(0). 在方法或变量前加上单下划线或者双下划线只是约定为private`，但无法阻止外部对内部方法的访问和修改。 12345678910111213141516171819202122232425262728293031class Person: def __init__(self, first_name): self._first_name = first_name self._last_name = &#x27;gan&#x27; # Getter函数 @property def first_name(self): return self._first_name # Setter函数 @first_name.setter def first_name(self, value): if not isinstance(value, str): raise TypeError(&#x27;不是字符串。&#x27;) self._first_name = value # Deleter函数 @first_name.deleter def first_name(self): raise AttributeError(&#x27;不能删除。&#x27;) @property def last_name(self): # #方法加入@property后，这个方法相当于一个属性，这个属性可以让用户进行使用，而且用户有没办法随意修改。 return self._last_namea = Person(&#x27;ke&#x27;)print(a.first_name)a.first_name = 42# TypeError: 不是字符串。del a.first_name# AttributeError: 不能删除。 上述三个相关联的方法，名字必须一样。 第一个方法是Getter函数，使first_name成为一个属性。 其他两个方法给first_name属性添加Setter、Deleter函数。只有first_name属性被创建后，后面的装饰器@first_name.setter、@first_name.deleter才能被定义。此时，可以修改 访问property时会自动触发getter、setter、deleter方法。 1234567891011121314```参考:- https://www.cnblogs.com/keye/p/15714098.html- https://www.cnblogs.com/techflow/p/12747480.html## 4. 列表生成式 与 生成器&gt; 生成器占用内存小，在使用的时候取值，降低CPU和内存空间，提高效率。并且一般都使用for循环进行取值。```pyrange(1,100,5) #第一个参数表示开始位，第二个参数表示结束位（不含），第三个参数表示步长，就是每5个数返回一次。a = [i for i in range(1,10)] #列表生成式表示返回i的值，并且返回9次，每次返回的是i的值。a = [2 for i in range(1,10)] #这里表示返回2，并且返回9次，但是每次的值都是2。a = [i for i in range10 if i%2==0] #表示在生成式内部加入if判断，当i除以2的余数等于0的时候将数值返回。a = [(i,j) for i in range(5) for j in range(5)] #表示将i和j的值以元组为元素的形式返回，当i循环一次的时候j循环5次，以此类推。 1234567891011a = (i for i in range(1,10)) #将列表生成试外部的中括号改为小括号，就能将生成式转化为生成器。print(next(a),a.__next__()) #生成器的取值方式只能使用next的方法。def num(): a,b = 0,1 for i in range(10): yield b #生成关键字yield，有yield的关键字的代码块就是yield的生成器。当运行到yield时代码就会停止，并返回运行结果，当在次运行时依旧是到yield停止，并返回结果。 切记：生成器只能使用next方法。 a,b = b,a+b temp = yield b #这里并不是变量的定义，当运行到yield时就会停止，所以当运行到等号右边的时候就会停止运行，当在次使用next的时候，将会把一个None赋值给temp，因为b的值已经在上轮循环中输出。这里可以使用num().send()方法将一个新的值赋值给temp。a = num() #将生成器赋值给变量a。for n in a: #生成器可以使用for循环使用，并且不会出错。 print(n) 5. 迭代器 生成器是可迭代对象，迭代器不一定是生成器。并且迭代器无法回取，只能向前取值。 一个对象具有 iter 方法的才能称为可迭代对象，使用yield生成的迭代器函数，也有iter方法。凡是没有iter方法的对象不是可迭代对象，凡是没有__next__()方法的不是是生成器。（这里的方法都是魔法方法，是内置方法，可以使用dir（）查看） 12345678910for i in &#x27;a&#x27;,[1,2],(3),&#123;4&#125;: pass#可以for循环的对象是可迭代对象。a = (i for i in range(100))#列表生成式，把中括号改为小括号就可以变为一个列表生成器，是可迭代对象。from collections.abc import Iterable #如果想验证是否是可迭代对象，可以使用isinstance()判断是否是可迭代对象。print(isinstance(&#x27;abc&#x27;,Iterable)) #判断语法a1 = [1,2,3,4,5]b1 = iter(a1) #使用iter()方法可以将可迭代对象转换为可迭代对象。 参考主体框架参考：https://blog.csdn.net/qq_41853758/article/details/82853811","categories":[{"name":"Python","slug":"Python","permalink":"http://shizhonggan.github.io/categories/Python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://shizhonggan.github.io/tags/python/"}]},{"title":"Python classmethod() 示例","slug":"Python/class_methods","date":"2022-08-30T05:39:04.000Z","updated":"2022-10-13T02:46:43.056Z","comments":true,"path":"2022/08/30/Python/class_methods/","link":"","permalink":"http://shizhonggan.github.io/2022/08/30/Python/class_methods/","excerpt":"","text":"介绍A Python class is like an outline for creating a new object. An object is anything that you wish to manipulate or change while working through the code. Every time a class object is instantiated, which is when we declare a variable, a new object is initiated from scratch. A class can contain different methods including: instance methods class methods static methods Python的类中包含实例方法、静态方法和类方法三种方法。这些方法无论是在代码编排中还是内存中都归属于类，区别在于传入的参数和调用方式不同。在类的内部，使用def关键字来定义一个方法。 python类方法 classmethod()类方法由类调用，采用@classmethod装饰，至少传入一个cls（代指类本身，类似self）参数。执行类方法时，自动将调用该方法的类赋值给cls。建议只使用类名.类方法的调用方式。（虽然也可以使用实例名.类方法的方式调用）","categories":[{"name":"Python","slug":"Python","permalink":"http://shizhonggan.github.io/categories/Python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://shizhonggan.github.io/tags/python/"},{"name":"classmethod","slug":"classmethod","permalink":"http://shizhonggan.github.io/tags/classmethod/"}]},{"title":"使用bind chroot配置DNS Server (CentOS/RHEL 7/8)","slug":"Linux/DNSserver","date":"2022-08-30T03:39:04.000Z","updated":"2022-10-13T02:46:42.940Z","comments":true,"path":"2022/08/30/Linux/DNSserver/","link":"","permalink":"http://shizhonggan.github.io/2022/08/30/Linux/DNSserver/","excerpt":"","text":"安装Bind Chroot RPM","categories":[{"name":"Linux","slug":"Linux","permalink":"http://shizhonggan.github.io/categories/Linux/"}],"tags":[{"name":"DNS server","slug":"DNS-server","permalink":"http://shizhonggan.github.io/tags/DNS-server/"},{"name":"Centos","slug":"Centos","permalink":"http://shizhonggan.github.io/tags/Centos/"},{"name":"bind chroot","slug":"bind-chroot","permalink":"http://shizhonggan.github.io/tags/bind-chroot/"}]},{"title":"基于Gunicorn与Nginx部署Flask","slug":"Python/FlaskDeploy_Gunicorn_nginx","date":"2022-08-29T01:39:04.000Z","updated":"2022-10-13T02:46:43.025Z","comments":true,"path":"2022/08/29/Python/FlaskDeploy_Gunicorn_nginx/","link":"","permalink":"http://shizhonggan.github.io/2022/08/29/Python/FlaskDeploy_Gunicorn_nginx/","excerpt":"","text":"1. 介绍Flask 是一个 WSGI应用程序。WSGI服务器用于运行应用程序，将传入的 HTTP 请求转换为标准的 WSGI 环境，并将传出的 WSGI 响应转换为 HTTP 响应。 WSGI协议: Web框架致力于如何生成HTML代码，而Web服务器用于处理和响应HTTP请求。Web框架和Web服务器之间的通信，需要一套双方都遵守的接口协议。WSGI协议就是用来统一这两者的接口的。 WSGI容器: 常用的WSGI容器有Gunicorn和uWSGI，但Gunicorn直接用命令启动，不需要编写配置文件，相对uWSGI要容易很多，所以这里我也选择用Gunicorn作为容器。 gunicorn: 是一个python Wsgi http server，只支持在Unix系统上运行，来源于Ruby的unicorn项目。Gunicorn使用prefork master-worker模型（在gunicorn中，master被称为arbiter），能够与各种wsgi web框架协作。 nginx: 使用gunicorn时试图将其绑定到80或者443端口，发现无效。如果想绑定到这些端口，常见的有如下的几种方法： 使用Nginx代理转发。 sudo启动gunicorn。 安装额外的程序。 2. 环境 OS: Ubuntu 20.04.1 Python version: 3.8.10 Flask version: 2.0.1 Gunicorn version: 20.1.0 Nginx version: 1.18.0 3. 安装部署3.1 python3与pip3安装123456789# 确定python3已经安装python3 --versionsudo apt update# 若python3未安装sudo apt install python3.8# 若提示 安装 python3.x-venv 才可创建虚拟环境sudo apt install python3.8-venv# 若pip3(python库管理工具)未安装sudo apt install python-pip 3.2 创建虚拟环境12345mkdir flask-gunicorn # 创建项目文件夹cd flask-gunicorn/python3 -m venv menv # 创建虚拟环境**menv**source ./menv/bin/activate # 激活虚拟环境deactivate # 退出 3.3 安装flask gunicorn1pip3 install flask gunicorn 3.4 创建Flask Web Application1mkdir flask-blog &amp;&amp; cd flask-blog/ 创建html模板文件夹 1mkdir templates &amp;&amp; cd templates/ 在模板文件夹下创建index.html 123456789101112&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;Hello&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h2&gt;Hello world!&lt;/h2&gt;&lt;/body&gt;&lt;/html&gt; 项目根目录下创建app.py脚本 12345678910from flask import Flask, render_templateapp = Flask(__name__)@app.route(&quot;/&quot;)def main(): return render_template(&quot;index.html&quot;)if __name__ == &quot;__main__&quot;: app.run(host=&#x27;0.0.0.0&#x27;,port=8999,debug=True) 启动应用 1python3 app.py 3.5 配置Gunicorn项目根目录下创建wsgi.py文件，作为应用程序的接入点 1234from app import appif __name__ == &quot;__main__&quot;: app.run() 项目目录结构如下： 123456.├── app.py├── templates│ └── index.html└── wsgi.py 启动Gunicorn option detail -w 指定服务器worker的个数 –bind 指定接口和端口，接口0.0.0.0将是服务器的公网IP 123456789gunicorn -w 4 --bind 0.0.0.0:8999 wsgi:app###[2022-08-30 08:38:34 +0800] [976060] [INFO] Starting gunicorn 20.1.0[2022-08-30 08:38:34 +0800] [976060] [INFO] Listening at: http://0.0.0.0:8999 (976060)[2022-08-30 08:38:34 +0800] [976060] [INFO] Using worker: sync[2022-08-30 08:38:34 +0800] [976062] [INFO] Booting worker with pid: 976062[2022-08-30 08:38:34 +0800] [976063] [INFO] Booting worker with pid: 976063[2022-08-30 08:38:34 +0800] [976064] [INFO] Booting worker with pid: 976064[2022-08-30 08:38:34 +0800] [976065] [INFO] Booting worker with pid: 976065 将Gunicorn配置为系统服务use Gunicorn as systemd service 将gunicorn修改为系统服务，这样即可通过systemd启停服务，并跟随服务器开机自动启动. 首先，创建一个以.service结尾的 /etc/systemd/system/my-flask.service文件，添加内容如下： 1234567891011121314[Unit]Description=Flask Web Application Server using GunicornAfter=network.target[Service]User=rootGroup=rootWorkingDirectory=/home/ec2-user/work/flask-gunicorn/flask-blogEnvironment=&quot;PATH=/home/ec2-user/work/flask-gunicorn/myenv/bin&quot;ExecStart=/bin/bash -c &#x27;source /home/ec2-user/work/flask-gunicorn/menv/bin/activate; gunicorn -w 3 --bind unix:/tmp/my-server/ipc.sock wsgi:app&#x27;Restart=always[Install]WantedBy=multi-user.target 该系统服务会在network服务up之后启动 User和Group可以根据全选需要适当选择，这里选择了最高权限的root用户用户组，与nginx通信也可只选择www-data用户组 WorkingDirecotry指定了 flask web app所在的路径 Environment指定了flask web app所需虚拟环境的路径 ExecStart包含通过gunicoron启动服务的命令，以及其他所需命令 unix:/tmp/my-server/ipc.sock wsgi:app是socket接口，用来与gunicron服务通信(interpersonal communication, IPC), 当服gunicorn启动服务的时候生成该socket文件，服务停止时即删除，也因此将产生的socket文件存放在/tmp目录下。同时，Nginx可以通过这个产生的socket文件与gunicorn通信 123mkdir /tmp/flask-serversudo systemctl enable my-flask --nowsudo systemctl status my-server.service 如果出现任何错误，可以通过journalctl -u my-server.service命令，并按Ctrl+G查看日志输出，可根据错误信息排查问题。 通过Supervisor 配置 Gunicorn(Configure Gunicorn as Supervisor)除了将Gunicron服务配置为系统守护进程，可以选择Supervisor监控服务 123456# 先停systemd 守护进程systemctl stop my-flasksystemctl disable my-flasksudo apt install supervisorpython3 -m pip install supervisor supervisord-dependent-startup # pip3 安装 修改配置文件/etc/supervisord/supervisord.conf 12345678910111213141516171819[supervisord]nodaemon=truepidfile = /tmp/supervisord.pidlogfile = /tmp/supervisord.loglogfile_maxbytes = 10MBlogfile_backups=10loglevel = debug[unix_http_server]file = /tmp/supervisor.sock[supervisorctl]serverurl = unix:///tmp/supervisor.sock[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface[include]files = /etc/supervisord.d/*.conf 同时在/etc/supervisord/supervisord.d/路径下，添加gunicorn.conf配置文件： 123456789[program:flask_catalog] command=/bin/bash -c &#x27;source /home/ec2-user/work/flask-gunicorn/menv/bin/activate; gunicorn -w 3 --bind unix:/tmp/my-server/ipc1.sock wsgi:app&#x27;directory=/home/ec2-user/work/flask-gunicorn/flask-bloguser=rootgroup=rootautostart=true autorestart=true stdout_logfile=/tmp/app.log stderr_logfile=/tmp/error.log 123456supervisord # 启动supervisorctl update # 更新配置supervisorctl status # 查看进程supervisorctl start xxx # 启动某个进程supervisorctl stop xxxx # 停止某个进程supervisorctl stop all 3.6 配置Nginx1sudo apt install nginx Nginx相关文件存放在/etc/nginx/nginx路径下，需要修改nginx配置文件，将nginx作为flask web app 的代理。nginx.conf是主要配置文件，通常开发人员或系统管理员不会修改此配置文件，新的配置文件会在sites-available/目录下修改，并链接到/sites-enabled/目录下。因此可在sites-available/目录下创建配置文件my-flask： 12345678server &#123; listen 8999; location &#x2F; &#123; include proxy_params; proxy_pass http:&#x2F;&#x2F;unix:&#x2F;tmp&#x2F;my-server&#x2F;ipc1.sock; &#125;&#125; 执行 nginx -t 确保配置文件语法正确，无误之后建立符号链接 1234sudo nginx -tsudo ln -s /etc/nginx/sites-available/my-flask /etc/nginx/sites-enabled/sudo ls -l /etc/nginx/sites-enabled/ 1nginx -s reload 以上配置使nginx监听8999端口，代理连接生成的socket文件，gunicorn可以从socket文件读取数据并允许flask web app 产生响应，然后gunicorn将flask web app的响应的数据写到socket文件，提供给nginx读取并返回用户 验证nginx代理请求，http://ip:8999，会得到响应 配置Nginx服务域名通过server_name给服务添加域名，添加一行配置如下： 123456789server &#123; listen 80; server_name server.example.com; ## 添加 location &#x2F; &#123; include proxy_params; proxy_pass http:&#x2F;&#x2F;unix:&#x2F;tmp&#x2F;my-server&#x2F;ipc1.sock; &#125;&#125; 然后在/etc/hosts添加域名解析，或者搭建配置DNS服务器便于查找域名 12...192.168.0.188 server.example.com 故障排查 sudo journalctl -u SERVICE 检查系统服务相关的错误 查看supervisord日志文件，提供了stderr_logfile和stdout_logfile，可以查看相关的错误 /var/log/nginx/access.log and /var/log/nginx/error.log可查看nginx相关错误 总结介绍了采用Gunicorn和Nginx部署flask应用的过程，利用gunicorn和nginx的并发性可以简单的对其配置文件进行扩展。 参考https://www.golinuxcloud.com/flask-gunicorn-nginx/ https://wizardforcel.gitbooks.io/the-way-to-flask/content/chapter013.html","categories":[{"name":"python","slug":"python","permalink":"http://shizhonggan.github.io/categories/python/"}],"tags":[{"name":"Flask","slug":"Flask","permalink":"http://shizhonggan.github.io/tags/Flask/"},{"name":"gunicorn","slug":"gunicorn","permalink":"http://shizhonggan.github.io/tags/gunicorn/"},{"name":"nginx","slug":"nginx","permalink":"http://shizhonggan.github.io/tags/nginx/"}]},{"title":"Kubernetes 架构","slug":"Python/K8s/architecture","date":"2022-08-29T01:39:04.000Z","updated":"2022-10-13T02:46:43.056Z","comments":true,"path":"2022/08/29/Python/K8s/architecture/","link":"","permalink":"http://shizhonggan.github.io/2022/08/29/Python/K8s/architecture/","excerpt":"","text":"介绍Kubernets 又称 K8s，由Google开发，用于容器编排。 容器编排 容器1 的应用依赖其他容器的应用，如数据库、消息、日志服务 在服务峰值时，需要扩大容器数量，提高应用服务资源，服务运行低谷时，减少容器数量 需要提供编排容器互联、自动伸缩的资源管理平台 容器编排（container orchestration）即部署、管理容器的过程 Kubernetes 即一种容器编排技术，用于编排集群环境中成百上千个容器的部署和管理 类似的技术还有：Docker Swarm, Kubernetes(Google), Mesos(Apache) 通过容器编排技术可以实现： Highly available,多个节点上存在多个应用实例 用户流量在各种容器之间进行负载均衡 Scalability当需求增加时，在几秒钟内无缝地部署更多应用程序实例，当我们耗尽硬件资源时，我们有能力在服务级别上完成这一工作，然后在不关闭应用程序的情况下扩展底层节点的数量，这一切都可以使用一组声明性对象配置文件轻松完成。 Disaster recovery 备份和恢复 安装参考https://www.golinuxcloud.com/kubernetes-architecture/ https://www.kubernetes.org.cn/k8s https://www.cnblogs.com/chiangchou/p/k8s-1.html","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://shizhonggan.github.io/categories/Kubernetes/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://shizhonggan.github.io/tags/Kubernetes/"}]},{"title":"Python基础","slug":"Python/python_interview","date":"2022-08-20T01:39:04.000Z","updated":"2022-10-13T02:46:43.056Z","comments":true,"path":"2022/08/20/Python/python_interview/","link":"","permalink":"http://shizhonggan.github.io/2022/08/20/Python/python_interview/","excerpt":"","text":"Python类和对象实例方法、静态方法、类方法区别http://c.biancheng.net/view/4552.html https://blog.csdn.net/qq_35642036/article/details/82854063 https://www.cnblogs.com/clschao/articles/10463267.html https://zhuanlan.zhihu.com/p/372957129#:~:text=Django%E5%AE%9E%E7%8E%B0%E6%82%B2%E8%A7%82%E9%94%81&amp;text=%E5%AE%83%E6%9C%AC%E8%B4%A8%E6%98%AF%E4%B8%80%E4%B8%AA%E8%A1%8C,%E8%A1%A8)%EF%BC%8C%E7%9B%B4%E5%88%B0%E4%BA%8B%E5%8A%A1%E7%BB%93%E6%9D%9F%E3%80%82 https://www.cnblogs.com/clschao/articles/10463267.html https://www.jianshu.com/p/6b45b150bfbf 服务器如何应对海量访问方法 Nginx 做负载均衡 CDN内容分发 做缓存 Nginx 限流 根据IP控制速率 控制并发连接数 1234567http&#123; limit_req_zone $binary_remote_addr zone&#x3D;contentRateLimit:10m rate&#x3D;2r&#x2F;s;&#125;http&#123; limit_conn perip 10;#单个客户端ip与服务器的连接数． limit_conn perserver 100; ＃限制与服务器的总连接数&#125; 参考：https://blog.csdn.net/weixin_43945983/article/details/106720933?spm=1001.2101.3001.6661.1&amp;utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EOPENSEARCH%7ERate-1-106720933-blog-99713416.pc_relevant_multi_platform_featuressortv2dupreplace&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EOPENSEARCH%7ERate-1-106720933-blog-99713416.pc_relevant_multi_platform_featuressortv2dupreplace&amp;utm_relevant_index=1","categories":[{"name":"python","slug":"python","permalink":"http://shizhonggan.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://shizhonggan.github.io/tags/python/"}]},{"title":"GitLab CI/CD 学习笔记","slug":"Git/gitlab_cicd","date":"2022-07-29T07:35:04.000Z","updated":"2022-08-05T12:34:58.244Z","comments":true,"path":"2022/07/29/Git/gitlab_cicd/","link":"","permalink":"http://shizhonggan.github.io/2022/07/29/Git/gitlab_cicd/","excerpt":"","text":"主要内容 使用docker部署ci/cd 环境 使用gitlab ci/cd 解决各种项目集成，部署问题 讲解ci/cd涉及到的各个组件、流程，知识点 实践各种部署项目的流水线 docker 部署 gitlab12345678910sudo docker run --detach \\ --hostname gitlab.ganshizhong.com \\ --publish 8011:80 --publish 8010:22 \\ --name gitlab \\ --restart always \\ --volume &#x2F;home&#x2F;ec2-user&#x2F;work&#x2F;gitlab&#x2F;config:&#x2F;etc&#x2F;gitlab \\ --volume &#x2F;home&#x2F;ec2-user&#x2F;work&#x2F;gitlab&#x2F;logs:&#x2F;var&#x2F;log&#x2F;gitlab \\ --volume &#x2F;home&#x2F;ec2-user&#x2F;work&#x2F;gitlab&#x2F;data:&#x2F;var&#x2F;opt&#x2F;gitlab \\ --shm-size 256m \\ gitlab&#x2F;gitlab-ce:latest 启动成功后，第一次登陆，直接用 root 用户，密码任意设置即可 1docker logs -f gitlab # 查看日志 CI/CD基础知识gitlab ci/cd gitlab runner pipline stage job .gitlab-ci.yml 定义流水线 1234sudo docker run -d --name gitlab-runner --restart always \\ -v &#x2F;home&#x2F;ec2-user&#x2F;work&#x2F;gitlab-runner&#x2F;config:&#x2F;etc&#x2F;gitlab-runner \\ -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock \\ gitlab&#x2F;gitlab-runner:latest docker-runner 注册 1234567891011docker run --rm -v &#x2F;home&#x2F;ec2-user&#x2F;work&#x2F;gitlab-runner&#x2F;config:&#x2F;etc&#x2F;gitlab-runner gitlab&#x2F;gitlab-runner register \\ --non-interactive \\ --executor &quot;docker&quot; \\ --docker-image alpine:latest \\ --url &quot;http:&#x2F;119.255.249.177:8011&#x2F;&quot; \\ --registration-token &quot;v_ghrbXKzYU3LWo6Qfb2&quot; \\ --description &quot;first-register-runner&quot; \\ --tag-list &quot;test-cicd1,dockercicd1&quot; \\ --run-untagged&#x3D;&quot;true&quot; \\ --locked&#x3D;&quot;false&quot; \\ --access-level&#x3D;&quot;not_protected&quot; gitlab-ci.yml 介绍与编写","categories":[{"name":"Git","slug":"Git","permalink":"http://shizhonggan.github.io/categories/Git/"}],"tags":[{"name":"gitlab","slug":"gitlab","permalink":"http://shizhonggan.github.io/tags/gitlab/"},{"name":"docker","slug":"docker","permalink":"http://shizhonggan.github.io/tags/docker/"},{"name":"ci/cd","slug":"ci-cd","permalink":"http://shizhonggan.github.io/tags/ci-cd/"}]},{"title":"计算机网络","slug":"NetWorking/networkbasic","date":"2022-07-27T03:03:04.000Z","updated":"2022-08-05T12:34:58.244Z","comments":true,"path":"2022/07/27/NetWorking/networkbasic/","link":"","permalink":"http://shizhonggan.github.io/2022/07/27/NetWorking/networkbasic/","excerpt":"","text":"应用程序 计算机组成原理 描述计算机是什么？计算是怎么回事？硬件如何为应用提供计算？ 操作系统 最大的实践意义是：如何合理规划应用的生命周期以及资源使用。比如如何处理高并发、如何提升系统的稳定性、如何节约硬件成本等。 计算机网络： 讲的是应用之间如何进行通信、如何设计应用之间的契约，形成稳定、高效、规范的协作关系（也就是协议），通过优化网络的性能，最终节省成本或者让用户满意 为了让页面秒开、服务秒回，所作出的努力 为了优化网络传输细节，去调整TCP的滑动窗口 为了提升网络的吞吐量、减少延迟，去开启多路复用能力 为了避免Downtime,去调整网络的连接池和线程数 为了开发某个应用，尝试理解应用层协议，如：SSH、RTCP、HTTP2.0、MQTT 为了做好日常开发，去理解一些基本概念，如：DNS、CDN、NAT、IPv4/6等 算法和数据结构【重学数据结构与算法，公瑾，笔记：https://www.cnblogs.com/jmcui/p/15224732.html】 算法是一个设计过程，数据结构是数据的组织方式 在给定资源的条件下，最低的延迟、最少的计算时间、最大的空间利用率 图形学 AI是将数据看作为图片，从图形中找到概率特征 编程技巧 需要深入学习 编译原理 程序语言如何被实现，源代码如何被编译 常见问题TCP队头阻塞，没有预备方案，导致分布式集群中部分发生延迟，导致系统雪崩 DDoS DNS 跨机房通信问题 TCP 为什么要三次握手HTTPS协议的TTFB传输时间DNS故障排查Linux下 诸如 nslookup, telnet, lsof, netstat等网络相关的指令一知半解导致不知道如何定位问题。 使用TCP连接时需注意问题只考虑收发数据、不能考虑到队头阻塞、多路复用等问题，导致经常出现系统负载不高、但是吞吐量很低的情况 网络调试、网络优化常识问题 telnet调试远程服务、用whireshark抓包定位网络故障 把ulimit设置成多少？ Dubbo异步单一连接扛不住了该怎么办？ 用HTTP协议的Keep-Alive维持心跳可不可行？ 开发应用或程序时，用什么协议？用哪个网络框架？ 没有办法优化参数，或者当承接了系统优化的工作时，由于计算机网络知识不扎实，会陷入无穷无尽的学习 TCP队头阻塞 滑动窗口 ARP和路由算法 网络的基础机构路由器、交换机、终端、基站等以及背后隐含的网络 网络的工作原理 算法问题 滑动窗口、路由和寻址 细节问题 封包格式 工作原理 多路复用、缓存设计、Socket、I/O模型等 网络的应用场景HTTPS 协议握手的过程RPC 是如何工作的IM系统是如何工作的抓包用什么工具要注意什么安全攻防网络出了问题怎么排查 计算机网络 互联网和传输层协议 互联网的整体架构 TCP协议 TCP的封包格式 TCP的原理和算法 UDP协议 网络层协议 IP协议 IPv6协议 局域网和NAT 实战：TCP/IP抓包 网络编程 Socket是什么 Socket和I/O模型 流和缓冲区 BIO, NIO, AIO RPC框架原理 Web技术 DNS CDN HTTP协议 流媒体技术 爬虫和反爬虫 网络安全 加密、解密和证书 信任链 常见攻防手段 互联网和传输层协议 互联网的体系和整体架构 硬件设备以及作用 传输层协议TCP和UDP 1. 漫游互联网： 什么是蜂窝移动网络 交换技术的本质：让数据切换路径 网络中的数据是以分组或封包(Packet)的形式 具备交换的网络设备： 路由器（Router）和链路层交换机（Link-Layer Switch） 在移动网络中，无线信号构成了通信链路，通信的核心被称为蜂窝塔（Cellular Tower），有时候也被称为基站（BaseStation）。ISP 将网络供给处于蜂窝网络边缘的路由器，路由器连接蜂窝塔，再通过蜂窝塔（基站）提供处于六边形地区中的设备。 在蜂窝网络一定范围内的区域，离用户较近的地方还可以部署服务器，帮助用户完成计算。这相当于计算资源的下沉，称为 “边缘计算”。相比中心化的计算，边缘计算延迟低、链路短，能够将更好的体验带给距离边缘计算集群最近的节点。从而让用户享受到更优质、延迟更低、算力更强的服务。 通信链路是一个抽象概念，这里说的抽象，就是面向对象中抽象类和继承类的关系，比如公司网络使用同轴电缆作为通信链路、移动网络使用无线信号的发送接收器作为通信链路、家用网络使用蓝牙信道作为通信链路等； 我们可以把网络传输分为两类，一类是端对端（Host-to-Host）的能力，由 TCP/IP 协议群提供；另一类是广播的能力，是一对多、多对多的能力，可以看作端对端（Host-to-Host）能力的延伸。 2. 传输层协议TCP: TCP为什么是握手3次、挥手是4次TCP（Transport Control Protocol）是一个传输层协议，提供 Host-To-Host 数据的可靠传输，支持全双工，是一个连接导向的协议。 TCP/IP 协议群 应用层提供的是应用到应用（Application-To-Application）的协议，比如微信和微信服务器； 传输层提供的是主机到主机（Host-To-Host）的协议，比如手机、平板、Linux 主机等； 网络层提供的是地址到地址（Address-To-Address）的协议，IP 协议就在这一层工作； 链路层提供的是设备到设备（Device-To-Device）的协议； 物理层提供最底层的传输能力，当信号在两个设备间传递的时候，物理层封装最底层的物理设备、传输介质等 TCP（Transport Control Protocol）是一个传输层协议，提供 Host-To-Host 数据的可靠传输，支持全双工，是一个连接导向的协议。 TCP 上层的应用层协议使用 TCP 能力的时候，需要告知 TCP 是哪个应用 —— 这就是端口号，端口号用于区分应用。 连接（Connection）是传输层的概念，是数据传输双方的契约；会话（Session）是应用层的概念，是应用的行为； TCP 是一个双工协议，数据任何时候都可以双向传输，那么什么是双工/单工： 单工：在任何一个时刻，数据只能单向发送。单工需要至少一条线路； 半双工：在某个时刻数据可以向一个方向传输，也可以向另一个方向反方向传输，而且交替进行。半双工需要至少一条线路； 全双工：任何时刻数据都可以双向发送。全双工需要大于一条线路； 客户端和服务端在TCP协议中都被称为Host(主机) 可靠性（数据保证无损传输）：如果发送方按照顺序发送，然后数据无序地在网络间传递，就必须有一种算法在接收方将数据恢复原有的顺序；如果发送方同时把消息发送给多个接收方，这种情况叫做多播，可靠性要求每个接收方都收到相同的副本。 TCP是一个连接导向的协议设计有建立（握手）和断开连接（挥手）的过程。 TCP协议的基本操作： 如果一个Host主动向另一个Host发起连接，成为SYN(Synchronization)，请求同步 如果一个Host主动断开请求，称为FIN(Finish),请求完成 如果一个Host给另一个Host发送数据，成为PSH(Push),数据推送 接收方收到数据后，都需要给发送一个ACK响应，保持连接和可靠性约束，TCP协议要保证每一条发出的数据必须给返回 三次握手： C–(SYN)–S–(SYN-ACK)–C–(ACK)–S 四次挥手： C–(FIN)–S–(ACK) 然后 (FIN) –C–ACK–S 为TCP协议增加协议头，在协议头中取多个位(bit),其中SYN,ACK,PSH都占有1个位，这种设计成为标识(Flag)04 TCP是一个面向连接的协议(Connection-oriented Protool),就是说TCP协议参与双方(Host)在手法数据前会先建立连接。而UDP是一面发送报文(Datagram-oriented)的协议，不需要建立连接，直接发送报文(数据) 因此，TCP3次握手4次挥手的原因：TCP是一个双工协议，为了让双方都保证，建立连接的时候，连接双方都需要向对方发起SYC(同步请求)和ACK(响应)，握手阶段双方都没有繁琐的工作，因此一方向另一方发起同步(SYN)之后，另一方可以将自己的ACK和SYN打包作为一条消息回复，因此是3次握手需要3次数据传输；挥手阶段，双方都有可能未完成的工作，收到挥手请求的一方，必须马上响应(ACK)，表示接收到了挥手请求，最后等所有工作结束，再发送请求中断连接(FIN)，因此是4次挥手 思考：一台内存为8G左右的服务器可以同时维护多少个连接？ 100w?连接是内存中的状态对象，从理论上分析，连接本身不太占用内存。不同语言连接对象大小不等，但是通常很小。当单机建立太多链接，会爆出 Cannot assign requested address 异常，这是由于没建立一个连接，操作系统就会为客户端分配端口号，端口号很快就被占用用尽所以核心问题是，通信需要缓冲区，通讯需要 I/O 。这是因为通讯占用资源，连接本身占用资源少。 压力测试最常用的工具是 Apache Benchmark （简称 AB）或者用JMeter(有界面) 123linux 可执行以下命令安装yum install httpd-tools&#x2F;&#x2F; orapt-get install apache2-utils 3. TCP的封包格式：TCP为什么要粘包和拆包 问题：传输层的协议为什么不选择将文件一次发送呢？ - 为了**稳定性**，一次发送的数据越多，出错的概念就越大 - 为了效率，网络中有时候存在着**并行**的路径，拆分数据包就能更好的利用这些并行的路径 - 发送和接收数据的时候，都存在**缓冲区**；如果随意发送很大的数据，可能导致网卡处理不过来，而导致其他应用实时性遭到破坏； - 内存最小的分配单位是**页表**，如果数据的大小超过一个页表，可能会存在页面置换问题，造成性能的损失 - 传输层封包不能太大，以缓冲区大小为单位，TCP协议会将数据拆分成不超过缓冲区大小的一个个部分，每个部分都有一个独特的名词，叫做**TCP段**(TCP Segment) 拆包：将数据拆分成多个TCP段传输；粘包：将多个数据合并成一个TCP段传输； TCP分组格式示意图 Source Port/Destination Port描述的是发送端口号和目标端口号，代表发送数据的应用程序和接受数据的应用程序； Data Offset是一个偏移量，原因TCP Header部分的长度可变，需要一个数值描述数据从哪个字节开始 Reserved 是很多协议设计会保留的一个区域，用于日后扩展能力 URG…FIN标志位描述TCP段行为 CWR —— Congestion Window Reduced 用于通知发送方，降低发送速率 ECE —— ECN ECHO 通知发送方收到拥塞控制 URG —— 为 1 表示高优先级数据包 ACK —— 为 1 表示确认号码字段有效 PSH —— 为 1 是带有 “PUSH” 标志的数据，指示接收方应当尽快将这个报文段交给应用层，而不用等待缓冲区装满 RST —— 为 1 表示出现严重差错，需要重置 TCP 连接 SYN —— 为 1 表示这是连接请求或者连接接受请求，用于创建连接和使序列号同步 FIN —— 为 1 表示发送方没有数据要传输了，要求释放连接 Window是TCP保证稳定性并进行流量控制的工具，窗口的大小，即接收方将要接受的字节数，该字段占 16 bit，因此窗口大小最大为 65535 bytes。 Checksum是校验和，用于校验TCP段有没有损坏、丢失，其算法本质上与 IP 中的校验和算法相同。 Urgent pointer只想最后一个紧急数据的序号(Sequence Number),在 URG 设置为 1 时生效，这个指针表示紧急数据在整个流中的位置。 TCP 可选项,TCP 头中的最后一个字段是一些附加的可选项，原始规范中提供了 3 个选项，但后来的规范中，不断增加了新的选项： MSS(Maximum Segment Size): 该 TCP 协议实现的可以接收的最大 TCP 段的大小，比较典型的例子是 IPv4 中 TCP 的最大段为 1460 bytes 如果设置过大，会导致服务器拒绝接收，或用户挤占用服务器太多资源；如果设置太小，会浪费传输资源(降低吞吐量) SACK(Selective Acknowledgment): 这个选项优化了数据包大量丢失并且接受者的数据窗口存在漏洞的情况。主要是因为 TCP 接收到的分组必须要能够根据其顺序组成完整的信息，丢掉其中任何一个都需要整个重传。而 SACK 就是允许 TCP 协议接收不连续的块，最后只需要重传丢失的块就可以了。 Window Scale: 窗口缩放选项，用于把窗口的大小从 65535 bytes 扩大到 1 G。具有更大的数据窗口，有利于批量的数据传输 Timestamps: TCP 时间戳，可以用这个时间戳计算每个 ACK 的 RTT，可以用来计算 TCP 重传超时 Padding存在的意义是因为Option的长度不固定，需要pading对齐 紧急指针，是在 URG 设置为 1 时生效，这个指针表示紧急数据在整个流中的位置。 序列号码表示 TCP 段的窗口索引，TCP 流中的每个字节都被编号串联起来。在进行握手的阶段，会先生成一个初始序列号码，之后在此基础上递增。 IP协议拆分太多的封包并没意义，1）导致同个TCP段的封包被不用不同的网络线路传输，加大延迟；拆包需要消耗硬件和计算资源 问题：TCP如何恢复数据的顺序的？TCP拆包和粘包的作用是什么？ TCP拆包的作用：将任务拆分处理，降低整体任务出错的概率，以及减小底层网络处理的压力，粘包过程需要保证数据经过网络的传输，又能恢复到原始的数据。 中间，需要数学提供保证顺序的理论依据，TCP利用（发送字节数、接受字节数）的唯一性来确定封包之间的顺序关系。 TCP粘包的作用：防止数据量过小导致大量的传输而将多个TCP段合并成一个发送 4. TCP的稳定性：滑动窗口和流速控制是怎么回事（保证顺序的算法，同时保证更高的吞吐量） TCP作为一个传输层协议，最核心的能力是传输，传输需要保证可靠性，还需要控制流速，这两个核心能力均有滑动窗口提供。[基于滑动窗口可设计分布式RPC框架，实现消息队列或分布式文件系统] 窗口大小的单位不是TCP段的数量，而是多少个字节 有了窗口，发送方利用滑动窗口算法发送消息；接收方构造缓冲区接收消息，并给发送方ACK 滑动窗口时TCP协议控制可靠性的核心，发送方将数据拆包，变成多个分组，然后将数据放入一个拥有滑动窗口的数组，依次发出，仍然遵循先入先出（FIFO）的顺序，但是窗口中的分组会一次性发送。窗口中序号最小的分组如果收到ACK，窗口就会发生滑动。如果最小序号的分组长时间没有收到ACK，就会触发整个窗口的数据重新发送。 思考：发送方有窗口，那么接收方也需要窗口吗？ 5. UDP协议：TCP协议和UDP协议的优势和劣势 TCP和UDP是应用最广泛的传输层协议，拥有最核心的垄断地位，TCP最核心的价值保证可靠性，UDP的核心价值是灵活性 UDP(User Datagram Protocol)，目标是在传输层提供直接发送报文（Datagram）的能力，Datagram是数据传输的最小单位，UDP协议不会帮助拆分数据，他的目标只有一个，就是发送报文 区别 TCP UDP 目的差异 提供可靠的网络传输 在提供报文交换能力基础上尽可能地简化协议轻装上阵 可靠性差异 在保证可靠性下提供更好的访问 只管发送数据封包 连接vs无链接 面向连接的协议(Connection-oriented Protocol) 无连接协议(Connection-less Protocol) 流控技术(Flow Control) 流控技术 在发送缓冲区中存储数据，并在接收缓冲区中接收数据 没有提供 传输速度 协议简化，封包小，没有连接、可靠性检查等，速度更快 场景差异 不适合高速数据传输场景[不适合网络游戏、视频传输] Ping和DNSLookup只需要一次简单的请求/返回，不需要建立连接 - - - 传输 无损传输 传输更快 协议 HTTP协议更可靠 HTTP3.0协议更多从功能上出发 任何一个用TCP协议构造的成熟应用层协议，都可以用UDP重构 TCP应用场景 远程控制(SSH) File Transfer Protocol(FTP) 邮件(SMTP、IMAP)等 点对点文件传出(微信等) UDP应用场景 网络游戏 音视频传输 DNS Ping 直播 模糊应用场景 HTTP(目前以TCP为主) 文件传输 UDP不提供可靠性，但不代表不能解决可靠性；UDP的核心价值：灵活、轻量，构造了最小版本的传输层协议；可以实现连接(可靠性)，实现会话(Session),实现可靠性(Reliability)… 总结：TCP比较严谨(序号的设计、滑动窗口的设计、快速重发的设计、内在状态机制的设计)，而UDP更加简单专注，报文传输，可靠性，流量控制，连接和会话 问题解析：TCP最核心的价值就是提供封装好的一套解决可靠性的优秀方案；TCP在确保吞吐量、延迟、丢包率的基础上，保证可靠性；UDP提供了最小版本的实现，支持Checksum,UDP最核心的价值：轻量、灵活、传输速度快 问题：Moba类游戏的网络应用应该用TCP还是UDP? 内存状态在同时刻只能有一个状态，所以多线程的操作必须有先后 对于游戏，在线竞技游戏，每个事件(英雄放大招)，游戏服务器必须给一个唯一的时序编号。服务器要尽快响应多个客户单提交的事件，并以最快的速度分配自增序号，然后返回给客户端。 所以moba 网络层协议(局域网和IP协议)6. IPv4协议：路由和寻址的区别 问题回答：寻址（Addressing）就是通过地址找到设备；路由（Routing）本质是路径的选择。就好像知道地址，但是到了每个十字路口，还需要选择具体的路径。因此，路由和寻址，是相辅相成的关系。 IP 协议（Internet Protocol）是一个处于垄断地位的网络层协议。IPv4 就是 IP 协议的第 4 个版本，是目前互联网的主要网络层协议。IP协议需要底的数据链路层的支持。IP 协议并不负责数据的可靠性，可靠性是 IP 协议上方的 Host-To-Host 协议（即传输层协议）保证的。 IP 协议接收 IP 协议上方的 Host-To-Host 协议（即传输层协议）传来的数据，然后进行拆分，这个能力叫做分片（Fragmentation）；然后 IP 协议为每个分片增加一个 IP 头（Header），组成一个 IP 封包（Datagram）；之后，IP 协议调用底层的局域网（数据链路层）传送数据。最后 IP 协议通过寻址和路由能力最终把封包送达目的地。 IP协议存在的问题： 封包损坏：数据传输过程中损坏 丢包：数据发送中丢失 重发：数据被重发，比如中间设备通过2个路径传递数据 乱序：到达目的地时数据和发送数据不一致 IP协议的工作原理 分片：是把数据切分成片，IP协议通过它下层的局域网(链路层)协议传输数据，因此需要适配底层网络的传输能力 增加协议头，如下图： IHL描述协议头大小 Type Of Service为了在延迟、吞吐量和丢包率做出选择 time to time描述封包存活时间 Protocol 上层协议，TCP=7,UDP=17 描述网络的三个指标： 延迟（Latency）：1bit 的数据从网络的一个终端传送到另一个终端需要的时间； 吞吐量（Throughput）：单位时间内可以传输的平均数据量,单位：bps=bit/s； 丢包率（Packet loss）：丢包率指的发送出去的封包没有达到目的地的比率； IPv4地址是4个8位(Octet)排列而成，总共可以编址43亿个地址。 IP: 103 16 3 1 Octet: 01100111 00010000 00000011 00010001 寻址步骤： 找到顶层网络，例如103.16.3.1最顶层的网络号可以和255.0.0.0(子网掩码)做位与运算得到103.16.3.1&amp;255.0.0.0=103.0.0.0 找到下一层网络，就需要IP地址和下一级的子网掩码做位与运算103.16.3.1&amp;255.255.0.0=103.16.0.0 找到再下一级网络，就需要IP地址和下一级的子网掩码做位与运算103.16.3.1&amp;255.255.255.0=103.16.3.0 定位设备，设备就是子网103.16.3.0中，最终找到设备号是1 在寻址过程中，数据总存在于某个局域网内，如果目的地在局域网中，可以直接定位到设备，如果目的不在局域网中，就需要去往其他网络。由于网络与网络之间是网关在连接，如果目的地的IP地址不在局域网中，就需要被IP封包，选择通往下一个网络的路径，其实就是选择下一个网关。如果一个网络和多个网络接壤，就会存在多个网关。例如：路由器为ip 14.215.117.38寻址，路由所在的编号为16.0.0.0，就需要知道去往14.0.0.0网络的gateway地址，如果用route查看路由表可以看到Destination:14.0.0.0 Gateway:16.12.1.100 Mask 255.0.0.0 Iface:16.12.1.1 14.215.117.38先要和mask进行位与运算，然后进行查表看到14.0.0.0得知去的网卡是16.12.1.1 思考：127.0.0.1,localhost,0.0.0.0有什么不同？ 127.0.0.1是本地回环地址（loopback），发送到 loopback 的数据会被转发到本地应用。 localhost 指代的是本地计算机，用于访问绑定在 loopback 上的服务。localhost 是一个主机名，不仅仅可以指向 IPv4 的本地回环地址，也可以指向 IPv6 的本地回环地址 [::1]。 0.0.0.0是一个特殊目的 IP 地址，称作不可路由 IP 地址，它的用途会被特殊规定。通常情况下，当我们把一个服务绑定到0.0.0.0，相当于把服务绑定到任意的 IP 地址。比如一台服务器上有多个网卡，不同网卡连接不同的网络，如果服务绑定到 0.0.0.0 就可以保证服务在多个 IP 地址上都可以用。 子网掩码的作用就是帮忙找到对应的子网 7. IPv6协议：Tunnel技术是什么IPv4 用 32 位整数描述地址，最多只能支持 43 亿设备，显然是不够用的，这也被称作 IP 地址耗尽问题。 为了解决这个问题，有一种可行的方法是拆分子网。拆分子网，会带来很多问题，比如说内外网数据交互，需要网络地址转换协议（NAT 协议），增加传输成本。再比如说，多级网络会增加数据的路由和传输链路，降低网络的速度。理想的状态当然是所有设备在一个网络中，互相可以通过地址访问。 为了解决这个问题，1998 年互联网工程工作小组推出了全新款的 IP 协议——IPv6 协议。但是目前 IPv6 的普及程度还不够高. 既然不能做到完全普及，也就引出了关联的一道面试题目：什么是 Tunnel 技术？ IPv6 的工作原理和 IPv4 类似，分成切片（Segmentation）、增加封包头、路由（寻址） 这样几个阶段去工作。 IPv6 同样接收上方主机到主机（Host-to-Host）协议传递来的数据，比如一个 TCP 段（Segment），然后将 TCP 段再次切片做成一个个的 IPv6 封包（Datagram or Packet），再调用底层局域网能力（数据链路层）传输数据。 具体的过程如下图所示： 区别 IPv4 IPv6 位数 4个8位(octeat)，共32位 8个16位(hextet),共128位 分割 用.分割，如103.28.7.35 用:分割，如0123:4567:89ab:cdef:0123:4567:89ab:cde IPv6 的寻址，和 IPv4 相同，寻址的目的是找到设备，以及规划到设备途经的路径。与IPv4 相同，IPv6寻址最核心的内容就是要对网络进行划分。IPv6 地址很充裕，因此对网络的划分和 IPv4 有很显著的差异。 IPv6 的寻址分类包括：全局单播寻址、 本地单播、分组多播、任意播 全局单播寻址：就是将消息从一个设备传到另一个设备，目标就是定位网络中的设备（和 IPv4 地址作用差不多，在互联网中通过地址查找一个设备，简单来说，单播就是 1 对 1）只不过格式略有差异。总的来说，IPv6 地址太多，因此不再需要子网掩码，而是直接将 IPv6 的地址分区即可；在实现全局单播时，IPv6 地址通常分成 3 个部分： 站点前缀（Site Prefix）48bit，一般是由 ISP（Internet Service Providor，运营商）或者RIR（Regional Internet Registry， 地区性互联网注册机构），RIR 将 IP 地址分配给运营商； 子网号（Subnet ID），16bit，用于站点内部区分子网； 接口号（Interface ID）， 64bit，用于站点内部区分设备 因此 IPv6 也是一个树状结构，站点前缀需要一定资质，子网号和接口号内部定义。IPv6 的寻址过程就是先通过站点前缀找到站点，然后追踪子网，再找到接口（也就是设备的网卡）。 本地单播（类似 IPv4 里的一个内部网络，要求地址必须以fe80开头，类似我们 IPv4 中127开头的地址）；理论上，虽然 IPv6 可以将所有的设备都连入一个网络。但在实际场景中，很多公司还是需要一个内部网络的。这种情况在 IPv6 的设计中属于局域网络。 在局域网络中，实现设备到设备的通信，就是本地单播。IPv6 的本地单播地址组成如下图所示： 这种协议比较简单，本地单播地址必须以fe80开头，后面 64 位的 0，然后接上 54 位的设备编号。上图中的 Interface 可以理解成网络接口，其实就是网卡 分组多播（Group Multicast），类似今天我们说的广播，将消息发送给多个接收者；有时候，我们需要实现广播。所谓广播，就是将消息同时发送给多个接收者。IPv6 中设计了分组多播，来实现广播的能力。当 IP 地址以 8 个 1 开头，也就是ff00开头，后面会跟上一个分组的编号时，就是在进行分组多播。这个时候，我们需要一个广播设备，在这个设备中已经定义了这些分组编号，并且拥有分组下所有设备的清单，这个广播设备会帮助我们将消息发送给对应分组下的所有设备。 任意播（Anycast），，本质是将消息发送给多个接收方，并选择一条最优的路径。这样说有点抽象，比如说在一个网络中有多个授时服务，这些授时服务都共享了一个任播地址。当一个客户端想要获取时间，就可以将请求发送到这个任播地址。客户端的请求扩散出去后，可能会找到授时服务中的一个或者多个，但是距离最近的往往会先被发现。这个时候，客户端就使用它第一次收到的授时信息修正自己的时间。 IPv6 和 IPv4 的兼容：目前 IPv6 还没有完全普及，大部分知名的网站都是同时支持 IPv6 和 IPv4。这个时候我们可以分成 2 种情况讨论： 一个 IPv4 的网络和一个 IPv6 的网络通信； 客户端通过 DNS64 服务器查询 AAAA 记录。DNS64 是国际互联网工程任务组（IETF）提供的一种解决 IPv4 和 IPv6 兼容问题的 DNS 服务。这个 DNS 查询服务会把 IPv4 地址和 IPv6 地址同时返回。 DNS64 服务器返回含 IPv4 地址的 AAAA 记录。 客户端将对应的 IPv4 地址请求发送给一个 NAT64 路由器 由这个 NAT64 路由器将 IPv6 地址转换为 IPv4 地址，从而访问 IPv4 网络，并收集结果。 消息返回到客户端。 一个 IPv6 的网络和一个 IPv6 的网络通信，但是中间需要经过一个 IPv4 的网络 这种情况在普及 IPv6 的过程中比较常见，IPv6 的网络一开始是一个个孤岛，IPv6 网络需要通信，就需要一些特别的手段。 隧道的本质就是在两个 IPv6 的网络出口网关处，实现一段地址转换的程序。 总结： IPv6 解决的是地址耗尽的问题。因为解决了地址耗尽的问题，所以很多其他问题也得到了解决，比如说减少了子网，更小的封包头部体积，最终提升了性能等。 问题：Tunnel 技术是什么 Tunnel 就是隧道，这和现实中的隧道是很相似的。隧道不是只有一辆车通过，而是每天都有大量的车辆来来往往。两个网络，用隧道连接，位于两个网络中的设备通信，都可以使用这个隧道。隧道是两个网络间用程序定义的一种通道。具体来说，如果两个 IPv6 网络被 IPv4 分隔开，那么两个 IPv6 网络的出口处（和 IPv4 网络的网关处）就可以用程序（或硬件）实现一个隧道，方便两个网络中设备的通信。 IPv6 和 IPv4 究竟有哪些区别 IPv6 和 IPv4 最核心的区别是地址空间大小不同。IPv6 用 128 位地址，解决了 IP 地址耗尽问题。因为地址空间大小不同，它们对地址的定义，对路由寻址策略都有显著的差异。 在路由寻址策略上，IPv6 消除了设备间地址冲突的问题，改变了划分子网的方式。在 IPv4 网络中，一个局域网往往会共享一个公网 IP，因此需要 NAT 协议和外网连接。 在划分子网的时候，IPv4 地址少，需要子网掩码来处理划分子网。IPv6 有充足的地址，因此不需要局域网共享外网 IP。也正因为 IPv6 地址多，可以直接将 IPv6 地址划分成站点、子网、设备，每个段都有充足的 IP 地址。 因为 IPv6 支持的 IP 地址数量大大上升，一个子网可以有 248 个 IP 地址，这个子网可能是公司网络、家庭网络等。这样 IP 地址的分配方式也发生了变化，IPv4 网络中设备分配 IP 地址的方式是中心化的，由 DHCP（动态主机协议）为局域网中的设备分配 IP 地址。而在 IPv6 网络中，因为 IP 地址很少发生冲突，可以由设备自己申请自己的 IP 地址。 另外因为 IPv6 中任何一个节点都可以是一个组播节点，这样就可以构造一个对等的网络，也就是可以支持在没有中心化的路由器，或者一个网络多个路由器的情况下工作。节点可以通过向周围节点类似打探消息的方式，发现更多的节点。这是一个配套 IPv6 的能力，叫作邻居发现（ND）。 8. 局域网：NAT是如何工作的广域网是由很多的局域网组成的，比如公司网络、家庭网络、校园网络等。之前我们一直在讨论广域网的设计，今天我们到微观层面，看看局域网是如何工作的。 IPv4 的地址不够，因此需要设计子网。当一个公司申请得到一个公网 IP 后，会在自己的公司内部设计一个局域网。这个局域网所有设备的 IP 地址，通常会以 192.168 开头。 假设小明，上班时间玩王者荣耀。当他用 UDP 协议向王者荣耀的服务器发送信息时，消息的源 IP 地址是一个内网 IP 地址，而王者荣耀的服务，是一个外网 IP 地址。 数据到王者荣耀服务器可以通过寻址和路由找到目的地，但是数据从王者荣耀服务器回来的时候，王者荣耀服务器如何知道192.168开头的地址应该如何寻址呢？ 要想回答这个问题，就涉及网络地址转换协议（NAT 协议）。 内部网络和外部网络对一个组织、机构、家庭来说，我们通常把内部网络称为局域网，外部网络就叫作外网。下图是一个公司多个部门的网络架构。 我们会看到外网通过路由器接入整个公司的局域网，和路由器关联的是三台交换机，代表公司的三个部门。交换机，或者称为链路层交换机，通常工作在链路层；而路由器通常也具有交换机的能力，工作在网络层和链路层。 光纤是一种透明的导光介质，多束光可以在一个介质中并行传播，不仅信号容量大，重量轻，并行度高而且传播距离远。当然，光纤不能弯曲，因此办公室里用来连接交换机和个人电脑的线路肯定不能是光纤，光线通常都用于主干网络。 局域网数据交换（MAC 地址）同一个局域网中的设备如何交换消息。 首先，先明确一个概念，设备间通信的本质其实是设备拥有的网络接口（网卡）间的通信。为了区别每个网络接口，互联网工程任务组（IETF）要求每个设备拥有一个唯一的编号，这个就是 MAC 地址。 IP 地址不也是唯一的吗？其实不然，一旦设备更换位置，比如你把你的电脑从北京邮寄的广州，那么 IP 地址就变了，而电脑网卡的 MAC 地址不会发生变化。总的来说，IP 地址更像现实生活中的地址，而 MAC 地址更像你的身份证号。 然后，再明确另一个基本的概念。在一个局域网中，我们不可以将消息从一个接口（网卡）发送到另一个接口（网卡），而是要通过交换机。为什么是这样呢？因为两个网卡间没有线啊！所以数据交换，必须经过交换机，因为线路都是由网卡连接交换机的。 总结：数据的发送方，将自己的 MAC 地址、目的地 MAC 地址，以及数据作为一个 分组（Packet），也称作 Frame 或者封包，发送给交换机。交换机再根据目的地 MAC 地址，将数据转发到目的地的网络接口（网卡）。 最后一个问题，这个分组或者 Frame，是不是 IP 协议的分组呢？不是，这里提到的是链路层的数据交换，它支持 IP 协议工作，是网络层的底层。所以，如果 IP 协议要传输数据，就要将数据转换成为链路层的分组，然后才可以在链路层传输。 链路层分组大小受限于链路层的网络设备、线路以及使用了链路层协议的设计。你有时候可能会看到 **MTU 这个缩写词，它指的是 Maximun Transmission Unit，最大传输单元，意思是链路层网络允许的最大传输数据分组的大小。因此IP 协议要根据 MTU 拆分封包**。 介绍 TCP 协议滑动窗口的时候，还提到过一个词，叫作 MSS，这里我们复习下,MSS（Maximun Segment Size，最大段大小）是 TCP 段，或者称为 TCP 分组（TCP Packet）的最大大小。MSS 是传输层概念，MTU 是链路层概念，因此，它们的关系如下是对的吗？ 1MTU &#x3D; MSS + TCP Header + IP Header 这个思路有一定道理，但是不对。先说说这个思路怎么来的，你可能会这么思考：TCP 传输数据大于 MSS，就拆包。每个封包加上 TCP Header ，之后经过 IP 协议，再加上 IP Header。于是这个加上 IP 头的分组（Packet）不能超过 MTU。固然这个思路很有道理，可惜是错的。因为 TCP 解决的是广域网的问题，MTU 是一个链路层的概念，要知道不同网络 MTU 是不同的，所以二者不可能产生关联。这也是为什么 IP 协议还可能会再拆包的原因。 地址解析协议（ARP） 链路层通过 MAC 地址定位网络接口（网卡）。在一个网络接口向另一个网络接口发送数据的时候，至少要提供这样 3 个字段： 源 MAC 地址 目标 MAC 地址 数据 这里我就要思考一个问题，对于一个网络接口，它如何能知道目标接口的 MAC 地址呢？ 我们在使用传输层协议的时候，清楚地知道目的地的 IP 地址，但是我们不知道 MAC 地址。这个时候，就需要一个中间服务帮助根据 IP 地址找到 MAC 地址——这就是地址解析协议（Address Resolution Protocol，ARP）。 整个工作过程和 DNS 非常类似，如果一个网络接口已经知道目标 IP 地址对应的 MAC 地址了，它会将数据直接发送给交换机，交换机将数据转发给目的地，这个过程如下图所示： 如果网络接口不知道目的地地址呢？这个时候，地址解析协议就开始工作了。发送接口会发送一个广播查询给到交换机，交换机将查询转发给所有接口。 如果某个接口发现自己就是对方要查询的接口，则会将自己的 MAC 地址回传。接下来，会在交换机和发送接口的 ARP 表中，增加一个缓存条目。也就是说，接下来发送接口再次向 IP 地址 2.2.2.2 发送数据时，不需要再广播一次查询了。 前面提到这个过程和 DNS 非常相似，采用的是逐级缓存的设计减少 ARP 请求。发送接口先查询本地的 ARP 表，如果本地没有数据，然后广播 ARP 查询。这个时候如果交换机中有数据，那么查询交换机的 ARP 表；如果交换机中没有数据，才去广播消息给其他接口。注意，ARP 表是一种缓存，也要考虑缓存的设计。通常缓存的设计要考虑缓存的 **失效时间(Time to Live)**，为每个缓存条目增加一个失效时间 更新策略，可以考虑利用 老化(Aging)算法 模拟LRU 数据结构等 最后请你思考路由器和交换机的异同点。不知道你有没有在网上订购过家用无线路由器，通常这种家用设备也会提供局域网，具备交换机的能力。同时，这种设备又具有路由器的能力。所以，很多同学可能会分不清路由器和交换机。 总的来说，家用的路由器，也具备交换机的功能。但是当 ARP 表很大的时候，就需要专门的、能够承载大量网络接口的交换设备。就好比，如果用数组实现 ARP 表，数据量小的时候，遍历即可；但如果数据量大的话，就需要设计更高效的查询结构和设计缓存【重学操作系统：存储器分级：L1 Cache比内存和SSD快多少倍；内存管理单元：什么情况下使用大内存分页；缓存置换算法：LRU用什么数据结构实现更合理】。 连接内网，有时候，公司内部有多个子网。这个时候一个子网如果要访问另一个子网，就需要通过路由器。也就是说，图中的路由器，其实充当了两个子网通信的桥梁。在上述过程中，发送接口不能直接通过 MAC 地址发送数据到接收接口，因为子网 1 的交换机不知道子网 2 的接口。这个时候，发送接口需要通过 IP 协议，将数据发送到路由器，再由路由器转发信息到子网 2 的交换机。这里提一个问题，子网 2 的交换机如何根据 IP 地址找到接收接口呢？答案是通过查询 ARP 表。 连接外网（网络地址转换技术，NAT），IPv4 协议因为存在网络地址耗尽的问题，不能为一个公司提供足够的地址，因此内网 IP 可能会和外网重复。比如内网 IP 地址192.168.0.1发送信息给22.22.22.22，这个时候，其实是跨着网络的。 跨网络必然会通过多次路由，最终将消息转发到目的地。但是这里存在一个问题，寻找的目标 IP 地址22.22.22.22是一个公网 IP，可以通过正常的寻址 + 路由算法定位。当22.22.22.22寻找192.168.0.1的时候，是寻找一个私网 IP，这个时候是找不到的。解决方案就是网络地址转换技术（Network Address Translation）。 NAT 技术转换的是 IP 地址，私有 IP 通过 NAT 转换为公网 IP 发送到服务器。服务器的响应，通过 NAT 转换为私有 IP，返回给客户端。通过这种方式，就解决了内网和外网的通信问题。 总结：链路层发送数据靠的是 MAC 地址，MAC 地址就好像人的身份证一样。局域网中，数据不可能从一个终端直达另一个终端，而是必须经过交换机交换。 交换机也叫作链路层交换机，它的工作就是不断接收数据，然后转发数据。通常意义上，交换机不具有路由功能，路由器往往具有交换功能。但是往往路由器交换的效率，不如交换机。 已知 IP 地址，找到 MAC 地址的协议，叫作地址解析协议（ARP）。 网络和网络的衔接，必须有路由器（或者等价的设备）。一个网络的设备不能直接发送链路层分组给另一个网络的设备，而是需要通过 IP 协议让路由器转发。 问题： 网络地址转换协议是如何工作的？ 网络地址解析协议（NAT）解决的是内外网通信的问题。 NAT 通常发生在内网和外网衔接的路由器中，由路由器中的 NAT 模块提供网络地址转换能力。 从设计上看，NAT 最核心的能力，就是能够将内网中某个 IP 地址映射到外网 IP，然后再把数据发送给外网的服务器。当服务器返回数据的时候，NAT 又能够准确地判断外网服务器的数据返回给哪个内网 IP。 NAT 是能做到上面这一点，需要做两件事: NAT 需要作为一个中间层替换 IP 地址。 发送的时候，NAT 替换源 IP 地址（也就是将内网 IP 替换为出口 IP）；接收的时候，NAT 替换目标 IP 地址（也就是将出口 IP 替换回内网 IP 地址）。 NAT 需要缓存内网 IP 地址和出口 IP 地址 + 端口的对应关系。也就是说，发送的时候，NAT 要为每个替换的内网 IP 地址分配不同的端口，确保出口 IP 地址+ 端口的唯一性，这样当服务器返回数据的时候，就可以根据出口 IP 地址 + 端口找到内网 IP。 IPv6 协议还需要 NAT 吗？ IPv6 解决了 IP 耗尽的问题，为机构、组织、公司、家庭等网络提供了充足的 IP 资源，从这个角度看是不是就不需要 NAT 协议了呢？ 在没有 IPv6 之前，NAT 是 IP 资源耗尽的主流解决方案。在一个内网中的全部设备通过 NAT 协议共 享一个外网的 IPv4 地址，是目前内外网对接的主要方式。IPv6 地址资源充足，可以给全球每个设备一个独立的地址。从这个角度看 IPv6 的确不需要 NAT 协议。 但是目前的情况，是 IPv6 网络还没有完全普及。尽管很多公司已经支持自己的互联网产品可以使用 IPv6 访问，但是公司内部员工使用的内部网络还是 IPv4。如果要连接 IPv6 和 IPv4 网络，仍然需要 NAT 协议（NAT64），这个协议可以让多个 IPv6 的设备共享一个 IPv4 的公网地址。 9. TCP实战：如何进行TCP抓包调试[略]网络编程 围绕Socket讨论网络编程 各种网络I/O模型和编程方式的优缺点 以RPC框架设计为题落地学到的知识和实现 做网络编程的时候都会碰到 Socket 对象 ，或者在配置代理的时候， 碰到配置 Socket 地址。 还经常会碰到 I/O 模型、异步编程、内存映射等概念。再往更深层次学习， 还会碰到 epoll/select 等编程模型。 有没有一种一团糟的感觉——其实学习好这些知识有一条主线，就是抓住操作系统对 Socket 文件的设计。 10. Socket编程：epoll为什么用红黑树Socket 是一种编程的模型。 下图中，从编程的角度来看，客户端将数据发送给在客户端侧的Socket 对象，然后客户端侧的 Socket 对象将数据发送给服务端侧的 Socket 对象。 Socket 对象负责提供通信能力，并处理底层的 TCP 连接/UDP 连接。 对服务端而言，每一个客户端接入，就会形成一个和客户端对应的 Socket 对象，如果服务器要读取客户端发送的信息，或者向客户端发送信息，就需要通过这个客户端 Socket 对象。 但是如果从另一个角度去分析，Socket 还是一种文件，准确来说是一种双向管道文件。 管道文件: 管道会将一个程序的输出，导向另一个程序的输入双向管道文件呢：双向管道文件连接的程序是对等的，都可以作为输入和输出 12var serverSocket = new ServerSocket();serverSocket.bind(new InetSocketAddress(80)); 上面代码，创建的是一个服务端 Socket 对象，但如果单纯看这个对象，它又代表什么呢？如果我们理解成代表服务端本身合不合理呢——这可能会比较抽象，在服务端存在一个服务端 Socket。但如果我们从管道文件的层面去理解它，就会比较容易了。其一，这是一个文件；其二，它里面存的是所有客户端 Socket 文件的文件描述符。 当一个客户端连接到服务端的时候，操作系统就会创建一个客户端 Socket 的文件。然后操作系统将这个文件的文件描述符写入服务端程序创建的服务端 Socket 文件中。服务端 Socket 文件，是一个管道文件。如果读取这个文件的内容，就相当于从管道中取走了一个客户端文件描述符 如上图所示，服务端 Socket 文件相当于一个客户端 Socket 的目录，线程可以通过 accept() 操作每次拿走一个客户端文件描述符。拿到客户端文件描述符，就相当于拿到了和客户端进行通信的接口。 前面我们提到 Socket 是一个双向的管道文件，当线程想要读取客户端传输来的数据时，就从客户端 Socket 文件中读取数据；当线程想要发送数据到客户端时，就向客户端 Socket 文件中写入数据。客户端 Socket 是一个双向管道，操作系统将客户端传来的数据写入这个管道，也将线程写入管道的数据发送到客户端。 总结下，Socket 首先是文件，存储的是数据。 对服务端而言，分成服务端 Socket 文件和客户端 Socket 文件。 服务端 Socket 文件存储的是客户端 Socket 文件描述符； 客户端 Socket 文件存储的是传输的数据。 读取客户端 Socket 文件，就是读取客户端发送来的数据；写入客户端文件，就是向客户端发送数据。对一个客户端而言， Socket 文件存储的是发送给服务端（或接收的）数据。 综上，Socket 首先是文件，在文件的基础上，又封装了一段程序，这段程序提供了 API 负责最终的数据传输。 服务端 Socket 的绑定 Nginx监听80端口 Node监听3000端口 SSH监听22端口 Tomcat监听8080端口 对于一个服务端 Socket 文件，我们要设置它监听的端口。比如 Nginx 监听 80 端口、Node 监听 3000 端口、SSH 监听 22 端口、Tomcat 监听 8080 端口。端口监听不能冲突，不然客户端连接进来创建客户端 Socket 文件，文件描述符就不知道写入哪个服务端 Socket 文件了。 这样操作系统就会把连接到不同端口的客户端分类，将客户端 Socket 文件描述符存到对应不同端口的服务端 Socket 文件中。 因此，服务端监听端口的本质，是将服务端 Socket 文件和端口绑定，这个操作也称为 bind。有时候我们不仅仅绑定端口，还需要绑定 IP 地址。这是因为有时候我们只想允许指定 IP 访问我们的服务端程序。 扫描和监听 对于一个服务端程序，可以定期扫描服务端 Socket 文件的变更，来了解有哪些客户端想要连接进来。如果在服务端 Socket 文件中读取到一个客户端的文件描述符，就可以将这个文件描述符实例化成一个 Socket 对象。 之后，服务端可以将这个 Socket 对象加入一个容器（集合），通过定期遍历所有的客户端 Socket 对象，查看背后 Socket 文件的状态，从而确定是否有新的数据从客户端传输过来。 上述的过程，我们通过一个线程就可以响应多个客户端的连接，也被称作I/O 多路复用技术。 响应式（Reactive）在 I/O 多路复用技术中，服务端程序（线程）需要维护一个 Socket 的集合（可以是数组、链表等），然后定期遍历这个集合。这样的做法在客户端 Socket 较少的情况下没有问题，但是如果接入的客户端 Socket 较多，比如达到上万，那么每次轮询的开销都会很大。 从程序设计的角度来看，像这样主动遍历，比如遍历一个 Socket 集合看看有没有发生写入（有数据从网卡传过来），称为命令式的程序。这样的程序设计就好像在执行一条条命令一样，程序主动地去查看每个 Socket 的状态。 命令式会让负责下命令的程序负载过重，例如，在高并发场景下，上述讨论中循环遍历 Socket 集合的线程，会因为负担过重导致系统吞吐量下降。 与命令式相反的是响应式（Reactive），响应式的程序就不会有这样的问题。在响应式的程序当中，每一个参与者有着独立的思考方式，就好像拥有独立的人格，可以自己针对不同的环境触发不同的行为。 从响应式的角度去看 Socket 编程，应该是有某个观察者会观察到 Socket 文件状态的变化，从而通知处理线程响应。线程不再需要遍历 Socket 集合，而是等待观察程序的通知。 最合适的观察者其实是操作系统本身，只有操作系统非常清楚每一个 Socket 文件的状态。原因是对 Socket 文件的读写都要经过操作系统。在实现这个模型的时候，有几件事情要注意。 线程需要告诉中间的观察者自己要观察什么，或者说在什么情况下才响应？比如具体到哪个 Socket 发生了什么事件？是读写还是其他的事件？这一步我们通常称为注册。 中间的观察者需要实现一个高效的数据结构（通常是基于红黑树的二叉搜索树）。这是因为中间的观察者不仅仅是服务于某个线程，而是服务于很多的线程。当一个 Socket 文件发生变化的时候，中间观察者需要立刻知道，究竟是哪个线程需要这个信息，而不是将所有的线程都遍历一遍 问题：为什么用红黑树？ 关于为什么要红黑树， 再仔细解释一下。考虑到中间观察者最核心的诉求有两个。 第一个核心诉求，是让线程可以注册自己关心的消息类型。 比如线程对文件描述符 =123 的 Socket 文件读写都感兴趣，会去中间观察者处注册。当 FD=123 的 Socket 发生读写时，中间观察者负责通知线程，这是一个响应式的模型。 第二个核心诉求，是当 FD=123 的 Socket 发生变化（读写等）时，能够快速地判断是哪个线程需要知道这个消息 所以，中间观察者需要一个快速能插入（注册过程）、查询（通知过程）一个整数的数据结构，这个整数就是 Socket 的文件描述符。综合来看，能够解决这个问题的数据结构中，跳表和二叉搜索树都是不错的选择。 因此，在 Linux 的 epoll 模型中，选择了红黑树。红黑树是二叉搜索树的一种，红与黑是红黑树的实现者才关心的内容，对于我们使用者来说不用关心颜色，Java 中的 TreeMap 底层就是红黑树 总结：Socket 既是一种编程模型，或者说是一段程序，同时也是一个文件，一个双向管道文件。可以理解，Socket API 是在 Socket 文件基础上进行的一层封装，而 Socket 文件是操作系统提供支持网络通信的一种文件格式。 在服务端有两种 Socket 文件，每个客户端接入之后会形成一个客户端的 Socket 文件，客户端 Socket 文件的文件描述符会存入服务端 Socket 文件。通过这种方式，一个线程可以通过读取服务端 Socket 文件中的内容拿到所有的客户端 Socket。这样一个线程就可以负责响应所有客户端的 I/O，这个技术称为 I/O 多路复用。 主动式的 I/O 多路复用，对负责 I/O 的线程压力过大，因此通常会设计一个高效的中间数据结构作为 I/O 事件的观察者，线程通过订阅 I/O 事件被动响应，这就是响应式模型。在 Socket 编程中，最适合提供这种中间数据结构的就是操作系统的内核，事实上 epoll 模型也是在操作系统的内核中提供了红黑树结构。 问题： epoll为什么是红黑树 在 Linux 的设计中有三种典型的 I/O 多路复用模型 select、poll、epoll。 select 是一个主动模型，需要线程自己通过一个集合存放所有的 Socket，然后发生 I/O 变化的时候遍历。在 select 模型下，操作系统不知道哪个线程应该响应哪个事件，而是由线程自己去操作系统看有没有发生网络 I/O 事件，然后再遍历自己管理的所有 Socket，看看这些 Socket 有没有发生变化。 poll 提供了更优质的编程接口，但是本质和 select 模型相同。因此千级并发以下的 I/O，你可以考虑 select 和 poll，但是如果出现更大的并发量，就需要用 epoll 模型。 epoll 模型在操作系统内核中提供了一个中间数据结构，这个中间数据结构会提供事件监听注册，以及快速判断消息关联到哪个线程的能力（红黑树实现）。因此在高并发 I/O 下，可以考虑 epoll 模型，它的速度更快，开销更小。 11. 流和缓冲区：缓冲区的 flip 是怎么回事？流和缓冲区都是用来描述数据的。 计算机中，数据往往会被抽象成流，然后传输。比如读取一个文件，数据会被抽象成文件流；播放一个视频，视频被抽象成视频流。处理节点为了防止过载，又会使用缓冲区削峰（减少瞬间压力）。在传输层协议当中，应用往往先把数据放入缓冲区，然后再将缓冲区提供给发送数据的程序。发送数据的程序，从缓冲区读取出数据，然后进行发送。 流 流代表数据，具体来说是随着时间产生的数据，类比自然界的河流。你不知道一个流什么时候会完结，直到你将流中的数据都读完。 读取文件的时候，文件被抽象成流。流的内部构造，决定了你每次能从文件中读取多少数据。从流中读取数据的操作，本质上是一种迭代器。流的内部构造决定了迭代器每次能读出的数据规模。比如你可以设计一个读文件的流，每次至少会读出 4k 大小，也可以设计一个读文件的程序，每次读出一个字节大小。 通常情况读取数据的流，是读取流；写入数据的流，是写入流。那么一个写入流还能被理解成随着时间产生的数据吗？其实是一样的，随着时间产生的数据，通过写入流写入某个文件，或者被其他线程、程序拿走使用。 思考一个问题：流中一定有数据吗？ 看上去的确是这样。对于文件流来说，打开一个文件，形成读取流。读取流的本质当然是内存中的一个对象。当用户读取文件内容的时候，实际上是通过流进行读取，看上去好像从流中读取了数据，而本质上读取的是文件的数据。从这个角度去观察整体的设计，数据从文件到了流，然后再到了用户线程，因此数据是经过流的。 但是仔细思考这个问题，可不可以将数据直接从文件传输到用户线程呢？比如流对象中只设计一个整数型指针，一开始指向文件的头部，每次发生读取，都从文件中读出内容，然后再返回给用户线程。做完这次操作，指针自增。通过这样的设计，流中就不需要再有数据了。可见，流中不一定要有数据。再举一个极端的例子，如果我们设计一个随机数的产生流，每次读取流中的数据，都调用随机数函数生成一个随机数并返回，那么流中也不需要有数据的存储。 为什么要缓冲区？在上面的例子当中，我们讨论的时候发现，设计文件流时，可以只保留一个位置指针，不用真的将整个文件都读入内存，像下图这样： 把文件看作是一系列线性排列连续字节的合集，用户线程调用流对象的读取数据方法，每次从文件中读取一个字节。流中只保留一个读取位置 position，指向下一个要读取的字节。 看上去这个方案可行，但实际上性能极差。因为从文件中读取数据这个操作，是一次磁盘的 I/O 操作，非常耗时。正确的做法是每次读取 2k、4k 这样大小的数据，这是因为操作系统中的内存分页通常是这样的大小，而磁盘的读写往往是会适配页表大小。而且现在的文件系统主要都是日志文件系统，存储的并不是原始数据本身，也就是说多数情况下你看到的文件并不是一个连续紧密的字节线性排列，而是日志。 当你向磁盘读取 2k 数据，读取到的不一定是 2k 实际的数据，很有可能会比 2k 少，这是因为文件内容是以日志形式存储，会有冗余 如上图所示，内核每次从文件系统中读取到的数据是确定的，但是里边的有效数据是不确定的。 流对象的设计，至少应该支持两种操作：一种是读取一个字节，另一种是读取多个字节。而无论读取一个字节还是读取多个字节，都应该适配内核的底层行为。也就是说，每次流对象读取一个字节，内核可能会读取 2k、4k 的数据。这样的行为，才能真的做到减少磁盘的 I/O 操作。 那内核为什么不一次先读取几兆数据或者读取更大的数据呢？这有两个原因。 如果是高并发场景下，并发读取数据时内存使用是根据并发数翻倍的，如果同时读取的数据量过大，可能会导致内存不足。 读取比 2k/4k……大很多倍的数据，比如 1M/2M 这种远远大于内存分页大小的数据，并不能提升性能。 上图中内核中的缓冲区，用于缓冲读取文件中的数据。流中的缓冲区，用于缓冲内核中拷贝过来的数据。 为什么不把内核的缓冲区直接给到流呢？这是因为流对象工作在用户空间，内核中的缓冲区工作在内核空间。用户空间的程序不可以直接访问内核空间的数据，这是操作系统的一种保护策略。 当然也存在一种叫作内存映射的方式，就是内核通过内存映射，直接将内核空间中的一块内存区域分享给用户空间只读使用，这样的方式可以节省一次数据拷贝。这个能力在 Java 的 NIO 中称作 DirectMemory，对应 C 语言是 mmap。 缓冲区上面的设计中，我们已经开始用缓冲区解决问题了。那么具体什么是缓冲区呢？缓冲区就是一块用来做缓冲的内存区域。在上面的例子当中，为了应对频繁的字节读取，我们在内存当中设置一个 2k 大小缓冲区。这样读取 2048 次，才会真的发生一次读取。同理，如果应对频繁的字节写入，也可以使用缓冲区。 不仅仅如此，比如说你设计一个秒杀系统，如果同时到达的流量过高，也可以使用缓冲区将用户请求先存储下来，再进行处理。这个操作我们称为削峰，削去流量的峰值。 缓冲区中的数据通常具有朴素的公平，说白了就是排队，先进先出（FIFO）。从数据结构的设计上，缓冲区像一个队列。在实际的使用场景中，缓冲区有一些自己特别的需求，比如说缓冲区需要被重复利用。多次读取数据，可以复用一个缓冲区，这样可以节省内存，也可以减少分配和回收内存的开销。 文件流 -&gt; 缓冲区 -&gt; 网络流 举个例子：读取一个流的数据到一个缓冲区，然后再将缓冲区中的数据交给另一个流。 比如说读取文件流中的数据交给网络流发送出去。首先，我们要将文件流的数据写入缓冲区，然后网络流会读取缓冲区中的数据。这个过程会反反复复进行，直到文件内容全部发送。 这个设计中，缓冲区需要支持这几种操作： 写入数据 读出数据 清空（应对下一次读写） 那么具体怎么设计这个缓冲区呢？如下图所示： 将 position 设置为 0，limit 不变的操作称为flip操作，flip 本意是翻转，在这个场景中是读、写状态的切换。 读取操作可以控制循环从 position 一直读取到 limit，这样就可以读取出 a,b,c,d。那么如果要继续写入应该如何操作呢？ 这个时候就需要用到缓冲区的clear操作，这个操作会清空缓冲区。具体来说，clear操作会把 position,limit 都设置为 0，而不需要真的一点点擦除缓冲区中已有的值，就可以做到重复利用缓冲区了。 写入过程从 position = 0 开始，position 和 limit 一起自增。读取时，用flip操作切换缓冲区读写状态。读取数据完毕，用clear操作重置缓冲区状态。 总结: 流是随着时间产生的数据。数据抽象成流，是因为客观世界存在着这样的现象。数据被抽象成流之后，我们不需要把所有的数据都读取到内存当中进行计算和迭代，而是每次处理或者计算一个缓冲区的数据。 缓冲区的作用是缓冲，它在高频的 I/O 操作中很有意义。针对不同场景，也不只有这一种缓冲区的设计，比如用双向链表实现队列（FIFO 结构）可以作为缓冲区；Redis 中的列表可以作为缓冲区；RocketMQ，Kafka 等也可以作为缓冲区。针对某些特定场景，比如高并发场景下的下单处理，可能会用订单队列表（MySQL 的表）作为缓冲区。 因此从这个角度来说，作为开发者我们首先要有缓冲的意识，去减少 I/O 的次数，提升 I/O 的性能，然后才是思考具体的缓冲策略。 问题：在缓存区的设计中，还通常有一个rewind操作，这个操作用来做什么的。 **12. 网络I/O模型：BIO, NIO和AIO有什么区别在处理 I/O 的时候，要结合具体的场景来思考程序怎么写。从程序的 API 设计上，我们经常会看到 3 类设计：BIO、NIO 和 AIO 。 从本质上说，讨论 BIO、NIO、AIO 的区别，其实就是在讨论 I/O 的模型，我们可以从下面 3 个方面来思考 。 编程模型：合理设计 API，让程序写得更舒服。 数据的传输和转化成本：比如减少数据拷贝次数，合理压缩数据等。 高效的数据结构：利用好缓冲区、红黑树等 I/O编程模型 BIO（Blocking I/O，阻塞 I/O），API 的设计会阻塞程序调用。 NIO（None Blocking I/O, 非阻塞I/O），API的设计不会阻塞程序的调用 比如： 1byte a &#x3D; readKey() 假设readKey方法从键盘读取一个按键，如果是非阻塞 I/O 的设计，readKey不会阻塞当前的线程。你可能会问：那如果用户没有按键怎么办？在阻塞 I/O 的设计中，如果用户没有按键线程会阻塞等待用户按键，在非阻塞 I/O 的设计中，线程不会阻塞，没有按键会返回一个空值，比如 null。 线程的上下文切换(Context Switch): 从一个线程执行切换到另一个线程执行 最后我们说说 AIO（Asynchronous I/O， 异步 I/O），API 的设计会多创造一条时间线。比如 1234func callBackFunction(byte keyCode) &#123; &#x2F;&#x2F; 处理按键&#125;readKey( callBackFunction ) 在异步 I/O 中，readKey方法会直接返回，但是没有结果。结果需要一个回调函数callBackFunction去接收。从这个角度看，其实有两条时间线。第一条是程序的主干时间线，readKey的执行到readKey下文的程序都在这条主干时间线中。而callBackFunction的执行会在用户按键时触发，也就是时间不确定，因此callBackFunction中的程序是另一条时间线也是基于这种原因产生的，我们称作异步，异步描述的就是这种时间线上无法同步的现象，你不知道callbackFunction何时会执行。 但是我们通常说某某语言提供了异步 I/O，不仅仅是说提供上面程序这种写法，上面的写法会产生一个叫作回调地狱的问题，本质是异步程序的时间线错乱，导致维护成本较高。 123456789request(&quot;&#x2F;order&#x2F;123&quot;, (data1) -&gt; &#123; &#x2F;&#x2F;.. request(&quot;&#x2F;product&#x2F;456&quot;, (data2) -&gt; &#123; &#x2F;&#x2F; .. request(&quot;&#x2F;sku&#x2F;789&quot;, (data3) -&gt; &#123; &#x2F;&#x2F;... &#125;) &#125;)&#125;) 比如上面这段程序（称作回调地狱）维护成本较高，因此通常提供异步 API 编程模型时，我们会提供一种将异步转化为同步程序的语法。比如下面这段伪代码： 12345678Future future1 &#x3D; request(&quot;&#x2F;order&#x2F;123&quot;)Future future2 &#x3D; request(&quot;&#x2F;product&#x2F;456&quot;)Future future3 &#x3D; request(&quot;&#x2F;sku&#x2F;789&quot;)&#x2F;&#x2F; ...&#x2F;&#x2F; ...order &#x3D; future1.get()product &#x3D; future2.get()sku &#x3D; future3.get() request 函数是一次网络调用，请求订单 ID=123 的订单数据。本身 request 函数不会阻塞，会马上执行完成，而网络调用是一次异步请求，调用不会在request(“/order/123”)下一行结束，而是会在未来的某个时间结束。因此，我们用一个 Future 对象封装这个异步操作。future.get()是一个阻塞操作，会阻塞直到网络调用返回。 在request和future.get之间，我们还可以进行很多别的操作，比如发送更多的请求。 像 Future 这样能够将异步操作再同步回主时间线的操作，我们称作异步转同步，也叫作异步编程。 数据的传输和转化成本 上面我们从编程的模型上对 I/O 进行了思考，接下来我们从内部实现分析下 BIO、NIO 和 AIO。无论是哪种 I/O 模型，都要将数据从网卡拷贝到用户程序（接收），或者将数据从用户程序传输到网卡（发送）。 另一方面，有的数据需要编码解码，比如 JSON 格式的数据。还有的数据需要压缩和解压。数据从网卡到内核再到用户程序是 2 次传输。注意，将数据从内存中的一个区域拷贝到另一个区域，这是一个 CPU 密集型操作。数据的拷贝归根结底要一个字节一个字节去做。 网卡 -&gt; 内核 -&gt; 用户程序 从网卡到内核空间的这步操作，可以用 DMA（Direct Memory Access）技术控制。DMA 是一种小型设备，用 DMA 拷贝数据可以不使用 CPU，从而节省计算资源。遗憾的是，通常我们写程序的时候，不能直接控制 DMA，因此 DMA 仅仅用于设备传输数据到内存中。 不过，从内核到用户空间这次拷贝，可以用内存映射技术，将内核空间的数据映射到用户空间。 无论I/O的编程模型如何选择，数据传输和转化成本是逃不掉的，通过DMA技术和内存映射技术，就可以节省成本： 减少数据传输 数据压缩解压 数据编码解码 数据结构运用 在处理网络 I/O 问题的时候，还有一个重点问题要注意，就是数据结构的运用。 缓冲区 是一种在处理 I/O 问题中常用的数据结构，一方面缓冲区起到缓冲作用，在瞬时 I/O 量较大的时候，利用排队机制进行处理；另一方面，缓冲区起到一个批处理的作用，比如 1000 次 I/O 请求进入缓冲区，可以合并成 50 次 I/O 请求，那么整体性能就会上一个档次。 举个例子，比如你有 1000 个订单要写入 MySQL，如果这个时候你可以将这 1000 次请求合并成 50 次，那么磁盘写入次数将大大减少。同理，假设有 10000 次网络请求，如果可以合并发送，会减少 TCP 协议握手时间，可以最大程度地复用连接；另一方面，如果这些请求都较小，还可以粘包复用 TCP 段。在处理 Web 网站的时候，经常会碰到将多个 HTTP 请求合并成一个发送，从而减少整体网络开销的情况。 除了上述两方面原因，缓冲区还可以减少实际对内存的诉求。数据在网卡到内核，内核到用户空间的过程中，建议都要使用缓冲区。当收到的某个请求较大的时候，抽象成流，然后使用缓冲区可以减少对内存的使用压力。这是因为使用了缓冲区和流，就不需要真的准备和请求数据大小一致的内存空间了。可以将缓冲区大小规模的数据分成多次处理完，实际的内存开销是缓冲区的大小 I/O 多路复用模型 在运用数据结构的时候，还要思考 I/O 的多路复用用什么模型。 假设你在处理一个高并发的网站，每秒有大量的请求打到你的服务器上，你用多少个线程去处理 I/O 呢？对于没有需要压缩解压的场景，处理 I/O 的主要开销还是数据的拷贝。那么一个 CPU 核心每秒可以完成多少次数据拷贝呢？ 拷贝，其实就是将内存中的数据从一个地址拷贝到另一个地址。再加上有 DMA，内存映射等技术，拷贝是非常快的。不考虑 DMA 和内存映射，一个 3GHz 主频的 CPU 每秒可以拷贝的数据也是百兆级别的。当然，速度还受限于内存本身的速度。因此总的来说，I/O 并不需要很大的计算资源。通常我们在处理高并发的时候，也不需要大量的线程去进行 I/O 处理。 对于多数应用来说，处理 I/O 的成本小于处理业务的成本。处理高并发的业务，可能需要大量的计算资源。每笔业务也可能会需要更多的 I/O，比如远程的 RPC 调用等。 因此我们在处理高并发的时候，一种常见的 I/O 多路复用模式就是由少量的线程处理大量的网络接收、发送工作。然后再由更多的线程，通常是一个线程池处理具体的业务工作。 在这样一个模式下，有一个核心问题需要解决，就是当操作系统内核监测到一次 I/O 操作发生，它如何具体地通知到哪个线程调用哪段程序呢？ 这时，一种高效的模型会要求我们将线程、线程监听的事件类型，以及响应的程序注册到内核。具体来说，比如某个客户端发送消息到服务器的时候，我们需要尽快知道哪个线程关心这条消息（处理这个数据）。例如 epoll 就是这样的模型，内部是红黑树。我们可以具体地看到文件描述符构成了一棵红黑树，而红黑树的节点上挂着文件描述符对应的线程、线程监听事件类型以及相应程序。 讲了这么多，缓冲区 和 BIO、AIO、NIO 有什么关系？这里有两个联系。 首先是无论哪种编程模型都需要使用缓冲区，也就是说 BIO、AIO、NIO 都需要缓冲区，因此关系很大。在我们使用任何编程模型的时候，如果内部没有使用缓冲区，那么一定要在外部增加缓冲区。另一个联系是类似 epoll 这种注册+消息推送的方式，可以帮助我们节省大量定位具体线程以及事件类型的时间。这是一个通用技巧，并不是独有某种 I/O 模型才可以使用。 不过从能力上分析，使用类似 epoll 这种模型，确实没有必要让处理 I/O 的线程阻塞，因为操作系统会将需要响应的事件源源不断地推送给处理的线程，因此可以考虑不让处理线程阻塞（比如用 NIO） 总结: 从 3 个方面讨论了 I/O 模型。 第一个是编程模型，阻塞、非阻塞、异步 3 者 API 的设计会有比较大的差异。通常情况下我们说的异步编程是异步转同步。异步转同步最大的价值，就是提升代码的可读性。可读，就意味着维护成本的下降以及扩展性的提升。 第二个在设计系统的 I/O 时，另一件需要考虑的就是数据传输以及转化的成本。传输主要是拷贝，比如可以使用内存映射来减少数据的传输。但是这里要注意一点，内存映射使用的内存是内核空间的缓冲区，因此千万不要忘记回收。因为这一部分内存往往不在我们所使用的语言提供的内存回收机制的管控范围之内。 最后是关于数据结构的运用，针对不同的场景使用不同的缓冲区，以及选择不同的消息通知机制，也是处理高并发的一个核心问题。 从上面几个角度去看 I/O 的模型，你会发现，编程模型是编程模型、数据的传输是数据的传输、消息的通知是消息的通知，它们是不同的模块，完全可以解耦，也可以根据自己不同的业务特性进行选择。虽然在一个完整的系统设计中，往往提出的是一套完整的解决方案 ，但实际上我们还是应该将它们分开去思考，这样可以产生更好的设计思路。 问题： BIO、NIO 和 AIO 有什么区别？ 总的来说，这三者是三个 I/O 的编程模型。BIO 接口设计会直接导致当前线程阻塞。NIO 的设计不会触发当前线程的阻塞。AIO 为 I/O 提供了异步能力，也就是将 I/O 的响应程序放到一个独立的时间线上去执行。但是通常 AIO 的提供者还会提供异步编程模型，就是实现一种对异步计算封装的数据结构，并且提供将异步计算同步回主线的能力。 通常情况下，这 3 种 API 都会伴随 I/O 多路复用。如果底层用红黑树管理注册的文件描述符和事件，可以在很小的开销内由内核将 I/O 消息发送给指定的线程。另外，还可以用 DMA，内存映射等方式优化 I/O。 问题： I/O 多路复用用协程和用线程的区别？ 线程是执行程序的最小单位。I/O 多路复用时，会用单个线程处理大量的 I/O。还有一种执行程序的模型，叫协作程，协程是轻量级的线程。操作系统将执行资源分配给了线程，然后再调度线程运行。如果要实现协程，就要利用分配给线程的执行资源，在这之上再创建更小的执行单位。协程不归操作系统调度，协程共享线程的执行资源。 而 I/O 多路复用的意义，是减少线程间的切换成本。因此从设计上，只要是用单个线程处理大量 I/O 工作，线程和协程是一样的，并无区别。如果是单线程处理大量 I/O，使用协程也是依托协程对应线程执行能力。 13. 面试中如何回答“怎样实现RPC框架”的问题随着微服务架构的盛行，远程调用成了开发微服务必不可少的能力，RPC 框架作为微服务体系的底层支撑，也成了日常开发的必备工具。当下，RPC 框架已经不仅是进行远程调用的基础工具，还需要提供路由、服务发现、负载均衡、容错等能力。那么今天，我们就以“怎样实现 RPC 框架”为引，从设计者角度看看如何设计一个 RPC 框架。 RPC（Remote Procedure Call）远程过程调用，顾名思义最基本的能力当然是远程调用一个过程。放到今天的面向对象的语言中，其实就是调用一个远程的方法。在远程我们必须先定义这个方法，然后才可以通过 RPC 框架调用该方法，远程调用不仅可以传参数、获取到返回值，还可以捕捉调用过程中的异常。RPC 让远程调用就像本地调用一样。 假设我们实现了一个rpc对象，其中的invoke方法可以实现远程调用。下面这段伪代码在调用远程的greetings方法（RPC 调用），并向远程方法传递参数arg1``arg2，然后再接收到远程的返回值。 1var result &#x3D; rpc.invoke(&quot;greetings&quot;, arg1, arg2, ...) 复制这段程序将本地看作 一个 RPC 的客户端，将远程看作一个 RPC 的服务端。如下图所示： 服务 A 发起远程方法调用，RPC 客户端通过某种协议将请求发送给服务 B，服务 B 解析请求，进行本地方法的调用，将结果返回到服务 B 的 RPC 服务端，最终返回到服务 A。 对服务 A 来说，调用的是一个函数，从接口到返回值的设计，和调用本地函数并没有太大的差别。 当然，我们不能完全忽略这是一次远程方法调用，因为远程调用的开销较大。如果程序员没有意识到调用远程方法有网络开销，就可能会写出下面这段程序： 123for(int i &#x3D; 0; i &lt; 1000000; i++) &#123; rpc.invoke(...)&#125; 之所以写出上面的程序，是因为 没有意识到 rpc.invoke 是一次远程调用。在实际的操作过程中，rpc.invoke可能被封装到了某个业务方法中，程序员调用的时候便容易忽视这是一次远程操作。所以 RPC 调用时就要求我们对性能有清晰的认识。 多路复用的优化 RPC 提供的是远程方法的调用，但本质上是数据的传递，传递数据有一个最基本的问题要处理，就是提升吞吐量（单位时间传递的数据量） 如果**为每个远程调用（请求）建立一个连接，就会造成资源的浪费，因此通常我们会考虑多个请求复用一个连接，叫作多路复用**。 在具体实现多路复用的时候，也会有不同的策略。假设我们要发送数据 A、B、C、D，那么一种方式是建立一个连接，依次将 A、B、C、D 发过去，就像下图这样： 在 A 较大的时候，B，C，D 就只能等 A 完全传送完成才能发生传送。这样的模型对于 RPC 请求/响应大小不平均的网络不太友好，体积小的请求/响应可能会因为一些大体积的请求/响应而延迟。 因此还有另一种常见的多路复用方案，就是将 A,B,C,D切片一起传输，如上图(3)所示 上图中，我们用不同颜色代表不同的传输任务。采用顺序传输方案将 A、B、C、D 用一个连接传输节省了握手、挥手的成本。切片传输的方案在这之上，将数据切片可以保证大、小任务并行，不会因为大任务阻塞小任务。 另外还有一个需要考虑的点，是单个 TCP 连接的极限传输速度受到窗口大小、缓冲区等因素的制约，不一定可以用满网络资源。如果传输量特别大的时候，有可能需要考虑提供多个连接，每个连接再去考虑多路复用的情况。 调用约定和命名 接下来，我们一起思考下服务的命名。远程调用一个函数，命名空间＋类名＋方法名是一个比较好的选择，简而言之，每个可以远程调用的方法就是一个字符串。 比如远程调用一个支付服务对象 PayService 的 pay 方法 命名空间可能是 trade.payment 对象名称是 PayService 方法名称是 pay 组合起来可以是一个完整的字符串，例如用 # 分割trade.payment#PayService#pay。 在进行远程调用的时候，给远程方法命名是调用约定的一部分。我们通过调用命名空间下完整的名称调用远程方法。在面向对象的语言中，还有一种常见的做法是先不具体指定调用的方法，而是先创造一个远程对象的实例。比如上面例子中我们先通过 RPC 框架构造一个 PayService 对象的实例。这里会用到一些特别的编程技巧，比如代理设计模式、动态接口生成等。 不过归根结底，我们调用的本质就是字符串名称。而实现这个调用，你需要知道两件事情： IP 是多少，也就是方法在哪台机器上调用； 端口是多少，也就是哪个服务提供这个调用。 注册和发现 调用的时候，我们需要根据字符串（命名）去获取 IP 和端口（机器和服务）。 机器可以是虚拟机、容器、实体机，也可以是某个拥有虚拟网卡的代理。在网络的世界中，需要的只是网络接口和 IP 地址。而操作系统区分应用需要的是端口。所以，在调用过程中，我们需要的是一个注册表，存储了字符串和 IP + 端口的对应关系。 聪明的同学可能马上会想到，用 Redis 的hash对象存储这个对应关系就很不错。当我们上线一个服务的时候，就在 Redis 的某个hash对象中存储它和它对应的 IP 地址 + 端口列表。为什么是存一个列表？因为一个服务可能由多个机器提供。 通常我们**将写这个hash对象的过程，也就是服务被记录的过程称作注册。我们远程调用一个 RPC 服务的时候，调用端提供的是 RPC 服务的名称（例如：命名空间+对象+方法），根据名称查找到提供服务的 IP + 端口清单并指定某个 IP + 端口（提供服务）的过程称作发现**。 当然，我们不能就这样简单理解成：注册就是写一个共享的哈希表，发现就是查哈希表再决定服务的响应者。在实际的设计中，要考虑的因素会更多。 比如基于 Redis 的实现，如果所有 RPC 调用都需要去 Redis 查询，会造成负责发现的中间件压力较大。 实际的操作过程中，往往会增加缓存。也就是 RPC 调用者会缓存上一次调用的 IP + 端口。但是这样设计，缓存又可能会和注册表之间产生数据不一致的问题。 这个时候，可以考虑由分布式共识服务比如 ZooKeeper 提供订阅，让 RPC 调用者订阅到服务地址的变更，及时更新自己的缓存。 设计注册和发现两个功能的最大的价值是让客户端不再需要关注服务的部署细节，这样方便在全局动态调整服务的部署策略。 负载均衡的设计 在设计 RPC 框架的时候，负载均衡器的设计往往需要和 RPC 框架一起考虑。因为 RPC 框架提供了注册、发现的能力，提供发现能力的模块本身就是一个负载均衡器。因此负载均衡可以看作发现模块的一个子组件。请求到达 RPC 的网关（或某个路由程序）后，发现组件会提供服务对应的所有实例（IP + 端口），然后负载均衡算法会指定其中一个响应这个请求。 可用性和容灾 当一个服务实例崩溃的时候（不可用），因为有发现模块的存在，可以及时从注册表中删除这个服务实例。 只要服务本身有足够多的实例，比如多个容器而且部署在不同的机器上，那么完全不可能用的风险会大大降低。当然，可用性是不可能 100% 实现的。 另外，注册表和 RPC 调用者之间必然存在不一致现象，而且注册表的更新本身也可能滞后。比如确认一个服务有没有崩溃，可能需要一个心跳程序持续请求这个服务，因此 RPC 的调用者如果调用到一个不存在的服务，或者调用到一个发生崩溃的服务，需要自己重新去发现组件申请新的服务实例（地址 + 端口）。 如果遇到临时访问量剧增，需要扩容的场景。这个时候只需要上线更多的容器，并且去注册即可。当然这要求部署模块和注册模块之间有较高的协同，这块可以用自动化脚本衔接。 总结 设计一个 RPC 框架最基础的能力就是实现远程方法的调用。这里需要一个调用约定， 比如怎么描述一个远程的方法， 发送端怎么传递参数， 接收方如何解析参数？ 如果发生异常应该如何处理？ 具体来说，这些事情都不难实现，只是比较烦琐。 其实不仅仅在 RPC 调用时有调用约定 编译器在实现函数调用的时候，也会有调用约定。 另外，还有一些在 RPC 基础上建立起来的更复杂、更体系化的约定，比如说面向服务架构（SOA）。 在实现了基本调用能力的基础上，**接下来就是提供服务的注册、发现能力。有了这两个能力，就可以向客户端完全屏蔽服务的部署细节，并衍生出容灾、负载均衡的设计。[我不理解]** 当然，程序员还需要思考底层具体网络的传输问题。 如果用 TCP 要思考多路复用以及连接数量的问题； 如果是 UDP，需要增加对于可靠性保证的思考。 如果使用了消息队列，还需要考虑服务的幂等性设计等。 问题： 如何理解Dubbo的几个组成部分Consumer, Provider, Monitor和Registry? Web技术 HTTP协议-&gt;Web技术生态 14. DNS域名解析系统：CNAME记录的作用是在浏览器中输入一个 URL，或者用curl请求一个网址……域名系统（Domain Name System）就开始工作了。作为互联网的一个重要成员，域名系统是将互联网资源和地址关联起来的一个分布式数据库。 统一资源定位符（URL, Uniform Resource Locator）可以通过字符串定位一个互联网的资源,比如视频、图片、文件、网页。 下图是一个 URL 的示例： Scheme 部分代表协议，不只有 https，还有 ftp、ssh 等。不同协议代表着不同类型的应用在提供资源。 Host 部分代表站点，我们今天介绍的 DNS 主要作用就是根据 Host 查找 IP 地址。 Port 是端口，代表提供服务的应用。 Path 是路径，代表资源在服务中的路径。 Query 是查询条件，代表需要的是资源中的某一个部分。 Fragment 是二级查询条件，通常不在服务端响应，而是用于前端展示定位内容。 总的来说，URL 是一种树状的设计， Host 代表主机（对应的 IP 地址由 DNS 服务提供）；Port 代表应用；Path 代表资源在应用中的路径；Query 代表对资源的查询条件。通过这种设计，互联网中万亿级别的资源都可以得到有效区分。 树状的设计在今天计算机中也非常常见，比如 文件目录的设计 源代码块的嵌套设计 JSON 和 XML 的设计，都是树状关系。 域名系统 DNS（Domain Name System，域名系统）是一个将域名和 IP 地址相互映射的分布式服务。 根域名服务器 （Root Name Server） 位于最顶层的是根域名服务器 DNS 本身是一个出色的分布式架构。 人们在全世界范围内搭建了多台根域名服务器，2016 年的统计数据中，全世界目前有 13 台 IPv4 根服务器，25 台 IPv6 根服务器。 根域名服务器存储的不是域名和 IP 的映射关系，而是一个目录。 如果将所有的域名记录都存放到根域名服务器，从存储量上来说，不会非常巨大。要知道一个域名记录——域名、IP 地址和额外少量信息，并不需要大量存储空间。 但是如果全世界所有的 DNS 请求都集中在少量的根服务器上，这个访问流量就会过于巨大。而且一旦发生故障，很容易导致大面积瘫痪。 而且因为根服务器较少，所以如果全部都走根服务器，不同客户端距离根服务器距离不同，感受到的延迟也不一样，这样对用户来说不太友好。 因此，因为流量、防止单点故障、平衡地理分布等问题，根域名服务器只是一个目录，并不提供具体的数据。 域名分级和数据分区 我们知道中文字典可以按照偏旁部首以及拼音索引，和字典类似，根服务器提供的目录也有一定的索引规则。 在域名的世界中，通过分级域名的策略建立索引。伴随着域名的分级策略，实际上是域名数据库的拆分。 通过域名的分级，可以将数据库划分成一个个区域。 平时我们看到的.com.cn.net等，称为顶级域名。比如对于 www.artisan.com 这个网址来说，com是顶级域名，artisan是二级域名，www是三级域名。 域名分级当然是为了建立目录和索引，并对数据存储进行分区。 根DNS服务器 com DNS服务器 baidu taobao net DNS服务器 org DNS服务器 DNS 的存储设计是一个树状结构。叶子节点中才存放真实的映射关系，中间节点都是目录。存储分成 3 层： 顶部第一级是根 DNS 存储，存储的是顶级域的目录，被称作根 DNS 服务器； 第二级是顶级域存储，存储的是二级域的目录，被称作顶级域 DNS 服务器（Top Level DNS，TLD）； 最后一级是叶子节点，存储的是具体的 DNS 记录，也被称作权威 DNS 服务器。 DNS 查询过程当用户在浏览器中输入一个网址，就会触发 DNS 查询。这个时候在上述的 3 个层级中，还会增加本地 DNS 服务器层级。本地 DNS 服务器包括用户自己路由器中的 DNS 缓存、小区的 DNS 服务器、ISP 的 DNS 服务器等。主要步骤如下： 用户输入网址，查询本地 DNS。 本地 DNS 是一系列 DNS 的合集，比如 ISP 提供的 DNS、公司网络提供的 DNS。本地 DNS 是一个代理，将 DNS 请求转发到 DNS 网络中。如果本地 DNS 中已经存在需要的记录，也就是本地 DNS 缓存中找到了对应的 DNS 条目，就会直接返回，而跳过之后的步骤。 客户端请求根 DNS 服务器。 如果本地 DNS 中没有对应的记录，那么请求会被转发到根 DNS 服务器。根 DNS 服务器只解析顶级域，以“www.artisan.com”为例，根 DNS 服务器只看 com 部分。 根 DNS 服务器返回顶级 DNS 服务器的 IP。 客户端请求顶级 DNS 服务器，顶级 DNS 服务器中是具体域名的目录。 顶级 DNS 服务器返回权威 DNS 服务器的 IP。 客户端请求权威 DNS 服务器。在权威 DNS 服务器上存有具体的 DNS 记录。以 artisan为例，权威 DNS 服务器中可能有和 artisan.com 相关的上百条甚至更多的 DNS 记录，会根据不同的 DNS 查询条件返回。 权威 DNS 服务器返回 DNS 记录到本地 DNS 服务器。 本地 DNS 服务器返回具体的 DNS 记录给客户端。 在上述 8 个过程全部结束后，客户端通过 DNS 记录中的 IP 地址，可以找到请求服务的主机。 客户端最终可以找到 对应的 IP 地址，从而获得 Web 服务。 关于缓存 在上面的例子当中，每一步都有缓存的设计。浏览器会缓存 DNS，此外，操作系统、路由器、本地 DNS 服务器也会……因此，绝大多数情况，请求不会到达根 DNS 服务器。 以artisan为例，如果在某个时刻同一个区域内有一个用户触发过上述 1~8 的过程，另一个同区域的用户就可以在本地 DNS 服务器中获得 DNS 记录，而不需要再走到根 DNS 服务器。这种设计，我们称作分级缓存策略。 在分级缓存策略中，每一层都会进行缓存，经过一层层的缓存，最终命中根 DNS 服务、顶级 DNS 服务器以及权威 DNS 服务的请求少之又少。这样，互联网中庞大流量的 DNS 查询就不需要大量集中的资源去响应。 DNS 记录 12;定义www.example.com的ip地址www.example.com. IN A 139.18.28.5; 上面的就是一条 DNS 记录，纯文本即可。 IN 代表记录用于互联网，是 Intenet 的缩写。在历史上 Internet 起源于阿帕网，在同时代有很多竞争的网络，IN 这个描述也就保留了下来。 www.example.com 是要解析的域名。 A 是记录的类型，A 记录代表着这是一条用于解析 IPv4 地址的记录。从这条记录可知，www.example.com的 IP 地址是 139.18.28.5。 ;是语句块的结尾，也是注释。 那么除了 A 记录，还有哪些 DNS 记录的类型呢？DNS 记录的类型非常多，有 30 多种。其中比较常见的有 A、AAAA、CNAME、MX，以及 NS 等 CNAME（Canonical Name Record） 用于定义域名的别名，如下面这条 DNS 记录： 12; 定义www.example.com的别名a.example.com. IN CNAME b.example.com. 当你想把一个网站迁移到新域名，旧域名仍然保留的时候；还有当你想将自己的静态资源放到 CDN 上的时候，CNAME 就非常有用 AAAA 记录 前面我们提到，A 记录是域名和 IPv4 地址的映射关系。和 A 记录类似，AAAA 记录则是域名和 IPv6 地址的映射关系。 MX 记录（Mail Exchanger Record）MX 记录是邮件记录，用来描述邮件服务器的域名。 在工作中，我们经常会发邮件到某个同事的邮箱。比如说，发送一封邮件到 &#120;&#x69;&#x61;&#111;&#x6d;&#x69;&#110;&#103;&#64;&#x61;&#114;&#x74;&#x69;&#115;&#x61;&#x6e;&#x2e;&#x63;&#111;&#x6d;，那么artisan如何知道哪个 IP 地址是邮件服务器呢？ 这个时候就可以用到下面这条 MX 记录： 1IN MX mail.artisan.com 这样凡是 @artisan的邮件都会发送到 mail.artisan.com 中，而 mail.artisan.com 的 IP 地址可以通过查询 mail.artisan.com 的 A 记录和 AAAA 记录获得。 NS 记录（Name Server）记录是描述 DNS 服务器网址。从 DNS 的存储结构上说，Name Server 中含有权威 DNS 服务的目录。也就是说，NS 记录指定哪台 Server 是回答 DNS 查询的权威域名服务器。 当一个 DNS 查询看到 NS 记录的时候，会再去 NS 记录配置的 DNS 服务器查询，得到最终的记录。如下面这个例子： 12a.com. IN NS ns1.a.com.a.com. IN NS ns2.a.com. 当解析 a.com 地址时，我们看到 a.com 有两个 NS 记录，所以确定最终 a.com 的记录在 ns1.a.com 和 ns2.a.com 上。从设计上看，ns1 和 ns2 是网站 a.com 提供的智能 DNS 服务器，可以提供负载均衡、分布式 Sharding 等服务。比如当一个北京的用户想要访问 a.com 的时候，ns1 看到这是一个北京的 IP 就返回一个离北京最近的机房 IP。 上面代码中 a.com 配置了两个 NS 记录。通常 NS 不会只有一个，这是为了保证高可用，一个挂了另一个还能继续服务。通常数字小的 NS 记录优先级更高，也就是 ns1 会优先于 ns2 响应。 配置了上面的 NS 记录后，如果还配置了 a.com 的 A 记录，那么这个 A 记录会被 NS 记录覆盖。 总结 用树状结构来分类和索引符合人类的直觉和习惯，URL 的设计遵循的依然是人的思考方式。 URL 中的 HOST 部分需要被解析为 IP 地址，于是就有了域名系统（DNS）。域名系统是一个分级的分布式系统，整体设计也是一个树状结构。 顶层的根域名服务器和中间的顶级域名服务器，存储的是目录，最终的 DNS 记录由权威域名服务器提供。DNS 记录并不仅仅只有映射 IP 一种能力，DNS 记录还可以设置网站的别名、邮件服务器、DNS 记录位置等能力。 问题： CNAME 记录的作用是？ CNAME 是一种 DNS 记录，它的作用是将一个域名映射到另一个域名。域名解析的时候，如果看到 CNAME 记录，则会从映射目标重新开始查询。 15. 内容分发网络：请简述CDN回源是如何工作对于一些体量较大的应用来说，如果把大量资源集中到单一节点进行分发，恐怕很难有某个机房可以支撑得住这么大的流量。 例如一个日活在 100W 的小型互联网产品，如果每次请求需要 1M 的数据，那就刚好是近 1TB 数据。对于这样的数据规模而言，完全由单一节点进行分发是不现实的。 因此现在互联网应用在分发内容的时候，并不是从自己架设的服务器上直分发内容，而是走一个叫作内容分发网络（Content Dilivery Network）的互联网底层建设。 域名系统类似，内容分发网络（Content Dilivery Network，CDN）是一个专门用来分发内容的分布式应用。 CDN 构建在现有的互联网之上，通过在各地部署数据中心，让不同地域的用户可以就近获取内容。 这里的内容通常指的是文件、图片、视频、声音、应用程序安装包等，它们具有一个显著的特征——无状态，或者说是静态的。这些资源不像订单数据、库存数据等，它们一旦发布，就很少会发生变化。另一个显著的特征，是这些资源往往会被大量的用户需要，因此分发它们的流量成本是较高的。 为什么不能集中提供这些静态资源呢？这和域名系统的 DNS 记录不能集中提供是一个道理，需要考虑到流量、单点故障、延迟等因素。 在离用户更近的地理位置提供资源，可以减少延迟。 按照地理位置分散地提供资源，也可以降低中心化带来的服务压力。 因此，CDN 的服务商会选择在全球布点，或者在某个国家布点。具体要看 CDN 服务提供商的服务范围。目前国内的阿里云、腾讯云等也在提供 CDN 业务。 内容的分发 CDN 是一个分布式的内容分发网络。 当用户请求一个网络资源时，用户请求的是 CDN 提供的资源。 和域名系统类似，当用户请求一个资源时，首先会接触到一个类似域名系统中目录的服务，这个服务会告诉用户究竟去哪个 IP 获取这个资源。 事实上，很多大型的应用，会把 DNS 解析作为一种负载均衡的手段。当用户请求一个网址的时候，会从该网站提供的智能 DNS 中获取网站的 IP。 例如当你请求百度的时候，具体连接到哪个百度的 IP，是由百度使用的智能 DNS 服务决定的。域名系统允许网站自己为自己的产品提供 DNS 解析 当用户请求一个静态资源的时候，首先会触发域名系统的解析。域名系统会将解析的责任交由 CDN 提供商来处理，CDN 的智能 DNS 服务会帮助用户选择离自己距离最近的节点，返回这个节点的 A（或 AAAA）记录。然后客户端会向 CDN 的资源节点发起请求，最终获得资源。 在上面整个过程当中，CDN 的智能 DNS 还充当了负载均衡的作用。如果一个节点压力过大，则可以将流量导向其他的节点。 回源 讨论了 CDN 的主要设计和架构，但是还有一个问题没有解决——就是资源怎么进入内容分发网络? 资源的生产者，也是 CDN 的购买者，目的是向用户提供网络服务。 那么服务提供者的静态资源如何进入 CDN 呢？ 手动上传、用接口推送，还是通过其他别的方式呢？ 可以把 CDN 想象成一个分布式的分级缓存，再加上数据库的两层设计，如下图所示： 用户的请求先到达缓存层，如果缓存被穿透，才到达最终的存储层。缓存的设计必须是分布式的，因为绝大多数的资源使用都会发生在缓存上，只有极少数的请求才会穿透到底层的存储。通常这种设计，我们期望缓存层至少需要帮挡住 99% 的流量。既然缓存层能挡住 99% 的流量，那么实际的数据存储就可以交由源站点完成。 值得一提的是，在程序设计当中有一个核心的原则，叫作单一数据源（Single Souce of Truth， SSOT）。这个原则指的是，在程序设计中，应该尽可能地减少数据的来源，最好每个数据来源只有单独一份。这样能够避免大量的数据不一致以及同步数据的问题。 基于这样的设计，谁来提供资源的存储呢？ 谁来提供这个单一的数据源呢？当然是服务提供者本身。如果 CDN 再提供 一份资源的存储，不就有两个数据源了吗？而且，只有服务的提供者才能更好地维护这个资源仓库。 在 CDN 的设计当中，CDN 实际上提供的是数据的缓存。而原始数据，则由服务的提供者提供。 用户请求静态资源通常用自己的域名（防止跨域和一些安全问题）。为了让用户请求的是自己的网站，而使用的是 CDN 的服务，这里会使用 CNAME 让自己的域名作为 CDN 域名的一个别名。当请求到 CDN 服务的时候，会首先由 CDN 的 DNS 服务帮助用户选择一个最优的节点，这个 DNS 服务还充当了负载均衡的作用。接下来，用户开始向 CDN 节点请求资源。**如果这个时候资源已经过期或者还没有在 CDN 节点上，就会从源站读取数据，这个步骤称为CDN 的回源**。 另一方面，CDN 上缓存的资源通常也会伴随失效时间的设置，当失效之后同样会触发回源。另一种情况是可以通过开放的 API 或者 CDN 管理后台直接删除缓存（让资源失效），这个操作结束后，同样会触发回源。 总结 CDN 是一种网络应用，作用是分发互联网上的资源。CDN 服务的提供商，会在世界（或国家）范围内设立数据中心，帮助分发资源。用户请求的资源会被 CDN 分发到最临近的节点获取。 CDN 作为一门生意，CDN 的服务商会大批量的从运营商处获取流量，然后再以较高但是可以接受的价格卖给服务提供方。 对于中小型互联网公司来说，购买一定的 CDN 流量成本可控，比如 1G 流量在 1 元以内。对于大型的互联网公司，特别是对 CDN 依赖严重的公司，可能还需要自己建设。比如 2021 年抖音每天分发的数据量在 50PB 左右（1PB=1024TB），如此庞大的数据量如果换算成钱是非常高的。按照阿里云的报价，50PB 的价格是 480W 人民币。按照这种体量计算，抖音每天要花 480W 人民币，一年是 17 亿。 所以当你设计一个内容分发的方案时，除了要考虑到其中的技术细节，也要从成本上进行思考，看看能不能从数据压缩、资源格式角度做一些文章。 问题： 请简述 CDN 回源是如何工作的？ CDN 回源就是 CDN 节点到源站请求资源，重新设置缓存。通常服务提供方在使用 CDN 的时候，会在自己的某个域名发布静态资源，然后将这个域名交给 CDN。 比如源站在 s.example.com 中发布静态资源，然后在 CDN 管理后台配置了这个源站。在使用 CDN 时，服务提供方会使用另一个域名，比如说 b.example.com。然后配置将 b.example.com 用 CNAME 记录指向 CDN 的智能 DNS。 这个时候，如果用户下载b.example.com/a.jpg，CDN 的智能 DNS 会帮用户选择一个最优的 IP 地址（最优的 CDN 节点）响应这次资源的请求。如果这个 CDN 节点没有 a.jpg，CDN 就会到 s.example.com 源站去下载，缓存到 CDN 节点，然后再返回给用户。 CDN 回源有 3 种情况， 一种是 CDN 节点没有对应资源时主动到源站获取资源； 另一种是缓存失效后，CDN 节点到源站获取资源； 还有一种情况是在 CDN 管理后台或者使用开放接口主动刷新触发回源。 如果你的应用需要智能 DNS 服务，你将如何实现？ 首先你可以在你的域名解析系统中增加两条（或以上）ns 记录。比如说你的域名是 example.com，那么你可以增加 ns1.exmaple.com, ns2.example.com。当然，指定这两个域名的 IP 还需要配置两个 A 记录。 然后你需要两台机器（也可以是容器或者虚拟机），对应 ns1 和 ns2。最好用不在同一个物理机上的两个容器，这样可以避免一台物理机故障导致服务瘫痪。然后在每个容器（虚拟机）上安装一个 Named 服务。 Named 是一个专门用来提供 DNS 服务的工具，在虚拟机上安装完成 Named 后，这个虚拟机就变成了一个权威服务器节点。 配置好 Named 后，你需要写几个脚本文件，给要提供 DNS 的域名配置信息。Named 配套使用的有个叫作 GeoDNS 的插件，可以提供基于地理位置的智能 DNS 服务。 16. HTTP协议面试通关：强制缓存和协商缓存的区别是超文本传输协议（HyperText Transfer Protocol，HTTP） 是目前使用最广泛的应用层协议。 1990 年蒂姆·伯纳斯·李开发了第一个浏览器，书写了第一个 Web 服务器程序和第一张网页。网页用的语言后来被称作超文本标记语言（HTML），而在服务器和客户端之间传输网页的时候，伯纳斯·李没有直接使用传输层协议，而是在 TCP 的基础上构造了一个应用层协议，这个就是超文本传输协议 HTTP。 万维网（World Wide Web， WWW） 是伯纳斯·李对这一系列发明，包括 Web 服务、HTTP 协议、HTML 语言等一个体系的综合。 请求响应和长连接 HTTP 协议采用请求/返回模型。客户端（通常是浏览器）发起 HTTP 请求，然后 Web 服务端收到请求后将数据回传。 HTTP 的请求和响应都是文本，可以简单认为 HTTP 协议利用 TCP 协议传输文本。当用户想要看一张网页的时候，就发送一个文本请求到 Web 服务器，Web 服务器解析了这段文本，然后给浏览器将网页回传。 那么这里有一个问题，是不是每次发送一个请求，都建立一个 TCP 连接呢？ 当然不能这样，为了节省握手、挥手的时间。当浏览器发送一个请求到 Web 服务器的时候，Web 服务器内部就设置一个定时器。在一定范围的时间内，如果客户端继续发送请求，那么服务器就会重置定时器。如果在一定范围的时间内，服务器没有收到请求，就会将连接断开。这样既防止浪费握手、挥手的资源，同时又避免一个连接占用时间过长无法回收导致内存使用效率下降。 这个能力可以利用 HTTP 协议头进行配置，比如下面这条请求头： 1Keep-Alive: timeout&#x3D;5s 会告诉 Web 服务器连接的持续时间是 5s，如果 5s 内没有请求，那么连接就会断开。 Keep-Alive 并不是伯纳斯·李设计 HTTP 协议时就有的能力。伯纳斯·李设计的第一版 HTTP 协议是 0.9 版，后来随着协议逐渐完善，有了 1.0 版。而 Keep-Alive 是 HTTP 1.1 版增加的功能，目的是应对越来越复杂的网页资源加载。从 HTTP 协议诞生以来，网页中需要的资源越来越丰富，打开一张页面需要发送的请求越来越多，于是就产生了 Keep-Alive 的设计。 同样，当一个网站需要加载的资源较多时，浏览器会尝试并发发送请求（利用多线程技术）。浏览器会限制同时发送并发请求的数量，通常是 6 个，这样做一方面是对用户本地体验的一种保护，防止浏览器抢占太多网络资源；另一方面也是对站点服务的保护，防止瞬时流量过大。 在 HTTP 2.0 之后，增加了多路复用能力。和 RPC 框架时提到的多路复用类似，请求、返回会被拆分成切片，然后混合传输。这样请求、返回之间就不会阻塞。你可以思考，对于一个 TCP 连接，在 HTTP 1.1 的 Keep-Alive 设计中，第二个请求，必须等待第一个请求返回。如果第一个请求阻塞了，那么后续所有的请求都会阻塞。而 HTTP 2.0 的多路复用，将请求返回都切分成小片，这样利用同一个连接，请求相当于并行的发出，互相之间不会有干扰。 HTTP 方法和 RestFul 架构 伴随着 HTTP 发展，也诞生了一些著名的架构，比如 RestFul。在面试中，经常会遇到 RestFul，RestFul 是 3 个单词的合并缩写： Re（Representational） st（State） Ful（Transfer） 这个命名非常有趣，让我联想到 grep 命令的命名，global regular pattern match。这是一种非常高端的命名技巧，提取词汇中的一个部分组合成为一个读起来朗朗上口的新词汇，建议在实战命名的时候也可以考虑试试。 在 RestFul 架构中，状态仅仅存在于服务端，前端无状态。 状态（State）可以理解为业务的状态，这个状态是由服务端管理的。这个无状态和服务端目前倡导的无状态设计不冲突，现在服务端倡导的无状态设计指的是容器内的服务没有状态，状态全部存到合适的存储中去。所以 Restful 中的 State，是服务端状态。 前端（浏览器、应用等）没有业务状态，却又要展示内容，因此前端拥有的是状态的表示，也就是 Representation。 比如一个订单，状态存在服务端（数据库中），前端展示订单只需要部分信息，不需要全部信息。前端只需要展示数据，展示数据需要服务端提供。所以服务端提供的不是状态，而是状态的表示。 前端没有状态，当用户想要改变订单状态的时候，比如支付，这个时候前端就向服务端提交表单，然后服务端触发状态的变化。这个过程我们称为转化（Transfer）。从这个角度来看，Restful 讲的是一套前端无状态、服务端管理状态，中间设计转化途径（请求、函数等）的架构方法。这个方法可以让前后端职责清晰，前端负责渲染， 服务端负责业务。前端不需要业务状态，只需要展示。服务端除了关心状态，还要提供状态的转换接口 缓存在 HTTP 的使用中，我们经常会遇到两种缓存，强制缓存和协商缓存，接下来举两个场景来说明。 强制缓存 举个例子： 公司用版本号管理某个对外提供的 JS 文件。比如说 libgo.1.2.3.js，就是 libgo 的 1.2.3 版本。其中 1 是主版本，2 是副版本，3 是补丁编号。每次你们有任何改动，都会更新 libgo 版本号。在这种情况下，当浏览器请求了一次 libgo.1.2.3.js 文件之后，还需要再请求一次吗？ 整理下我们的需求，浏览器在第一次进行了GET /libgo.1.2.3.js这个操作后，如果后续某个网页还用到了这个文件（libgo.1.2.3.js），我们不再发送第二次请求。这个方案要求浏览器将文件缓存到本地，并且设置这个文件的失效时间（或者永久有效）。这种请求过一次不需要再次发送请求的缓存模式，在 HTTP 协议中称为强制缓存。当一个文件被强制缓存后，下一次请求会直接使用本地版本，而不会真的发出去。 使用强制缓存时要注意，千万别把需要动态更新的数据强制缓存。一个负面例子就是小明把获取用户信息数据的接口设置为强制缓存，导致用户更新了自己的信息后，一直要等到强制缓存失效才能看到这次更新。 协商缓存 我们再说一个场景：小明开发了一个接口，这个接口提供全国省市区的 3 级信息。先问你一个问题，这个场景可以用强制缓存吗？小明一开始觉得强制缓存可以，然后突然有一天接到运营的通知，某市下属的两个县合并了，需要调整接口数据。小明错手不急，更新了接口数据，但是数据要等到强制缓存失效。 为了应对这种场景，HTTP 协议还设计了协商缓存。协商缓存启用后，第一次获取接口数据，会将数据缓存到本地，并存储下数据的摘要。第二次请求时，浏览器检查到本地有缓存，将摘要发送给服务端。服务端会检查服务端数据的摘要和浏览器发送来的是否一致。如果不一致，说明服务端数据发生了更新，服务端会回传全部数据。如果一致，说明数据没有更新，服务端不需要回传数据。 从这个角度看，协商缓存的方式节省了流量。对于小明开发的这个接口，多数情况下协商缓存会生效。当小明更新了数据后，协商缓存失效，客户端数据可以马上更新。和强制缓存相比，协商缓存的代价是需要多发一次请求。 总结 目前 HTTP 协议已经发展到了 2.0 版本，不少网站都更新到了 HTTP 2.0。大部分浏览器、CDN 也支持了 HTTP 2.0。 可以自行查阅更多关于 HTTP 2.0 解决队头阻塞、HPack 压缩算法、Server Push 等资料。 另外 HTTP 3.0 协议也在建设当中，HTTP 3.0 对 HTTP 2.0 兼容，主要调整发生在网络底层。HTTP 3.0 开始采用 UDP 协议，并在 UDP 协议之上，根据 HTTP 协议的需求特性，研发了网络层、应用层去解决可靠性等问题。 17. 流媒体技术：直播网站是如何实现的如何将视频抽象成流？就是传输一部分即可播放一部分 在实际的操作当中，设计了一种类似目录的格式，将音频数据进行切片，这部分能力利用现有的工具FFmpeg就可以轻松做到，安装FFmpeg，利用如下指令处理一个mp4，就可以生成很多切片（切割成HTTP Live Streaming可以播放的切片）和一个目录文件 12ffmpeg -i input.mp4 -c:v libx264 -c:a aac -strict -2 -fhls output.m3u8ls # 可查看目录文件，下载视频时可根据&#96;.m3u8&#96;内容下载对应的&#96;.ts&#96;文件 流媒体的架构 视频录制得到MP4等格式的文件 上传到服务器进行编码[编码产生不同清晰度文件]，产生上述切片文件 切片文件存储到流媒体服务器中 然后从视频目录读取 直播 录制吨不断上传视频内容 视频内容编码后由流媒体服务器负责分发 如果观看人数较多，可以使用CDN回源到流媒体服务器 m3u8文件可以看作一个动态的文件，能够不断产生新的数据，因此直播技术中，可以将获取m3u8文件设计成一个接口，不断由播放器获取新的m3u8文件 其他音视频网站 将视频编码后切片 然后利用CDN分发目录和切片文件，就可以播放了 视频的编码和解码 视频文件较大，因此在传输前需要压缩 在播放前需要解码 视频的压缩技术：是针对视频的特征进行特别处理的压缩技术，视频的压缩算法本质上是对图片的压缩，主要依靠人类视觉的残留效应 H264 就是国际标准化组织在推广的一种编码格式。在 H264 的视频编码技术中，有一个叫作宏块的概念。宏块，就是将画面分成大小不等的区域。比如说 8x8、16x16 等。当播放两个连续的画面的时候，你可以理解成两张图片。如果基于图片分析，那么播放的就是很多个宏块。在这连续的两帧画面中，并不是所有的宏块都发生了变化。 点到点视频技术 在视频会议、面对面聊天等场景下，需要点到点的视频技术 如果是1对1的视频聊天，可以考虑点到点的服务 Host1 &lt;–(UDP等)–&gt; Host2 在NAT通信中，往往需要在内网的主机发起连接，这个时候NAT模块识别发起的端口并记录。如上图，如果客户是公网IP，Host1可以找到该客户建立连接，但是客户是无法主动连接Host1 如下图，如果双方都在内网，都需要NAT场景，就无法建立连接。Host1 发送请求但由于客户没有建立连接而被拒绝，反之亦然，类似多线程的死锁问题无法解决。这是就需要第三方服务器，这台服务器可以作，为NAT模块辅助功能，让双方的NAT模块以为和对方发起过连接请求，这个解决方案叫做NAT穿透 在WebRTC协议中，可以提供网页版的1对1聊天，如果需要连接两个内网的机器，就需要架设第三方服务。 如果在线会议，人数较少可以点到点，但人数较多就需要考虑以下方案： 放弃点到点技术，直接采用类似直播架构的中心化服务 利用边缘计算，让距离相近的参会者利用共同的离自己最近的服务器交换数据 总结流媒体，就是把多媒体数据抽象成为流进行传输。视频本质上是一张张图片在播放，因此非常适合流传输。要知道，流是随着时间产生的数据。 通常在一个网络中，等价成本下吞吐量、丢包率和延迟 3 者不能兼得。 对延迟要求较高的场景，可能需要降低视频质量或者部署边缘服务器 人数较少，可以采用点对点技术，但是要考虑NAT穿透问题 问题： 直播网站是如何实现的 录制端： 负责录制视频直播视频，用流的形式上传 计算集群：专门负责编码上传的流数据，然后进行压缩、转码、切片等工作 对象存储：存储原视频和转码后的视频（相当于CDN的源，回源用） CDN: 将转码后的内容分发到离用户较近的节点，方便用户获取 直播APP：给用户看直播时使用 作业：写一张网页：用webrtc实现点到点通信 18. 爬虫和反爬虫：如何防止黑产爬取我的数据反爬虫的手段主要有：robots.txt、用户识别、字符加密算法、数据加密算法。 robots.txt文件规定哪些数据可以爬虫、哪些不可以爬虫； 针对自己账号范围实现某个功能，如对建立筛选，不属于违法行为； 爬虫的原理：本质上就是一次网络请求，然后将返回的数据保存下来 对于搜索引擎的爬虫而言，通常会在请求头中加上自己的标识，比如百度会加上baidu字符串，这样方便网站服务器识别。 爬虫如果是非法的，往往就需要伪装成浏览器，通常会用到浏览器内核，模拟发出网络请求、 chronium(Chrome的开源内核) 用chronium发请求的时候，对于服务提供方的反爬虫系统，请求就变成了一次标准的用户行为，如果对方网站需要登陆才能爬取数据，不法分子还会模拟登陆行为。如果仅仅输入用户名和密码，那这个网站的登陆行为非常容易模拟，只需要找到对应的接口，用户和密码传输过去，就可以拿到访问资源的令牌 验证码–通过深度学习模型训练图片，进行识别；更难的就是加滑块 模拟用户动作 将原始数据存储，然后进行分析 如果爬取网页数据，后续会用到HTML解析器(Parser) 如果爬取的接口数据，通常就是分析json IP的反追踪，就是利用代理，增加追踪的成本。可以通过大量购买IP然后模拟多用户攻击【临时租用大量的IP地址的价格低廉，降低犯罪成本】 反爬虫基本操作 robots.txt 从法律上告诉爬虫哪些页面是不可爬取的 用户识别 对高频访问的IP加以限制，但有时候有些公司共用一个IP出口，也不是很有效 设备指纹:利用设备上的信息，生成一个具有唯一性的字符串，这种算法是非标准化的，因此不同的数据安全团队会有自己的算法，比限制IP好 根据唯一用户设置数据安全策略，访问频次，黑名单等 字体加密, 爬虫爬取的通常就是用户本身可以看到的内容，将UTF8编码中的汉字顺序打乱，然后将对应的数据换序。 加密传输 APP的数据抓取依赖APP数据传输使用的标准协议，比如用HTTPS协议传输数据的App,爬虫可以在App端安装证书，然后利用代理实现中间人抓包。如果数据用自己的协议加密，抓包的同时，必须破解这个加密协议 网络安全 基础设施（证书、加解密、公私钥体系、信任链等） 具体的攻击手段（DDos、XSS、SQL注入、ARP攻击、中间人攻击等） 防御手段 19. 网络安全概述：对称、非对称加密的区别 对称加密：数据加密标准（DES）算法在 1976 年被美国国家标准局定为使用标准，DES 采用的 56 位密钥，每次计算加密 64 位的数据，目前已经被证明可以被暴力破解，所谓暴力破解，就是遍历所有可能的密钥解析数据的方法；为了应对暴力破解等问题，很多团队选择对称加密算法时开始使用高级加密标准（AES），这个加密法用 128 位密钥，并设计了更难破解的算法。 非对称加密：目前最常见且广泛使用的非对称加密算法是 RSA 算法。RSA 依赖的是大整数的分解，以及一些和素数相关的算法。目前没有理论可以破译 RSA 算法。总体来说，RSA 密钥越长破解成本就越高，因此仍然被广泛使用。 对称加密和解密可以用同一套秘钥 非对称加密利用数学的方法生成公私钥对，公钥加密的数据私钥可以解密，私钥加密的数据公钥可以解密 公钥不能解密公钥加密的数据，私钥也不能解密私钥加密的数据 20. 信任链：为什么可以相信一个HTTPS网站当用户用浏览器打开一个 HTTPS 网站时，会到目标网站下载目标网站的证书。接下来，浏览器会去验证证书上的签名，一直验证到根证书。如果根证书被预装，那么就会信任这个网站。也就是说，网站的信用是由操作系统的提供商、根证书机构、中间证书机构一起在担保。 摘要和签名 MD5 SHA-1 摘要算法 摘要是一种数学证明 在摘要上用私钥加密就是签名，签名可以防止数据被篡改、伪造等 在摘要和签名的基础上，可以利用原本的社会关系，让一些信用优秀的结构提供信用 21. 攻防手段介绍：如何低于SYN拒绝攻击DDoS 拒绝服务攻击(Denial of Service Attack, DoS)，利用大量的流量迅速向一个网站发送出去，攻击者一般没有足够的经济实力购买机器，利用中病毒、木马的肉机组织流量攻击，这种方式也被称为分布式拒绝服务攻击(Distributed Denial of Service Attack, DDoS) 直接不停发送Ping消息的，利用底层的ICMP协议，称为ICMP攻击 走UDP协议的，称为**UDP洪水(UDP Flood) 不停的用TCP协议发送SYN消息的，也叫SYN攻击 防范措施： 防火墙根据特征识别出攻击行为，通过这样的方式将攻击行为过滤掉，让系统不会因为DDos而过载造成崩溃 切换流量，从日常生产环境-同城灾备环境-异地灾备环境 CDN 是大量缓存节点，DDoS攻击CDN的时候用不上力 设计一台吞吐量极高的代理服务器，作为反向代理挡在所有服务器前面，如果遇到DDoS，代理服务器可以识别出一些特征并丢弃一些流量 在遇到攻击的时候，对服务适当降级也是有必要的，通过允许防火墙造成一部分的误伤来识别更多的攻击流量 前端框架 React和 Vue开发基本杜绝XSS攻击 中间人攻击 不法分子利用自己的伪装基站设备伪装成基站 跨站脚本攻击(XSS) 跨站脚本(Cross Site Scripting)，利用漏洞将脚本注入网页，例如提交个人信息的输入框，如果在服务端没有处理好，就可能出发夸张脚本攻击 如何抵御 SYN 拒绝攻击？ SYN 攻击是 DDoS 攻击的一种形式。这种形式攻击者伪装成终端不停地向服务器发起 SYN 请求。 通常攻击者的“肉鸡”，发送了 SYN 之后，不等给服务端 ACK，就下线了。 这样攻击者不断发送 SYN ，然后下线，而服务端会等待一段时间（通常会在 3s 以上），等待 ACK。这样就导致了大量的连接对象在服务端被积累。 针对这个特点，可以实现TCP代理(防火墙) 哪些情况服务器的/etc/passwd文件会被黑客拿走 漫游互联网： 什么是蜂窝移动网络参考：https://www.bilibili.com/video/BV1B34y1e7kU?p=8&amp;spm_id_from=pageDriver&amp;vd_source=27f6135965c74480fdc752d98427d3b2 https://cloud.tencent.com/developer/article/1862663 https://www.cnblogs.com/jmcui/p/15003579.html#top 非常好的网络基础教程：https://docs.oracle.com/cd/E19253-01/819-7058/oviewtm-1/index.html","categories":[{"name":"Networking","slug":"Networking","permalink":"http://shizhonggan.github.io/categories/Networking/"}],"tags":[{"name":"Networking","slug":"Networking","permalink":"http://shizhonggan.github.io/tags/Networking/"}]},{"title":"Docker 部署 Django","slug":"Django/django_deploy","date":"2022-07-17T03:03:04.000Z","updated":"2022-08-05T12:34:58.213Z","comments":true,"path":"2022/07/17/Django/django_deploy/","link":"","permalink":"http://shizhonggan.github.io/2022/07/17/Django/django_deploy/","excerpt":"","text":"docker 部署 django web123456789101112131415161718demosite├── db.sqlite3├── demosite│ ├── htmlstudy.py│ ├── __init__.py│ ├── search.py│ ├── settings.py│ ├── testdb.py│ ├── urls.py│ ├── views.py│ └── wsgi.py├── manage.py├── media├── readme├── test.py├── uwsgi.ini└── uwsgi_params mysql 安装 与设置123456789101112131415161718192021222324252627282930313233$ apt install mysql-server # 安装数据库$ apt-get install libmysqlclient-dev # 必须安装$ pip3 install mysqlclient # 不安装上面module，此处安装会失败$ sql ### 常用命令mysql&gt; create database database_name # 创建数据库mysql&gt; show databases; # 查看数据库列表mysql&gt; use database_name; # 使用某一个数据库,进入该数据库下mysql&gt; create table table_name (id int,age int) # 在该数据库下创建表格,括号内是列名和对应的类型,一列即可mysql&gt; drop database database_name # 删除某个数据库mysql&gt; show tables; # 查看所有表#####mysql&gt; create database demosite; # 创建名为demosite的数据库mysql&gt; use demosite; # 进入该数据库下mysql&gt; create table demosite # 创建名为demosite的表，可与数据库名重复mysql&gt; create user &#x27;demosite&#x27;@&#x27;localhost&#x27; identified by &#x27;setting-user-password&#x27;;## grant使用说明Grant &lt;权限&gt; on 表名[(列名)] to 用户 With grant option或 GRANT &lt;权限&gt; ON &lt;数据对象&gt; FROM &lt;数据库用户&gt; mysql&gt; grant usage on *.* to &#x27;demosite&#x27;@&#x27;localhost&#x27;; # demoste无权访问所有文件mysql&gt; grant all privileges on demosite.* to &#x27;demosite&#x27;@&#x27;localhost&#x27;;# 赋予demosite用户访问demosite数据库下所有表的权限,注意demosite区分###### demosite django程序的setting.py文件修改DATABASES = &#123; &#x27;default&#x27;: &#123; &#x27;ENGINE&#x27;: &#x27;django.db.backends.mysql&#x27;, &#x27;NAME&#x27;: &#x27;demosite&#x27;, # 数据库名 &#x27;USER&#x27;: &#x27;demosite&#x27;, # 用户名 &#x27;PASSWORD&#x27;: &#x27;1234&#x27;, # 用户密码 &#x27;HOST&#x27;: &#x27;localhost&#x27;, &#x27;PORT&#x27;:3306, # mysql默认端口 &#125;&#125; docker 安装操作系统ubuntu18，该系统有大量的软件库，因此安装docker极为方便，通常命令行输入docker，若未安装该软件，会提示如何快捷安装。 1sudo apt install docker.io 1$ docker search ubuntu 12345678910NAME DESCRIPTION STARS OFFICIAL AUTOMATEDubuntu Ubuntu is a Debian-based Linux operating sys… 9843 [OK]dorowu&#x2F;ubuntu-desktop-lxde-vnc Docker image to provide HTML5 VNC interface … 334 [OK]rastasheep&#x2F;ubuntu-sshd Dockerized SSH service, built on top of offi… 228 [OK]consol&#x2F;ubuntu-xfce-vnc Ubuntu container with &quot;headless&quot; VNC session… 186 [OK]ubuntu-upstart Upstart is an event-based replacement for th… 99 [OK]ansible&#x2F;ubuntu14.04-ansible Ubuntu 14.04 LTS with ansible 97 [OK]neurodebian NeuroDebian provides neuroscience research s… 58 [OK]1and1internet&#x2F;ubuntu-16-nginx-php-phpmyadmin-mysql-5 ubuntu-16-nginx-php-phpmyadmin-mysql-5 50 [OK]ubuntu-debootstrap debootstrap --variant&#x3D;minbase --components&#x3D;m… 40 [OK] 12$ docker pull ubuntu$ docker images uwsgi 安装 设置1234567pip3 install uwsgi# demosite下创建test.py，测试uwsgi def application(env, start_response): start_response(&#x27;200 OK&#x27;, [(&#x27;Content-Type&#x27;,&#x27;text/html&#x27;)]) return [b&quot;Hello World&quot;] # python3 #return [&quot;Hello World&quot;] # python2uwsgi --http :8000 --wsgi-file test.py # 若服务器IP:8000访问成功，即没有问题，一般情况都是正常的 运行123456789101112### 前三行命令参考菜鸟教程，后边为正常操作$ python manage.py migrate # 创建表结构, 此处我也不是很明白$ python manage.py makemigrations TestModel # 让 Django 知道我们在我们的模型有一些变更$ python manage.py migrate TestModel # 创建表结构python3 manage.py makemigrations # 执行该命令,djangoweb就知道发生了哪些变化，日常操作python3 manage.py runserver 0.0.0.0:8000 # 服务器首先需要打开端口8000，浏览器打开 服务器IP:8000 即可访问uwsgi --http :8000 --module demosite.wsgi # 或者采用这种方式### 关闭服务器远程桌面，django web 后台保护模式运行，不停止nohup uwsgi --http :8000 --module demosite.wsgi &amp; ps -aux | grep uwsgi |awk &#x27;&#123;print $2&#125;&#x27; |xargs kill -9 #终止后台托管uwsgi --http-socket :6816 --plugin python --wsgi-file demosite/wsgi.py 静态文件部署docker 部署123456789101112131415FROM ubuntu/python:3.6.8MAINTAINER gsz &quot;gan_shizhong@163.com&quot;ENV mypath /demositeWORKDIR $mypathCOPY ./demosite/* $mypathRUN apt update \\ &amp;&amp; apt install -y python3-pip \\ mysql-server\\ &amp;&amp; pip3 install uwsgi \\ djangoEXPOSE 8001CMD python3 manage.py makemigrationsENTRYPOINT [ &quot;uwsgi&quot; ]CMD [&quot;--http :8001 --module demosite.wsgi&quot;] 123456789101112131415FROM ubuntu/python:3.6.8MAINTAINER gsz &quot;gan_shizhong@163.com&quot;ENV mypath /demositeWORKDIR $mypathCOPY ./sendcloud_django2/* $mypathRUN apt update \\ &amp;&amp; apt install -y python3-pip &amp;&amp; pip3 install uwsgi \\ django==2.2.8EXPOSE 8002CMD python3 manage.py makemigrationsCMD python3 manage.py migrateENTRYPOINT [ &quot;uwsgi&quot; ]CMD [&quot;--http :8002 --module demosite.wsgi&quot;] nginx uwsgi 部署1. 参考文献Django 部署(Nginx) 添加镜像源 编辑源配置文件 /etc/apt/sources.list 123456789101112131415161718192021222324echo &#39;#aliyundeb http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; trusty main restricted universe multiversedeb http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; trusty-security main restricted universe multiversedeb http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; trusty-updates main restricted universe multiversedeb http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; trusty-proposed main restricted universe multiversedeb http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; trusty-backports main restricted universe multiversedeb-src http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; trusty main restricted universe multiversedeb-src http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; trusty-security main restricted universe multiversedeb-src http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; trusty-updates main restricted universe multiversedeb-src http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; trusty-proposed main restricted universe multiversedeb-src http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; trusty-backports main restricted universe multiverseecho &#39;# tsinghuadeb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; xenial main restricteddeb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; xenial-updates main restricteddeb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; xenial universedeb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; xenial-updates universedeb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; xenial multiversedeb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; xenial-updates multiversedeb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; xenial-backports main restricted universe multiversedeb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; xenial-security main restricteddeb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; xenial-security universedeb http:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;ubuntu&#x2F; xenial-security multiverse&#39; &gt; &#x2F;etc&#x2F;apt&#x2F;sources.list 执行 apt-get update pip添加镜像源 临时使用1pip3 install -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple some-package 设置默认(存在问题pip3 不行)12pip3 install pip3 -Upip3 config set global.index-url https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple PYTHONIOENCODING=utf-8 python your_script.py 2. 具体流程 启动docker1docker run -it -p 8321:8001 -v /home/ec2-user/sinnetflow/:/home/ --name sinnetflow centos:centos7 bash 安装12345678910111213141516171819202122232425262728293031323334## nginx 安装yum install epel-releaseyum install nginx## mariadb 安装 vi /etc/yum.repos.d/MariaDB.repo[mariadb]name = MariaDBbaseurl = https://mirrors.tuna.tsinghua.edu.cn/mariadb/yum/10.5/centos7-amd64/gpgkey = https://mirrors.tuna.tsinghua.edu.cn/mariadb/yum/RPM-GPG-KEY-MariaDBgpgcheck = 1## 清楚并创建缓存yum clean allyum makecacheyum install MariaDB-server MariaDB-client -ysystemctl start mariadbsystemctl enable mariadbsystemctl status mariadbyum install python3-pipyum install gcc mysql-devel python3-develpip install mysqlclienttraceroute ICMP 1234pip3 install uwsgi --upgradepip3 install django==2.2pip3 install requests nginx 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354## 配置文件 cp /etc/nginx/sites-available/default /etc/nginx/sites-available/default.bakvim /etc/nginx/sites-available/default## 内容如下：server &#123; listen 8000; location / &#123; uwsgi_pass django; include /etc/nginx/uwsgi_params; &#125; location /media &#123; alias /home/media; &#125; location /static &#123; alias /static; &#125;&#125;upstream django&#123; server unix:///etc/workflow/workflow.sock; # server 127.0.0.1:8001;&#125;## 项目根目录下新建uwsgi.ini , 内容如下：# mysite_uwsgi.ini file[uwsgi]# Django-related settings# the base directory (full path)chdir = /home# Django&#x27;s wsgi filemodule = sinnet.wsgi# the virtualenv (full path)# process-related settings# mastermaster = true# maximum number of worker processesprocesses = 4# the socket (use the full path to be safesocket = /etc/mailweb/mysite.sock# ... with appropriate permissions - may be needed# chmod-socket = 664# clear environment on exitvacuum = truesocket-timeout = 20000daemonize = /etc/mailweb/mailweb.loglog-maxsize = 50000000disable-logging = truemax-requests = 5000pidfile = /etc/mailweb/mailweb.pid 部署操作12345678910# setting.py 设置 static_root &#x3D; &quot;path&quot;，服务器环境的绝对路径# Debug改成False# 时区修改python3 manage.py collectstatic # 首先将静态文件集中到一个文件夹下# 启动 nginxservice nginx restart# 启动 uwsgiuwsgi -d --ini uwsgi.ini #后台uwsgi --stop mailweb.pid # 终止进程 使用supervisor管理进程12345678910111213141516171819pip3 install supervisor # 安装echo_supervisord_conf &gt; /etc/supervisord.conf # 生成默认配置文件## 修改配置文件，再supervisord.conf末尾添加，同事修改其他log文件路径，避免放在temp文件下。[program:celerytask]command=celery worker -A celerytask.main -l infodirectory=/home/startsecs=0stopwaitsecs=0autostart=trueautorestart=truestdout_logfile=/var/log/sinnetMail/sinnetmail_celery.logstdout_logfile_maxbytes=10MB ; max # logfile bytes b4 rotation (default 50MB)stderr_logfile=/var/log/sinnetMail/sinnetmail_celery_err.logstderr_logfile_maxbytes=10MB ; max # logfile bytes b4 rotation (default 50MB)# 启动supervisord -c /etc/supervisord.conf# 通用命令supervisorctl -c /etc/supervisord.conf [start|stop|restart] [program-name|all] git .gitigonre 失效解决办法123git rm -r --cachedgit add .git commit -m &quot;update .gitignore&quot;","categories":[{"name":"Django","slug":"Django","permalink":"http://shizhonggan.github.io/categories/Django/"}],"tags":[{"name":"Django","slug":"Django","permalink":"http://shizhonggan.github.io/tags/Django/"},{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/tags/Docker/"},{"name":"Mysql","slug":"Mysql","permalink":"http://shizhonggan.github.io/tags/Mysql/"}]},{"title":"Shell编程学习","slug":"Shell/shell","date":"2022-05-30T07:54:23.000Z","updated":"2022-10-13T02:46:43.160Z","comments":true,"path":"2022/05/30/Shell/shell/","link":"","permalink":"http://shizhonggan.github.io/2022/05/30/Shell/shell/","excerpt":"","text":"shell 概述命令行解释器 硬件 -&gt; Linux 内核 -&gt; shell (cd, ls, …) -&gt; 外层应用程序。 shell 解析器12345678910111213# Linux提供的shell解析器有：[ec2-user@master bin]$ cat /bin/shell /bin/sh/bin/bash/usr/bin/sh/usr/bin/bash/usr/bin/tmux[ec2-user@master bin]$ ll |grep bash-rwxr-xr-x 1 root root 964608 Oct 31 2018 bashlrwxrwxrwx 1 root root 10 Feb 26 2019 bashbug -&gt; bashbug-64-rwxr-xr-x 1 root root 6964 Oct 31 2018 bashbug-64lrwxrwxrwx 1 root root 4 Feb 26 2019 sh -&gt; bash 可以看出sh也用的bash解析器 shell 脚本入门脚本格式，如下，开头指定解析器，不是注释 1#!/bin/bash 初识shell脚本 12345678910111213141516171819202122[ec2-user@master test]$ touch helloworld.sh # 创建第一个shell脚本[ec2-user@master test]$ vi helloworld.sh#!/bin/bashecho &quot;hello world, ganshizhong&quot;## 执行脚本的三种方式[ec2-user@master test]$ sh helloworld.shhello world, ganshizhong[ec2-user@master test]$ bash helloworld.shhello world, ganshizhong[ec2-user@master test]$ ./helloworld.sh-bash: ./helloworld.sh: Permission denied# 第三种要给权限，如下操作[ec2-user@master test]$ lltotal 4-rw-rw-r-- 1 ec2-user ec2-user 44 May 30 14:39 helloworld.sh[ec2-user@master test]$ chmod 777 helloworld.sh # 赋予+x权限[ec2-user@master test]$ lltotal 4-rwxrwxrwx 1 ec2-user ec2-user 44 May 30 14:39 helloworld.sh[ec2-user@master test]$ ./helloworld.shhello world, ganshizhong 例子 1234#!&#x2F;bin&#x2F;bashcd &#x2F;home&#x2F;ec2-user&#x2F;test&#x2F;touch test1.txtecho &quot;i love you&quot; &gt;&gt; test1.txt shell中的变量1. 常用变量: $HOME, $PWD, $SHELL, $USER等1echo $HOME, $PWD, $SHELL, $USER 2. 自定义变量 基本语法 定义变量：变量=值 撤销变量：unset 变量 声明静态变量： readonly变量，注意不能unset 变量定义规则 变量可由字母、数字和下划线组成，但不能以数字开头，环境变量建议大写 等号两侧不能有空格 在bash中，变量默认类型都是字符串类型，无法直接进行数值计算 变量的值如果有空格，需要使用双引号或单引号括起来 12345678910111213A=1echo $Aunset Areadonly B=3unset B # 不生效D=&quot;I love gsz&quot;echo D# 把变量提升到全局变量，供其他shell程序使用export 变量名 3. 特殊变量$n 功能描述：n为数字，$0代表该脚本名称，$1-$9代表第一到第九个参数，十以上的参数需要用大括号，如 ${10} 12345678910[ec2-user@master test]$ vi parameter.sh[ec2-user@master test]$ sh parameter.sh#!/bin/bashecho &quot;$0&quot;echo &quot;$1 $2 $3&quot;echo &quot;$@&quot;echo &quot;$*&quot;[ec2-user@master test]$ sh parameter.sh gsz a aa aaaaparameter.shgsz a aa $# 功能描述：获取所有输入参数个数，常用循环 $* 功能描述：表示命令行中所有的参数，并把所有参数看作一个整体 $@ 功能描述：表示命令行中所有的参数，但区分对待每个参数 $? 功能描述：最后一次执行的命令的返回状态。如果这个变量的值为0，证明上一个命令正确执行；如果这个变量的值为非0，则不正确。 运算符基本语法 “$((运算式))” 或 “$[运算式]” expr +,-,*,/,% 加减乘除取余 expr运算符间要有空格 123456789[ec2-user@master test]$ expr 3 + 25[ec2-user@master test]$ expr `expr 2 + 3` \\* 420[ec2-user@master test]$ expr `expr 2 + 3` \\* 420[ec2-user@master test]$ s=$[(2+3)*4][ec2-user@master test]$ echo $s20 条件判断 基本语法 [ condition ] 注意前后要有空格，条件非空即为true，[atguigu]返回true,[]返回false. 常用判断条件 两个整数之间比较 =字符串比较 -lt 小于(less than) -le 小于等于(less equal) -eq 等于(equal) -gt 大于(greater than) -ge 大于等于(greater equal) -ne 不等于(not equal) 按照文件权限进行判断 -r 有读写权限(read) -w 有写的权限（write) -x 有执行的权限(execute) 按照文件类型进行判断 -f 文件存在且是一个常规的文件（file） -e 文件存在(existence) -d 文件存在并且是一个目录(directory) 多条件判断 &amp;&amp; 表示前面一条执行成功，才执行后一条命令 || 表示上一条命令执行失败后，才执行下一条命令 123456789101112131415[ec2-user@master test]$ [23 -ge 22]-bash: [23: command not found[ec2-user@master test]$ [ 23 -ge 22 ][ec2-user@master test]$ echo $?0[ec2-user@master test]$ [ 23 -le 22 ][ec2-user@master test]$ echo $?1[ec2-user@master test]$ [ -w helloworld.sh ][ec2-user@master test]$ echo $?0[ec2-user@master test]$ [ 23 -ge 22 ] &amp;&amp; echo okok[ec2-user@master test]$ [ 23 -ge 22 ] &amp;&amp; [ ] || echo notoknotok 流程控制（重点）if 判断 基本语法123456789if [ 条件判断式子 ];then 程序eliffi# 或if [ 条件判断式 ]then 程序if if后必须有空格 例子123456#!/bin/bashif [ $1 -eq 1 ];then echo &quot;ganshizhong is handsome&quot;elif [ $1 -eq 2 ];then echo &quot;ganshizhong&quot;if case 语句 基本语法 123456789101112131415#!/bin/bashcase 值 in模式1) command1 command2 ... commandN ;;模式2) command1 command2 ... commandN ;;esac 例子 1234567891011#!/bin/bashcase $1 in1) echo &quot;print 1&quot; ;;2) echo &quot;print 2&quot; ;;*) echo &quot;print other&quot;esac for 循环 基本语法 1234for ((初始值;循环控制条件;变量变化))do 程序done 例子 1234567#!/bin/bashs=0for ((i=1;i&lt;=100;i++))do s=$[$s+$i] doneecho $s 1234567891011#!/bin/bashs=0for i in $*do echo $i done[ec2-user@master test]$ sh for2.sh 1 2 231223 1234567891011#!/bin/bashs=0for i in &quot;$@&quot;do echo $i done[ec2-user@master test]$ sh for2.sh &quot;1 2 23&quot;1223 此处应该注意’$*’和’$@’之间的区别 while循环 基本语法 1234while [ 条件判断式 ]do 程序done 例子 123456789#/bin/bashs=0i=1while [ $i -le 100 ]do s=$[$i+$s] i=$[$i+1]doneecho $s 条件中 只能用 -le 不能用 &lt;= read读取控制台输入 基本语法 123456read(选项)(参数)选项： -p: 指定读取值时的提示符 -t: 指定读取值时等待的时间（秒）参数： 变量：指定读取值的变量名 例子 1234567#/bin/bashread -t 7 -p &quot;Enter your name in 7 seconds: &quot; NAMEecho $NAME[ec2-user@master test]$ sh read.shEnter your name in 7 seconds: ganshizhongganshizhong 函数 系统函数basename 和 dirname 12345basename [string/pathname] [suffix] #获取文件名[ec2-user@master test]$ basename ./read.shread.sh[ec2-user@master test]$ basename ./read.sh .shread 中括号都是可选参数 1234dirname 文件绝对路径 # 获取路径[ec2-user@master test]$ dirname /home/ec2-user/test/read.sh/home/ec2-user/test 自定函数 123456[ function ] funname[()]&#123; action; [return int;]&#125;funname 1)必须在调用之前声明函数，shell是逐行运行的，不会先编译 2)函数返回值，只能通过$?系统变量获得，可以显示加：return返回，如果不加，将以最后一条命令运行结果，作为返回值。return后跟数值n(0-255) 12345678910111213141516#!/bin/bashfunction sum()&#123; s=0; s=$[$1+$2] echo $s&#125;read -p &quot;input your parameter: &quot; p1read -p &quot;input your parameter: &quot; p2sum $p1 $p2[ec2-user@master test]$ sh sumfunc.sh123 shell工具(重点)cut在文件中负责剪切数据。cut命令从文件的每一行剪切字节、字符和字段并输出。 基本用法 12345678910111213141516171819202122232425262728cut [选项参数] filename # -f: 列号，提取第几列 -d: 分隔符，按照指定分隔符分割列[ec2-user@master test]$ cat cut.txta bc dee ffgg hh[ec2-user@master test]$ cut -d &quot; &quot; -f 1,2 cut.txta bc dee ffgg[ec2-user@master test]$ cat cut.txt |grep ff |cut -d &quot; &quot; -f 1ee## 切割环境变量[ec2-user@master ~]$ echo $PATH/opt/java/jdk1.8.0_271/bin:/opt/hadoop/hadoop-3.2.3/bin:/opt/hadoop/hadoop-3.2.3/sbin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/java/jdk1.8.0_271/bin:/home/ec2-user/.local/bin:/home/ec2-user/bin[ec2-user@master ~]$ echo $PATH| cut -d : -f 3-/opt/hadoop/hadoop-3.2.3/sbin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/java/jdk1.8.0_271/bin:/home/ec2-user/.local/bin:/home/ec2-user/bin## 切割ip[ec2-user@master ~]$ ifconfig eth0 |grep &quot;inet &quot; inet 192.168.1.4 netmask 255.255.255.0 broadcast 192.168.1.255[ec2-user@master ~]$ ifconfig eth0 |grep &quot;inet &quot;|cut -d &quot;t&quot; -f 2 192.168.1.4 ne[ec2-user@master ~]$ ifconfig eth0 |grep &quot;inet &quot;|cut -d &quot;t&quot; -f 2| cut -d&quot; &quot; -f2192.168.1.4 缺点，cut只能切一个字符，如果存在很多空格，就会很麻烦 sedsed是一种流编辑器，它一次处理一行内容。处理时，把当前处理的行存储在临时缓冲区中，成为”模式空间”，接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕中。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有改变，除非你使用重定向存储输出。 基本用法 1234567sed [选项参数] &quot;command&quot; filename 选项参数： -e: 直接在指令列模式上进行sed的动作编辑 命令： a: 新增，a的后面可以接字串，在下一行出现 d: 删除 s：查找并替换 案例 12345678910111213141516171819202122232425## 将&quot;xiao ming&quot;这个单词插入sed.txt第二行，打印。[ec2-user@master ~]$ cat sed.txtgan shizhongg sz[ec2-user@master ~]$ sed &quot;1a xiao ming&quot; sed.txtgan shizhongxiao mingg sz[ec2-user@master ~]$ cat sed.txtgan shizhongg sz## 删除&quot;g sz&quot;[ec2-user@master ~]$ sed &quot;/sz/d&quot; sed.txtgan shizhong[ec2-user@master ~]$ cat sed.txtgan shizhongg sz## 替换&quot;g sz&quot; 为 &quot;xiao ming&quot;[ec2-user@master ~]$ sed &quot;s/g sz/xiao ming/g&quot; sed.txt # g表示gan shizhongxiao ming## 删除第1行，并将&quot;g sz&quot; 替换为&quot;gan sz&quot;[ec2-user@master test]$ sed -e &quot;1d&quot; -e &quot;s/g sz/gan sz/g&quot; sed.txtgan sz awk一个强大的文本分析工具，把文件逐行读取，以空格为默认分隔符将每行切片，切开的部分再进行分析处理。 基本用法123456awk [选项参数] &quot;pattern1&#123;action1&#125; pattern2&#123;action2&#125; ...&quot; filename pattern: 表示AWK在数据中查找的内容，就是匹配模式 action: 在找到匹配内容时所执行的一系列命令,基本用print 选项参数 -F: 指定输入文件分析分隔符 -v: 复制一个用户定义变量 123456789101112131415sudo cp /etc/passwd ./sudo chown ec2-user:ec2-user passwd## 搜索passwd文件以root关键字开头的所有行，并输出改行的第七列[ec2-user@master test]$ awk -F : &#x27;/^root/&#123;print $7&#125;&#x27; passwd/bin/bash[ec2-user@master test]$ awk -F : &#x27;/^root/&#123;print $1,$7&#125;&#x27; passwdroot /bin/bash[ec2-user@master test]$ awk -F : &#x27;/^root/&#123;print $1 $7&#125;&#x27; passwdroot /bin/bash[ec2-user@master test]$ awk -F : &#x27;/^root/&#123;print $1&quot;,&quot;$7&#125;&#x27; passwdroot,/bin/bash## 只显示第一列和第七列，以逗号隔开，且在所有行前面添加列名user,shell在最后一行添加&quot;gsz,/bin/gsz&quot;[ec2-user@master test]$ awk -F : &#x27;BEGIN&#123;print &quot;user,shell&quot;&#125; &#123;print $1&quot;,&quot;$7&#125; END&#123;print &quot;gsz,/bin/gsz&quot;&#125;&#x27; passwd## passwd中用户id增加数值1并输出[ec2-user@master test]$ awk -F : -v i=1 &#x27;&#123;print $3+i&#125;&#x27; passwd 此处要用单引号，单引号里的内容不可转义 两个斜杠之间时正则表达式 BEGIN 是所有行前，END是所有行后 awk 内置变量 123FILENAME 文件名NR 已读的记录数NF 浏览记录的个数（切割后，列的个数） 12345678910111213141516## 统计passwd文件中，每行的行号，每行的列数[ec2-user@master test]$ awk -F : &#x27;&#123;print &quot;filename:&quot; FILENAME &quot;,linenumber:&quot; NR &quot;,columns:&quot; NF&#125;&#x27; passwdfilename:passwd,linenumber:1,columns:7filename:passwd,linenumber:2,columns:7filename:passwd,linenumber:3,columns:7...## 切割IP[ec2-user@master test]$ ifconfig eth0 |grep &quot;inet &quot;|awk -F t &#x27;&#123;print $2&#125;&#x27;|awk -F &quot; &quot; &#x27;&#123;print$1&#125;&#x27;192.168.1.4## 查询sed.txt文件空行所在的行号[ec2-user@master test]$ cat sed.txtgan shizhongg sz[ec2-user@master test]$ awk &#x27;/^$/&#123;print NR&#125;&#x27; sed.txt2 sortsort命令实在Linu非常有用，他将文件进行排序，并将排序结果标准输出 基本语法 12345sort (选项) (说明) -n: 依照数值大小排序 -r: 以相反的顺序来排序 -t: 设置排序时所用的分隔字符 -k: 指定排序的列 123456789101112[ec2-user@master test]$ cat sort.shbb:40:5.1bd:30:4.3xz:50:2.3cls:10:3.5ss:25:1.6[ec2-user@master test]$ sort -t : -nrk 2 sort.shxz:50:2.3bb:40:5.1bd:30:4.3ss:25:1.6cls:10:3.5 企业真实面试题（重点）1234567# 求列和[ec2-user@master test]$ cat chengji.txt张三 40李四 50王五 60[ec2-user@master test]$ cat chengji.txt | awk -F &quot; &quot; &#x27;&#123;sum+=$2&#125; END&#123;print sum&#125;&#x27; 150 12345678# 检查文件是否存在#!/bin/bashif [ -f file.txt ]then echo &quot;存在&quot;else echo &quot;不存在&quot;fi 12345678910111213141516171819202122232425262728# 排序[ec2-user@master test]$ cat sort.txt913572438431[ec2-user@master test]$ sort -n sort.txt |awk &#x27;&#123;a+=$0;print$0&#125;END&#123;print &quot;SUM=&quot;a&#125;&#x27;112333445789SUM=50 awk里的变量可以添加可以不添加 12345678910111213141516171819# 查找当前文件夹中，所有的文本文件内容包含“gsz”的文件名称[ec2-user@master test]$ grep -r &quot;sz&quot; /home/ec2-user/test/home/ec2-user/test/sed.txt:g sz[ec2-user@master test]$ grep -r &quot;shizhong&quot; /home/ec2-user/test/home/ec2-user/test/helloworld.sh:echo &quot;hello world, ganshizhong&quot;/home/ec2-user/test/if.sh: echo &quot;ganshizhong is handsome&quot;/home/ec2-user/test/if.sh: echo &quot;ganshizhong&quot;/home/ec2-user/test/sed.txt:gan shizhong[ec2-user@master test]$ grep -r &quot;shizhong&quot; ././helloworld.sh:echo &quot;hello world, ganshizhong&quot;./if.sh: echo &quot;ganshizhong is handsome&quot;./if.sh: echo &quot;ganshizhong&quot;./sed.txt:gan shizhong[ec2-user@master test]$ grep -r &quot;shizhong&quot; /home/ec2-user/test |cut -d &quot;:&quot; -f 1/home/ec2-user/test/helloworld.sh/home/ec2-user/test/if.sh/home/ec2-user/test/if.sh/home/ec2-user/test/sed.txt 正则表达语法 字符 说明 \\ 转义 ^ 开始 $ 结尾 * 0次或多次匹配 + 一次或多次匹配 shell编程题 Linux运维之批量下载指定网站的100个图片文件，并找出大于200KB的文件 123456#!/bin/bashfor i in &#123;1..100&#125;do wget http://down.fengge.com/img/$i.pngdonefind ./ -name &quot;*.png&quot; -size +200K 一个文本文件info.txt的内容如下： aa,201 zz,502 bb,1 ee,42 每行都是按照逗号分隔，其中第二列都是数字，请对该文件按照第二列数字从大到小排列。 1sort -t &quot;,&quot; -k 2 info.txt -rn 查看当前Linux服务器是否监听80端口，如果在监听，请找出其进程ID，并结束该进程。 1234lsof -i:端口号kill -9 pid# 或netstat -tunlp curl命令最常用的参数就是-I，仅返回头部信息，使用HEAD请求，获取的结果如下 1curl -I http://192.168.100.115","categories":[{"name":"Shell","slug":"Shell","permalink":"http://shizhonggan.github.io/categories/Shell/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"http://shizhonggan.github.io/tags/Shell/"}]},{"title":"Spark on YARN 环境搭建","slug":"BigData/SparkYarn","date":"2022-05-25T07:54:23.000Z","updated":"2022-06-13T01:30:51.048Z","comments":true,"path":"2022/05/25/BigData/SparkYarn/","link":"","permalink":"http://shizhonggan.github.io/2022/05/25/BigData/SparkYarn/","excerpt":"","text":"Spark on YARN 本质构建HA standAlone集群可以满足稳定的Spark生产环境要求。 而在YARN集群之上构建Hadoop集群可以提高资源利用率，因为企业的服务器资源总是紧张的 YARN本身是一个资源调度框架，负责对运行在内部的计算框架进行资源调度管理 作为典型的计算框架，Spark本身也是直接运行在YARN中，并接受YARN调度。 所以，SPARK on YARN 无需部署Spark集群，只要找一台服务器，充当Spark的客户端，既可以提交任务到YARN 集群中运行。 本质: Master角色由YARN的ResourceManager担任。Worker角色由YARN的NodeManager担任。 Driver角色运行在YARN容器内 或 提交任务的客户端进程。 真正干活的Executor运行在YARN提供的容器内。 配置spark on YARN 环境1vi /opt/spark/conf/spark-env.sh 只要配置好HADOOP_CONF_DIR和YARN_CONF_DIR配置即可 123# 启动./bin/spark-submit --master yarn./bin/spark-submit --master yarn /opt/spark/examples/src/main/python/pi.py 100 部署模式DeployModeSpark on YARN 有两种运行模式： Cluster模式：Driver运行在容器内部，和ApplicationMaster在同一个容器内 Clinet模式：Driver运行在客户端进程中，比如Driver运行在spark-submit程序的进程中 通过spark-submit,pyspark,spark-shell启动的任务 cluster模式 效率高，但产生的日志也在容器内部不宜查找 Spark on YARN 两种模式总结 Cluster Client Driver运行位置 YARN容器内 客户端进程内 通讯效率 高 低于cluster 日志查看 日志输出在容器内，查看不方便 日志输出在客户端的标准输出流中，方便查看 生产可用 推荐不推荐 稳定性 稳定 基于客户端进程，受到客户端进程影响 两种模式详细流程","categories":[{"name":"BigData","slug":"BigData","permalink":"http://shizhonggan.github.io/categories/BigData/"}],"tags":[{"name":"Spark","slug":"Spark","permalink":"http://shizhonggan.github.io/tags/Spark/"},{"name":"YARN","slug":"YARN","permalink":"http://shizhonggan.github.io/tags/YARN/"}]},{"title":"Spark部署","slug":"BigData/SparkDeploy","date":"2022-05-18T07:54:23.000Z","updated":"2022-06-13T01:30:50.995Z","comments":true,"path":"2022/05/18/BigData/SparkDeploy/","link":"","permalink":"http://shizhonggan.github.io/2022/05/18/BigData/SparkDeploy/","excerpt":"","text":"Local 部署安装下载地址： https://dlcdn.apache.org/spark/spark-3.1.3/spark-3.1.3-bin-hadoop3.2.tgz https://www.anaconda.com/products/distribution#Downloads 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758sh Anaconda3-2022.05-Linux-x86_64.shsource ~/.bashrc # 使环境生效conda list # 正常python -V #3.9## 修改镜像源 vi ~/.condarc ## 网上自己找echo &#x27;channels: - http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/linux-64 - http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r/linux-64 - http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2/linux-64 - http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/linux-64 - http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro/linux-64 - http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/linux-64 - http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/linux-64 - http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/linux-64 - http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/menpo/linux-64 - http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/linux-64 - http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/simpleitk/linux-64 - defaultsshow_channel_urls: true&#x27; &gt; ~/.condarcconda config --show channelsconda clean -i ## 保证生效# 配置虚拟环境conda create -n pyspark python=3.8 environment location: /opt/anaconda3/envs/pyspark#To activate this environment, use$ conda activate pyspark# To deactivate an active environment, use$ conda deactivate################# 安装sparktar -zxvf spark-3.1.3-bin-hadoop3.2.tgzln -s /opt/spark-xxx /opt/spark # 可以起别名，我这里直接用mv 替换文件夹名# 配置spark环境变量SPARK_HOME: Spark安装目录PYSPARK_PYTHON: 表示python想运行Python程序，去哪里找python执行器JAVA_HOME:告知Java在哪里HADOOP_CONF_DIR: 告知Spark Hadoop的配置文件位置HADOOP_HOME: 告知spark Hadoop安装在哪里echo &#x27;export SPARK_HOME=/opt/sparkexport PYSPARK_PYTHON=/opt/anaconda3/envs/pyspark/bin/python3.8export JAVA_HOME=/opt/java/jdk1.8.0_271export HADOOP_CONF_DIR=/opt/hadoop/hadoop-3.2.3/etc/hadoopexport HADOOP_HOME=/opt/hadoop/hadoop-3.2.3export PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH &#x27; &gt;&gt; /etc/profile.d/spark-3.1.3.shsource /etc/profileecho &#x27;export PYSPARK_PYTHON=/opt/anaconda3/envs/pyspark/bin/python3.8export JAVA_HOME=/opt/java/jdk1.8.0_271&#x27;&gt;&gt; ~/.bashrcsource ~/.bashrc 测试123456789$ sudo su(base) [root@master ec2-user]# conda activate pyspark(pyspark) [root@master ec2-user]#cd /opt/spark/bin/### pyspark 运行python脚本./pysparkprint(&quot;i am Spark&quot;)sc.parallelize([1,2,3,4,5]).map(lambda x: x*10).collect() http://ip:port 访问相应的端口ip可以看到spark job如下： 1234### spark-shell 运行scala./spark-shellsc.parallelize(Array(1,2,3,4,5)).map(x=&gt;x*10).collect() spark-shell 运行scala交互如下： 12### submit-submit 直接运行 ./spark-submit --master local[*] /opt/spark/examples/src/main/python/pi.py 10 ## 10次迭代求解圆周率 Standalone 架构Standalone 模式是Spark自带的一种集群模式，不同于前面本地模式启动多个进程来模拟集群环境，Standalone模式是真实的在多个机器之间搭建spark集群的环境，完全可以利用该模式搭建多机器集群，用于实际的大数据处理。 Standalone 是完整的spark运行环境，其中： Master角色以Master进程存在，worker角色以worker进程存在 Driver角色在运行时存在于Master进程内，Executor运行于Worker进程内 Standalone集群在进程上主要有3类进程： 主节点Master进程： master角色，管理整个集群资源，并托管运行各个任务的Driver 从节点Workers: worker角色，管理每个机器的资源，分配对应的资源来运行Excutor（Task） 历史服务器HistoryServer(可选)： spark Application运行完成以后，保存时间日志数据至HDFS，启动HistoryServer可以查看应用运行相关信息 Standalone 集群环境安装master 运行Spark的Master进程和1个work进程worker1 运行Spark的1个work进程worker2 运行Spark的1个work进程 每台机器部署Anaconda(python) 环境【略，同上】每台机器部署spark 环境【略,同上】spark集群文件配置12345678cd /opt/spark/confcp workers.template workerscp spark-env.sh.template spark-env.shcp spark-defaults.conf.template spark-defaults.confcp log4j.properties.template log4j.properties# 将spark程序运行的历史日志 存到hdfs的/sparklog文件夹中hadoop fs -mkdir /sparklogmkdir -p /data/spark/log/ 1）修改 workers123echo &#x27;masterworker1worker2&#x27; &gt;&gt; workers 2) 修改 spark-env.sh123456789101112131415161718192021222324echo &#x27;## java安装目录JAVA_HOME=/opt/java/jdk1.8.0_271## HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群HADOOP_CONF_DIR=/opt/hadoop/hadoop-3.2.3/etc/hadoopYARN_CONF_DIR=/opt/hadoop/hadoop-3.2.3/etc/hadoop## 指定spark master运行在哪台机器export SPARK_MASTER_HOST=master## 指定spark master的通讯端口export SPARK_MASTER_PORT=9777## 告知spark master的webui 端口SPARK_MASTER_WEBUI_PORT=9780## work cpu可用核数SPARK_WORKER_CORES=1## work 可用内存SPARK_WORKER_MEMORY=1g## work 的工作通讯地址SPARK_WORKER_PORT=9778## work 的webui地址SPARK_WORKER_WEBUI_PORT=9781## 设置历史服务器# 配置的意思是 将spark程序运行的历史日志 存到hdfs的/sparklog文件夹中SPARK_HISTORY_OPTS=&quot;-Dspark.history.fs.logDirectory=hdfs://master:9710/sparklog -Dspark.history.fs.cleaner.enabled=true&quot;&#x27; &gt;&gt; spark-env.sh hdfs://master:9710 对应 fs.defaultFS；同时需要在hadoop下创建/sparklog文件夹 “hadoop fs -mkdir /sparklog” 3) 修改 spark-defaults.conf123456789echo &#x27;# 开启spark的日期记录功能spark.eventLog.enabled true# 设置spark日志记录路径spark.eventLog.dir hdfs://master:9710/sparklog/# spark.eventLog.dir file:/data/spark/log/# 设置spark日志是否启动压缩spark.eventLog.compress false&#x27; &gt;&gt; spark-defaults.conf 4) 修改 log4j.properties1234log4j.rootCategory=WARN, console # 修改cat log4j.properties | grep log4j.rootCategory=sed -i &#x27;s#log4j.rootCategory=INFO, console#log4j.rootCategory=WARN, console#&#x27; log4j.properties 复制文件到其他节点123456789scp workers 192.168.1.7:/opt/spark/confscp spark-env.sh 192.168.1.7:/opt/spark/confscp spark-defaults.conf 192.168.1.7:/opt/spark/confscp log4j.properties 192.168.1.7:/opt/spark/confscp workers 192.168.1.9:/opt/spark/confscp spark-env.sh 192.168.1.9:/opt/spark/confscp spark-defaults.conf 192.168.1.9:/opt/spark/confscp log4j.properties 192.168.1.9:/opt/spark/conf 启动spark集群 一定要用”./path/start-all.sh “或”./start-all.sh”形式， 而不是绝对路径或直接文件执行 12345cd /opt/hadoop/hadoop-3.2.3/etc/hadoop/ &amp;&amp; stop-all.shcd /data/hadoop/pid/ ./sbin/start-history-server.sh ./sbin/start-all.sh 检查spark集群http://ip:9780 集群连接测试12345678cd /opt/spark## pyspark./bin/pyspark --master spark://master:9777sc.parallelize([1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5]).map(lambda x: x*10).collect()sc.textFile(&quot;hdfs://master:9710/input/word.txt&quot;).flatMap(lambda line: line.split(&quot; &quot;)).map(lambda x:(x,1)).reduceByKey(lambda a,b: a+b).collect()## spark-submit./bin/spark-submit --master spark://master:9777 /opt/spark/examples/src/main/python/pi.py 100 总结 StandAlone的原理？ Master和Worker角色以独立进程的形式存在，并组成Spark运行时环境（集群） Spark角色在StandAlone中的分布？ Master角色： Master进程， worker角色： worker进程， Driver角色： 以线程运行在Master中，Excutor角色：以线程运行在worker中 Standalone如何提交Spark应用？ ./bin/spark-submit –master spark://server:9777 Job\\Stage\\Task的关系？ 一个Spark运行程序会被分成多个子任务（Job）运行，每一个Job会分成多个阶段（Stage）来运行，每个Stage内会分出来多个线程（Task）来执行具体任务。","categories":[{"name":"BigData","slug":"BigData","permalink":"http://shizhonggan.github.io/categories/BigData/"},{"name":"Spark","slug":"BigData/Spark","permalink":"http://shizhonggan.github.io/categories/BigData/Spark/"}],"tags":[]},{"title":"Spark StandAlone HA集群搭建","slug":"BigData/SparkStandAloneHA","date":"2022-05-18T07:54:23.000Z","updated":"2022-06-13T01:30:51.004Z","comments":true,"path":"2022/05/18/BigData/SparkStandAloneHA/","link":"","permalink":"http://shizhonggan.github.io/2022/05/18/BigData/SparkStandAloneHA/","excerpt":"","text":"StandAlone HA 运行原理Spark Standalone集群是Master-Slaves架构的集群模式，存在着Master单点故障的问题。 高可用 HA解决单点故障有两种方案： 基于文件系统的单点恢复（Single-Node Recovery with Local File System）:只能用于开发或测试环境 基于zookeeper的Standby Masters(Standby Masters with ZooKeeper): 可用于生产环境 ZooKeeper 提供了一个Leader Election 机制， 利用这个机制可以保证虽然集群存在多个Master，但是只有一个Active的，其他都是Standby。当Active的Master出现故障时，另外的一个Standby Master会被选举出来。由于集群的信息，包括Worker, Driver和Applicaiton 的信息都已经持久化到文件系统，因此在切换的过程中只会影响新的job的提交，对于正在进行的job没有任何的影响。加入ZooKeeper的集群整体架构如下图所示： 高可用HA StandAlone集群搭建 前提： 确保Zookeeper和HDFS均已经启动 修改配置文件即可 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748cd /opt/spark/confvi spark-env.shecho &#x27;## java安装目录JAVA_HOME=/opt/java/jdk1.8.0_271## HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群HADOOP_CONF_DIR=/opt/hadoop/hadoop-3.2.3/etc/hadoopYARN_CONF_DIR=/opt/hadoop/hadoop-3.2.3/etc/hadoop# ## 指定spark master运行在哪台机器# export SPARK_MASTER_HOST=master## 指定spark master的通讯端口export SPARK_MASTER_PORT=9777## 告知spark master的webui 端口SPARK_MASTER_WEBUI_PORT=9780## work cpu可用核数SPARK_WORKER_CORES=1## work 可用内存SPARK_WORKER_MEMORY=1g## work 的工作通讯地址SPARK_WORKER_PORT=9778## work 的webui地址SPARK_WORKER_WEBUI_PORT=9781## 设置历史服务器# 配置的意思是 将spark程序运行的历史日志 存到hdfs的/sparklog文件夹中SPARK_HISTORY_OPTS=&quot;-Dspark.history.fs.logDirectory=hdfs://master:9710/sparklog -Dspark.history.fs.cleaner.enabled=true&quot;SPARK_DAEMON_JAVA_OPTS=&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=master:2181,worker1:2181,worker2:2181 -Dspark.deploy.zookeeper.dir=/spark-ha&quot;&#x27; &gt;&gt; spark-env.sh# 发送到各个节点scp spark-env.sh 192.168.1.7:/opt/spark/conf/scp spark-env.sh 192.168.1.9:/opt/spark/conf/# 重启./sbin/stop-all.sh./sbin/start-all.sh# 这个时候 master节点必然是 master# 进入worker1节点，启动master，然后jps查看进程./sbin/start-master.sh# 有时候存在端口被占用或顺延，如下方式查端口JPS # 查看进程ID 34784netstart -anp|grep 34784 master注释掉；spark.deploy.recoveryMode 指定HA模式,基于zookeeper实现;指定zookeeper的连接地址；指定zookeeper中注册临时节点的路径。 测试运行1234## 只需要把master的停掉kill -9 JPS查询master_进程ID# 可以在worker1节点先启动任务（以pi圆周率任务为例），执行过程中停掉master进程","categories":[{"name":"BigData","slug":"BigData","permalink":"http://shizhonggan.github.io/categories/BigData/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://shizhonggan.github.io/tags/Zookeeper/"},{"name":"Spark","slug":"Spark","permalink":"http://shizhonggan.github.io/tags/Spark/"}]},{"title":"Hadoop安装常见错误","slug":"BigData/hadoop_installerror","date":"2022-05-17T07:54:23.000Z","updated":"2022-06-13T01:30:51.053Z","comments":true,"path":"2022/05/17/BigData/hadoop_installerror/","link":"","permalink":"http://shizhonggan.github.io/2022/05/17/BigData/hadoop_installerror/","excerpt":"","text":"tcp端口被占用暴力重启，stop集群后常见该问题，一些端口tcp仍然保持连接，挨个kill较为麻烦， 配置文件配置文件要认真人配置 ping: socket: Permission denied, attempting raw socket…ICMP协议开通 java.io.IOException: Got error, status=ERROR, status message , ack with firstBadLink as 192.168.1.7:9866端口打开","categories":[{"name":"BigData","slug":"BigData","permalink":"http://shizhonggan.github.io/categories/BigData/"},{"name":"Hadoop","slug":"BigData/Hadoop","permalink":"http://shizhonggan.github.io/categories/BigData/Hadoop/"}],"tags":[]},{"title":"Hadoop 部署","slug":"BigData/HadoopDeploy","date":"2022-05-14T07:54:23.000Z","updated":"2022-06-13T01:30:50.994Z","comments":true,"path":"2022/05/14/BigData/HadoopDeploy/","link":"","permalink":"http://shizhonggan.github.io/2022/05/14/BigData/HadoopDeploy/","excerpt":"","text":"基础环境三台Linux虚拟机服务器 node1: Master(HDFS\\YARN\\Spark) 和 Worker(HDFS\\YARN\\Spark)node2: Worker(HDFS\\YARN\\Spark)node3: Worker(HDFS\\YARN\\Spark) 和 Hive Hadoop3集群、JDK1.8、Centos7.6 192.168.1.4 master 【绑定公网IP】192.168.1.7 worker1192.168.1.9 worker2 123hostnamectl set-hostname masterhostnamectl set-hostname worker1hostnamectl set-hostname worker2 设置免密登录：http://t.zoukankan.com/Nanaya-p-13202946.html 12345678910111213141516171819ssh-keygen -t rsascp &#x2F;root&#x2F;.ssh&#x2F;id_rsa.pub ec2-user@192.168.1.7:&#x2F;home&#x2F;ec2-userscp &#x2F;root&#x2F;.ssh&#x2F;id_rsa.pub ec2-user@192.168.1.9:&#x2F;home&#x2F;ec2-usercat id_rsa.pub &gt;&gt; authorized_keysvim etc&#x2F;ssh&#x2F;sshd_configPermitRootLogin yes # 允许root认证登录PubkeyAuthentication # 启用公钥私钥配对认证方式AuthorizedKeysFile .ssh&#x2F;authorized_keys # 公钥文件路径（和上面生成的文件相同）systemctl restart sshd## 配置hostsecho &#39;192.168.1.4 master192.168.1.7 worker1192.168.1.9 worker2&#39; &gt;&gt; &#x2F;etc&#x2F;hosts Local模式基本原理本质：启动一个JVM Process进程（一个进程里面有多个线程），执行任务TaskLocal模式可以限制模拟Spark集群环境的线程数量，即Local[N]或Local[],其中，N代表可以使用的N个线程，每个线程拥有一个CPU core。如果不指定N,则默认1个线程(该线程有1个Core)。通常Cpu有几个Core，就指定几个线程，最大化利用计算能力。如果是Local[]，则按照Cpu最多的Cores设置线程数。 下载安装【三台】参考：https://blog.csdn.net/dream_an/article/details/80258283 https://blog.csdn.net/weixin_53227758/article/details/121977047 [很详细] https://blog.csdn.net/zyx1260168395/article/details/120921697?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-120921697-blog-123827164.pc_relevant_antiscanv2&amp;spm=1001.2101.3001.4242.1&amp;utm_relevant_index=3 https://blog.csdn.net/weixin_49167174/article/details/123827164 1234567891011121314151617网上找java8的安装包，百度网盘比较好，官方下载需要一堆注册信息mkdir /opt/java # 上传javatar -zxf jdk-8u271-linux-x64.tar.gzmv jdk1.8.0_271/ /opt/java/## 配置JAVA环境变量echo &#x27;export JAVA_HOME=/opt/java/jdk1.8.0_271export CLASSPATH=.:$&#123;JAVA_HOME&#125;/jre/lib/rt.jar:$&#123;JAVA_HOME&#125;/lib/dt.jar:$&#123;JAVA_HOME&#125;/lib/tools.jarexport PATH=$PATH:$&#123;JAVA_HOME&#125;/bin&#x27; &gt; /etc/profile.d/jdk-1.8.sh# 使环境变量生效source /etc/profile# 查看javajava -version hadoop3+配置文件 github配置文件源码地址 123456789Hadoop官网：http://hadoop.apache.org/yum install wget # 太慢，直接网页下载再上传https://downloads.apache.org/hadoop/common/hadoop-3.2.3/mkdir /opt/hadoop#共需要配置/opt/hadoop/hadoop-3.2.3/etc/hadoop/下的六个个文件，分别是# hadoop-env.sh、core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml、workerstar -zxf hadoop-3.2.3.tar.gz mv hadoop-3.2.3 /opt/hadoop/ 修改master配置文件 配置文件，主从都一样，并不影响，除非主节点你不设置DataNode 配置文件备份1234567cd /opt/hadoop/hadoop-3.2.3/etc/hadoop/cp hadoop-env.sh hadoop-env.sh.bakcp core-site.xml core-site.xml.bakcp hdfs-site.xml hdfs-site.xml.bakcp yarn-site.xml yarn-site.xml.bakcp mapred-site.xml mapred-site.xml.bakcp workers workers.bak 创建目录1mkdir -p /data/hadoop/tmp /data/hadoop/hdfs/data /data/hadoop/hdfs/name /data/hadoop/pid/ /data/hadoop/log/ 修改hadoop-env.sh 环境变量https://baijiahao.baidu.com/s?id=1668099113918809329&amp;wfr=spider&amp;for=pc 123456789101112131415161718192021222324252627echo &#x27;export JAVA_HOME=/opt/java/jdk1.8.0_271export HADOOP_HOME=/opt/hadoop/hadoop-3.2.3export HADOOP_PID_DIR=/data/hadoop/pidexport HADOOP_LOG_DIR=/data/hadoop/logexport HADOOP_MAPRED_HOME=$HADOOP_HOMEexport HADOOP_COMMON_HOME=$HADOOP_HOMEexport HADOOP_HDFS_HOME=$HADOOP_HOMEexport YARN_HOME=$HADOOP_HOMEexport HADOOP_CONF_DIR=$&#123;HADOOP_HOME&#125;/etc/hadoopexport HDFS_CONF_DIR=$&#123;HADOOP_HOME&#125;/etc/hadoopexport YARN_CONF_DIR=$&#123;HADOOP_HOME&#125;/etc/hadoop# export HIVE_HOME=/opt/hive# export HBASE_HOME=/opt/hbaseexport PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATHexport HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoopexport YARN_CONF_DIR=$HADOOP_HOME/etc/hadoopexport HDFS_NAMENODE_USER=&quot;root&quot;export HDFS_DATANODE_USER=&quot;root&quot;export HDFS_SECONDARYNAMENODE_USER=&quot;root&quot;export YARN_RESOURCEMANAGER_USER=&quot;root&quot;export YARN_NODEMANAGER_USER=&quot;root&quot; &#x27; &gt;&gt; /opt/hadoop/hadoop-3.2.3/etc/hadoop/hadoop-env.sh 也可以在/etc/profile.d/中配置 修改 core-site.xml1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9710&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;io.file.buffer.size&lt;/name&gt; &lt;value&gt;131072&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/data/hadoop/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; name: fs.default.name 和fs.defaultFS 区别：FS是两台主机以上进行高可用配置，name则是单点使用;value: NameNode URI name: io.file.buffer.size: Size of read/write buffer used in SequenceFiles name: hadoop.tmp.dir： A base for other temporary directories. 修改 hdfs-site.xml12345678910111213141516171819202122232425262728&lt;configuration&gt; &lt;!-- Configurations for NameNode: --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/data/hadoop/hdfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.blocksize&lt;/name&gt; &lt;value&gt;268435456&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.ttp-address&lt;/name&gt; &lt;value&gt;master:9711&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt; &lt;value&gt;100&lt;/value&gt; &lt;/property&gt; &lt;!-- Configurations for DataNode: --&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/data/hadoop/hdfs/data&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; name: dfs.blocksize: HDFS blocksize of 256MB for large file-systems. name: dfs.namenode.http-address: The address and the base port where the dfs namenode web ui will listen on. name: dfs.namenode.handler.count: More NameNode server threads to handle RPCs from large number of DataNodes. name: dfs.datanode.data.dir: If this is a comma-delimited list of directories, then data will be stored in all named directories, typically on different devices. 修改 yarn-site.xml1234567891011121314151617181920212223242526272829303132&lt;configuration&gt;&lt;!-- Configurations for ResourceManager and NodeManager: 未配置 --&gt;&lt;!-- Configurations for ResourceManager: --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;master&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;master:9712&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;master:9713&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;master:9714&lt;/value&gt; &lt;/property&gt;&lt;!-- Configurations for NodeManager: --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt; &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ,HADOOP_MAPRED_HOME&lt;/value&gt; &lt;/property&gt;&lt;!-- Configurations for History Server: 暂时不配置吧--&gt;&lt;/configuration&gt; 修改 mapred-site.xml123456789101112&lt;configuration&gt;&lt;!-- Configurations for MapReduce Applications: --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;!-- Configurations for MapReduce JobHistory Server: --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;master:9715&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改 workers123masterworker1worker2 复制Hadoop文件到其他集群、配置Hadoop环境变量、格式化hdfs、开启集群、查看、关闭、重置集群12345678910111213141516mkdir -p /data/hadoop/tmp /data/hadoop/hdfs/data /data/hadoop/hdfs/name /data/hadoop/pid/ /data/hadoop/log/scp hadoop-env.sh 192.168.1.7:/opt/hadoop/hadoop-3.2.3/etc/hadoop/scp core-site.xml 192.168.1.7:/opt/hadoop/hadoop-3.2.3/etc/hadoop/scp hdfs-site.xml 192.168.1.7:/opt/hadoop/hadoop-3.2.3/etc/hadoop/scp yarn-site.xml 192.168.1.7:/opt/hadoop/hadoop-3.2.3/etc/hadoop/scp mapred-site.xml 192.168.1.7:/opt/hadoop/hadoop-3.2.3/etc/hadoop/scp workers 192.168.1.7:/opt/hadoop/hadoop-3.2.3/etc/hadoop/scp hadoop-env.sh 192.168.1.9:/opt/hadoop/hadoop-3.2.3/etc/hadoop/scp core-site.xml 192.168.1.9:/opt/hadoop/hadoop-3.2.3/etc/hadoop/scp hdfs-site.xml 192.168.1.9:/opt/hadoop/hadoop-3.2.3/etc/hadoop/scp yarn-site.xml 192.168.1.9:/opt/hadoop/hadoop-3.2.3/etc/hadoop/scp mapred-site.xml 192.168.1.9:/opt/hadoop/hadoop-3.2.3/etc/hadoop/scp workers 192.168.1.9:/opt/hadoop/hadoop-3.2.3/etc/hadoop/ 格式化并启动集群12345/opt/hadoop/hadoop-3.2.3/bin/hdfs namenode -format /opt/hadoop/hadoop-3.2.3/sbin/start-all.sh/opt/hadoop/hadoop-3.2.3/sbin/start-dfs.sh/opt/hadoop/hadoop-3.2.3/sbin/start-yarn.sh 测试1 ## 报错参考: https://mathsigit.github.io/blog_page/2017/11/16/hole-of-submitting-mr-of-hadoop300RC0/ https://blog.csdn.net/qianhuihan/article/details/83379837 https://www.jianshu.com/p/9ebe74753794 https://stackoverflow.com/questions/50927577/could-not-find-or-load-main-class-org-apache-hadoop-mapreduce-v2-app-mrappmaster","categories":[{"name":"BigData","slug":"BigData","permalink":"http://shizhonggan.github.io/categories/BigData/"},{"name":"Spark","slug":"BigData/Spark","permalink":"http://shizhonggan.github.io/categories/BigData/Spark/"}],"tags":[]},{"title":"MYSQL游标使用方法","slug":"SQL/mysql_cursor","date":"2022-05-07T10:07:50.328Z","updated":"2022-05-07T10:07:50.328Z","comments":true,"path":"2022/05/07/SQL/mysql_cursor/","link":"","permalink":"http://shizhonggan.github.io/2022/05/07/SQL/mysql_cursor/","excerpt":"","text":"游标游标的特性 不敏感：数据库可以选择不复制结果集 只读 不滚动：游标只能向一方向前进，并且不可以跳过任何一行数据 游标的优点 游标是针对行操作的，对从数据库中 select 查询得到的结果集的 每一行可以 进行分开的独立的相同或者不相同的操作，是一种分离的思想。 游标的缺点 性能不高 只能一行一行操作 使用游标会产生死锁，造成内存开销大 游标的适用场景 存储过程 函数 触发器 事件游标使用方法游标五步法： 一、声明一个游标: DECLARE cursor_name CURSOR FOR select_statement 这个语句声明一个游标。也可以在子程序中定义多个游标，一个块中的每一个游标必须命名唯一。声明游标后也是单条操作的。 二、打开定义的游标: OPEN cursor_name 这个语句打开先前声明的游标。 三、获得下一行数据: FETCH cursor_name INTO var_name [, var_name] … 这个语句用指定的打开游标读取下一行（如果有下一行的话），并且前进游标指针至该行。 四、需要执行的语句(增删改查):这里视具体情况而定 五、释放游标: CLOSE cursor_name 这个语句关闭先前打开的游标，注意，用完后必须关闭。 123456789101112131415161718192021222324DROP PROCEDURE UpdateImgURL;/***游标***/CREATE PROCEDURE UpdateImgURL()BEGIN -- 遍历数据结束标志DECLARE Done INT DEFAULT 0;DECLARE Imgurl CHAR(255) DEFAULT &quot;&quot;;-- 游标DECLARE RS CURSOR FOR SELECT imgurl FROM weixin_linkface_userinfo ;-- 异常处理DECLARE CONTINUE HANDLER FOR SQLSTATE &#x27;02000&#x27; SET Done = 1;-- 打开游标OPEN RS;FETCH NEXT FROM RS INTO Imgurl;REPEATIF NOT Done THEN/**update 表名 set 字段名=REPLACE (字段名,&#x27;原来的值&#x27;,&#x27;要修改的值&#x27;) where 条件 **/END IF;FETCH NEXT FROM RS INTO Imgurl;UNTIL Done END REPEAT;CLOSE rs;END/**执行存储过程**/CALL UpdateImgURL 1234567891011121314151617181920BEGIN DECLARE no_more_record INT DEFAULT 0; DECLARE pID BIGINT(20); DECLARE pValue DECIMAL(15,5); DECLARE cur_record CURSOR FOR SELECT colA, colB from tableABC; /*首先这里对游标进行定义*/ DECLARE CONTINUE HANDLER FOR NOT FOUND SET no_more_record = 1; /*这个是个条件处理,针对NOT FOUND的条件,当没有记录时赋值为1*/ OPEN cur_record; /*接着使用OPEN打开游标*/ FETCH cur_record INTO pID, pValue; /*把第一行数据写入变量中,游标也随之指向了记录的第一行*/ WHILE no_more_record != 1 DO INSERT INTO testTable(ID, Value) VALUES (pID, pValue); FETCH cur_record INTO pID, pValue; END WHILE; CLOSE cur_record; /*用完后记得用CLOSE把资源释放掉*/END","categories":[{"name":"SQL","slug":"SQL","permalink":"http://shizhonggan.github.io/categories/SQL/"}],"tags":[{"name":"游标","slug":"游标","permalink":"http://shizhonggan.github.io/tags/%E6%B8%B8%E6%A0%87/"}]},{"title":"Spark框架概述","slug":"BigData/SparkOverview","date":"2022-05-01T07:54:23.000Z","updated":"2022-06-13T01:30:51.003Z","comments":true,"path":"2022/05/01/BigData/SparkOverview/","link":"","permalink":"http://shizhonggan.github.io/2022/05/01/BigData/SparkOverview/","excerpt":"","text":"Spark定义Apache Spark是用于大规模数据（Large-scala data）处理的统一（unified）分析引擎。 Spark最早源于一篇论文Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing, 该论文是由加州大学伯克利分校的Matei Zaharia 等人发表的。论文中提出了一种弹性分布式数据集（即：RDD）的概念。 A distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a fault-tolerant manner. RDD是一种分布式内存抽象，其使得程序员能够在大规模集群中做内存运算，并且有一定的容错。而这也是整个Spark的核心数据结构，Spark整个平台围绕着RDD进行。 Spark VS Hadoop(MapReduce) Haddop Spark 类型 基础平台，包含计算（MapReduce）、存储（HDFS）、调度(YARN) 纯计算工具（分布式） 场景 海量数据批处理(离线计算，磁盘迭代计算) 海量数据的批处理（内存计算、交互式计算）、海量数据流计算 价格 对机器要求低，便宜 堆内存有要求，相对较贵 编程范式 Map+Reduce, API较为底层，算法适应性差 RDD组成DAG有向环图，API较为顶层，方便使用 数据存储结构 MapReduce中间计算结果在HDFS磁盘上，延迟大 RDD中间运算结果在内存中，延迟小 运行方式 Task以进程方式维护，任务启动慢 Task以线程方式维护，任务启动快，可批量创建提高并行能力 Spark四大特点 速度快 比Hadoop快一百倍 Spark处理数据时，可以将中间内存处理结果存储到内存中 Spark提供了非常丰富的算子(API),可以做到复杂任务在一个Spark程序中完成 易于使用 概念多，编程容易123df &#x3D; spark.read.json(&quot;logs.json&quot;) # 读取数据df.where(&quot;age &gt; 20&quot;) # 过滤 . select(&quot;name.first&quot;).show() # 选取字段，进行展示 通用性强 在Spark的基础上，提供了Spark SQL、Spark Streaming、 MLib及 Graph在内的多个工具库 运行方式 可以在Hadoop和Mesos上，也支持Standalone的独立运行模式，也支持云上Kubernetes（2.3以上版本）。 数据源支持HDFS，Hbase,Cassandra和Kafak等多种途径 Spark框架模块Spark Core: Spark的核心，Spark核心功能均由Spark Core模块提供，是Spark运行的基础。Spark Core以RDD为数据抽象，提供Python, JAVA,Scala，R语言的API,可以编程进行海量离线数据处理 SparkSQL: 基于Spark Core之上，提供结构化数据的处理模块。SparkSQL支持以SQL语言对数据进行处理，SparkSQL本身针对离线计算场景。同时基于SparkSQL,Spark提供了StructuredStreaming模块，可以以SparkSQL为基础，进行数据的流式计算。 SparkStreaming: 以SparkCore为基础，提供数据的流式计算【有一定缺陷】 MLib: 以SparkCore为基础，进行机器学习计算，内置了大量的机器学习库和API算法。方便用户以分布式计算的模式进行机器学习计算 GraphX: 以SparkCore为基础，进行图计算，提供了大量的图计算API，方便用于以分布式计算模式进行图计算 Spark运行模式本地模式（单机, Local）【开发测试环境】 以一个独立的进程，通过其内部的多个线程来模拟整个Spark运行时环境 Standalone模式（集群） Spark中的各个角色以独立进程的形式存在，并组成Spark集群环境 Hadoop YARN模式（集群） Spark的各个角色运行在YARN的容器内部，并组成Spark集群环境 Kubernetes模式（容器集群） Spark中的各个角色运行在Kubernetes的容器内部，并组成Spark集群环境 云服务模式（运行在云平台上） Spark的架构角色 YARN 主要有四类角色，从2个层面去看：资源管理层面 集群资源管理者(Master):ResourceManager 单机资源管理者(Worker):NodeManager 任务计算层面 单任务管理者(Master):ApplicationMaster 单任务执行者(worker):Task(容器内计算框架的工作角色) Spar 主要有四类角色，从2个层面去看：资源管理层面 集群资源管理者(Master) 单机资源管理者(Worker) 任务计算层面 单任务管理者(Driver) 单任务执行者(Executor)","categories":[{"name":"BigData","slug":"BigData","permalink":"http://shizhonggan.github.io/categories/BigData/"},{"name":"Spark","slug":"BigData/Spark","permalink":"http://shizhonggan.github.io/categories/BigData/Spark/"}],"tags":[]},{"title":"基于Ansible API的任务管理web系统","slug":"Ansible/ansible_api","date":"2022-03-18T07:35:04.000Z","updated":"2022-05-07T10:07:50.296Z","comments":true,"path":"2022/03/18/Ansible/ansible_api/","link":"","permalink":"http://shizhonggan.github.io/2022/03/18/Ansible/ansible_api/","excerpt":"","text":"参考https://github.com/lfbear/ansible-api","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://shizhonggan.github.io/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://shizhonggan.github.io/tags/Ansible/"},{"name":"devops","slug":"devops","permalink":"http://shizhonggan.github.io/tags/devops/"},{"name":"python3","slug":"python3","permalink":"http://shizhonggan.github.io/tags/python3/"},{"name":"django","slug":"django","permalink":"http://shizhonggan.github.io/tags/django/"}]},{"title":"基于Ansible API的任务管理web系统","slug":"Ansible/ansible_ui","date":"2022-03-18T07:35:04.000Z","updated":"2022-05-07T10:07:50.296Z","comments":true,"path":"2022/03/18/Ansible/ansible_ui/","link":"","permalink":"http://shizhonggan.github.io/2022/03/18/Ansible/ansible_ui/","excerpt":"","text":"AWX 是开源的ansible web工具 该教程是在Centos7/8下完成部署。 配置SElinuxCentos/RHEL 7/8 在默认情况下 SELiunx是开启状态，这里需要时期失效，将SELinux配置文件中的 SELINUX=enforcing 修改为 SELINUX=disable。 1234# vi &#x2F;etc&#x2F;sysconfig&#x2F;selinux...SELINUX&#x3D;disabled... 保存退出后，reboot重启服务器。 配置epel源123yum -y updateyum -y install epel-releasereboot 所需要的安装包1yum -y install git gcc gcc-c++ ansible nodejs gettext device-mapper-persistent-data lvm2 bzip2 python3-pip nano wget 安装docker123456789101112131415wget https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo –directory-prefix &#x2F;etc&#x2F;yum.repos.d&#x2F;yum -y install docker-cesystemctl start dockersystemctl enable dockersystemctl status dockerwget https:&#x2F;&#x2F;files.pythonhosted.org&#x2F;packages&#x2F;0b&#x2F;f5&#x2F;be8e741434a4bf4ce5dbc235aa28ed0666178ea8986ddc10d035023744e6&#x2F;pip-20.2.4.tar.gz #下载安装包tar -zxvf pip-20.2.4.tar.gz # 解压cd pip-20.2.4&#x2F;sudo python setup.py install #给予权限不然可能安装失败pip install -U pip #再次更新pip install --ignore-installed requestspip install docker-compose # centos7用pip centos8用 安装AWX1234567891011121314151617181920git clone -b 17.1.0 https://github.com/ansible/awx.gitopenssl rand -base64 30 p6gtdhmTKiyObdOM19CCqri2gNxPD+9xLNuyaxHyvi ~/awx/installer/inventory#####postgres_data_dir=”/var/lib/awx/pgdocker”docker_compose_dir=”/var/lib/awx/awxcompose”pg_username=awxpg_password=Password@123pg_database=postgresadmin_user=adminadmin_password=Password@123secret_key=rVVKN3T9BaLffFhS4/kx8q6nyTiK660L28+yt0pxawx_alternate_dns_servers=”114.114.114.114″project_data_dir=/var/lib/awx/projects##### 1ansible-playbook -i ~/awx/installer/inventory ~/awx/installer/install.yml 这里postgre docker容器起不起来，配置文件选择的12版本，修改为10版本就行，同时不做升级操作。网上有解决办法是改成12.1-apline版本，因此根据不同环境，自行选择 完成如下12docker ps 防火墙12345678910&#96;&#96;&#96;## 访问AWXhttps:&#x2F;&#x2F;www.abidibo.net&#x2F;blog&#x2F;2012&#x2F;06&#x2F;29&#x2F;deploy-django-applications-nginx-uwsgi-virtualenv-south-git-and-fabric-part-5&#x2F;&#x2F;## 魔改### AWX_WEB “/home/ec2-user/work/awx_data/awx/awxcompose/nginx.conf:/etc/nginx/nginx.conf:ro”, “/home/ec2-user/work/awx_data/awx/awxcompose/SECRET_KEY:/etc/tower/SECRET_KEY:rw”, “awxcompose_rsyslog-socket:/var/run/awx-rsyslog:rw”, “awxcompose_rsyslog-config:/var/lib/awx/rsyslog:rw”, “awxcompose_supervisor-socket:/var/run/supervisor:rw”, “/home/ec2-user/work/awx_data/awx/projects:/var/lib/awx/projects:rw”, “/home/ec2-user/work/awx_data/awx/awxcompose/credentials.py:/etc/tower/conf.d/credentials.py:rw”, “/home/ec2-user/work/awx_data/awx/awxcompose/redis_socket:/var/run/redis:rw”, “/home/ec2-user/work/awx_data/awx/awxcompose/environment.sh:/etc/tower/conf.d/environment.sh:rw” STATIC_ROOT = ‘/var/lib/awx/public/static’ PROJECTS_ROOT = ‘/var/lib/awx/projects’ AWX_ANSIBLE_COLLECTIONS_PATHS = ‘/var/lib/awx/vendor/awx_ansible_collections’ JOBOUTPUT_ROOT = ‘/var/lib/awx/job_status’ SECRET_KEY = get_secret() ALLOWED_HOSTS = [‘*’] 1 docker exec -it awx_web bashcat /etc/nginx/nginx.conflocation /static/ { alias /var/lib/awx/public/static/; } location /favicon.ico &#123; alias /var/lib/awx/public/static/favicon.ico; &#125; 1 dnf -y update &amp;&amp; dnf -y install epel-release ‘dnf-command(config-manager)’ &amp;&amp; dnf module -y enable ‘postgresql:10’ &amp;&amp; dnf config-manager –set-enabled powertools &amp;&amp; dnf -y install ansible gcc gcc-c++ git-core glibc-langpack-en libcurl-devel libffi-devel libtool-ltdl-devel make nodejs nss openldap-devel patch @postgresql:10 postgresql-devel python3-devel python3-pip python3-psycopg2 python3-setuptools swig unzip xmlsec1-devel xmlsec1-openssl-devel ansible-playbook -i installer/inventory installer/build.yml -vvvvvv &amp; 123456## 自定义Ansible Tower LOGO&#96;&#96;&#96;sh# 上传custom_console_logo.png到&#x2F;var&#x2F;lib&#x2F;awx&#x2F;public&#x2F;static&#x2F;assets&#x2F;vi &#x2F;var&#x2F;lib&#x2F;awx&#x2F;public&#x2F;static&#x2F;local_settings.json&#123; “custom_logo” ： true &#125; # 如何设置为false 或不修改，则无法生效 awx 17.1.0 部署 参考https://n-guitar.hatenablog.com/entry/2021/10/16/020000 https://mpolinowski.github.io/devnotes/2021-04-28-ansible-tower-rhel 免密登录使用方法参考文献 免密登录 https://blog.csdn.net/qq_36830911/article/details/108107926 http://t.zoukankan.com/Nanaya-p-13202946.html 使用方法 https://blog.51cto.com/u_10616534/2407182 https://www.onitroad.com/jc/ya/ansible/how-to-add-new-inventory-create-host-credential-awx-ansible-tower.html https://www.unixarena.com/2018/12/awx-ansible-tower-inventory-bulk-hosts-import.html/","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://shizhonggan.github.io/categories/Ansible/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://shizhonggan.github.io/tags/Ansible/"},{"name":"devops","slug":"devops","permalink":"http://shizhonggan.github.io/tags/devops/"},{"name":"python3","slug":"python3","permalink":"http://shizhonggan.github.io/tags/python3/"},{"name":"django","slug":"django","permalink":"http://shizhonggan.github.io/tags/django/"}]},{"title":"Django RESTframework 教程","slug":"Django/DjangoRESTframework","date":"2022-03-16T03:03:04.000Z","updated":"2022-05-07T10:07:50.305Z","comments":true,"path":"2022/03/16/Django/DjangoRESTframework/","link":"","permalink":"http://shizhonggan.github.io/2022/03/16/Django/DjangoRESTframework/","excerpt":"","text":"介绍 序列化和反序列化序列化：将程序中的一个数据结构转化为其他格式（字典、JSON、xml等），例如django中将模型类对象转化为JSON字符串，这一过程被称为序列化。增改查，删不用返回 反序列化：修改和新增 增：校验请求数据-&gt; 执行反序列化 -&gt; 保存数据库 -&gt; 将保存的对象序列化输出 删：判断要删除的数据是否存在 -&gt; 执行数据库删除 改：判断要修改的数据是否存在 -&gt; 校验请求的数据 -&gt; 执行反序列化过程 -&gt; 保存数据库 -&gt; 将保存的对象序列化返回 查：查询数据库 -&gt; 将数据库序列化返回 DRF作用Django REST framework 可以帮助我们简化序列化和反序列化部分的代码编写，大大提高REST API的开发速度。 DRF特点 提供了定义序列化器Serializer的方法，可以快速根据Django ORM 或者其他库自动序列化/反序列化 提供了丰富的类视图、Mixin扩展类，简化视图的编写 丰富的定制层级：函数视图、类视图、试图集合到自动生成API，满足各种需求 多种身份认证和权限认证方式的支持 内置了限流系统 直观的API web界面 可扩展性，插件丰富 相关文档官方文档： http://www.django-rest-framework.org/ 源码：https://github.com/encode/django-rest-framework/tree/master DRF安装使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152## 环境依赖pip install djangorestframeworkpip install markdown # Markdown support for the browsable API.pip install django-filter # Filtering support## Add &#x27;rest_framework&#x27; to your INSTALLED_APPS setting.INSTALLED_APPS = [ ... &#x27;rest_framework&#x27;,]## If you&#x27;re intending to use the browsable API you&#x27;ll probably also want to add REST framework&#x27;s login and logout views. Add the following to your root urls.py file.urlpatterns = [ ... path(&#x27;api-auth/&#x27;, include(&#x27;rest_framework.urls&#x27;)) # Note that the URL path can be whatever you want.]## REST_FRAMEWORK = &#123; # Use Django&#x27;s standard `django.contrib.auth` permissions, # or allow read-only access for unauthenticated users. &#x27;DEFAULT_PERMISSION_CLASSES&#x27;: [ &#x27;rest_framework.permissions.DjangoModelPermissionsOrAnonReadOnly&#x27; ]&#125;## 添加路由from django.urls import path, includefrom django.contrib.auth.models import Userfrom rest_framework import routers, serializers, viewsets# Serializers define the API representation.class UserSerializer(serializers.HyperlinkedModelSerializer): class Meta: model = User fields = [&#x27;url&#x27;, &#x27;username&#x27;, &#x27;email&#x27;, &#x27;is_staff&#x27;]# ViewSets define the view behavior.class UserViewSet(viewsets.ModelViewSet): queryset = User.objects.all() serializer_class = UserSerializer# Routers provide an easy way of automatically determining the URL conf.router = routers.DefaultRouter()router.register(r&#x27;users&#x27;, UserViewSet)# Wire up our API using automatic URL routing.# Additionally, we include login URLs for the browsable API.urlpatterns = [ path(&#x27;&#x27;, include(router.urls)), path(&#x27;api-auth/&#x27;, include(&#x27;rest_framework.urls&#x27;, namespace=&#x27;rest_framework&#x27;))] DRF 序列化器12345678910111213141516171819202122class BookInfo(models.Model): btitle &#x3D; models.CharField(max_length&#x3D;30, verbose_name &#x3D;&#39;名称&#39;) bup_date &#x3D; models.DateField(auto_now&#x3D;True, verbose_name&#x3D;&#39;发布日期&#39;)## 自定义序列化器class BookInfoSerializer1(serializers.Serializer): # read_only&#x3D;True 只做序列化 write_only&#x3D;True 只做反序列化 id &#x3D; serializers.IntegerField(label&#x3D;&quot;ID&quot;, read_only&#x3D;True) btitle &#x3D; serializers.CharField(max_length&#x3D;30, label&#x3D;&#39;名称&#39;,required&#x3D;True) bup_date &#x3D; serializers.DateField(label&#x3D;&#39;发布日期&#39;) hello &#x3D; serializers.CharField(max_length&#x3D;10) # 新添加的字段from booktest.serializers import BookInfoSerializer, HeroInfoSerializerfrom booktest.models import BookInfo, HeroInfobook &#x3D; BookInfo.objects.get(id&#x3D;1)s &#x3D; BookInfoSerializer1(instance&#x3D;book, many&#x3D;False)s.databooks &#x3D; BookInfo.objects.all()s &#x3D; BookInfoSerializer1(instance&#x3D;books, many&#x3D;True)s.data 序列化器中的字段个数可以与模型的属性个数不同 可以添加不存在的，也可以不写，但是不能修改 创建序列化器有两个参数BookInfoSerializer(instance, data) S = BookInfoSerializer(instance=book, many=true) 只做序列化， S.data 可以取值 序列化 == 模型数据 -&gt; python字典（用于输出，返回数据给前端） S = BookInfoSerializer(data=data) 只做反序列化 反序列化 == 前端发送的数据 -&gt; 经过验证 -&gt; python字典 -&gt;save -&gt;模型类对象（用于输入，接受前端数据） jsonresponse 如果返回的是列表，safe=False; 序列化如果是一个查询集合，many=True DRF 关联序列化1234567891011# 只能序列化输出, 默认是将关联模型的ID序列化hbook &#x3D; serializers.PrimaryKeyRelatedField(label&#x3D;&quot;书籍&quot;,read_only&#x3D;True) # 默认是将关联模型的__str__方法返回值序列化hbook &#x3D; serializers.StringRelatedField(label&#x3D;&quot;书籍&quot;, read_only&#x3D;True) # 关联模型对象的序列化器中所有字段序列化出来hbook &#x3D; BookInfoSerializer1(read_only&#x3D;True) # 如果一里面关联序列化多时，需要指定many&#x3D;Trueheroinfo_set &#x3D; HeroInfoSerializer1(many&#x3D;True) 两个序列化器只能一个做关联 DRF 反序列化 is_valid()方法 ：在获取序列化的数据前，通过该方法进行验证 errors属性: 验证失败，可以通过序列化器对象的errors属性获取错误信息，返回字典 validated_data属性： 验证成功，获取数据 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647data = &#123; &#x27;btitle&#x27;: &#x27;三国&#x27;&#125;serializer = BookInfoSerializer(data=data)serializer.is_valid() # 调用序列化器的校验方法， True或False【必须执行】serializer.is_valid(raise_exception=True) # 校验出错后，自动抛出错误信息serializer.errors # 获取校验的错误信息，可不用，用上面这一个serializer.validated_data # 获取反序列化校验后的数据还是字典【然后执行】## 额外对某些字段进行校验class BookInfoSerializer1(serializers.Serializer): # read_only=True 只做序列化 write_only=True 只做反序列化 id = serializers.IntegerField(label=&quot;ID&quot;, read_only=True) btitle = serializers.CharField(max_length=30, label=&#x27;名称&#x27;,required=True) bup_date = serializers.DateField(label=&#x27;发布日期&#x27;) hello = serializers.CharField(max_length=10) # 新添加的字段 ## 以下是反序列化进行的操作 def validate_btitle(self, value): # 对某字段单独添加校验，注意命名 if &#x27;django&#x27; not in value.lower(): raise serializers.ValidationError(&quot;图书不是关于Django的&quot;) return value def validate(self, attrs): # 多个字段进行联合校验 attrs[&quot;hello&quot;] = &quot;word&quot; # 添加数据 return attrs def validate_btitle(self, value): # 对某字段单独添加校验，注意命名 if &#x27;django&#x27; not in value.lower(): raise serializers.ValidationError(&quot;图书不是关于Django的&quot;) return value def create(self, validated_data): # validated_data 反序列化校验后的字典型数据 # 当调用序列化器的save方法时，如果当初创建序列化器对象是没有给instance传参数 book = BookInfo.objects.create(**validated_data) BookInfo.objects.create(**&#123;&#x27;btitle&#x27;:&#x27;三国&#x27;&#125;) # 将字典 转换成 关键字=value 这种格式 BookInfo.objects.create( btitle=&quot;三国&quot; ) return book def update(self, instance, validated_data): # 如果传入参数，实际上会调用该方法 instance.btitle = validated_data.get(&#x27;btitle&#x27;) instance.save() return instance## 校验成功后操作serializer.save() # 会执行序列化器中的create方法或update方法","categories":[{"name":"Django","slug":"Django","permalink":"http://shizhonggan.github.io/categories/Django/"}],"tags":[{"name":"Django","slug":"Django","permalink":"http://shizhonggan.github.io/tags/Django/"},{"name":"RESTful","slug":"RESTful","permalink":"http://shizhonggan.github.io/tags/RESTful/"},{"name":"API","slug":"API","permalink":"http://shizhonggan.github.io/tags/API/"}]},{"title":"基于docker部署的gitlab迁移","slug":"Docker/gitlabmigrate","date":"2022-03-16T03:03:04.000Z","updated":"2022-08-05T12:34:58.229Z","comments":true,"path":"2022/03/16/Docker/gitlabmigrate/","link":"","permalink":"http://shizhonggan.github.io/2022/03/16/Docker/gitlabmigrate/","excerpt":"","text":"环境准备准备一台新云主机，系统centos7.6，挂载一块硬盘（以往经验挺耗内存的） 1234567891011121314#0. 挂载硬盘fdisk -l # 查看磁盘fdisk /dev/vdc # 对磁盘进行分区ne # 选择拓展分区w # 退出fdisk /dev/vdc n l # 创建逻辑分区w # 退出vi /etc/fstab # 修改挂载配置文件信息，添加：/etc/vdc5 /../work/ default 0 0 # 绝对路径mount /etc/vdc5 /../work/ # 挂载重启也无事#1、Docker 要求 CentOS 系统的内核版本高于 3.10 ，查看本页面的前提条件来验证你的CentOS 版本是否支持 Docker 。 12345678910111213141516171819202122232425#通过 uname -r 命令查看你当前的内核版本$ uname -r# 2、使用 root 权限登录 Centos。确保 yum 包更新到最新。$ sudo yum update#3、卸载旧版本(如果安装过旧版本的话)$ sudo yum remove docker docker-common docker-selinux docker-engine#4、安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的$ sudo yum install -y yum-utils device-mapper-persistent-data lvm2#5、设置yum源$ sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo#6、可以查看所有仓库中所有docker版本，并选择特定版本安装$ yum list docker-ce --showduplicates | sort -r#7、安装docker$ sudo yum install docker-ce #由于repo中默认只开启stable仓库，故这里安装的是最新稳定版17.12.0$ sudo yum install &lt;FQPN&gt; # 例如：sudo yum install docker-ce-17.12.1.cesudo yum install docker-ce-17.12.1.ce 12345678910111213141516171819# 修改docker.service配置文件，在EXECStart的后面增加 --graph=/data/docker(修改后的docker存储路径)。# 方法一：【这个比较好】cat /etc/docker/daemon.json&#123; &quot;data-root&quot;: &quot;/home/ec2-user/work/docker&quot;, &quot;registry-mirrors&quot;: [&quot;http://hub-mirror.c.163.com&quot;], # 这个下载速度挺快 &quot;mtu&quot;: 1400&#125;方法二：【一般】vim /usr/lib/systemd/system/docker.service......ExecStart=/usr/bin/dockerd --graph=/data/docker......# 执行下列命令然后重启dockersystemctl daemon-reloadsystemctl disable docker.servicesystemctl enable docker.service 搭建私人git仓库12345678910sudo docker run --detach \\ --hostname gitlab.ganshizhong.com \\ --publish 8011:80 --publish 8010:22 \\ --name gitlab \\ --restart always \\ --volume /home/ec2-user/work/gitlab/config:/etc/gitlab \\ --volume /home/ec2-user/work/gitlab/logs:/var/log/gitlab \\ --volume /home/ec2-user/work/gitlab/data:/var/opt/gitlab \\ --shm-size 256m \\ gitlab/gitlab-ce:latest 更换远程仓库地址首先进入项目所在文件夹，右键git bash （1）查看当前的远程地址 git remote -v （2）删除当前的远程地址 git remote rm origin （3）添加远程地址 git remote add origin http://119.255.249.177:8011/ganshizhong/sinnet.git (git@…) （*4）首次推代码 git push -u origin master http://119.255.249.177:8011/ganshizhong/sinnet","categories":[{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/categories/Docker/"}],"tags":[{"name":"gitlab","slug":"gitlab","permalink":"http://shizhonggan.github.io/tags/gitlab/"},{"name":"docker","slug":"docker","permalink":"http://shizhonggan.github.io/tags/docker/"}]},{"title":"Python 内存管理 & 垃圾回收","slug":"Python/memoryManagement","date":"2022-03-09T06:39:04.000Z","updated":"2022-05-07T10:07:50.318Z","comments":true,"path":"2022/03/09/Python/memoryManagement/","link":"","permalink":"http://shizhonggan.github.io/2022/03/09/Python/memoryManagement/","excerpt":"","text":"非人话定义 引用计数器为主 标记清楚和分代回收为辅 缓存机制 Python 垃圾回收引用计数器1. 环状的双向链表 refchain , 循环双向链表python 创建的任何对象都会放在refchain链表中。 12345678910name=&quot;gsz&quot;age=27hobby =[&quot;游泳&quot;]name=&quot;gsz&quot; 内部会创建一些数据【上一个对象、下一个对象、类型、引用的个数】new= name 这个时候new会直接应用，并且引用个数+1age=27 内部会创建一些数据【上一个对象、下一个对象、类型、引用的个数、value=18】hobby =[&quot;游泳&quot;] 内部会创建一些数据【上一个对象、下一个对象、类型、引用的个数、items=元素、元素个数】 在C源码中，通过PyObject结构体（4个值）体现每个对象都有相同的值 多个元素组成的对象，PyObject+ob_size 2. 类型封装结构12345678data&#x3D;3.14内部会创建： _ob_pre &#x3D; refchain中的上一个对象 _ob_next &#x3D; refchain中的下一个对象 ob_refcnt&#x3D;1 ob_type&#x3D;float ob_fval &#x3D; 3.13 3. 引用计数器123v1 =3.14v2=999v3=(1,2,3) python程序运行时，会根据数据类型的不同找到其对应的结构体，根据结构体中的字段来进行创建相关的数据，然后将对象添加refchain双线链表中。 在C源码中有两个关键的结构体，PyObject,PyVarObject 每个对象中有ob_refcnt就是引用计数器，默认值为1，当其他变量引用对象时，应用计数器就会发生变化。 12345678# 引用a=999b=a # 计数器+1# 删除引用a=999b=a # a和b指向同一个对象del b # b变量删除，b对应对象引用计数器-1del a # a变量删除，a对应对象引用计数器-1 当一个对象的引用计数器为0时，意味着没有人在使用这个对象了，这个对象就是垃圾，然后进行垃圾回收。回收：1.将对象从reflchain链表移除；2.将对象销毁，内存归还。 4. 循环引用存在问题123456v1 = [1,2,3]v2 = [4,5,6]v1.append(v2) # 引用计数器+1=2v2.append(v1) # 引用计数器+1=2del v1 # 引用计数器-1del v2 # 引用计数器-1 此时，变量v1,v2删除，但是指向的数据对象并没有销毁，这些数据一直存在内存中 标记清除目的：为了解决引用计数器循环引用的不足 实现方法： 在python的底层再维护一个链表，链表中专门放那些可能存在循环引用的对象（list,tuple,dict,set等可能被引用的数据） 在python内部 某种情况下触发，会去扫描 可能存在循环应用的链表中的每个元素，检查是否有循环引用，如果有让双方的引用计数器-1；如果是0则垃圾回收。 也存在问题： 什么时候扫描？ 链表扫描代价大，耗时久 分代回收 将可能存在循环引用的对象维护成三个链表： 0代： 0代中对象个数达到700个扫描一次 1代： 0代扫描10次，1代扫描一次 2代： 1代扫描10次，2代扫描一次总结 python中维护了一个refchain的双向环状链表，这个链表中存储程序创建的对象，每种类型的对象中都有一个ob_refcnt引用计数器的值，引用个数+1，-1，最后当引用计数器变为0时会进行垃圾回收（对象销毁、refchain中移除） 但是，在python中对于那些可以有多个元素组成的对象会存在循环引用的问题，为了解决这个问题python又引用标记清除和分代回收，在内部为四个链表。 在源码内部当达到各自的阈值，就会触发扫描链表进行标记清除的东走（有循环则各自-1） 但是，源码内部在上述的流程中提出了优化机制 缓存机制1. 池为了避免重复创建和销毁常见对象，维护池。 1234# 启动解释器时，python内部会帮助创建-5，-4，...257v1 = 7 # 内部不会开辟，直接去池中获取v2 = 9 # 内部不会开辟，直接去池中获取v3 = 9 # 内部不会开辟，直接去池中获取 2. free_list（float/list/tuple/dict）当一个对象的引用计数器为0时，按理说应该回收，但内部不会直接回收，而是将对象添加到free_list链表中当缓存，以后再创建对象时，不会重新开辟内存，而是直接使用free_list 123v1 = 3.14 # 开辟内存，内部存储结构体中定义的那几个值，并存到refchain中del v1 # refchain中移除，将对象添加到free_list中，当free_list满了则销毁v9 =99.99 # 不会重新开辟内存，去free_list中获取对象，对象内部数据初始化，再放到refchain中 参考：https://pythonav.com/wiki/detail/6/88/","categories":[{"name":"Python","slug":"Python","permalink":"http://shizhonggan.github.io/categories/Python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://shizhonggan.github.io/tags/python/"}]},{"title":"Python发布包和模块--setup.py","slug":"Python/setup","date":"2022-03-09T06:39:04.000Z","updated":"2022-05-07T10:07:50.320Z","comments":true,"path":"2022/03/09/Python/setup/","link":"","permalink":"http://shizhonggan.github.io/2022/03/09/Python/setup/","excerpt":"","text":"","categories":[{"name":"Python","slug":"Python","permalink":"http://shizhonggan.github.io/categories/Python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://shizhonggan.github.io/tags/python/"}]},{"title":"python 并发编程","slug":"Python/concurrentprogramming","date":"2022-02-25T08:39:04.000Z","updated":"2022-05-07T10:07:50.317Z","comments":true,"path":"2022/02/25/Python/concurrentprogramming/","link":"","permalink":"http://shizhonggan.github.io/2022/02/25/Python/concurrentprogramming/","excerpt":"","text":"并发编程并发编程，程序提速方法： 单线程串行 不加改造的程序 CPU-IO-CPU-IO… IO期间CPU是等待状态的 多线程并发 threading IO的同时让CPU进行其他任务，IO执行完CPU执行下一步任务 多CPU并行 multiprocessing 每个CPU都可以 CPU-IO… 多机器并行 hadoop/hive/spark https://blog.csdn.net/chenkaifang/article/details/80961211https://www.dongwm.com/archivespython 对并发编程的支持 多线程：threading, 利用CPU和IO可以同时执行的原理，让CPU在IO的同时执行其他任务 多进程：multiprocessing, 利用多核CPU的能力，真正的并行执行任务 异步IO: asyncio, 在单线程利用CPU和IO同时执行的原理，实现函数异步执行 使用Lock对资源加锁，防止冲突访问 使用Queue实现不同线程/进程之间的数据通信，实现生产者-消费者模式 改造爬虫，边爬虫-边解析 使用线程池Pool/进程池Pool，简化线程/进程的任务提交，等待结束、获取结果 使用subprocess启动外部程序的京城，并进行输入输出交互 CPU密集型计算、IO密集型计算 CPU密集型（CPU-bound） 也叫计算密集型，是指I/O在很短的时间就可以完成，CPU需要大量的计算和处理，特点CPU占用率很高； 例如：压缩解压缩、加密解密、正则表达式搜索 IO密集型（I/O bound） IO密集型指的是系统运作大部分的状况是CPU在等待I/O（硬盘/内存）的读写操作，CPU占用率仍然较低。 例如：文件处理程序（文件读取），网络爬虫程序（大量的下载）、多谢数据库程序 多线程、多进程、多协程的对比 多进程Process(multiprocessing) 优点：可以利用多核CPU并行运算 缺点：占用资源最多、可启动数目比线程少 适用于：CPU密集型计算 多线程Thread(threadin) 优点：相比进程，更轻量级，占用资源少 缺点：（Python多线程只能同时用一个CPU） 相比进程：多线程只能并发执行，不能利用多CPU（GIL); 相比协程：启动数目有限制，占用内存资源，有线程切换开销 适用于：IO密集型计算、同时运行的任务数目要求不多 多协程Coroutine(asyncio) 优点：内存开销最少、启动协程数量最多 缺点：支持的库有限制（aiohttp vs requests）、代码实现复杂 适用于: IO密集型计算、需要超多任务运行、但有现成库支持的场景 一个进程中可以启动N个线程，一个线程中可以启动N个协程 根据任务选择对应技术1234567if CPU密集型： 使用多进程Multiprocessingelif IP密集型： if 任务多 and 有协程库支持 and 协程实现复杂度不高： 使用多协程asyncio else: 使用多线程threading Python被吐槽慢，头号嫌疑犯，全局解释器锁GIL相比C/C++/JAVA,Python确实慢，在一些特殊场景下，Python比C++慢100~200倍 由于速度慢的原因，很多公司的基础架构代码依然用C/C++开发比如各大公司阿里/腾讯/快手的推荐引擎、搜索引擎、存储引擎等底层对性能要求高的模块 Python速度慢两大原因： 动态类型语言，边解释边执行，一个变量可以做数字、字符串或者列表，所以执行过程中都要检查变量类型，导致很慢 GIL无法利用多核CPU并发执行 GIL全局解释器锁（Global Interpreter Lock, GIL），是计算机程序设计语言解释器用于同步线程的一种机制，它使得任何时刻仅有一个线程在执行，即便在多核心处理上，使用GIL的解释器也只允许同一时间执行一个线程。 GIL的存在，即使电脑有多核CPU，单个时刻也只能使用1个，相比并发加速的C/C++慢 为什么有GIL这个东西python设计初期，为了规避并发问题引入了GIL，现在想去除去不掉了 为了解决多线程之间数据完整性和状态同步问题 python中对象的管理，是使用引用计数器进行的，引用数为0则释放对象 开始：线程A和线程B都引用了对象obj, obj.ref_num=2, 线程A和B都想撤销对obj的引用 GIL确实有好处：简化了Python对共享资源的管理 如何规避GIL带来的限制 多线程threading机制依然是有用的，用于IO密集型计算 因为I/O(read,write,send,recv,etc.)期间，线程会释放GIL，实现CPU和IO的并行，因此多线程用于IO密集型计算依然可以大幅度提升速度 但多线程用于CPU密集型计算时，只会更加拖慢速度 使用multiprocessing 的多进程机制实现并行计算、利用多核CPU优势 为了应对GIL，python提供了multiprocessing python多线程加速爬虫程序python创建多线程的方法12345678910# 准备一个函数def my_func(a,b): do_craw(a,b)# 怎样创建一个线程import threadingt = threading.Thread(target=my_func, args=(100,200))# 启动线程t.start()# 等待结束t.join() multi-threads example12345678910111213141516171819202122232425262728293031323334353637383940414243import requestsimport threadingimport timeurls = [f&quot;https://www.cnblogs.com/#p&#123;page&#125;&quot; for page in range(1,50+1)]# urls = [&quot;https://www.cnblogs.com/#p&#123;&#125;&quot;.format(page) for page in range(1,50+1)]def craw(url): r = requests.get(url) print(url,len(r.text))craw(urls[0])## multi threaddef single_thread(): print(&quot;single thread begin&quot;) for url in urls: craw(url) print(&quot;single thread end&quot;)def multi_thread(): print(&quot;multi-thread begin&quot;) threads = [] for url in urls: threads.append( threading.Thread(target=craw, args=(url,)) ) for thread in threads: thread.start() for thread in threads: thread.join() print(&quot;multi-thread end&quot;)if __name__ == &#x27;__main__&#x27;: start = time.time() single_thread() end = time.time() print(&quot;single thread cost: &quot;, end-start, &quot;seconds&quot;) start = time.time() multi_thread() end = time.time() print(&quot;multi-thread cost: &quot;, end - start, &quot;seconds&quot;) 多组件的Pipeline技术架构复杂的事情一般不会一下子做完，而是会分很多中间步骤一步一步完成 多线程数据通信的quene.Queuequeue.Queue可以用于多线程之间的线程安全的数据通信 1234567891011121314# 导入类库import queue# 创建Queueq = queue.Queue()# 添加元素q.put(item)# 获取元素item.get()# 查看元素的多少q.qsize()# 判断是否为空q.empty()# 判断是否已满q.full() 代码编写实现生产者消费者爬虫1234567891011121314import requestsimport threadingimport timefrom bs4 import BeautifulSoupurls = [f&quot;https://www.cnblogs.com/#p&#123;page&#125;&quot; for page in range(1,50+1)]# urls = [&quot;https://www.cnblogs.com/#p&#123;&#125;&quot;.format(page) for page in range(1,50+1)]def craw(url): r = requests.get(url) return r.textdef txtparse(html): soup = BeautifulSoup(html, &#x27;html.parser&#x27;) links = soup.find_all(&quot;a&quot;, class_ = &quot;post-item-title&quot;) return [(link[&quot;href&quot;], link.get_text()) for link in links] 1234567891011121314151617181920212223242526272829303132333435363738394041424344import requestsimport queueimport timeimport randomfrom bs4 import BeautifulSoupimport threadingurls = [f&quot;https://www.cnblogs.com/#p&#123;page&#125;&quot; for page in range(1,50+1)]# urls = [&quot;https://www.cnblogs.com/#p&#123;&#125;&quot;.format(page) for page in range(1,50+1)]def craw(url): r = requests.get(url) return r.textdef txtparse(html): soup = BeautifulSoup(html, &#x27;html.parser&#x27;) links = soup.find_all(&quot;a&quot;, class_ = &quot;post-item-title&quot;) return [(link[&quot;href&quot;], link.get_text()) for link in links]def do_craw(url_queue: queue.Queue, html_queue: queue.Queue): while True: url = url_queue.get() html = craw(url) html_queue.put(html) print(threading.current_thread().name, f&quot;craw &#123;url&#125;&quot;, &quot;url_queue.size=&quot;, url_queue.qsize()) time.sleep(random.randint(1,2))def do_parse(html_queue: queue.Queue, fout): while True: html = html_queue.get() results = txtparse(html) for result in results: fout.write(str(result) +&#x27;\\n&#x27;) print(threading.current_thread().name, f&quot;results.size&quot;, len(results), &quot;html_queue.size=&quot; , html_queue.qsize()) time.sleep(random.randint(1, 2))if __name__ == &#x27;__main__&#x27;: url_queue = queue.Queue() html_queue= queue.Queue() for url in urls: url_queue.put(url) for idx in range(3): t = threading.Thread(target=do_craw, args=(url_queue,html_queue), name=f&quot;craw&#123;idx&#125;&quot;) t.start() fout = open(&quot;02.data.txt&quot;,&#x27;w&#x27;) for idx in range(2): t = threading.Thread(target=do_parse, args=(html_queue, fout), name=f&quot;parse&#123;idx&#125;&quot;) t.start() 线程安全介绍线程安全指某个函数、函数库在多线程环境中被调用时，能够正确地处理多个线程之间的共享变量，使程序功能正确完成。 由于现成的执行随时会发生切换，就造成了不可预料的结果，出现线程不安全。 尤其是在远程调用或sleep的时候会经常出现 例如： 123def draw(account, amount): if account.balance &gt;= amount: account.balance -=amount 如果是多线程，同时进行两笔取钱操作，线程切换过程中，系统依次先执行了两次判断语句，导致接下来都完成了取钱操作，就出现了问题。 互斥访问；判断和执行语句捆绑为原子性；mysql幻读 Lock用于解决线程安全问题 锁就是让任务排队;锁让判断和执行语句捆绑上锁同时执行；锁是数据共享的地方； 方法一： try-finally 模式 1234567import threadinglock = threading.Lock()lock.acquire()try: # do somethingfinally: lock.release() 方法二： with模式 1234import threadinglock = threading.Lock()with lock: # do something 具体例子： 123456789101112131415161718192021222324import threadingimport timelock = threading.Lock()class Account: def __init__(self, balance): self.balance = balancedef draw(account, amount): with lock: if account.balance &gt;= amount: time.sleep(0.1) print(threading.current_thread().name, &quot;取钱成功\\n&quot;) account.balance -= amount print(threading.current_thread().name, &quot;余额&quot;, account.balance,&quot;\\n&quot;) else: print(threading.current_thread().name, &quot;取钱失败，余额不足&quot;,&quot;\\n&quot;)if __name__ == &#x27;__main__&#x27;: account = Account(1000) ta = threading.Thread(name=&quot;ta&quot;, target=draw, args=(account, 800)) tb = threading.Thread(name=&quot;tb&quot;, target=draw, args=(account, 800)) ta.start() tb.start() 线程池原理新建线程系统需要分配资源、终止线程系统需要回收资源，如果可以重用线程，则可以减去新建/终止的开销。 使用线程池的好处 提升性能：因为减去大量新建、终止线程的开销，重用了线程资源 使用场景：适合处理突发性大量请求或需要大量线程完成任务、但实际处理时间较短 防御功能：能有效避免系统因创建线程过多，而导致系统负荷过大相应变慢等问题 代码优势：使用线程池的语法比自己新建线程执行更加简洁 使用线程池ThreadPoolExecutor改造爬虫程序1234567891011121314151617181920212223242526272829303132333435363738from concurrent.futures import ThreadPoolExecutor, as_completedimport requestsimport queueimport timeimport randomfrom bs4 import BeautifulSoupimport threadingurls = [f&quot;https://www.cnblogs.com/#p&#123;page&#125;&quot; for page in range(1,50+1)]def craw(url): r = requests.get(url) return r.textdef txtparse(html): soup = BeautifulSoup(html, &#x27;html.parser&#x27;) links = soup.find_all(&quot;a&quot;, class_ = &quot;post-item-title&quot;) return [(link[&quot;href&quot;], link.get_text()) for link in links]## 用法一with ThreadPoolExecutor() as pool: results = pool.map(craw, urls) results = list(zip(urls, results)) for result in results: print(result)## 用法二with ThreadPoolExecutor() as pool: futures = &#123;&#125; for url, html in results: future = pool.submit(txtparse, html) futures[future] = url ## 方法一：顺序执行 # for future, url in futures.items(): # print(url, future.result()) ## 方法二:这个好，先结束先返回 for future in as_completed(futures): url = futures[future] print(url, future.result()) note: 用法一：map函数，结果和入参顺序对应；用法二：future模式更强大，as_completed顺序不定。 在web服务中，使用线程池加速web服务的架构以及特定 web后台服务的特点 web 服务对响应时间要求非常高，比如200MS返回 web 服务有大量的IO操作的调用，比如磁盘文件、数据库、远程API web 服务经常需要处理几万人、几百万人的同时请求 使用线程池ThreadPoolExecutor加速使用ThreadPoolExecutor的好处 方便的将磁盘文件、数据库、远程API的IO调用并发执行 线程池的线程数目不会无限创建（导致系统挂掉），具有防御功能 代码用Flask实现web服务并实现加速12345678910111213141516171819202122232425import flaskimport jsonimport timeapp = flask.Flask(__name__)def read_db(): time.sleep(0.1) return &quot;db result&quot;def read_file(): time.sleep(0.2) return &quot;file result&quot;def read_api(): time.sleep(0.3) return &quot;api result&quot;@app.route(&quot;/&quot;)def index(): result_file = read_file() result_db =read_db() result_api = read_api() return json.dumps(&#123; &quot;result_file&quot;:result_file, &quot;result_db&quot;:result_db, &quot;result_api&quot;:result_api &#125;)if __name__ == &#x27;__main__&#x27;: app.run() 12345678910111213141516171819202122232425import flaskimport jsonimport timeapp = flask.Flask(__name__)def read_db(): time.sleep(0.1) return &quot;db result&quot;def read_file(): time.sleep(0.2) return &quot;file result&quot;def read_api(): time.sleep(0.3) return &quot;api result&quot;@app.route(&quot;/&quot;)def index(): result_file = read_file() result_db =read_db() result_api = read_api() return json.dumps(&#123; &quot;result_file&quot;:result_file, &quot;result_db&quot;:result_db, &quot;result_api&quot;:result_api &#125;)if __name__ == &#x27;__main__&#x27;: app.run() 多进程multiprocessing 加速程序的运行有了多线程threading，为什么还要使用多进程multiprocessing?如果遇到了CPU密集型计算，多线程反而会降低执行速度！ multiprocessing模块就是python为解决GIL缺陷引入的一个模块，原理是用多进程在多CPU并行执行 多进程mutliprocessing知识梳理（语法上二者十分相似） 代码对比单线程、多线程、多进程在CPU密集计算速度123456789101112131415161718192021222324252627282930313233343536373839404142434445import mathimport timefrom concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutorPRIMES = [112272535095293]*100 # 这个数字很关键，不然很快就判断结束了def is_prime(n): # 判单是否是质数 if n&lt;2: return False if n ==2: return True if n %2 ==0: return False sqrt_n = int(math.floor(math.sqrt(n))) for i in range(3, sqrt_n+1,2): if n % i ==0: return False return Truedef single_thread(): for num in PRIMES: is_prime(num)def multi_thread(): with ThreadPoolExecutor() as pool: pool.map(is_prime, PRIMES)def multi_process(): with ProcessPoolExecutor() as pool: pool.map(is_prime, PRIMES)if __name__ == &#x27;__main__&#x27;: start = time.time() single_thread() end = time.time() print(&quot;single thread cost:&quot;, end-start, &quot;seconds&quot;) start = time.time() multi_thread() end = time.time() print(&quot;multi thread cost:&quot;, end - start, &quot;seconds&quot;) start = time.time() multi_process() end = time.time() print(&quot;multi process cost:&quot;, end-start, &quot;seconds&quot;)### print结果# single thread cost: 83.22900080680847 seconds# multi thread cost: 64.15043830871582 seconds# multi process cost: 24.825831413269043 seconds Flask服务中使用进程池加速123456789101112131415161718192021222324252627import jsonimport flaskfrom concurrent.futures import ProcessPoolExecutorimport mathapp = flask.Flask(__name__)def is_prime(n): # 判单是否是质数 if n&lt;2: return False if n ==2: return True if n %2 ==0: return False sqrt_n = int(math.floor(math.sqrt(n))) for i in range(3, sqrt_n+1,2): if n % i ==0: return False return True@app.route(&quot;/is_prime/&lt;numbers&gt;&quot;)def api_is_prime(numbers): numbers_list = [int(x) for x in numbers.split(&quot;,&quot;)] results = process_pool.map(is_prime, numbers_list) return json.dumps(dict(zip(numbers_list, results)))if __name__ == &#x27;__main__&#x27;: process_pool = ProcessPoolExecutor() app.run() python异步IO实现并发爬虫单线程爬虫的执行路径 协程：在单线程内实现并发 Python异步IO库介绍asyncio1234567891011121314151617181920212223242526import asyncioimport aiohttpimport timeurls = [f&quot;https://www.cnblogs.com/#p&#123;page&#125;&quot; for page in range(1,50+1)]# 获取事件循环loop = asyncio.get_event_loop()# 定义协程async def async_craw(url): print(&quot;craw url: &quot;, url) async with aiohttp.ClientSession() as session: async with session.get(url) as resp: result = await resp.text() print(f&quot;craw url: &#123;url&#125;, &#123;len(result)&#125;&quot;)# 创建task列表tasks = [ loop.create_task(async_craw(url)) for url in urls]# 执行爬虫事件列表start = time.time()loop.run_until_complete(asyncio.wait(tasks))end = time.time()print(&quot;use time seconds: &quot;, end-start)## print# single thread cost: 11.99697756767273 seconds# multi-thread cost: 1.426210880279541 seconds# asyncio cost: 1.3427538871765137 async 表示这是一个协程，await表示这是一个IO note: 要用在异步IO编程中，依赖的库必须支持异步IO特性;爬虫引用中，requests不支持异步，需要用aiohttp 在异步IO中使用信号量控制爬虫并发度信号量（Semaphore），又称为心好累、旗语，是一个同步对象，用于保持在0至指定最大值之间的一个技术之。 当线程完成一次对该semaphore对象的等待（wait）时，该计数值减一； 当线程完成一次对semaphore对象的释放（release）时，计数值加一； 当计数值为0，则线程等待该semaphore对象不再能成功直至该semaphore对象变成signaled状态 semaphore对象的计数值大于0，为signaled状态；计数值等于0，为nonsignaled状态。 12345678910111213########## 使用方式1sem = asyncio.Semaphore(10)# ...laterasyncio with sem: # work with shared resource########## 使用方式2sem = asyncio.Semaphore(10)# ...laterawait sem.acquire() try: # work with shared resourcefinally: sem.release() 12345678910111213141516171819202122232425262728import asyncioimport aiohttpimport timeurls = [f&quot;https://www.cnblogs.com/#p&#123;page&#125;&quot; for page in range(1,50+1)]semaphore = asyncio.Semaphore(10)# 获取事件循环loop = asyncio.get_event_loop()# 定义协程async def async_craw(url): async with semaphore: print(&quot;craw url: &quot;, url) async with aiohttp.ClientSession() as session: async with session.get(url) as resp: result = await resp.text() await asyncio.sleep(5) print(f&quot;craw url: &#123;url&#125;, &#123;len(result)&#125;&quot;)# 创建task列表tasks = [ loop.create_task(async_craw(url)) for url in urls]# 执行爬虫事件列表start = time.time()loop.run_until_complete(asyncio.wait(tasks))end = time.time()print(&quot;use time seconds: &quot;, end-start)","categories":[{"name":"python","slug":"python","permalink":"http://shizhonggan.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://shizhonggan.github.io/tags/python/"},{"name":"thread","slug":"thread","permalink":"http://shizhonggan.github.io/tags/thread/"},{"name":"process","slug":"process","permalink":"http://shizhonggan.github.io/tags/process/"},{"name":"coroutine","slug":"coroutine","permalink":"http://shizhonggan.github.io/tags/coroutine/"}]},{"title":"tkinter快速入门","slug":"Python/pywebbakdevtest1","date":"2022-02-21T08:39:04.000Z","updated":"2022-05-07T10:07:50.319Z","comments":true,"path":"2022/02/21/Python/pywebbakdevtest1/","link":"","permalink":"http://shizhonggan.github.io/2022/02/21/Python/pywebbakdevtest1/","excerpt":"","text":"1. python类变量和实例变量的异同 类变量：可在类的所有实例之间共享的值（也就是说，它们不是单独分配给每个实例的）。 实例变量：实例化之后，每个实例单独拥有的变量。1234567891011121314class student(): age = 0 name = &#x27;stu&#x27; # age,name是类变量 def __init__(self,age,name): self.age = age self.name = name # 访问实例变量(用self.age self.name)student1 = student(18,&#x27;hello&#x27;)print(student1.name) # 打印实例变量，输出helloprint(student.name) # 打印类变量，输出stu 2. python中的协程如何实现的 进程：进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位。每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。 2、线程 线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。 3、协程 协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。 首页 注册 登录V2EX = way to exploreV2EX 是一个关于分享和探索的地方现在注册已注册用户请 登录FinClipDataPacketCDN77广告FinClip2022 FinClip 黑客马拉松，寻找「最强大脑」广告rapospectreV2EX › 程序员2017 后端面试经历分享 44 rapospectre · bluedazzle · 2017-03-20 11:36:07 +08:00 · 26188 次点击这是一个创建于 1814 天前的主题，其中的信息可能已经有所发展或是发生改变。0.背景博主本人 2015 年毕业于郫县某 985 大学通信工程系，因为大学期间一直自己创业所以错过了大四秋招春招，毕业后又在北京继续创业一年，但在创业公司一直无法沉淀技术累积，于 16 年年底萌生进大公司学习的想法，于是从 16 年年底开始通过社招找工作。虽然大学就开始做研发，但无奈简历只看毕业工作经验，所以本人简历只有一年工作经验。 在此总结一篇文章给各位参考； 1.阿凡题应该算是人生第一场面试，早上 11 点开始，公司是做 k12 在线教育相关业务，在五道口那边； 一面前台登记后发了一套笔试题，开始写，主要都是 Python 基础知识，不算难，基本就是 可变对象不可变对象区别、 Python 垃圾回收机制之类的题目，有一两道编程题也很简单，最后有个根据题目设计数据表的问题也不难，搞定后等面试官开始二面； 二面面试官好像是个主管，开始让做自我介绍，他在看我的笔试题，然后根据简历问了一些项目相关的问题以及简单的一些系统设计问题，之后大概问了问笔试题里一些问题和补充，感觉聊的比较开心，面试官也对之前我的经历比较感兴趣，于是去通知 CTO 进行三面； 三面CTO 面里问题的广度和深度都很大，从服务器部署的相关知识到 Nginx 一些细节问题都有问到，不得不说问的还是比较全面的，印象最深的应该是这个问题： 浏览器的一个请求从发送到返回都经历了什么，讲的越详细越好我大概讲下我的答案： 1 、先从网络模型层面： client （浏览器）与 server 通过 http 协议通讯， http 协议属于应用层协议， http 基于 tcp 协议，所以 client 与 server 主要通过 socket 进行通讯； 而 tcp 属于传输层协议、如果走 https 还需要会话层 TLS 、 SSL 等协议； 传输层之下网络层，这里主要是路由协议 OSPF 等进行路由转发之类的。再向下数据链路层主要是 ARP 、 RARP 协议完成 IP 和 Mac 地址互解析，再向下到最底层物理层基本就是 IEEE 802.X 等协议进行数据比特流转成高低电平的的一些定义等等； 当浏览器发出请求，首先进行数据封包，然后数据链路层解析 IP 与 mac 地址的映射，然后上层网路层进行路由查表路由，通过应用层 DNS 协议得到目标地址对应的 IP ，在这里进行 n 跳的路由寻路；而传输层 tcp 协议可以说下比较经典的三次握手、四次分手的过程和状态机，这里放个图可以作为参考： 2 、应用层方面： 数据交换主要通过 http 协议， http 协议是无状态协议，这里可以谈一谈 post 、 get 的区别以及 RESTFul 接口设计，然后可以讲服务器 server 模型 epoll 、 select 等，接着可以根据实际经验讲下 server 处理流程，比如我： server 这边 Nginx 拿到请求，进行一些验证，比如黑名单拦截之类的，然后 Nginx 直接处理静态资源请求，其他请求 Nginx 转发给后端服务器，这里我用 uWSGI, 他们之间通过 uwsgi 协议通讯， uWSGI 拿到请求，可以进行一些逻辑， 验证黑名单、判断爬虫等，根据 wsgi 标准，把拿到的 environs 参数扔给 Django ， Django 根据 wsgi 标准接收请求和 env ， 然后开始 start_response ，先跑 Django 相关后台逻辑， Django 拿到请求执行 request middleware 内的相关逻辑，然后路由到相应 view 执行逻辑，出错执行 exception middleware 相关逻辑，接着 response 前执行 response middleware 逻辑，最后通过 wsgi 标准构造 response ， 拿到需要返回的东西，设置一些 headers ，或者 cookies 之类的，最后 finish_response 返回，再通过 uWSGI 给 Nginx ， Nginx 返回给浏览器。 谈完后 CTO 根据我说的一些细节提出了一些问题，最后当时就谈了 offer ， CTO 说不走 hr 那边了直接和我谈，比较意外的是 offer 给的比我自己要的还高 5k 。对于第一次找工作的我来说当时满心激动。 最后大概说说环境：公司在五道口一栋写字楼内容，规模还算比较大，听 CTO 谈做的事情也比较有意思，有机器学习、大数据等等 （ 主要是处理各种初高中学科的题目，涉及到文字识别深度学习等等，当然我如果进去肯定要从业务写起 ），包午餐、下午茶之类的其他我就不太清楚了，因为下午就走了，不过公司好像是每周六天班。公司发展感觉还是比较高速，感兴趣的同学可以去试试。 学堂在线公司也在五道口，清华科技园里， Google 前中国办公室对面的楼里 （ 好像现在搬到 Google 那里了 ） 一面一面面试官应该是个后端研发工程师，感觉有些羞涩，全程一直不看我，主要聊了一些简历里的项目经验，系统设计，然后问了几个简单的算法题和一些 Python 的基本知识，然后就去叫二面面试官了。 二面二面面试官是部门主管，嗯，这次总算看着我跟我聊了，哈哈，感觉目光交流也很重要，同样问了一些系统设计的问题和经验问题，因为博主 Django 相关的经验还算比较丰富，感觉他们也主要是找业务研发，所以没什么意外就过了。 三面hr 面，主要问了一些薪资期望，发展规划之类的，主要是聊天，然后就发了 offer 。 学堂在线主要是做慕课平台，并且是和国内各大高校合作，福利方面因为最后没有去所以不是特别了解，公司环境还是不错的。 3.果壳果壳在国贸百朗园里，在园区最里面，不是很好找，一进去先发了一套面试题和一张登记表，登记表连父母家庭资料都要，不是很理解要面试者这些信息干什么，又不一定去你家，等入职再填不行吗？所以除了本人信息，其他我没填。（ 面了这么多家就果壳要填这个，还要填特别详细的信息，不能懂 ） 一面面试题难度适中，不过涉及到的面比较多，还要写数据库查询语句等等，博主非科班，只大概自学过数据库，然后一直在用 orm ，毕业后就没怎么写过原生 SQL ，相关题目只能凭借记忆大概写了下，还有一道题是 用 O(1) 的复杂度实现一个 栈 的出栈入栈和返回 max 、 min 值的操作，其他就是一些 Python 基础和表设计题。 这里说下这道设计栈的题： 出入栈函数 O(1) 没什么问题，主要是 max 、 min 操作（ 博主找工作时没看过面试题目，只是刷了一些 LeetCode ，后来发现这道题很经典，网上很多答案）当时没遇到过这种需求，但是可以肯定想要时间复杂度下降，肯定是要用空间去换时间，所以当时有设计了额外的数据结构存 max min ，但当时设计的还是有问题，后面又和面试官讨论了一下，还是没有得出最好的方案，最后回去网上搜了下发现其实很简单，当时只差最后一步，感兴趣的同学可以看下：栈在 O(1) 时间内求 min 二面面试官一上来就直接拿着笔试题开始一道一道问，嗯，连我叫什么都没让介绍，更别说介绍项目什么的，感觉有点懵逼，全程没一句废话，全是纯技术问题和算法，然后自己擅长的面试官感觉不太感兴趣，我不太熟悉的他很愿意追问，嗯，二脸懵逼，之后又问道 tcp 流量控制，当时直接说错给说了拥塞控制，面试官表示我 tcp 掌握的不好（ 确实是我的问题，回去之后又整个看了一遍 tcp ）。 最后又问了很多数据库底层的东西，博主完全没接触过，所以面试官表示下一轮面试官有事 （ 哈哈哈 ），接着问我有什么想问的，我问了两个问题面试官表示自己还有事。。。好吧，那就不聊了。 总结：数据库知识很重要，即使你投的是研发不是 dba ，你也一定要懂数据库底层的基本原理，至少要知道 索引原理、 MySQL 数据引擎等等，因为之后凡是博主挂的面试都有数据库的锅。 果壳环境看上去有些乱，但比较温馨，但实在不敢恭维面试的方式，所以挂了博主也没惋惜。其他方面就不太了解啦，因为根本没拿到 offer 。 4.Veeva公司也在国贸附近，是一家给生物科技企业（ 药厂 ）做 crm 的外企 ( 不过国内的好像和国外母公司没什么关系，就是个单独的子公司 )，不算是互联网公司，但是薪资很给力。 一面首先是 phone interview ， hr 大概问了问跳槽的原因，项目经验，发展规划等，然后发来 homework ，做完后提交； 二面homework 比较简单，就是一个判断是否润年的函数，不过这里是有坑的，当题目很简单时，人家考验的就不是智商了，而是看你的编码能力，工程化能力及面向对象抽象能力，所以果断完整的写了个工程，加上完整的测试，然后提交之。 三面hr 说技术同事看了 homework 感觉还是比较 ok 的，所以约面试，首先来的面试官好像就是个 leader ，问了很多 Python 和 Django 相关的基础知识和算法题，现场有个白版，直接在上面她出题，我写，然后她 review ，基本上就是 LeetCode easy 难度的题，没有太大问题。 四面应该是个技术大牛，问了问经验开始系统设计，我记得当时是让设计一个短网址生成方案，有一些额外要求，比如不能按照字符顺序生成短网址，而是要随机生成，如何避免碰撞，如何最大效率利用所有空间。 具体方案可以看知乎，上面有人讨论过： 短链接是如何设计的 然后面试结束。 面试完后接到 hr 电话说技术同事感觉不错，问我有没有意向入职，但当时考虑还是想去互联网公司所以就拒掉了。不过 veeva 的薪资很给力，感兴趣的同学可以去看看。 5.知乎博主的 dream company ，哈哈，去面试的时候特紧张。知乎在 768 创意园，环境很棒。 一面一面面试官问了项目经历及一些个人信息后开始考基础，主要是面试官出题，然后我在纸上写代码，难度适中，因为面试的比较久了，记不太清楚全部题目，记得让手写了快排，然后 Python 相关基础知识，一些 LeetCode 题， tcp 相关知识， epoll 服务模型、 tornado 的一些原理 （ 可以看博主之前文章 tornado ioloop 分析 ）数据库知识 （ 坦白掌握不多 ）末尾问了下二分查找，一面就过了。 二面面试官好像是商业化后台的主管？问了项目经验，问了经历，对我大学期间创业经历表示赞扬，但毕业后又创业一年表示不满意（ 不是很明白为什么 ），之后开始问一些系统设计相关题目，印象比较深的是设计微信抢红包的构架，嗯，当时根据自己的见解说了一套系统和注意的点以及分配红包的算法，感觉面试官应该不太满意。回去后看了看网上，还真有写，果断研读了一发： 微信红包构架设计. 后面又聊了一些系统设计相关的内容，然后让我等等。 三面等了半个小时，期间看到前两面面试官一直在和 hr 讨论，应该是要不要我的问题，半个小时后 hr 来跟我聊了聊规划和项目以及为何来知乎，然后就回去周五前给回复。 到此大概确定应该要我的可能性不大，应该是当做备胎了。 这里自己的问题主要是系统设计方面当时并没有准备，另一方面数据库这块明明果壳问到了但是没有重视起来。最后，年底出去找工作还是要谨慎，很多大点公司没什么招聘需求，除非特别优秀。 最后，周五没有收到消息，基本确定挂了，果然在下周周一的时候收到了拒信，这点要赞一下，至少有明确的拒信，不像一些其他公司，嗯，就不明说了。 知乎氛围觉得还是挺赞的， 福利也很好，包三餐，不加班，嗯，不多说了，都是泪。 最近知乎开始大量招人了，大家可以去试试哦，替我完成我的 dc 梦，哈哈哈。 6.春雨医生春雨医生在知乎隔壁，真的是紧隔壁，环境也不错~ 一面照例进行自我介绍，然后问项目经验，开始纸上写代码，不过这里要赞一下春雨，面试题都非常接地气，全是根据实际项目里的问题进行编码，比如有个给医生和病人聊天记录分组提醒的题目，都是类似的实际场景题目，完全没有那种纯算法题目，之后又聊了一些 Python Django 基础相关的东西，顺利进入二面。 二面问了一些项目信息，然后开始系统设计，没记错的话应该是设计一个类似 QQ 的聊天工具，要求有群，并且可以发送图片、语音等各类消息，群管理员可以进行群管理等等。后面又问道数据库，直言数据库基础掌握的比较少，面试官也没有为难我。 三面三面的时候到晚上饭点了， hr 姐姐超级好，带我去外面中餐馆点菜吃饭，回来后 CTO 面试， 考了阿凡题 CTO 问过的问题： 浏览器的一个请求从发送到返回都经历了什么 于是本人又根据上面那个流程讲了一遍，接着又问了问自己的发展规划和期望，然后我问了问春雨相关的一些问题，面试结束。 隔天收到了 offer ， 请我吃饭的小姐姐发给我的，哈哈，但是由于年前无法到岗，只能拒掉了。 总体讲，春雨环境也很不错，但其他福利我也没有问，所以其他不太清楚咯，有兴趣的同学可以去试试。 360360 在酒仙桥，最不靠谱的面试。。。 直接通过拉钩邀请第二天早上面试，当时已经下午五点。完全没打电话发短信，接到邮件的我一脸懵逼，于是主动打电话过去确认，得到肯定后第二天做两个多小时车赶往望京。 （ 我住在八宝山这块 ） 一面前台不让进，让通知面试的人来接，等了会儿面试官来接我，然后七绕八绕不知道绕道哪去给了我一份笔试题，让我做，着重强调不要看手机 （ 本来就没打算看好嘛，我坐的头顶有个摄像头，你让我怎么看，哈哈哈 ）写完让我打他电话，然后他就闪了。 我一看题目，除了前三道是 Python 之后全是 Linux 基础题，当时心里想：不亏是做安全的啊，要求就是不一样，然而博主半吊子 Linux 水平只会一些常用的命令，笔试题里的高端用法实在是臣妾不会做啊，于是本着诚实的原则做完会做的打了电话。 二面面试官来没有让自我介绍，直接对着题目开始问 （ 我的内心已经产生了抵触感，和果壳一样 ）。第一题是个 Python 改错题，面试官问为何这样改，我大概讲了下，然后是讲了下 lambda 表达式并提供编程例子，面试官看完也没说什么，接着是一个用两个队列模拟栈，写实现代码，也没有太大问题，只是面试官也没有看代码，就是问了我怎么实现。 接着到了 Linux 部分，基本都不会，会的也只能写出简单的命令，面试官直言：你这个笔试题做的不好啊。怎么都不会 （ 确实有我的问题， Linux 基础不好，但是直接否定了前面其他部分有点冤啊 ） 接着问了一些项目经验，看到我的开源项目 djanog-simple-serializer 问这是干嘛的，然后我说了下是序列化解决方案，面试官说：序列化不是很简单嘛？（ 我也没说难啊大兄弟，只是其他的没有好用的自己写了个嘛 ）接着面试官问了我一句让我十脸懵逼的话，作为一个不懂 Python 的人，你能给我简单讲讲 Django 和你做的东西吗？当时我的内心全是黑人问号脸， wtf ？不懂 Python ？那你招 Python ？ 怎么面试啊大兄弟，虽然我知道其他语言用的 6 写 Python 也没问题，但是招进来就要写业务你怎么也得找个有相关经验的面试吧，这下我明白为啥之前 Python 部分面试官不怎么看了。 此刻我只想赶紧离开了，于是就说感觉招聘需要和我不太一致，就不耽误时间了。 好吧，应该我算是遇到个例，请大家不要对 360 产生偏见。 今日头条今日头条在中航广场，人民大学旁边，不得不说，是我面试过离我最近的公司，头条大楼很霸气。发展也很迅速。 一面面试前一天晚上莫名失眠，真的是一宿没睡，睁眼到天亮，然后一脸懵逼的去面试，到了头条前台我勒个去，从没见过这么多人来面试，大厅做不下了，当时心里想：完蛋，这么多人，竞争得多激烈，昨晚还失眠，血崩。 在前台签到，领了候选人的牌子，等了一会儿就叫到了我，由于面试的人实在太多，我实在 -1 楼食堂进行的面试，一面面试官是广告投放部门的工程师，先自我介绍，谈创业经历，问了 redis 用法及原理 （ 前面几次问到数据库的前车之鉴，博主特意狠狠看了下各种数据库的基本原理 ），然后根据我说使用 hash table 的经验，提了一个分布式 redis 使用 hash 的潜在问题，当时没有想出来，面试官提醒了下大概说到了点子上，主要是分布式机器 hash 后可能存在储存分配不均匀问题。然后 hash 表又问了冲突解决方案，主要是拉链法和进位法，之后聊了 tcp ，没什么问题。 问了排序算法的最小时间复杂度及原因。接着出了一道费那波数列的题，要求在常数时间复杂度内计算任意 fib(n) 当时可能没听清，估计没睡的原因，听成了常数时间复杂度，向面试官确认是常数时间复杂度 （ 面试官可能没听清我说的，以为我说的空间复杂度 ）于是苦思冥想无果，面试官提示动态规划，于是开始推导转移方程，最后面试官说没那么复杂，这时一对才发现我们理解岔了。其实很简单： def fib(n): a, b = 0, 1 for x in xrange(n): a, b = b, a + b return b一面问题结束，在我写题的时候面试官看了我的博客和 GitHub ，表示满意 （ 有点惊讶，第一次有面试官看我博客和 GitHub ，虽然简历上有，但从没有人说看过 ），然后又带我把一面所有问题过了一遍，我不清楚的地方都完整的给出了答案，没见过这么好的面试官！！不知道他们给我多少分，我给他们满分！ 二面二面面试官是头条广告后台组主管，对我的创业经历很感兴趣，问了很多相关问题，然后看到我的开源项目又问了一些问题，然后提了一个很有意思的题目，在极端情况下，系统缓存全部失效，该如何防止流量全部打到数据库上，当时从很多方面考虑但是感觉面试官没有非常满意，不过也算是答到了点子上，也就算过了。回去后特意看了看，缓存失效的解决方案，感兴趣的同学自行搜索 “缓存重建”。 然后问了问一些项目相关的经验和解决方案，出了一道单链表逆置的题目 （ 和面试官透露非科班，没有出很难的题目 ），然而当时大脑基本处于停转状态，太困了，最后写出来有个 bug ，其实题目很简单，回去稍微想了下就写了出来： def revese(node): p = node cur = node.next p.next = None while cur: tmp = cur.next cur.next = p p = cur cur = tmp return p面试官表示 coding 能力需要加强，当时也不好说自己没睡觉，就直接说确实能力需要加强。面试关说让我等等去找下一轮面试官，等了一会儿告诉我下个面试官不在，当时觉得我是挂了 （ 结果是面试官真的不在 ），面试官好像看出了我的想法，重复了一句面试官真的不在。让我回去，稍后 hr 约下次面试时间。 三面三面是一周后的下午 6 点，这次终于来到了面试室，里面有一块白版，三面面试官是广告大组的 leader ，进来没有再考基础题，问过经历后出了五道系统设计题，于是开始在白板上写，大概记得有多端登录管理、二维码登录等等一些设计，要求设计出系统结构，相关数据库和表，博主设计完后给面试官讲了一遍，感觉面试官比较满意，也没再问其他的，直接去叫下一轮面试官了。 四面四面面试官是头条 data 部门的 vp ，感觉人超级和善，进来直接跟我说一起去吃饭吧，刚好体验下头条食堂，然后，第四轮面试是在饭桌上进行的，主要谈了谈我的项目经验和发展方向以及为何来头条，最后吃完饭面试官说本来这一轮也会考技术，但是感觉聊得不错，就不聊技术了，让我回去等 hr 电话。（ 头条食堂真的不错呀，只是当时没好意思多打，哈哈 ） 五面hr 电话聊了聊个人发展及规划，然后确定了薪资，就发了 offer ~~ 头条环境非常不错，包三餐，自助食堂，无限水果零食还有下午茶，晚上 10 点后打车报销，入职发 mac ， 住公司周围房补，大小周加班有加班费等等，总之福利非常多 （ 为何我知道的这么多 ）还是推荐大家来哦。 总结最后，博主选择了头条的 offer 。（ 已经找到当初面试我的大神们，哈哈，开心 ） 从去年底找工作找到今年节后，终于找到一个满意的 offer ，曾经也纠结过，感觉自己高不成低不就，有段时间甚至拒绝出去找工作。 很多大公司社招都是三年经验起，所以像博主这种毕业一年的人在没有内推的情况下参加社招非常尴尬，在这里奉劝各位学弟学妹，一定要抓住校招的机会啊！！社招跟你竞争的可不光是你们同级的人。 找到工作后偶然发现一本神书 《剑指 offer 》我面试过基本所有问题上面都有，推荐大家一定过一遍（ 要是早点看到就好了，哈哈 ） 这里还有博主当时刷过的 LeetCode https://github.com/bluedazzle/leetcode_python ，可以参考一下，之后有时间博主也打算一直刷下去。 平时一定要注意多积累，有条件的情况下尽量自己多写一些自己的项目，这样面试会有很大的加分，比如博主之前写过的小程序：式神猎手 ( https://www.rapospectre.com/blog/create-an-onmyoji-weapp-in-24-hours ) 在面试中就很有益处。 还没完说到抓住校招，今日头条春招刚刚开始，学弟学妹抓紧机会，本人可以内推哦： 今日头条春季校园招聘火热进行中！ [面向对象] ： 2017 年应届毕业生和 2018 年应届暑期实习生 [职位方向] ：研发、产品、运营、销售、投资、 HR 等 [春季招聘 - 2017 届] ： https://job.toutiao.com/campus/spring [暑期实习 - 2018 届] ： https://job.toutiao.com/campus/summer [投递时间] ： 3 月 9 日 - 4 月 30 日 [头条邀请码] ： iUGUiF （不区分大小写） 登录相关网址输入我的头条邀请码即可成功内推哟，快到碗里来！！ 社招的同学也别灰心，只要你找得到我的邮箱（ 应该挺好找的 ），简历发给我，帮你内推~ 当然，对于以上其他家公司，只要我拿到 offer 的公司我都可以帮大家推哟。 面试过程中还去过几家创业公司聊过，发展也很好，比如 青橙科技、视频帮等等，如果大家感兴趣，我都可以帮大家直推 CTO 。 原文地址 https://www.rapospectre.com/blog/2017-backend-interview-share 作者：rapospectre 第 1 条附言 · 2017-03-20 12:27:24 +08:00fib 数列那里是常数空间复杂度哈，文中写错了。 感谢 @razrlele 指正 面试 Python 博主 官170 条回复 • 2020-10-01 21:47:50 +08:001 21❮ ❯everhythm 1everhythm 2017-03-20 11:45:21 +08:00郫县群众握爪，同在帝都metrue 2metrue 2017-03-20 11:50:12 +08:00 via iPhone很详细，可是不知道这样泄漏面试内容是否不妥。ljcarsenal 3ljcarsenal 2017-03-20 11:53:02 +08:00真厉害razrlele 4razrlele 2017-03-20 11:58:30 +08:00 via iPhone你写的那个 fib 应该是 O(n)时间复杂度吧，常数时间复杂度应该是套公式法吧？rapospectre 5rapospectreOP 2017-03-20 12:06:51 +08:00@razrlele 是的，面试要求的是要常数空间复杂度，不是时间复杂度哈。rapospectre 6rapospectreOP 2017-03-20 12:07:53 +08:00@metrue 已经省略了很多关键细节，很多题都没写，都直接拿 LeetCode 代替了，只是写了几个比较有意思的题目。rapospectre 7rapospectreOP 2017-03-20 12:08:28 +08:00@everhythm 哈哈，想念豆瓣不rapospectre 8rapospectreOP 2017-03-20 12:08:47 +08:00@ljcarsenal 客气啦xiahei 9xiahei 2017-03-20 12:25:09 +08:00邀请码已用，简历已投，谢谢楼主！！lichao0x7cc 10lichao0x7cc 2017-03-20 12:43:21 +08:00非常感谢楼主的分享。iloveyou 11iloveyou 2017-03-20 12:57:04 +08:00请问能大概透漏下薪资不，本人最近也打算去帝都发展guoer 12guoer 2017-03-20 13:02:01 +08:00 via iPhone写得很好byebyejude 13byebyejude 2017-03-20 13:03:11 +08:00 via Android又是你电道友。。zhihhh 14zhihhh 2017-03-20 13:08:35 +08:00哈哈 楼主的头像果然在哪儿都一样，超高辨识度。。WangYanjie 15WangYanjie 2017-03-20 13:09:51 +08:00“浏览器的一个请求从发送到返回都经历了什么，讲的越详细越好”另一种思路： Client-&gt;DNS-&gt;Load Balancer-&gt;Web ServerAmayadream 16Amayadream 2017-03-20 13:13:45 +08:00 via iPhone写的好详细，楼主也好厉害whiler 17whiler 2017-03-20 13:18:54 +08:00看来博主很少逛河畔，握爪HLT 18HLT 2017-03-20 13:26:23 +08:00看完了 超赞 满满的干货 言语诙谐 祝一直好运cxyfreedom 19cxyfreedom 2017-03-20 13:31:21 +08:00最早是看 tornado 搜到楼主的，真心不错iloveyou 20iloveyou 2017-03-20 13:40:22 +08:00请问楼主是在哪个平台找的工作？智联还是其他？welkinzh 21welkinzh 2017-03-20 13:41:33 +08:00 via Android学习了 谢谢楼主rapospectre 22rapospectreOP 2017-03-20 13:49:36 +08:00@xiahei 不客气！rapospectre 23rapospectreOP 2017-03-20 13:50:14 +08:00@lichao0x7cc 客气啦lxy 24lxy 2017-03-20 13:51:53 +08:00前段时间找 Django 序列化方案看过楼主的项目，可惜不支持 Python3 ……我一直奇怪应该经常用到的功能怎么在 Django 中就这么麻烦。找了一圈感觉貌似 SqlAlchemy 不错，然而 Django 换 ORM 很麻烦，项目做了一半又不能换 Flask 。最后只能用 Django 内建序列化然后自己手动过滤解决，就是代码丑了点。pathbox 25pathbox 2017-03-20 13:54:07 +08:00 via Androidlz 面的是 Python 后端Yc1992 26Yc1992 2017-03-20 13:54:39 +08:00楼主透露下拿到的几个 offer 都有多少呗，说个区间也行呀。rapospectre 27rapospectreOP 2017-03-20 13:54:49 +08:00@iloveyou 就是招聘网站上的薪资差不多哈，具体不便透露。rieuse 28rieuse 2017-03-20 13:55:03 +08:00 via Android看完了，必须点个赞！有帮助rapospectre 29rapospectreOP 2017-03-20 13:55:21 +08:00@guoer 谢谢夸奖rapospectre 30rapospectreOP 2017-03-20 13:55:50 +08:00@byebyejude 道友好rapospectre 31rapospectreOP 2017-03-20 13:56:48 +08:00@zhihhh 哈哈哈哈，我是这只绿狗的米弟rapospectre 32rapospectreOP 2017-03-20 13:57:34 +08:00@WangYanjie 是的，其实把这一套说明白面试官就会很满意了rapospectre 33rapospectreOP 2017-03-20 13:57:48 +08:00@Amayadream 谢谢啦rapospectre 34rapospectreOP 2017-03-20 13:58:15 +08:00@HLT 谢谢祝福！！rapospectre 35rapospectreOP 2017-03-20 13:58:48 +08:00@cxyfreedom 之后还会继续写，谢谢支持！rapospectre 36rapospectreOP 2017-03-20 13:59:26 +08:00@iloveyou 拉钩 boss 指聘以及自己去官网投rapospectre 37rapospectreOP 2017-03-20 13:59:47 +08:00@welkinzh 客气啦jppxhz01 38jppxhz01 2017-03-20 14:00:41 +08:00学长好～rapospectre 39rapospectreOP 2017-03-20 14:00:53 +08:00@lxy 我也很诧异，所以自己写了一套，你需要 py3 支持是嘛？ 好的，最近我更新一下，做好 @ 你哈。fancy20 40fancy20 2017-03-20 14:07:48 +08:00斐波那契数列那个估计期望你能用矩阵快速幂，时间复杂度是 O(logn)iamzhuyi 41iamzhuyi 2017-03-20 14:09:48 +08:00不错 收藏了ansheng 42ansheng 2017-03-20 14:14:34 +08:00被露珠面过AdamChrist 43AdamChrist 2017-03-20 14:19:21 +08:00工作好几年了..楼主说的一些问题我好像都不懂…好惭愧…例如 http 里面具体是怎么样的流程…楼主平时有用到这些知识?imink 44imink 2017-03-20 14:22:53 +08:00和楼主经历差不多，也是本来校招的时候，错过了，然后创业（不过我就创业 3 个月，老板不靠谱，就做不下去了，但是自己积累了技术积淀，而且 leetcode 刷题总体上没断）。开始认真找工作的时候就很尴尬了，对于我这去年九月份毕业的人来说，只能硬着头皮投社招，或者一些校招的补招。恭喜楼主找到工作！我也继续加油！imink 45imink 2017-03-20 14:23:33 +08:00好奇楼主为什么没有投递 bat 大厂的社招？robinlovemaggie 46robinlovemaggie 2017-03-20 14:24:55 +08:00想到当年高考一考定终身，再看现在的社会招聘一面二面…… N 面，还是一样的”理论+答题实践“，我们永远都是那个必须能给出正确答案的人，不知为何心生一种隐隐的悲哀……starryin 47starryin 2017-03-20 14:30:12 +08:00果壳还是一如既往之烂啊，当年被果壳从外地约到北京面试，连一家外企报销机票+住宿面试的机会都没等，提前跑到北京，结果约定面试时间到后面试官迟到 20 分钟，面试刚开始就被人叫去开会，然后对通知的人说给我 20 分钟我把这个人面完，结束后还告诉我回去补做一套果壳的笔试题fxxkgw 48fxxkgw 2017-03-20 14:32:33 +08:00建议 LZ 少说点记得知乎上有个大牛拿到暴雪的 offer 然后洋洋洒洒写一堆最后 offer 会收回了。。quxiangxuanqxx 49quxiangxuanqxx 2017-03-20 14:58:37 +08:00@fxxkgw 那个是真的透露太多了，基本上就差一个监控录像和自己的旁白介绍了。。。。炫耀太过了。。。misaka19000 50misaka19000 2017-03-20 15:04:17 +08:00@fxxkgw 哈哈，暴雪那哥们，也是惨rapospectre 51rapospectreOP 2017-03-20 15:23:18 +08:00@pathbox 恩恩，是哒rapospectre 52rapospectreOP 2017-03-20 15:25:20 +08:00@Yc1992 就是网站上的 15-30 呀rapospectre 53rapospectreOP 2017-03-20 15:26:08 +08:00@rieuse 谢谢支持rapospectre 54rapospectreOP 2017-03-20 15:26:36 +08:00@jppxhz01 学弟好，快到碗里来~rapospectre 55rapospectreOP 2017-03-20 15:27:40 +08:00@fancy20 这个高端了，面试的时候能写出来估计面试官会很满意的rapospectre 56rapospectreOP 2017-03-20 15:28:01 +08:00@iamzhuyi 谢谢呀rapospectre 57rapospectreOP 2017-03-20 15:28:45 +08:00@ansheng 你也加油呀~rapospectre 58rapospectreOP 2017-03-20 15:29:34 +08:00@AdamChrist 会用到，看一些框架源码的时候，需要了解底层的处理逻辑哈rapospectre 59rapospectreOP 2017-03-20 15:30:49 +08:00@imink BAT 社招 三年经验起，要么有人能内推你，要么简历造假。头条发展很迅速呀，对于我现在的发展来讲可能更合适一些rapospectre 60rapospectreOP 2017-03-20 15:31:43 +08:00@robinlovemaggie 哎，没办法，竞争压力过大时只能采取这种相对公平的方式进行角逐了repus911 61repus911 2017-03-20 15:32:18 +08:00小公司躺枪。。。发给面你的人看看去rapospectre 62rapospectreOP 2017-03-20 15:32:18 +08:00@starryin 这个确实有点坑congeec 63congeec 2017-03-20 15:33:04 +08:00 via iPhone@misaka19000 不能更惨了rapospectre 64rapospectreOP 2017-03-20 15:34:08 +08:00@fxxkgw 谢谢大兄弟提醒呀，关于新东家的面试信息你有没有发现除了那两道简单的编程题，我都只说了问题没说答案，哈哈哈。rapospectre 65rapospectreOP 2017-03-20 15:36:02 +08:00@repus911 小公司也有小公司的好啊，把握机会。你认识面我的人，厉害。johnny23 66johnny23 2017-03-20 15:39:20 +08:00 via iPhone清水河小师弟yuzhiquan 67yuzhiquan 2017-03-20 15:44:09 +08:00爆炸了，工作三年的人表示很多不会的啊dreamwar 68dreamwar 2017-03-20 15:45:38 +08:00这帖子强Antidictator 69Antidictator 2017-03-20 15:46:57 +08:00Q ：为什么来知乎？ A ：因为上班可以刷啊。artandlol 70artandlol 2017-03-20 15:47:21 +08:00 via Androidk12 就那几家 让猜猜看jz361 71jz361 2017-03-20 15:56:11 +08:00非常感谢楼主，已经收藏了a87150 72a87150 2017-03-20 15:58:13 +08:00难得的好文Michaelssss 73Michaelssss 2017-03-20 16:03:45 +08:00郫县电子竞技高中的校友好~v2orz 74v2orz 2017-03-20 16:27:59 +08:00有帮助，感谢楼主话说一年经验问这么多，我等偏远地方根本没人可用了……苦缓存失效那一块我得再深入研究一下MushishiXian 75MushishiXian 2017-03-20 16:46:43 +08:00很赞的体会分享,谢谢楼主init 76init 2017-03-20 17:24:27 +08:00楼主你好 我最近也在找工作 前一段时间一直在面试现在处于不想找工作的状态很烦，主要是不想干通讯这一行业了想回到互联网公司，悲催的是手头上的项目更多的是偏底层的，导致找工作颇为坎坷，现在都不知道怎么办了KIDJourney 77KIDJourney 2017-03-20 17:32:16 +08:00讲道理。。我刷题比你多， github 和你差不多，之前在饿厂和美团实习，独立搞服务，竞赛也有成绩，而且我今年才毕业。 但 我 连 头 条 的 面 试 资 格 都 没 有。 悲伤的故事。留个联系方式，让我们在寒冷的北京面个基。。。rapospectre 78rapospectreOP 2017-03-20 17:39:03 +08:00@johnny23 学长好~rapospectre 79rapospectreOP 2017-03-20 17:39:29 +08:00@yuzhiquan 我也是临时抱佛脚哈rapospectre 80rapospectreOP 2017-03-20 17:39:43 +08:00@dreamwar 谢谢支持rapospectre 81rapospectreOP 2017-03-20 17:40:09 +08:00@Antidictator 哈哈，那在头条不也可以刷2owe 822owe 2017-03-20 17:54:04 +08:00赞，细节和原理并重。rapospectre 83rapospectreOP 2017-03-20 17:59:45 +08:00@artandlol 已经写了公司名了哟daozhihun 84daozhihun 2017-03-20 17:59:55 +08:00 via Android赞一个，谢谢楼主分享。顺便问下头条招 Java 么？rapospectre 85rapospectreOP 2017-03-20 18:00:06 +08:00@jz361 感谢支持rapospectre 86rapospectreOP 2017-03-20 18:00:19 +08:00@a87150 谢谢夸奖~rapospectre 87rapospectreOP 2017-03-20 18:01:15 +08:00@Michaelssss 道友好rapospectre 88rapospectreOP 2017-03-20 18:01:58 +08:00@v2orz 面试都不是让你造火箭这种类型嘛，啥都要问，我也很方rapospectre 89rapospectreOP 2017-03-20 18:02:16 +08:00@MushishiXian 谢谢支持stanfordwang 90stanfordwang 2017-03-20 18:03:04 +08:00 via Android谢谢分享rapospectre 91rapospectreOP 2017-03-20 18:03:15 +08:00@init 偏底层试试 C++ 的职位？ 我也不是很了解哈，建议你看看我推荐的书和一些知识，找工作还是挺有帮助的rapospectre 92rapospectreOP 2017-03-20 18:04:28 +08:00@KIDJourney 这么厉害！我可以帮你内推啊，投简历这事还得看运气，好啊，我微信就是 rapospectrerapospectre 93rapospectreOP 2017-03-20 18:04:44 +08:00@2owe 感谢支持!KIDJourney 94KIDJourney 2017-03-20 18:07:33 +08:00@rapospectre 内推了很多次了，每次都是 hr 把我简历刷了。。。。服辣Antidictator 95Antidictator 2017-03-20 18:13:44 +08:00 via Android@rapospectre 头条我只刷开发者Allianzcortex 96Allianzcortex 2017-03-20 18:26:58 +08:00 via iPhone很厉害啊:-Da87150 97a87150 2017-03-20 18:32:22 +08:00@rapospectre 发现一个问题，斐波那契数列 打错成 费那波数列jesson 98jesson 2017-03-20 19:46:01 +08:00好多系统设计题啊？难道创业公司或者 Python 的都喜欢问这些？楼主平时是怎么准备这类题目的？onyourroad 99onyourroad 2017-03-20 19:50:37 +08:00985 不是白给的啊。rapospectre 100rapospectreOP 2017-03-20 19:53:40 +08:00@daozhihun 招，不过进来后应该是要写 Python 或者 golang ，头条面试不考语言本身的，你看我面试的时候一点 Python 知识都没考1 21❮ ❯万维广告联盟V2EX专享😍对象存储cos硬核福利，官方放价1元/年！ 新老用户多重好礼万维广告关于 · 帮助文档 · API · FAQ · 我们的愿景 · 广告投放 · 感谢 · 实用小工具 · 4641 人在线 最高记录 5497 · Select Language创意工作者们的社区World is powered by solitudeVERSION: 3.9.8.5 · 46ms · UTC 02:20 · PVG 10:20 · LAX 18:20 · JFK 21:20Developed with CodeLauncher♥ Do have faith in what you’re doing.","categories":[{"name":"python","slug":"python","permalink":"http://shizhonggan.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://shizhonggan.github.io/tags/python/"},{"name":"后端","slug":"后端","permalink":"http://shizhonggan.github.io/tags/%E5%90%8E%E7%AB%AF/"}]},{"title":"Docker 部署 Django-Mysql常见错误","slug":"Django/djangodeployerror","date":"2022-01-30T03:03:04.000Z","updated":"2022-05-07T10:07:50.305Z","comments":true,"path":"2022/01/30/Django/djangodeployerror/","link":"","permalink":"http://shizhonggan.github.io/2022/01/30/Django/djangodeployerror/","excerpt":"","text":"123456 apt-get install python3-dev nginxpip3 install -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple uwsgiapt-get install mysql-server mysql-client # 连接数据库需要的环境apt-get install libmysqlclient-devpip3 install -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple mysqlclient 123456789101112docker: Error response from daemon: driver failed programming external connectivity on endpoint testcontainer (c55fc0dd481c36765fcd968118c3fbf5c7fa686cdfc625c485f963109b0f89e3): (iptables failed: iptables --wait -t nat -A DOCKER -p tcp -d 0&#x2F;0 --dport 5000 -j DNAT --to-destination 172.17.0.2:80 ! -i docker0: iptables: No chain&#x2F;target&#x2F;match by that name. (exit status 1))# Enter below command, it will clear all chains.$ sudo iptables -t filter -F$ iptables -t filter -X# Then restart Docker Service using below comamnd$ systemctl restart dockerModuleNotFoundError: No module named &#39;statsmodels&#39;pip3 install -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple statsmodels django 连接已有的MySQL数据库 操作方式方法一：采用django自由的语法进行操作参考：https://docs.djangoproject.com/zh-hans/3.0/howto/legacy-databases/ 123456789101112python manage.py inspectdb # 将mysql的数据库创建对应的模型python manage.py inspectdb &gt; models.py # 将结果保存成文件python manage.py database table_name &gt; models.py # 只输出特定数据库下某张表对应的模型 ## 例如：class Person(models.Model): id = models.IntegerField(primary_key=True) first_name = models.CharField(max_length=70) class Meta: managed = False # 默认不能进行创建、修改和删除 ，此处修改为True db_table = &#x27;CENSUS_PERSONS&#x27;python manage.py migrate 方法一会存在以下几个问题：（django=2.2，本地windows环境） 生成model.py文件时，应当在app目录下生成，否则会报错，得不到相应的模型 生成的model.py文件，是utf-16进制（或其他格式），需要转换为utf-8进制，否则无法识别文件，pycharm右下角可以看到文件进制并修改 数据库的表存在依赖关系，别名重复等情况。在指定特定表生成模型，注意也要将其他表也生成下来，同时别名重复需要加related_name，可以仔细阅读报错信息进行相应操作 多个数据库之前不容易操作，需要配置多数据库 多数据库识别，虽然setting配置了多数据库，但是还是要进行路由操作才能识别，否则只能识别default数据库 方法二： 第三方库pymysql，优点： 免去多数据库的路由配置 直接用mysql语句","categories":[{"name":"Django","slug":"Django","permalink":"http://shizhonggan.github.io/categories/Django/"}],"tags":[{"name":"Django","slug":"Django","permalink":"http://shizhonggan.github.io/tags/Django/"},{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/tags/Docker/"},{"name":"Mysql","slug":"Mysql","permalink":"http://shizhonggan.github.io/tags/Mysql/"}]},{"title":"Ansible学习笔记--roles","slug":"Ansible/roles","date":"2021-12-29T02:24:04.000Z","updated":"2022-05-07T10:07:50.298Z","comments":true,"path":"2021/12/29/Ansible/roles/","link":"","permalink":"http://shizhonggan.github.io/2021/12/29/Ansible/roles/","excerpt":"","text":"rolesansible自1.2版本引入的新特性，用于层次性、结构化地组织playbook。roles能够根据层次型结构自动装载变量文件、tasks以及handlers等。要使用roles只需要在playbook中使用include[已经废弃不用了]指令即可。简单来讲，roles就是通过分别将变量、文件、任务、模板及处理器放置于单独的目录中，并可以便捷地include它们的一种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程等场景中 复杂场景：建议使用roles，代码复用度高 变更指定主机或主机组 如命名不规范维护和传承成本大 某些功能需多个Playbook，通过includes即可实现 角色(roles)：角色集合 1234567mkdir roles/&#123;mysql,httpd,nginx,memcache&#125; -pv tree rolesroles/ mysql/ httpd/ nginx/ memcached/ 基于ansible roles 安装 nginx123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# 环境准备，清除已安装的nginx和用户组ansible internal -m shell -a &#x27;yum -y remove nginx&#x27; -bansible internal -m shell -a &#x27;rpm -q nginx&#x27;ansible internal -m shell -a &#x27;getent passwd nginx&#x27;ansible internal -m shell -a &#x27;getent group nginx&#x27; ansible internal -m user -a &#x27;name=nginx state=absent&#x27; -b# 开始cd ansible/ # 根目录cd roles/nginx # 项目文件夹[ec2-user@master ansible]$ tree.├── nginx_role.yml # 调用文件└── roles ├── httpd ├── memcached ├── mysql └── nginx ├── tasks # 在该文件下创建多个任务 │ ├── group.yml │ ├── main.yml # 入口文件 │ ├── restart.yml │ ├── start.yml │ ├── template.yml │ ├── user.yml │ └── yum.yml └── templates # 创建配置文件的j2模板 └── nginx.conf.j2mkdir tasks templates # 创建两个常用文件夹cd tasksvi main.yml # 入口- include: group.yml- include: user.yml- include: yum.yml- include: template.yml- include: start.ymlvi group.yml- name: create group group: name=nginx gid=80vi user.yml- name: create user user: name=nginx uid=80 group=nginx system=yes shell=/sbin/nologinvi yum.yml- name: install package yum: name=nginxvi template.yml- name: copy conf template: src=nginx.conf.j2 dest=/etc/nginx/nginx.confvi start.yml- name: start service service: name=nginx state=started enabled=yescd ../../../vi nginx_role.yml---- hosts: internal remote_user: ec2-user become: yes roles: - role: nginxansible-playbook -C nginx_role.yml # 检查再执行rpm -qa nginx # 查看系统是否有这个安装包ansible internal -m shell -a &#x27;ss -ntlp&#x27; # 可查看到80端口ansible internal -m shell -a &#x27;ps aux|grep nginx&#x27; # 查看进程 ``` ## roles目录结构可以互相调用,roles目录结构,每个角色，以特定的层级目录结构进行组织 playbook.yml 调用角色roles/ project/ (角色名称) tasks/ files/ vars/ templates/ handlers/ default/ 不常用 meta/ 不常用 1## Roles各目录作用 /roles/project/ :项目名称,有以下子目录 files/ ：存放由copy或script模块等调用的文件 templates/：template模块查找所需要模板文件的目录 tasks/：定义task,role的基本元素，至少应该包含一个名为main.yml的文件； 其它的文件需要在此文件中通过include进行包含 handlers/：至少应该包含一个名为main.yml的文件； 其它的文件需要在此文件中通过include进行包含 vars/：定义变量，至少应该包含一个名为main.yml的文件； 其它的文件需要在此文件中通过include进行包含 meta/：定义当前角色的特殊设定及其依赖关系,至少应该包含一个名为main.yml的文件， 其它文件需在此文件中通过include进行包含 default/：设定默认变量时使用此目录中的main.yml文件 1roles&#x2F;appname 目录结构 tasks目录：至少应该包含一个名为main.yml的文件，其定义了此角色的任务列表； 此文件可以使用include包含其它的位于此目录中的task文件 files目录：存放由copy或script等模块调用的文件； templates目录：template模块会自动在此目录中寻找Jinja2模板文件 handlers目录：此目录中应当包含一个main.yml文件，用于定义此角色用到的各handler； 在handler中使用include包含的其它的handler文件也应该位于此目录中； vars目录：应当包含一个main.yml文件，用于定义此角色用到的变量； meta目录：应当包含一个main.yml文件，用于定义此角色的特殊设定及其依赖关系； ansible1.3及其以后的版本才支持； default目录：为当前角色设定默认变量时使用此目录；应当包含一个main.yml文件 1234567&#96;&#96;&#96;roles&#x2F;example_role&#x2F;files&#x2F; 所有文件，都将可存放在这里roles&#x2F;example_role&#x2F;templates&#x2F; 所有模板都存放在这里roles&#x2F;example_role&#x2F;tasks&#x2F;main.yml： 主函数，包括在其中的所有任务将被执行roles&#x2F;example_role&#x2F;handlers&#x2F;main.yml：所有包括其中的 handlers 将被执行roles&#x2F;example_role&#x2F;vars&#x2F;main.yml： 所有包括在其中的变量将在roles中生效roles&#x2F;example_role&#x2F;meta&#x2F;main.yml： roles所有依赖将被正常登入 创建role创建role的步骤 创建以roles命名的目录 在roles目录中分别创建以各角色名称命名的目录，如webservers等 在每个角色命名的目录中分别创建files、handlers、meta、tasks、templates和vars目录；用不到的目录可以创建为空目录，也可以不创建 在playbook文件中，调用各角色 实验: 创建httpd角色1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992001&gt; 创建roles目录 mkdir roles&#x2F;&#123;httpd,mysql,redis&#125;&#x2F;tasks -pv mkdir roles&#x2F;httpd&#x2F;&#123;handlers,files&#125;查看目录结构tree roles&#x2F; roles&#x2F; ├── httpd │ ├── files │ ├── handlers │ └── tasks ├── mysql │ └── tasks └── redis └── tasks2&gt; 创建目标文件 cd roles&#x2F;httpd&#x2F;tasks&#x2F; touch install.yml config.yml service.yml3&gt; vim install.yml - name: install httpd package yum: name&#x3D;httpd vim config.yml - name: config file copy: src&#x3D;httpd.conf dest&#x3D;&#x2F;etc&#x2F;httpd&#x2F;conf&#x2F; backup&#x3D;yes vim service.yml - name: start service service: name&#x3D;httpd state&#x3D;started enabled&#x3D;yes 4&gt; 创建main.yml主控文件,调用以上单独的yml文件, main.yml定义了谁先执行谁后执行的顺序 vim main.yml - include: install.yml - include: config.yml - include: service.yml 5&gt; 准备httpd.conf文件,放到httpd单独的文件目录下 cp &#x2F;app&#x2F;ansible&#x2F;flies&#x2F;httpd.conf ..&#x2F;files&#x2F; 6&gt; 创建一个网页 vim flies&#x2F;index.html &lt;h1&gt; welcome to weixiaodong home &lt;\\h1&gt;7&gt; 创建网页的yml文件 vim tasks&#x2F;index.yml - name: index.html copy: src&#x3D;index.html dest&#x3D;&#x2F;var&#x2F;www&#x2F;html 8&gt; 将网页的yml文件写进mian.yml文件中 vim mian.yml - include: install.yml - include: config.yml - include: index.yml - include: service.yml9&gt; 在handlers目录下创建handler文件mian.yml vim handlers&#x2F;main.yml - name: restart service httpd service: name&#x3D;httpd state&#x3D;restarted10&gt; 创建文件调用httpd角色 cd &#x2F;app&#x2F;ansidle&#x2F;roles vim role_httpd.yml --- # httpd role - hosts: appsrvs remote_user: root roles: #调用角色 - role: httpd 11&gt; 查看目录结构 tree . httpd ├── files │ ├── httpd.conf │ └── index.html ├── handlers │ └── main.yml └── tasks ├── config.yml ├── index.yml ├── install.yml ├── main.yml └── service.yml12&gt; ansible-playbook role_httpd.yml针对大型项目使用Roles进行编排roles目录结构：playbook.ymlroles&#x2F; project&#x2F; tasks&#x2F; files&#x2F; vars&#x2F; templates&#x2F; handlers&#x2F; default&#x2F; # 不经常用 meta&#x2F; # 不经常用示例：nginx-role.ymlroles&#x2F;└── nginx ├── files │ └── main.yml ├── tasks │ ├── groupadd.yml │ ├── install.yml │ ├── main.yml │ ├── restart.yml │ └── useradd.yml └── vars └── main.yml示例roles的示例如下所示：site.ymlwebservers.ymldbservers.ymlroles&#x2F; common&#x2F; files&#x2F; templates&#x2F; tasks&#x2F; handlers&#x2F; vars&#x2F; meta&#x2F; webservers&#x2F; files&#x2F; templates&#x2F; tasks&#x2F; handlers&#x2F; vars&#x2F; meta&#x2F;实验： 创建一个nginx角色建立nginx角色在多台主机上来部署nginx需要安装 创建账号1&gt; 创建nginx角色目录 cd &#x2F;app&#x2F;ansible&#x2F;role mkdir nginx&#123;tesks,templates,hanslers&#125; -pv2&gt; 创建任务目录 cd tasks&#x2F; touch insatll.yml config.yml service.yml file.yml user.yml 创建main.yml文件定义任务执行顺序 vim main.yml - include: user.yml - include: insatll.yml - include: config.yml - include: file.yml - include: service.yml 3&gt; 准备配置文件(centos7、8) ll &#x2F;app&#x2F;ansible&#x2F;role&#x2F;nginx&#x2F;templates&#x2F; nginx7.conf.j2 nginx8.conf.j24&gt; 定义任务 vim tasks&#x2F;install.yml - name: install yum: name&#x3D;nginx vim tasks&#x2F;config.yml - name: config file template: src&#x3D;nginx7.conf.j2 dest&#x3D;&#x2F;etc&#x2F;nginx&#x2F;nginx.conf when: ansible_distribution_major_version&#x3D;&#x3D;&quot;7&quot; notify: restrat - name: config file template: src&#x3D;nginx8.conf.j2 dest&#x3D;&#x2F;etc&#x2F;nginx&#x2F;nginx.conf when: ansible_distribution_major_version&#x3D;&#x3D;&quot;8&quot; notify: restrat vim tasks&#x2F;file.yml 跨角色调用file.yum文件,实现文件复用 - name: index.html copy: src&#x3D;roles&#x2F;httpd&#x2F;files&#x2F;index.html dest&#x3D;&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F; vim tasks&#x2F;service.yml - nmae: start service service: name&#x3D;nginx state&#x3D;started enabled&#x3D;yes vim handlers&#x2F;main.yml - name: restrat service: name&#x3D;nginx state&#x3D;restarted vim roles&#x2F;role_nginix.yml --- #test rcle - hosts: appsrvs roles: - role: nginx 5&gt; 测试安装 ansible-playbook role_nginx.yml playbook调用角色调用角色方法1： 1234567- hosts: websrvs remote_user: root roles: - mysql - memcached - nginx 调用角色方法2：传递变量给角色 1234567- hosts: remote_user: roles: - mysql - &#123; role: nginx, username: nginx &#125; #不同的角色调用不同的变量 键role用于指定角色名称 后续的k/v用于传递变量给角色 调用角色方法3：还可基于条件测试实现角色调用 12roles: - &#123; role: nginx, username: nginx, when: ansible_distribution_major_version &#x3D;&#x3D; &#39;7&#39; &#125; 通过roles传递变量当给一个主机应用角色的时候可以传递变量，然后在角色内使用这些变量 示例： 1234- hosts: webservers roles: - common - &#123; role: foo_app_instance, dir: &#39;&#x2F;web&#x2F;htdocs&#x2F;a.com&#39;, port: 8080 &#125; 向roles传递参数而在playbook中，可以这样使用roles: 12345---- hosts: webservers roles: - common - webservers 也可以向roles传递参数,示例： 123456---- hosts: webservers roles: - common - &#123; role: foo_app_instance, dir: &#39;&#x2F;opt&#x2F;a&#39;, port: 5000 &#125; - &#123; role: foo_app_instance, dir: &#39;&#x2F;opt&#x2F;b&#39;, port: 5001 &#125; 条件式地使用roles示例： 1234---- hosts: webservers roles: - &#123; role: some_role, when: &quot;ansible_os_family == &#x27;RedHat&#x27;&quot; &#125; Roles条件及变量等案例12345678910# When条件 roles: - &#123;role: nginx, when: &quot;ansible_distribution_major_version == &#x27;7&#x27; &quot; ,username: nginx &#125;# 变量调用- hosts: zabbix-proxy sudo: yes roles: - &#123; role: geerlingguy.php-mysql &#125; - &#123; role: dj-wasabi.zabbix-proxy, zabbix_server_host: 192.168.37.167 &#125; 完整的roles架构12345678910111213141516171819202122232425262728293031# nginx-role.yml 顶层任务调用yml文件---- hosts: testweb remote_user: root roles: - role: nginx - role: httpd 可执行多个rolecat roles/nginx/tasks/main.yml---- include: groupadd.yml- include: useradd.yml- include: install.yml- include: restart.yml- include: filecp.yml# roles/nginx/tasks/groupadd.yml---- name: add group nginx user: name=nginx state=presentcat roles/nginx/tasks/filecp.yml---- name: file copy copy: src=tom.conf dest=/tmp/tom.conf#以下文件格式类似：useradd.yml,install.yml,restart.ymlls roles/nginx/files/tom.conf roles playbook tags使用123456789101112ansible-playbook --tags=&quot;nginx,httpd,mysql&quot; nginx-role.yml #对标签进行挑选执行# nginx-role.yml---- hosts: testweb remote_user: root roles: - &#123; role: nginx ,tags: [ &#x27;nginx&#x27;, &#x27;web&#x27; ] ,when: ansible_distribution_major_version == &quot;6“ &#125; - &#123; role: httpd ,tags: [ &#x27;httpd&#x27;, &#x27;web&#x27; ] &#125; - &#123; role: mysql ,tags: [ &#x27;mysql&#x27;, &#x27;db&#x27; ] &#125; - &#123; role: marridb ,tags: [ &#x27;mysql&#x27;, &#x27;db&#x27; ] &#125; - &#123; role: php &#125; 实验: 创建角色memcachedmemcacched 当做缓存用,会在内存中开启一块空间充当缓存 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950cat /etc/sysconfig/memcached PORT=&quot;11211&quot; USER=&quot;memcached&quot; MAXCONN=&quot;1024&quot; CACHESIZE=&quot;64&quot; # 缓存空间默认64M OPTIONS=&quot;&quot;1&gt; 创建对用目录 cd /app/ansible mkdir roles/memcached/&#123;tasks,templates&#125; -pv 2&gt; 拷贝memcached配置文件模板 cp /etc/sysconfig/memcached templates/memcached.j2 vim templates/memcached.j2 CACHESIZE=&quot;&#123;&#123;ansible_memtotal_mb//4&#125;&#125;&quot; #物理内存的1/4用做缓存 3&gt; 创建对应yml文件,并做相应配置 cd tasks/ touch install.yml config.yml service.yml 创建main.yml文件定义任务执行顺序 vim main.yml - include: install.yml - include: config.yml - include: service.yml vim install.yml - name: install yum: name=memcached vim config.yml - name: config file template: src=memcached.j2 dets=/etc/sysconfig/memcached vim service.yml - name: service service: name=memcached state=started enabled=yes4&gt; 创建调用角色文件 cd /app/ansible/roles/ vim role_memcached.yml --- - hosts: appsrvs roles: - role: memcached5&gt; 安装 ansible-playbook role_memcached.yml memcached端口号11211 其它功能 委任（指定某一台机器做某一个task） delegate_to local_action (专指针对ansible命令执行的机器做的变更操作) 交互提示 prompt *暂停（java） wait_for Debug debug: msg=”This always executes.” Include Template 多值合并 Template 动态变量配置 Ansible Roles 委任 delegate_to 交互提示 prompt 暂停 wait_for Debug debug: msg=”This always executes.” Include Template 多值合并 Template 动态变量配置 推荐资料123456http:&#x2F;&#x2F;galaxy.ansible.comhttps:&#x2F;&#x2F;galaxy.ansible.com&#x2F;explore#&#x2F;http:&#x2F;&#x2F;github.com&#x2F;http:&#x2F;&#x2F;ansible.com.cn&#x2F;https:&#x2F;&#x2F;github.com&#x2F;ansible&#x2F;ansiblehttps:&#x2F;&#x2F;github.com&#x2F;ansible&#x2F;ansible-examples 实验: 实现二进制安装mysql的卸载12345678910111213141516171819202122cat remove_mysql.yml ---# install mariadb server - hosts: appsrvs:!192.168.38.108 remote_user: root tasks: - name: stop service shell: /etc/init.d/mysqld stop - name: delete user user: name=mysql state=absent remove=yes - name: delete file: path=&#123;&#123;item&#125;&#125; state=absent with_items: - /usr/local/mysql - /usr/local/mariadb-10.2.27-linux-x86_64 - /etc/init.d/mysqld - /etc/profile.d/mysql.sh - /etc/my.cnf - /data/mysqlansible-playbook remove_mysql.yml","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://shizhonggan.github.io/categories/Ansible/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://shizhonggan.github.io/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"容器数据磁盘被写满处理","slug":"Docker/dockerclean","date":"2021-12-24T05:54:04.000Z","updated":"2022-05-07T10:07:50.307Z","comments":true,"path":"2021/12/24/Docker/dockerclean/","link":"","permalink":"http://shizhonggan.github.io/2021/12/24/Docker/dockerclean/","excerpt":"","text":"参考挺不错的博客： https://tencentcloudcontainerteam.github.io/tke-handbook/best-practice/kubernetes-best-practice-handle-disk-full.html 简略步骤1234d /var/lib/docker/containers$ du -sh * # 找到比较大的目录$ cd dda02c9a7491fa797ab730c1568ba06cba74cecd4e4a82e9d90d00fa11de743c$ cat /dev/null &gt; dda02c9a7491fa797ab730c1568ba06cba74cecd4e4a82e9d90d00fa11de743c-json.log.9 # 删除log文件","categories":[{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/tags/Docker/"}]},{"title":"Linux 常用命令","slug":"Linux/command","date":"2021-11-29T02:24:04.000Z","updated":"2022-05-07T10:07:50.314Z","comments":true,"path":"2021/11/29/Linux/command/","link":"","permalink":"http://shizhonggan.github.io/2021/11/29/Linux/command/","excerpt":"","text":"wc -l 统计行数1ansible-doc -l |wc -l # 统计ansible模块个数 cat 追加方式 修改网卡文件123456cat &gt; ifcfg-eth1 # 当没有对应网卡的配置文件时DEVICE=eth1BOOTPROTO=dhcp service network restart service NetworkManager restart # 重启","categories":[{"name":"Linux","slug":"Linux","permalink":"http://shizhonggan.github.io/categories/Linux/"}],"tags":[{"name":"Shell commands","slug":"Shell-commands","permalink":"http://shizhonggan.github.io/tags/Shell-commands/"}]},{"title":"Nvidia 2022年会议","slug":"Note/Nvidia_2022","date":"2021-11-29T02:24:04.000Z","updated":"2022-05-07T10:07:50.315Z","comments":true,"path":"2021/11/29/Note/Nvidia_2022/","link":"","permalink":"http://shizhonggan.github.io/2021/11/29/Note/Nvidia_2022/","excerpt":"","text":"","categories":[{"name":"Nvidia","slug":"Nvidia","permalink":"http://shizhonggan.github.io/categories/Nvidia/"}],"tags":[{"name":"Nvidia","slug":"Nvidia","permalink":"http://shizhonggan.github.io/tags/Nvidia/"}]},{"title":"Beats信息采集","slug":"ELK/Beats","date":"2021-11-01T02:03:04.000Z","updated":"2022-05-07T10:07:50.308Z","comments":true,"path":"2021/11/01/ELK/Beats/","link":"","permalink":"http://shizhonggan.github.io/2021/11/01/ELK/Beats/","excerpt":"","text":"介绍官网 FilebeatFilebeat是一个轻量级的日志采集器 当面对成百上千、甚至成千上万的服务器、虚拟机和容器生成的日志时，采用ssh十分麻烦。而Filebeat 可以提供一种轻量型方法，用于转发和汇总日志与文件，让简单的事情不再繁杂。 启动Filebeat后， 打开Logs UI, 直接在Kibana中观看对您的文件进行tail操作的过程。通过搜索栏按照服务、应用程序、主机、数据中心或者其他条件筛选，以跟踪您的全部汇总日志中的异常行为。 安装1234curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.15.1-linux-x86_64.tar.gztar xzvf filebeat-7.15.1-linux-x86_64.tar.gzmv filebeat-7.15.1-linux-x86_64 /filebeat 运行1234567891011121314cd filebeatvim gszbeat.yml # 创建配置文件#### 内容如下filebeat.inputs: # filebeat input输入- type: stdin # 标准输入 enabled: true # 启用标准输入setup.template.settings: index.number_of_shards: 3 # 指定下载数output.console: # 控制台输出 pretty: true # 启用美化功能 enable: true#####################################./filebeat -e -c gszbeat.yml # 启动chmod go-w /home/ec2-user/test/filebeat/gszbeat.yml # 若报错执行此命令 然后我们在控制台输入hello，就能看到我们会有一个json的输出，是通过读取到我们控制台的内容后输出的。 读取文件1234567891011121314151617vim gszbeat-log.yml # 创建配置文件#### 内容如下filebeat.inputs:- type: log enabled: true paths: - /home/ec2-user/test/filebeattest/*.logsetup.template.settings: index.number_of_shards: 2output.console: pretty: true enable: true#####################################./filebeat -e -c gszbeat.yml # 启动cd /home/ec2-user/test/filebeattest/ # 执行如下操作，会立刻读取更新的内容，并输出到控制台echo &quot;ganshizhong&quot; &gt;&gt; a.log 自定义字段123456789101112131415161718192021vim gszbeat-log.yml # 创建配置文件#### 内容如下filebeat.inputs:- type: log enabled: true paths: - /home/ec2-user/test/filebeattest/*.log tags:[&quot;web&quot;,&quot;test&quot;] #添加自定义tag，便于后续的处理 fields: # 添加自定义字段 from: test-web fields_under_root: true #true为添加到根节点，false为添加到子节点中setup.template.settings: index.number_of_shards: 2output.console: pretty: true enable: true#####################################./filebeat -e -c gszbeat.yml # 启动cd /home/ec2-user/test/filebeattest/ # 执行如下操作，会立刻读取更新的内容，并输出到控制台echo &quot;ganshizhong&quot; &gt;&gt; a.log 输出到Elasticsearch1234567891011121314151617181920vim gszbeat-log.yml # 创建配置文件#### 内容如下filebeat.inputs:- type: log enabled: true paths: - /home/ec2-user/test/filebeattest/*.log tags:[&quot;web&quot;,&quot;test&quot;] #添加自定义tag，便于后续的处理 fields: # 添加自定义字段 from: test-web fields_under_root: true #true为添加到根节点，false为添加到子节点中setup.template.settings: index.number_of_shards: 2output.elasticsearch: hosts: [&quot;127.0.0.1:9200&quot;]#####################################./filebeat -e -c gszbeat.yml # 启动cd /home/ec2-user/test/filebeattest/ # 执行如下操作，会立刻读取更新的内容，并输出到控制台echo &quot;ganshizhong&quot; &gt;&gt; a.log Filebeat工作原理Filebeat主要由下面几个组件组成： harvester、prospector 、input harvester 负责读取单个文件的内容 harvester逐行读取每个文件（一行一行读取），并把这些内容发送到输出 每个文件启动一个harvester，并且harvester负责打开和关闭这些文件，这就意味着harvester运行时文件描述符保持着打开的状态。 在harvester正在读取文件内容的时候，文件被删除或者重命名了，那么Filebeat就会续读这个文件，这就会造成一个问题，就是只要负责这个文件的harvester没用关闭，那么磁盘空间就不会被释放，默认情况下，Filebeat保存问价你打开直到close_inactive到达 prospector prospector负责管理harvester并找到所有要读取的文件来源 如果输入类型为日志，则查找器将查找路径匹配的所有文件，并为每个文件启动一个harvester Filebeat目前支持两种prospector类型：log和stdin Filebeat如何保持文件的状态 Filebeat保存每个文件的状态并经常将状态刷新到磁盘上的注册文件中 该状态用于记住harvester正在读取的最后偏移量，并确保发送所有日志行。 如果输出（例如ElasticSearch或Logstash）无法访问，Filebeat会跟踪最后发送的行，并在输出再次可以用时继续读取文件。 在Filebeat运行时，每个prospector内存中也会保存的文件状态信息，当重新启动Filebat时，将使用注册文件的数量来重建文件状态，Filebeat将每个harvester在从保存的最后偏移量继续读取 文件状态记录在data/registry文件中 input 一个input负责管理harvester，并找到所有要读取的源 如果input类型是log，则input查找驱动器上与已定义的glob路径匹配的所有文件，并为每个文件启动一个harvester 每个input都在自己的Go例程中运行 下面的例子配置Filebeat从所有匹配指定的glob模式的文件中读取行 12345filebeat.inputs:- type: log paths: - /var/log/*.log - /var/path2/*.log 启动命令123456./filebeat -e -c mogublog-es.yml./filebeat -e -c mogublog-es.yml -d &quot;publish&quot;## 参数说明-e: 输出到标准输出，默认输出到syslog和logs下-c：指定配置文件-d：输出debug信息 Module 日志数据处理前面要想实现日志数据的读取以及处理都是自己手动配置的，其实，在Filebeat中，有大量的Module，可以简化我们的配置，直接就可以使用，如下： 12345678910111213./filebeat modules list## 显示如下：Enabled:nginxDisabled:...kafkakibanamongodbmysqlredis... 12./filebeat modules enable nginx # 启动./filebeat modules disable nginx # 禁用 12345678910111213141516171819202122232425## 启用nginx后，进行配置cd modules.d/grep -Ev &#x27;*#|^$&#x27; nginx.yml## 输出，然后修改如下：- module: nginx access: enabled: true var.paths: [&quot;/home/ec2-user/program/gitlab/logs/nginx/*.log&quot;] error: enabled: true var.paths: [&quot;/home/ec2-user/program/gitlab/logs/nginx/*.log&quot;] ingress_controller: enabled: falsecd ..vi nginx.yml # 新建配置文件，内容如下#filebeat.inputs:setup.template.settings: index.number_of_shards: 3output.elasticsearch: hosts: [&quot;127.0.0.1:9200&quot;]filebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: false s Metricbeat用于从系统和服务搜集指标。Matricbeat能够以一种轻量型的方式，输送各种系统和服务统计数据，从CPU到内存，从Redis到Nginx，不一而足。 定期收集操作系统或应用程序的指标数据 存储到Elasticsearch中，进行实施的分析 Metricbeat组成Metricbeat有2部分组成，一部分是Module，另一个部分为Metricset Module 收集的对象：如 MySQL、Redis、Nginx、操作系统等 Metricset 收集指标的集合：如 cpu、memory，network等 安装123456789curl -L -O https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-7.15.1-linux-arm64.tar.gztar xzvf filebeat-7.15.1-linux-x86_64.tar.gzwget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -sudo apt-get install apt-transport-httpsecho &quot;deb https://artifacts.elastic.co/packages/7.x/apt stable main&quot; | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list # 貌似不用修改x,也可自动下载7.15.1，默认最新的sudo systemctl enable metricbeat# If your system does not use systemd then run:# sudo update-rc.d metricbeat defaults 95 10 配置123456789101112131415161718192021grep -Ev &quot;^*#|^$&quot; metricbeat.yml### 返回metricbeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: falsesetup.template.settings: index.number_of_shards: 1 index.codec: best_compressionsetup.kibana:output.elasticsearch: # hosts: [&quot;localhost:9200&quot;]# 修改 hosts: [&quot;119.255.249.177:9200&quot;]processors: - add_host_metadata: ~ - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~sed -i &#x27;s#hosts: \\[&quot;localhost:9200&quot;\\]#hosts: [&quot;119.255.249.177:9200&quot;]#&#x27; metricbeat.yml./metricbeat -e Nginx Module123456789101112131415161718192021222324#开启Nginx Module，#在nginx中，需要开启状态查询，才能查询到指标数据。#重新编译nginx./configure --prefix=/usr/local/nginx --with-http_stub_status_modulemakemake install./nginx -V #查询版本信息nginx version: nginx/1.11.6built by gcc 4.4.7 20120313 (Red Hat 4.4.7-23) (GCC)configure arguments: --prefix=/usr/local/nginx --with-http_stub_status_module#配置nginxvim nginx.conflocation /nginx-status &#123; stub_status on; access_log off;&#125;# 重启nginx./nginx -s reload### 测试： 119.255.x.x/nginx-status 结果说明： Active connections：正在处理的活动连接数 server accepts handled requests 第一个 server 表示Nginx启动到现在共处理了9个连接 第二个 accepts 表示Nginx启动到现在共成功创建 9 次握手 第三个 handled requests 表示总共处理了 21 次请求 请求丢失数 = 握手数 - 连接数 ，可以看出目前为止没有丢失请求 Reading: 0 Writing: 1 Waiting: 1 Reading：Nginx 读取到客户端的 Header 信息数 Writing：Nginx 返回给客户端 Header 信息数 Waiting：Nginx 已经处理完正在等候下一次请求指令的驻留链接（开启keep-alive的情况下，这个值等于 Active - (Reading+Writing)） 1234567891011121314151617181920212223242526配置nginx module#启用redis module./metricbeat modules enable nginx#修改redis module配置vim modules.d/nginx.yml#### 然后修改下面的信息# Module: nginx# Docs: https://www.elastic.co/guide/en/beats/metricbeat/6.5/metricbeat-modulenginx.html - module: nginx#metricsets:# - stubstatus period: 10s# Nginx hosts hosts: [&quot;http://127.0.0.1&quot;]# Path to server status. Default server-status server_status_path: &quot;nginx-status&quot;#username: &quot;user&quot;#password: &quot;secret&quot;修改完成后，启动nginx#启动./metricbeat -e 更多Module使用参见官方文档：https://www.elastic.co/guide/en/beats/metricbeat/current/metricbeat-modules.html https://www.cnblogs.com/cjsblog/p/9495024.html","categories":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/tags/ELK/"},{"name":"Nginx","slug":"Nginx","permalink":"http://shizhonggan.github.io/tags/Nginx/"}]},{"title":"Nginx日志分析系统","slug":"ELK/NgixLog","date":"2021-11-01T02:03:04.000Z","updated":"2022-05-07T10:07:50.310Z","comments":true,"path":"2021/11/01/ELK/NgixLog/","link":"","permalink":"http://shizhonggan.github.io/2021/11/01/ELK/NgixLog/","excerpt":"","text":"项目需求Nginx是一款非常优秀的web服务器，往往nginx服务会作为项目的访问入口，那么，nginx的性能保障就变得非常重要了，如果nginx的运行出现了问题就会对项目有较大的影响，所以，我们需要对nginx的运行有监控措施，实时掌握nginx的运行情况，那就需要收集nginx的运行指标和分析nginx的运行日志了。 业务流程 说明： 通过Beats采集Nginx的指标数据和日志数据 Beats采集到数据后发送到Elasticsearch中 Kibana读取数据进行分析 用户通过Kibana进行查看分析报表 Nginx部署安装123456789101112## 官网下载地址 http://nginx.org/download/## ubuntu 安装sudo apt install nginx # 80端口, 此处不要与gitlab的nginx冲突tail -f /var/log/nginx/access.logtail -f gitlab/logs/nginx/gitlab_access.log## centos 源码安装tar -xvf nginx-xxxx.tar.gzyum -y install pcre-devel zlib-devel./configuremake installcd /usr/local/nginx/sbin/./nginx centos安装Nginx参考 filebeat安装与使用参 1234567891011121314151617vim best-nginx.yml # 创建配置文件#### 内容如下filebeat.inputs:- type: log enabled: true paths: - /home/ec2-user/program/gitlab/logs/nginx/*.log tags:[&quot;nginx&quot;] fields_under_root: falsesetup.template.settings: index.number_of_shards: 3output.elasticsearch: hosts: [&quot;127.0.0.1:9200&quot;]#####################################./filebeat -e -c gszbeat.yml # 启动echo &quot;ganshizhong&quot; &gt;&gt; a.log","categories":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/tags/ELK/"},{"name":"Nginx","slug":"Nginx","permalink":"http://shizhonggan.github.io/tags/Nginx/"}]},{"title":"Kibana数据可视化","slug":"ELK/Kibana","date":"2021-11-01T02:03:04.000Z","updated":"2022-05-07T10:07:50.309Z","comments":true,"path":"2021/11/01/ELK/Kibana/","link":"","permalink":"http://shizhonggan.github.io/2021/11/01/ELK/Kibana/","excerpt":"","text":"介绍Kibana 是一款开源的数据分析和可视化平台，它是 Elastic Stack 成员之一，设计用于和 Elasticsearch 协作。您可以使用 Kibana 对 Elasticsearch 索引中的数据进行搜索、查看、交互操作。您可以很方便的利用图表、表格及地图对数据进行多元化的分析和呈现。 官网：https://www.elastic.co/cn/kibana 安装1234567891011# Create a file called kibana.repo in the /etc/yum.repos.d/ directory for RedHat based distributionssudo echo &quot;[kibana-7.15.1]name=Kibana repository for 7.15.1 packagesbaseurl=https://artifacts.elastic.co/packages/7.15.1/yumgpgcheck=1gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearchenabled=1autorefresh=1type=rpm-md&quot; &gt; /etc/yum.repos.d/kibana.reposudo yum install kibana 123456docker network create elasticdocker pull docker.elastic.co/elasticsearch/elasticsearch:7.15.2docker run --name es01-test --net elastic -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; docker.elastic.co/elasticsearch/elasticsearch:7.15.2docker pull docker.elastic.co/kibana/kibana:7.15.1docker run --name kib01-test --net elastic -p 5601:5601 -e &quot;ELASTICSEARCH_HOSTS=http://119.255.249.177:9200&quot; docker.elastic.co/kibana/kibana:7.15.1 1234567891011121314# 解压tar -zxvf kibana-7.15.1-linux-x86_64.tar.gz# 重命名mv kibana-7.15.1-linux-x86_64 kibana## 然后在进入kibana目录，找到config文件夹下的kibana.yml进行配置的修改grep -Ev &quot;^#|^$&quot; kibana.yml## 输出如下server.host: &quot;0.0.0.0&quot; #对外暴露服务的地址elasticsearch.hosts: [&quot;http://192.168.0.8:9200&quot;,&quot;http://192.168.0.13:9200&quot;] #配置Elasticsearchsed -i &#x27;s#\\#server.host: &quot;localhost&quot;#server.host: &quot;0.0.0.0&quot;#&#x27; kibana.ymlsed -i &#x27;s#\\#elasticsearch.hosts: \\[&quot;http://localhost:9200&quot;\\]#elasticsearch.hosts: \\[&quot;http://192.168.0.8:9200&quot;,&quot;http://192.168.0.13:9200&quot;\\]#&#x27; kibana.yml Metricbeat 仪表盘现在将Metricbeat的数据展示在Kibana中，首先需要修改我们的MetricBeat配置 1234567#修改metricbeat配置setup.kibana: host: &quot;192.168.40.133:5601&quot; #安装仪表盘到Kibana【需要确保Kibana在正常运行，这个过程可能会有些耗时】./metricbeat setup --dashboards./metricbeat -e 然后到kibana页面下，找到刚刚安装的仪表盘**[Metricbeat System] Host overview ECS**, 得到如下界面 Nginx 指标仪表盘首先打开nginx状态；然后到kibana页面下，找到仪表盘**[Metricbeat Nginx] Overview**, Nginx 日志仪表盘我们可以和刚刚Metricbeat的仪表盘一样，也可以将filebeat收集的日志记录，推送到Kibana中 首先我们需要修改filebeat的 kibana-nginx.yml配置文件 12345678910filebeat.inputs:setup.template.settings: index.number_of_shards: 1output.elasticsearch: hosts: [&quot;119.255.249.177:9200&quot;]filebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: falsesetup.kibana: host: &quot;119.254.169.244:5601&quot; 然后按照仪表盘 1./filebeat -c kibana-nginx.yml setup 安装成功显示如下： 然后我们启动filebeat即可 1./filebeat -e -c kibana-nginx.yml 自定义图标Visualize 里设置，然后可以在Dashboard里导入。 开发者工具","categories":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/tags/ELK/"},{"name":"Nginx","slug":"Nginx","permalink":"http://shizhonggan.github.io/tags/Nginx/"}]},{"title":"Logstash","slug":"ELK/Logstash","date":"2021-11-01T02:03:04.000Z","updated":"2022-05-07T10:07:50.310Z","comments":true,"path":"2021/11/01/ELK/Logstash/","link":"","permalink":"http://shizhonggan.github.io/2021/11/01/ELK/Logstash/","excerpt":"","text":"介绍Logstash是一个开源的服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到最喜欢的存储库中（我们的存储库当然是ElasticSearch） Logstash充当数据处理的需求，当我们的数据需要处理的时候，会将它发送到Logstash进行处理，否则直接送到ElasticSearch中 安装部署12345678#检查jdk环境，要求jdk1.8+java -version#解压安装包tar -xvf logstash-7.9.1.tar.gz#第一个logstash示例bin/logstash -e &#x27;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123;&#125; &#125;&#x27; 其实原来的logstash的作用，就是为了做数据的采集，但是因为logstash的速度比较慢，所以后面使用beats来代替了Logstash，当我们使用上面的命令进行启动的时候，就可以发现了，因为logstash使用java写的，首先需要启动虚拟机，完成启动后，输入hello即可得到输出结果，如下图所示： 配置详解Logstash配置有三个部分，如下： 123456789input &#123; #输入stdin &#123; ... &#125; #标准输入&#125;filter &#123; #过滤，对数据进行分割、截取等处理...&#125;output &#123; #输出stdout &#123; ... &#125; #标准输出&#125; 输入 采集各种样式、大小和来源的数据，数据往往以各种各样的形式，或分散或集中地存在于很多系统中。 Logstash 支持各种输入选择 ，可以在同一时间从众多常用来源捕捉事件。能够以连续的流式传输方式，轻松地从您的日志、指标、Web 应用、数据存储以及各种 AWS 服务采集数据。 过滤 实时解析和转换数据 数据从源传输到存储库的过程中，Logstash 过滤器能够解析各个事件，识别已命名的字段以构建结构，并将它们转换成通用格式，以便更轻松、更快速地分析和实现商业价值。 输出 Logstash 提供众多输出选择，您可以将数据发送到您要指定的地方，并且能够灵活地解锁众多下游用例。 读取自定义日志Filebeat读取了nginx的日志，如果是自定义结构的日志，就需要读取处理后才能使用，所以，这个时候就需要使用Logstash了，因为Logstash有着强大的处理能力，可以应对各种各样的场景。 日志结构12019-03-15 21:21:21|ERROR|1 读取数据出错|参数：id=1002 可以看到，日志中的内容是使用“|”进行分割的，使用，我们在处理的时候，也需要对数据做分割处理。 编写配置文件 12345678910111213141516171819202122vim test-pipeline.conf## 然后添加如下内容input &#123; file &#123; path =&gt; &quot;/home/ec2-user/test/testlog/app.log&quot; ## 不能用相对路径 start_position =&gt; &quot;beginning&quot; &#125;&#125;filter &#123; mutate &#123; split =&gt; &#123;&quot;message&quot;=&gt;&quot;|&quot;&#125; &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125;&#125;# 启动./bin/logstash -f mogublog-pipeline.conf## 然后我们就插入我们的测试数据echo &quot;2019-03-15 21:21:21|ERROR|读取数据出错|参数：id=1002&quot; &gt;&gt; app.log 然后我们就可以看到logstash就会捕获到刚刚我们插入的数据，同时我们的数据也被分割了 结果如下： 输出到Elasticsearch修改配置文件，将我们的日志记录输出到ElasticSearch中 12345678910111213141516input &#123; file &#123; path =&gt; &quot;/soft/beats/logs/app.log&quot; start_position =&gt; &quot;beginning&quot; &#125;&#125;filter &#123; mutate &#123; split =&gt; &#123;&quot;message&quot;=&gt;&quot;|&quot;&#125; &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;119.255.249.177:9200&quot;] &#125;&#125;","categories":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/tags/ELK/"},{"name":"Logstash","slug":"Logstash","permalink":"http://shizhonggan.github.io/tags/Logstash/"}]},{"title":"Elastic Stack(01)--Elasticsearch安装","slug":"ELK/ElasticSearch01","date":"2021-10-11T02:03:04.000Z","updated":"2022-05-07T10:07:50.308Z","comments":true,"path":"2021/10/11/ELK/ElasticSearch01/","link":"","permalink":"http://shizhonggan.github.io/2021/10/11/ELK/ElasticSearch01/","excerpt":"","text":"Elastic Stack 简介如果你没有听说过Elastic Stack，那你一定听说过ELK，实际上ELK是三款软件的简称，分别是Elasticsearch、 Logstash、Kibana组成，在发展的过程中，又有新成员Beats的加入，所以就形成了Elastic Stack。所以说，ELK是旧的称呼，Elastic Stack是新的名字。 Beats 采集一切数据 Filebeat 日志文件 Metricbeat 服务指标 Winlogbeat Win事件日志 Packetbeat 网络流量 健康检查 elasticsearch 核心存储和检索引擎。 基于java，是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。 logstash 高吞吐量数据处理引擎 基于java，是一个开源的用于收集,分析和存储日志的工具。 kibana 数据可视化 基于nodejs，也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的Web 界面，可以汇总、分析和搜索重要数据日志。 Beats是elastic公司开源的一款采集系统监控数据的代理agent，是在被监控服务器上以客户端形式运行的数据收集器的统称，可以直接把数据发送给Elasticsearch或者通过Logstash发送给Elasticsearch，然后进行后续的数据分析活动。Beats由如下组成: Packetbeat：是一个网络数据包分析器，用于监控、收集网络流量信息，Packetbeat嗅探服务器之间的流量，解析应用层协议，并关联到消息的处理，其支 持ICMP (v4 and v6)、DNS、HTTP、Mysql、PostgreSQL、Redis、MongoDB、Memcache等协议； Filebeat：用于监控、收集服务器日志文件，其已取代 logstash forwarder； Metricbeat：可定期获取外部系统的监控指标信息，其可以监控、收集 Apache、HAProxy、MongoDB MySQL、Nginx、PostgreSQL、Redis、System、Zookeeper等服务； Winlogbeat:用于监控、手机Windows系统的日志信息 Beats和Logstash其实都可以进行数据的采集，但是目前主流的是使用Beats进行数据采集，然后使用 Logstash进行数据的分割处理等，早期没有Beats的时候，使用的就是Logstash进行数据的采集。 Elasticsearch 安装centos7 云主机先打开9200端口 68端口 单机版安装1234567891011121314151617181920212223242526272829# 添加新用户useradd elsearch# 创建一个目录，存放下载的软件mkdir /itcastcd /itcastmkdir es # 将软件安装到这个目录chown elsearch:elsearch /itcast/ -R# 进入，然后通过xftp工具，将刚刚下载的文件拖动到该目录下cd /soft# 解压缩tar -zxvf elasticsearch-7.15.0-linux-x86_64.tar.gz -C esvi config/elasticsearch.yml network.host: 192.168.0.1 #0.0.0.0#在Elasticsearch中如果，network.host不是localhost或者127.0.0.1的话，就会认为是生产环境，会对环境的要求比较高，我们的测试环境不一定能够满足，一般情况下需要修改2处配置，如下：vi config/jvm.options -Xms256m # 内存128M，根据机器修改 -Xmx256mvi /etc/sysctl.conf # root用户操作 vm.max_map_count=655360sysctl -p # root用户下，使生效su - elsearch # 切换用户cd bin./elasticsearch 或 ./elasticsearch -d #后台系统 123456789101112131415# 报错一：bootstrap check failure [1] of [2]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535]## 解决方法vi /etc/security/limits.conf # root用户修改，且用户退出后重新登录生效 * soft nofile 65536 * hard nofile 131072 * soft nproc 2048 * hard nproc 65535# 报错二：bootstrap check failure [2] of [2]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configuredERROR: Elasticsearch did not exit normally - check the logs at /itcast/es/elasticsearch-7.15.0/logs/elasticsearch.log## 解决方法vi config/elasticsearch.yml # 取消注释，并保留一个节点 node.name: node-1 cluster.initial_master_nodes: [&quot;node-1] 更多错误参见： https://gitee.com/moxi159753/LearningNotes/tree/master/ElasticStack/1_ElasticSearch%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%AE%89%E8%A3%85 成功安装后访问如下地址，如图所示： ElasticSearchHead可视化工具由于ES官方没有给ES提供可视化管理工具，仅仅是提供了后台的服务，elasticsearch-head是一个为ES开发的一个页面客户端工具，其源码托管于Github，地址为 传送门 head提供了以下安装方式 源码安装，通过npm run start启动（不推荐） 通过docker安装（推荐） 通过chrome插件安装（推荐, 需翻墙） 通过ES的plugin方式安装（不推荐） Dcoker方式安装1234567891011121314151617## 在另外一台安装docker的云主机部署的，随意哪里都行#拉取镜像docker pull mobz/elasticsearch-head:5#创建容器docker create --name elasticsearch-head -p 9100:9100 mobz/elasticsearch-head:5docker network create --subnet=10.0.30.0/24 --opt com.docker.network.driver.mtu=1450 docker-gszdocker create --name elasticsearch-head --net docker-gsz --ip 10.0.30.11 -p 9100:9100 mobz/elasticsearch-head:5#启动容器docker start elasticsearch-head## 注意： 由于前后端分离开发，所以会存在跨域问题，需要在服务端做CORS的配置，如下：vim elasticsearch.ymlhttp.cors.enabled: true http.cors.allow-origin: &quot;*&quot; 成功安装并连接如下图所示： 通过Chrome插件安装打开chrome的应用商店，即可安装（该方法不需要修改配置文件） https://chrome.google.com/webstore/detail/elasticsearch-head/ffmkiejjmecolpfloofpjologoblkegm 报错问题解决1. 使用 Elasticsearch Head 查看“数据浏览”时，右侧不出数据，使用浏览器F12查看后，发现 406 Not Acceptable 错误12345678cd _site/vi vendor.js ##修改两处将 6886行 contentType: &quot;application/x-www-form-urlencoded&quot; 修改为 contentType: &quot;application/json;charset=UTF-8&quot;然后再将 7574行 var inspectData = s.contentType === &quot;application/x-www-form-urlencoded&quot; &amp;&amp; 修改为 var inspectData = s.contentType === &quot;application/json;charset=UTF-8&quot; &amp;&amp;## 具体步骤，由于容器中安装不了编辑器sed -i &#x27;s#var inspectData = s.contentType === &quot;application/x-www-form-urlencoded&quot;#var inspectData = s.contentType === &quot;application/json;charset=UTF-8&quot;#&#x27; vendor.jssed -i &#x27;s#contentType: &quot;application/x-www-form-urlencoded&quot;#contentType: &quot;application/json;charset=UTF-8&quot;#&#x27; vendor.js","categories":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/tags/ELK/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://shizhonggan.github.io/tags/Elasticsearch/"}]},{"title":"Elastic Stack(02)--Elasticsearch基本概念","slug":"ELK/ElasticSearch02","date":"2021-10-11T02:03:04.000Z","updated":"2022-05-07T10:07:50.309Z","comments":true,"path":"2021/10/11/ELK/ElasticSearch02/","link":"","permalink":"http://shizhonggan.github.io/2021/10/11/ELK/ElasticSearch02/","excerpt":"","text":"数据格式Elasticsearch 是面向文档型数据库，一条数据在这里就是一个文档。采用倒排索引。 Elasticsearch Index(索引) Type(类型，没这个概念了) Documents(文档) Fields(字段) MySQL DataBase(数据库) Table(表) Row(行) Column(列) 索引 索引（index）是Elasticsearch对逻辑数据的逻辑存储，所以它可以分为更小的部分。 可以把索引看成关系型数据库的表，索引的结构是为快速有效的全文索引准备的，特别是它不存储原始值。 Elasticsearch可以把索引存放在一台机器或者分散在多台服务器上，每个索引有一或多个分片（shard），每个分片可以有多个副本（replica）。 文档 存储在Elasticsearch中的主要实体叫文档（document）。用关系型数据库来类比的话，一个文档相当于数据库表中的一行记录。 Elasticsearch和MongoDB中的文档类似，都可以有不同的结构，但Elasticsearch的文档中，相同字段必须有相同类型。 文档由多个字段组成，每个字段可能多次出现在一个文档里，这样的字段叫多值字段（multivalued）。 每个字段的类型，可以是文本、数值、日期等。字段类型也可以是复杂类型，一个字段包含其他子文档或者数组。 映射 所有文档写进索引之前都会先进行分析，如何将输入的文本分割为词条、哪些词条又会被过滤，这种行为叫做 映射（mapping）。一般由用户自己定义规则。 文档类型 在Elasticsearch中，一个索引对象可以存储很多不同用途的对象。例如，一个博客应用程序可以保存文章和评 论。 每个文档可以有不同的结构。 不同的文档类型不能为相同的属性设置不同的类型。例如，在同一索引中的所有文档类型中，一个叫title的字段必须具有相同的类型。 RESTful API 在Elasticsearch中，提供了功能丰富的RESTful API的操作，包括基本的CRUD、创建索引、删除索引等操作。 创建非结构化索引在Lucene中，创建索引是需要定义字段名称以及字段的类型的，在Elasticsearch中提供了非结构化的索引，就是不需要创建索引结构，即可写入数据到索引中，实际上在Elasticsearch底层会进行结构化操作，此操作对用户是透明的。 索引操作 DSL搜索： Elasticsearch提供丰富且灵活的查询语言叫做DSL查询(Query DSL),它允许你构建更加复杂、强大的查询。 DSL(Domain Specific Language特定领域语言)以JSON请求体的形式出现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// 1. 创建索引,PUT有幂等性，所以不可以用POSTPUT http://127.0.0.0.1:9200/shopping// BODY raw json 请求参数可以设置如下，不设置默认 &#123;&quot;settings&quot;: &#123;&quot;index&quot;: &#123;&quot;number_of_shards&quot;: &quot;2&quot;,&quot;number_of_replicas&quot;: &quot;0&quot;&#125;&#125;&#125; // shards分片数 replicas副本数 &#123; # 返回结果 &quot;acknowledged&quot;: true, &quot;shards_acknowledged&quot;: true, &quot;index&quot;: &quot;shopping&quot; &#125;// 2. 获取索引信息GET http://127.0.0.0.1:9200/shopping DELETE http://127.0.0.0.1:9200/shopping # 删除索引GET http://127.0.0.1:9200/_cat/indices?v#_cat 表示查看的意思， indices 表示索引，所以整体含义就是查看当前 ES服务器中的所有索引，就好像 MySQL 中的 show tables// health status index uuid pri rep docs.count docs.deleted store.size pri.store.size green open .geoip_databases F2VtNo9NTMS-B18XqvCcaA 1 0 41 52 51mb 51mb green open test 0gFXqM0qQJ61S5e2iTk45A 2 0 0 0 416b 416b yellow open shopping m_9bLGjIToCSCYF1VhHSng 1 1 0 0 208b 208b// 3. 创建文档 POST POST http://127.0.0.0.1:9200/shopping/_doc # 会随机生成ID,所以不能用PUTPUT/POST http://127.0.0.0.1:9200/shopping/_doc/1001 # 设置ID, 该方式可以用PUTPUT/POST http://127.0.0.0.1:9200/shopping/_create/1001 # create功能同上 &#123;&quot;title&quot;:&quot;小米手机&quot;,&quot;category&quot;:&quot;小米&quot;,&quot;images&quot;:&quot;http://www.gulixueyuan.com/xm.jpg&quot;,&quot;price&quot;:3999.00&#125; &#123;//返回结果 &quot;_index&quot;: &quot;shopping&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;PoxKeHwBU1XQD5ffmuP9&quot;, &quot;_version&quot;: 1, &quot;result&quot;: &quot;created&quot;, &quot;_shards&quot;: &#123; &quot;total&quot;: 2, &quot;successful&quot;: 1, &quot;failed&quot;: 0 &#125;, &quot;_seq_no&quot;: 0, &quot;_primary_term&quot;: 1&#125;// 4. 文档查询 主键查询 全量查询GET http://127.0.0.0.1:9200/shopping/_doc/1002GET http://127.0.0.0.1:9200/shopping/_search #获取全部// 5. 修改PUT/POST http://127.0.0.0.1:9200/shopping/_doc/1001 # 全量覆盖, &#123;&quot;title&quot;:&quot;小米手机&quot;,&quot;images&quot;:&quot;http://www.gulixueyuan.com/xm.jpg&quot;,&quot;price&quot;:4999.00&#125;POST http://127.0.0.0.1:9200/shopping/_update/1001 # 局部更新 &#123;&quot;doc&quot;:&#123;&quot;title&quot;: &quot;华为手机&quot;&#125;&#125;// 6. 条件查询 分页查询 查询排序GET http://127.0.0.0.1:9200/shopping/_search?q=category:小米 # 这种方式不好，q是query GET http://127.0.0.0.1:9200/shopping/_search &#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;category&quot;:&quot;小米&quot;&#125;&#125;&#125; # 条件查询 &#123;&quot;query&quot;:&#123;&quot;match_all&quot;:&#123;&#125;&#125;&#125; # 全量查询 &#123;&quot;query&quot;:&#123;&quot;match_all&quot;:&#123;&#125;&#125;, &quot;from&quot;: 0, // 从第0开始，(页码-1)*每页数据条数 &quot;size&quot;: 2, // 每页显示2条 &quot;_source&quot;: [&quot;titile&quot;], // 指定显示的内容 &quot;sort&quot;:&#123; &quot;price&quot;:&#123; &quot;order&quot;: &quot;desc&quot; // 降序 &#125; &#125; &#125; # 全量查询 1234567891011// 7. 多条件查询 范围查询 过滤查询GET http://127.0.0.0.1:9200/shopping/_search # must 多个条件同时满足 &#123;&quot;query&quot;:&#123;&quot;bool&quot;:&#123;&quot;must&quot;:[&#123;&quot;match&quot;:&#123;&quot;category&quot;:&quot;小米&quot;&#125;&#125;, &#123;&quot;match&quot;:&#123;&quot;proce&quot;:&quot;1999.00&quot;&#125;&#125;], &quot;filter&quot;:&#123;&quot;range&quot;:&#123;&quot;price&quot;:&#123;&quot;gt&quot;:5000&#125;&#125;&#125;, &#125;&#125;&#125; #should 或 &#123;&quot;query&quot;:&#123;&quot;bool&quot;:&#123;&quot;should&quot;:[&#123;&quot;match&quot;:&#123;&quot;category&quot;:&quot;小米&quot;&#125;&#125;, &#123;&quot;match&quot;:&#123;&quot;category&quot;:&quot;华为&quot;&#125;&#125;], &#125;&#125;&#125; bool 查询可以用来合并多个条件查询结果的布尔逻辑，它包含一下操作符： must :: 多个查询条件的完全匹配,相当于 and 。 must_not :: 多个查询条件的相反匹配，相当于 not 。 should :: 至少有一个查询条件匹配, 相当于 or 。 gt : 大于 gte:: 大于等于 lt : 小于 lte: 小于等于 查询和过滤的对比 一条过滤语句会询问每个文档的字段值是否包含着特定值。 查询语句会询问每个文档的字段值与特定值的匹配程度如何。 一条查询语句会计算每个文档与查询语句的相关性，会给出一个相关性评分 _score，并且 按照相关性对匹 配到的文档进行排序。 这种评分方式非常适用于一个没有完全配置结果的全文本搜索。 一个简单的文档列表，快速匹配运算并存入内存是十分方便的， 每个文档仅需要1个字节。这些缓存的过滤结果集与后续请求的结合使用是非常高效的。 查询语句不仅要查找相匹配的文档，还需要计算每个文档的相关性，所以一般来说查询语句要比 过滤语句更耗时，并且查询结果也不可缓存。 123456// 8. 全文检索 完全匹配 高亮查询GET http://127.0.0.0.1:9200/shopping/_search &#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;category&quot;:&quot;小华&quot;&#125;&#125;&#125; # 以此查询会同时返回“小米”和“华为” &#123;&quot;query&quot;:&#123;&quot;match_phrase&quot;:&#123;&quot;category&quot;:&quot;小米&quot;&#125;&#125;, &quot;highlight&quot;:&#123;&quot;fields&quot;:&#123;&quot;category&quot;:&#123;&#125;&#125;&#125; # 对 &quot;category&quot;字段高亮显示 &#125; # 完全匹配 1234567891011121314151617181920// 9. 聚合查询GET http://127.0.0.0.1:9200/shopping/_search &#123;&quot;aggs&quot;:&#123; //聚合操作 &quot;price_group&quot;:&#123; //名称，随便起 &quot;terms&quot;:&#123; //分组 &quot;field&quot;:&quot;price&quot; //分组字段 &#125; &#125; &#125;, &quot;size&quot;:0 //原始数据不显示 &#125; &#123;&quot;aggs&quot;:&#123; //聚合操作 &quot;price_avg&quot;:&#123; //名称，随便起 &quot;avg&quot;:&#123; //平均值 &quot;field&quot;:&quot;price&quot; //分组字段 &#125; &#125; &#125;, &quot;size&quot;:0 //原始数据不显示 &#125; 有了索引库，等于有了数据库中的 database。接下来就需要建索引库(index)中的映射了，类似于数据库(database)中的表结构(table)。创建数据库表需要设置字段名称，类型，长度，约束等；索引库也一样，需要知道这个类型下有哪些字段，每个字段有哪些约束信息，这就叫做映射(mapping)。 123456789101112131415161718192021// 9. 映射关系PUT http://127.0.0.1:9200/user //先创建索引 userPUT http://127.0.0.1:9200/user/_mapping //创建映射&#123; &quot;properties&quot;:&#123; &quot;name&quot;:&#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: true &#125;, &quot;sex&quot;:&#123; &quot;type&quot;: &quot;keyword&quot;, //查询的时候必须完全匹配 &quot;index&quot;: true &#125;, &quot;tel&quot;:&#123; &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: false //不能被索引查询 &#125; &#125;&#125;PUT http://127.0.0.1:9200/user/_create/1001&#123;&quot;name&quot;:&quot;小米&quot;,&quot;sex&quot;:&quot;男的&quot;,&quot;tel&quot;:&quot;1111&quot;&#125; tring类型在ElasticSearch 旧版本中使用较多，从ElasticSearch 5.x开始不再支持string，由text和 keyword类型替代。 text 类型，当一个字段是要被全文搜索的，比如Email内容、产品描述，应该使用text类型。设置text类型 以后，字段内容会被分析，在生成倒排索引以前，字符串会被分析器分成一个一个词项。text类型的字段 不用于排序，很少用于聚合。 keyword类型适用于索引结构化的字段，比如email地址、主机名、状态码和标签。如果字段需要进行过 滤(比如查找已发布博客中status属性为published的文章)、排序、聚合。keyword类型的字段只能通过精 确值搜索到。 增加数据后，进行数据查询，可以发现对sex必须完全匹配才能查询，对于tel字段不能被查询 12// 10. 判断文档是否存在HEAD http://127.0.0.1:9200/user/1009 //返回状态码 12345678910111213141516// 11. 批量操作POST http://127.0.0.1:9200/user/_mget //_mget 批量获取数据 &#123;&quot;ids&quot;:[&quot;1001&quot;,&quot;1003&quot;]&#125;post http://127.0.0.1:9200/user/_bulk //_bulk 批零插入、修改、删除操作 &#123;action: &#123;metada&#125;&#125; //create delete &#123;request body&#125; ... &#123;&quot;create&quot;:&#123;&quot;_index&quot;:&quot;user&quot;,&quot;_id&quot;:2001&#125;&#125; &#123;&quot;name&quot;:&quot;name1&quot;,&quot;tel&quot;:&quot;1111&quot;,&quot;sex&quot;: &quot;男&quot;&#125; &#123;&quot;create&quot;:&#123;&quot;_index&quot;:&quot;user&quot;,&quot;_id&quot;:2002&#125;&#125; &#123;&quot;name&quot;:&quot;name2&quot;,&quot;tel&quot;:&quot;1111&quot;,&quot;sex&quot;: &quot;男&quot;&#125; &#123;&quot;create&quot;:&#123;&quot;_index&quot;:&quot;user&quot;,&quot;_id&quot;:2003&#125;&#125; &#123;&quot;name&quot;:&quot;name3&quot;,&quot;tel&quot;:&quot;1111&quot;,&quot;sex&quot;: &quot;男&quot;&#125; &#123;&quot;delete&quot;:&#123;&quot;_index&quot;:&quot;user&quot;,&quot;_id&quot;:2001&#125;&#125; &#123;&quot;delete&quot;:&#123;&quot;_index&quot;:&quot;user&quot;,&quot;_id&quot;:2002&#125;&#125; &#123;&quot;delete&quot;:&#123;&quot;_index&quot;:&quot;user&quot;,&quot;_id&quot;:2003&#125;&#125; _bulk批量处理报错The bulk request must be terminated by a newline，在JSON数据最后回车换行，代码中可以，主要是最后一行要换行 其他操作就类似了。一次请求多少性能最高？ 整个批量请求需要被加载到接受我们请求节点的内存里，所以请求越大，给其它请求可用的内存就越小。有一 个最佳的bulk请求大小。超过这个大小，性能不再提升而且可能降低。 最佳大小，当然并不是一个固定的数字。它完全取决于你的硬件、你文档的大小和复杂度以及索引和搜索的负 载。 幸运的是，这个最佳点(sweetspot)还是容易找到的：试着批量索引标准的文档，随着大小的增长，当性能开始 降低，说明你每个批次的大小太大了。开始的数量可以在1000~5000个文档之间，如果你的文档非常大，可以使用较小的批次。 通常着眼于你请求批次的物理大小是非常有用的。一千个1kB的文档和一千个1MB的文档大不相同。一个好的 批次最好保持在5-15MB大小间。 12345678// 12. 结构化查询&#123; &quot;query&quot;:&#123; &quot;term&quot;&#123; // 精确匹配；terms多个条件匹配 range范围查询结构gt等使用； exits文章中是否包含; match 全文本查询，结构化非结构化数据都可以查； bool，参照上面条件查询 ... &#125; &#125;&#125; 分词分词就是指将一个文本转化成一系列单词的过程，也叫文本分析，在Elasticsearch中称之为Analysis。 指定分词器进行分词 1234567891011121314151617181920212223POST /_analyze &#123;//输入参数 &quot;analyzer&quot;:&quot;standard&quot;, &quot;text&quot;:&quot;hello world&quot; &#125; &#123;//返回结果 &quot;tokens&quot;: [ &#123; &quot;token&quot;: &quot;hello&quot;, &quot;start_offset&quot;: 0, &quot;end_offset&quot;: 5, &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot;: 0 &#125;, &#123; &quot;token&quot;: &quot;world&quot;, &quot;start_offset&quot;: 6, &quot;end_offset&quot;: 11, &quot;type&quot;: &quot;&lt;ALPHANUM&gt;&quot;, &quot;position&quot;: 1 &#125; ] &#125; 中文分词难点 中文分词的难点在于，在汉语中没有明显的词汇分界点，如在英语中，空格可以作为分隔符，如果分隔不正确就会造成歧义。如： 我/爱/炒肉丝 我/爱/炒/肉丝 常用中文分词器，IK、jieba、THULAC等，推荐使用IK分词器。 IK Analyzer是一个开源的，基于java语言开发的轻量级的中文分词工具包。从2006年12月推出1.0版开始，IKAnalyzer已经推出了3个大版本。最初，它是以开源项目Luence为应用主体的，结合词典分词和文法分析算法的中文分词组件。新版本的IK Analyzer 3.0则发展为面向Java的公用分词组件，独立于Lucene项目，同时提供了对Lucene的默认优化实现。 采用了特有的“正向迭代最细粒度切分算法“，具有80万字/秒的高速处理能力 采用了多子处理器分析模式，支持：英文字母（IP地址、Email、URL）、数字（日期，常用中文数量词，罗马数字，科学计数法），中文词汇（姓名、地名处理）等分词处理。 优化的词典存储，更小的内存占用。 IK分词器 Elasticsearch插件地址：https://github.com/medcl/elasticsearch-analysis-ik 安装分词器首先下载到最新的ik分词器：下载地址:https://github.com/medcl/elasticsearch-analysis-ik/releases/tag/v7.9.1 注意版本匹配，否则报错：[ERROR][o.e.b.ElasticsearchUncaughtExceptionHandler] [node-1] uncaught exception in thread [main]org.elasticsearch.bootstrap.StartupException: java.lang.IllegalArgumentException: Plugin [analysis-ik] was built for Elasticsearch version 7.9.1 but version 7.15.0 is running 下载完成后，使用xftp工具，拷贝到服务器上 1234567#安装方法：将下载到的 es/plugins/ik 目录下mkdir es/plugins/ik#解压unzip elasticsearch-analysis-ik-7.9.1.zip#重启ps aux |grep elasticsearch # 查询进程先kill./bin/elasticsearch -d 123456789#### 报错：[ERROR][o.e.b.ElasticsearchUncaughtExceptionHandler] [node-1] fatal error in thread [elasticsearch[node-1][system_read][T#2]], exitingjava.lang.OutOfMemoryError: Java heap spacefatal error in thread [elasticsearch[node-1][system_read][T#2]], exitingjava.lang.OutOfMemoryError: Java heap space# 解决方法vi config/jvm.options -Xms128m # 改大 256m -Xmx128m 1234567891011121314151617181920212223242526272829303132333435363738394041424344POST http://127.0.0.1:9200/_analyze &#123;//输入参数 &quot;analyzer&quot;:&quot;ik_max_word&quot;, //默认分词器 standard ,返回&#123;&quot;我&quot;,&quot;是&quot;,&quot;中&quot;,&quot;国&quot;,&quot;人&quot;&#125;，效果不好 &quot;text&quot;:&quot;我是中国人&quot; &#125; &#123;//返回结果 &quot;tokens&quot;: [ &#123; &quot;token&quot;: &quot;我&quot;, &quot;start_offset&quot;: 0, &quot;end_offset&quot;: 1, &quot;type&quot;: &quot;CN_CHAR&quot;, &quot;position&quot;: 0 &#125;, &#123; &quot;token&quot;: &quot;是&quot;, &quot;start_offset&quot;: 1, &quot;end_offset&quot;: 2, &quot;type&quot;: &quot;CN_CHAR&quot;, &quot;position&quot;: 1 &#125;, &#123; &quot;token&quot;: &quot;中国人&quot;, &quot;start_offset&quot;: 2, &quot;end_offset&quot;: 5, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 2 &#125;, &#123; &quot;token&quot;: &quot;中国&quot;, &quot;start_offset&quot;: 2, &quot;end_offset&quot;: 4, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 3 &#125;, &#123; &quot;token&quot;: &quot;国人&quot;, &quot;start_offset&quot;: 3, &quot;end_offset&quot;: 5, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 4 &#125; ]&#125; 全文搜索全文搜索两个最重要的方面是： 相关性（Relevance） 它是评价查询与其结果间的相关程度，并根据这种相关程度对结果排名的一种能力，这 种计算方式可以是 TF/IDF 方法、地理位置邻近、模糊相似，或其他的某些算法。 分词（Analysis） 它是将文本块转换为有区别的、规范化的 token 的一个过程，目的是为了创建倒排索引以及查询倒排索引。 ES 7.4 默认不在支持指定索引类型，默认索引类型是_doc 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// 创建索引PUT http://127.0.0.1:9200/itcast?include_type_name=true&#123; &quot;settings&quot;:&#123; &quot;index&quot;:&#123; &quot;number_of_shards&quot;:&quot;1&quot;, &quot;number_of_replicas&quot;:&quot;0&quot; &#125; &#125;, &quot;mappings&quot;:&#123; &quot;person&quot;:&#123; &quot;properties&quot;:&#123; &quot;name&quot;:&#123; &quot;type&quot;:&quot;text&quot; &#125;, &quot;age&quot;:&#123; &quot;type&quot;:&quot;integer&quot; &#125;, &quot;mail&quot;:&#123; &quot;type&quot;:&quot;keyword&quot; &#125;, &quot;hobby&quot;:&#123; &quot;type&quot;:&quot;text&quot;, &quot;analyzer&quot;:&quot;ik_max_word&quot; // 指定分词器 &#125; &#125; &#125; &#125;&#125;// 插入数据POST http://127.0.0.1:9200/itcast/_bulk&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;itcast&quot;,&quot;_type&quot;:&quot;person&quot;&#125;&#125;&#123;&quot;name&quot;:&quot;张三&quot;,&quot;age&quot;: 20,&quot;mail&quot;: &quot;111@qq.com&quot;,&quot;hobby&quot;:&quot;羽毛球、乒乓球、足球&quot;&#125;&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;itcast&quot;,&quot;_type&quot;:&quot;person&quot;&#125;&#125;&#123;&quot;name&quot;:&quot;李四&quot;,&quot;age&quot;: 21,&quot;mail&quot;: &quot;222@qq.com&quot;,&quot;hobby&quot;:&quot;羽毛球、乒乓球、足球、篮球&quot;&#125;&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;itcast&quot;,&quot;_type&quot;:&quot;person&quot;&#125;&#125;&#123;&quot;name&quot;:&quot;王五&quot;,&quot;age&quot;: 22,&quot;mail&quot;: &quot;333@qq.com&quot;,&quot;hobby&quot;:&quot;羽毛球、篮球、游泳、听音乐&quot;&#125;&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;itcast&quot;,&quot;_type&quot;:&quot;person&quot;&#125;&#125;&#123;&quot;name&quot;:&quot;赵六&quot;,&quot;age&quot;: 23,&quot;mail&quot;: &quot;444@qq.com&quot;,&quot;hobby&quot;:&quot;跑步、游泳、篮球&quot;&#125;&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;itcast&quot;,&quot;_type&quot;:&quot;person&quot;&#125;&#125;&#123;&quot;name&quot;:&quot;孙七&quot;,&quot;age&quot;: 24,&quot;mail&quot;: &quot;555@qq.com&quot;,&quot;hobby&quot;:&quot;听音乐、看电影、羽毛球&quot;&#125;// 单词搜索POST http://127.0.0.1:9200/itcast/person/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&quot;音乐&quot; &#125; &#125;, &quot;highlight&quot;:&#123; &quot;fields&quot;:&#123; &quot;hobby&quot;:&#123;&#125; &#125; &#125;&#125; 过程说明： 检查字段类型 爱好 hobby 字段是一个 text 类型（ 指定了IK分词器），这意味着查询字符串本身也应该被分词。 分析查询字符串 。 将查询的字符串 “音乐” 传入IK分词器中，输出的结果是单个项 音乐。因为只有一个单词项，所以 match 查询执行的是单个底层 term 查询。 查找匹配文档 。 用 term 查询在倒排索引中查找 “音乐” 然后获取一组包含该项的文档，本例的结果是文档：3 、5 。 为每个文档评分 。 用 term 查询计算每个文档相关度评分 _score ，这是种将 词频（term frequency，即词 “音乐” 在相关文档的hobby 字段中出现的频率）和 反向文档频率（inverse document frequency，即词 “音乐” 在所有文档的hobby 字段中出现的频率），以及字段的长度（即字段越短相关度越高）相结合的计算方式。 12345678910111213141516//多次搜索POST http://127.0.0.1:9200/itcast/person/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&quot;音乐 篮球&quot; &#125; &#125;, &quot;highlight&quot;:&#123; &quot;fields&quot;:&#123; &quot;hobby&quot;:&#123; &#125; &#125; &#125;&#125; 结果返回的“或”的关系，包含了“音乐”、“篮球”的数据都已经被搜索到了。如果想搜索的是既包含“音乐”又包含“篮球”的用户，在Elasticsearch中，可以指定词之间的逻辑关系，如下: 12345678910111213141516POST http://127.0.0.1:9200/itcast/person/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&quot;音乐 篮球&quot; &quot;operator&quot;:&quot;and&quot; &#125; &#125;, &quot;highlight&quot;:&#123; &quot;fields&quot;:&#123; &quot;hobby&quot;:&#123; &#125; &#125; &#125;&#125; 前面我们测试了“OR” 和 “AND”搜索，这是两个极端，其实在实际场景中，并不会选取这2个极端，更有可能是选取这种，或者说，只需要符合一定的相似度就可以查询到数据，在Elasticsearch中也支持这样的查询，通过 minimum_should_match来指定匹配度，如：70%； 123456789101112131415161718192021222324252627282930313233343536373839404142434445&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&#123; &quot;query&quot;:&quot;游泳 羽毛球&quot;, &quot;minimum_should_match&quot;:&quot;80%&quot; &#125; &#125; &#125;, &quot;highlight&quot;: &#123; &quot;fields&quot;: &#123; &quot;hobby&quot;: &#123;&#125; &#125; &#125;&#125;#结果：省略显示&quot;hits&quot;: &#123;&quot;total&quot;: 4, #相似度为80%的情况下，查询到4条数据&quot;max_score&quot;: 1.621458,&quot;hits&quot;: [&#125;#设置40%进行测试：&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&#123; &quot;query&quot;:&quot;游泳 羽毛球&quot;, &quot;minimum_should_match&quot;:&quot;40%&quot; &#125; &#125; &#125;, &quot;highlight&quot;: &#123; &quot;fields&quot;: &#123; &quot;hobby&quot;: &#123;&#125; &#125; &#125;&#125;#结果：&quot;hits&quot;: &#123;&quot;total&quot;: 5, #相似度为40%的情况下，查询到5条数据&quot;max_score&quot;: 1.621458,&quot;hits&quot;: [&#125; 相似度应该多少合适，需要在实际的需求中进行反复测试，才可得到合理的值。 1234567891011121314151617181920212223242526272829303132// 组合搜索POST http://127.0.0.1:9200/itcast/person/_search&#123; &quot;query&quot;:&#123; &quot;bool&quot;:&#123; &quot;must&quot;:&#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&quot;篮球&quot; &#125; &#125;, &quot;must_not&quot;:&#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&quot;音乐&quot; &#125; &#125;, &quot;should&quot;:[ &#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&quot;游泳&quot; &#125; &#125; ] &#125; &#125;, &quot;highlight&quot;:&#123; &quot;fields&quot;:&#123; &quot;hobby&quot;:&#123; &#125; &#125; &#125;&#125; 评分的计算规则 bool 查询会为每个文档计算相关度评分_score ， 再将所有匹配的 must 和 should 语句的分数_score 求和，最后除以 must 和 should 语句的总数。 默认情况下，should中的内容不是必须匹配的，如果查询语句中没有must，那么就会至少匹配其中一个。当然了，也可以通过minimum_should_match参数进行控制，该值可以是数字也可以的百分比。 1234567891011121314151617181920212223242526272829303132POST http://127.0.0.1:9200/itcast/person/_search&#123; &quot;query&quot;:&#123; &quot;bool&quot;:&#123; &quot;should&quot;:[ &#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&quot;游泳&quot; &#125; &#125;, &#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&quot;篮球&quot; &#125; &#125;, &#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&quot;音乐&quot; &#125; &#125; ], &quot;minimum_should_match&quot;:2 //意思是should中的三个词，至少要满足2个。 &#125; &#125;, &quot;highlight&quot;:&#123; &quot;fields&quot;:&#123; &quot;hobby&quot;:&#123; &#125; &#125; &#125;&#125; 有些时候，我们可能需要对某些词增加权重来影响该条数据的得分。如下： 搜索关键字为“游泳篮球”，如果结果中包含了“音乐”权重为10，包含了“跑步”权重为2。 1234567891011121314151617181920212223242526272829303132333435363738394041// 加权重 搜索POST http://127.0.0.1:9200/itcast/person/_search&#123; &quot;query&quot;:&#123; &quot;bool&quot;:&#123; &quot;must&quot;:&#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&#123; &quot;query&quot;:&quot;游泳篮球&quot;, &quot;operator&quot;:&quot;and&quot; &#125; &#125; &#125;, &quot;should&quot;:[ &#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&#123; &quot;query&quot;:&quot;音乐&quot;, &quot;boost&quot;:10 &#125; &#125; &#125;, &#123; &quot;match&quot;:&#123; &quot;hobby&quot;:&#123; &quot;query&quot;:&quot;跑步&quot;, &quot;boost&quot;:2 &#125; &#125; &#125; ] &#125; &#125;, &quot;highlight&quot;:&#123; &quot;fields&quot;:&#123; &quot;hobby&quot;:&#123; &#125; &#125; &#125;&#125; ElasticSearch集群集群节点ELasticsearch的集群是由多个节点组成的，通过cluster.name设置集群名称，并且用于区分其它的集群，每个节点通过node.name指定节点的名称。 在Elasticsearch中，节点的类型主要有4种： master节点 配置文件中node.master属性为true(默认为true)，就有资格被选为master节点。master节点用于控制整个集群的操作。比如创建或删除索引，管理其它非master节点等。 data节点 配置文件中node.data属性为true(默认为true)，就有资格被设置成data节点。data节点主要用于执行数据相关的操作。比如文档的CRUD。 客户端节点 配置文件中node.master属性和node.data属性均为false。 该节点不能作为master节点，也不能作为data节点。 可以作为客户端节点，用于响应用户的请求，把请求转发到其他节点 部落节点 当一个节点配置tribe.*的时候，它是一个特殊的客户端，它可以连接多个集群，在所有连接的集群上执行 搜索和其他操作。 搭建集群123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#启动3个虚拟机，分别在3台虚拟机上部署安装Elasticsearchmkdir /itcast/es-cluster## 此处将单节点的安装文件拷贝过来，并删除数据文件cp es/elasticsearch-7.15.0/ ../es-cluster/ -Rcd /itcast/es-cluster/elasticsearch-7.15.0/datarm -rf *cd /itcast/es-cluster/elasticsearch-7.15.0/logrm -rf *#分发到其它机器scp -r es-cluster elsearch@192.168.40.134:/itcast#node01的配置：cluster.name: es-itcast-clusternode.name: node01node.master: truenode.data: truenetwork.host: 0.0.0.0http.port: 9200discovery.zen.ping.unicast.hosts: [&quot;192.168.40.133&quot;,&quot;192.168.40.134&quot;,&quot;192.168.40.135&quot;] # 发现集群的广播的地址 旧版本discovery.seed_hosts: [&quot;192.168.0.8&quot;,&quot;192.168.0.13&quot;] # 新版本，改其一即可cluster.initial_master_nodes: [&quot;node01&quot;，&quot;node02&quot;] # 新版本修改# 最小节点数discovery.zen.minimum_master_nodes: 2 # 新版本没有此选项，暂不修改添加# 跨域专用，最开始已经修改过了，此处不用修改，可以用echo 追加方式改http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;cat elasticsearch.yml |grep \\#cluster.name:cat elasticsearch.yml |grep node.name:cat elasticsearch.yml |grep network.host # 不需要改cat elasticsearch.yml |grep http.port # 不需要修改cat elasticsearch.yml |grep \\#discoverycat elasticsearch.yml |grep cluster.initial_master_nodes: sed -i &#x27;s#\\#cluster.name: my-application#cluster.name: es-itcast-cluster#&#x27; elasticsearch.ymlsed -i &#x27;s#node.name: node-1#node.name: node01#&#x27; elasticsearch.ymlsed -i &#x27;s#node.name: node01#node.name: node01\\nnode.master: true\\nnode.data: true#&#x27; elasticsearch.yml # 可以跟上面合并sed -i &#x27;s#\\#discovery.seed_hosts: \\[&quot;host1&quot;, &quot;host2&quot;\\]#discovery.seed_hosts: \\[&quot;192.168.0.8&quot;,&quot;192.168.0.13&quot;\\]#&#x27; elasticsearch.ymlsed -i &#x27;s#cluster.initial_master_nodes: \\[&quot;node-1&quot;\\]#cluster.initial_master_nodes: \\[&quot;node01&quot;，&quot;node02&quot;\\]#&#x27; elasticsearch.yml#node02的配置：grep -Ev &#x27;^#|^$&#x27; elasticsearch.yml cluster.name: es-itcast-cluster node.name: node02 node.master: false node.data: true network.host: 0.0.0.0 http.port: 9200 discovery.seed_hosts: [&quot;192.168.0.8&quot;,&quot;192.168.0.13&quot;] # 新版本，改其一即可 cluster.initial_master_nodes: [&quot;node01&quot;,&quot;node02&quot;] # 新版本修改 http.cors.enabled: true http.cors.allow-origin: &quot;*&quot;sed -i &#x27;s#\\#cluster.name: my-application#cluster.name: es-itcast-cluster#&#x27; elasticsearch.ymlsed -i &#x27;s#node.name: node-1#node.name: node02\\nnode.master: false\\nnode.data: true#&#x27; elasticsearch.ymlsed -i &#x27;s#\\#discovery.seed_hosts: \\[&quot;host1&quot;, &quot;host2&quot;\\]#discovery.seed_hosts: \\[&quot;192.168.0.8&quot;,&quot;192.168.0.13&quot;\\]#&#x27; elasticsearch.ymlsed -i &#x27;s#cluster.initial_master_nodes: \\[&quot;node-1&quot;\\]#cluster.initial_master_nodes: \\[&quot;node01&quot;,&quot;node02&quot;\\]#&#x27; elasticsearch.yml#node03的配置：,暂时没做三节点cluster.name: es-itcast-clusternode.name: node02node.master: falsenode.data: truenetwork.host: 0.0.0.0http.port: 9200discovery.zen.ping.unicast.hosts: [&quot;192.168.40.133&quot;,&quot;192.168.40.134&quot;,&quot;192.168.40.135&quot;]discovery.zen.minimum_master_nodes: 2http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;#分别启动3个节点./elasticsearch 打开elasticsearch_head前端，创建test索引，分片书为5，副本数为1，如下图所示，其中细边框是粗边框的副本： 12//查询集群状态GET http://127.0.0.1:9200/_cluster/health 集群状态的三种颜色 颜色 意义 green 所有主要分片和复制分片都可用 yellow 所有主要分片可以，但不是所有复制分片可用 red 不是所有的主要分片都可用 分片和副本为了将数据添加到Elasticsearch，我们需要索引(index)——一个存储关联数据的地方。实际上，索引只是一个用来指向一个或多个分片(shards)的“逻辑命名空间(logical namespace)”. 一个分片(shard)是一个最小级别“工作单元(worker unit)”,它只是保存了索引中所有数据的一部分。 我们需要知道是分片就是一个Lucene实例，并且它本身就是一个完整的搜索引擎。应用程序不会和它直接通 信。 分片可以是主分片(primary shard)或者是复制分片(replica shard)。 索引中的每个文档属于一个单独的主分片，所以主分片的数量决定了索引最多能存储多少数据。 复制分片只是主分片的一个副本，它可以防止硬件故障导致的数据丢失，同时可以提供读请求，比如搜索或者从别的shard取回文档。 当索引创建完成的时候，主分片的数量就固定了，但是复制分片的数量可以随时调整。 如果有个节点，分片均匀分配到三个节点，让其中一个节点宕机，集群状态先变黄，经过一段时间，宕机的节点不再显示，(如果主节点宕机，主节点将重新选举产生)，集群恢复到绿色 分布式文档存储问题： 集群保存文档时，文档该存储到哪个节点？随机还是轮询？如果读取又该如何查找？ elasticsearch采用计算的方式来确定存储到哪个节点，计算公式如下： 1shard = hash(routing) % number_of_primary_shards 式中：routing值是一个任意字符串，它默认是”_id”，也可以自定义；routing字符串通过哈希函数生一个数字；这个routing字符串通过哈希函数生成一个数字，然后除以主切片的数量后得到余数(remainder),该余数就是特定文档所在的分片，这也是创建主分片后，不能修改的原因。 分布式文档读写新建、索引和删除请求都是写（write）操作，它们必须在主分片上成功完成才能复制分片上 下面我们罗列在主分片和复制分片上成功新建、索引或删除一个文档必要的顺序步骤： 客户端给Node 1 发送新建、索引或删除请求。 节点使用文档的_id 确定文档属于分片0 。它转发请求到Node 3 ，分片0 位于这个节点上。 Node 3 在主分片上执行请求，如果成功，它转发请求到相应的位于Node 1 和Node 2 的复制节点上。当所有 的复制节点报告成功， Node 3 报告成功到请求的节点，请求的节点再报告给客户端。 客户端接收到成功响应的时候，文档的修改已经被应用于主分片和所有的复制分片。你的修改生效了。 分布式文档搜索（单个文档）文档能够从主分片或任意一个复制分片被检索。 下面我们罗列在主分片或复制分片上检索一个文档必要的顺序步骤： 客户端给Node 1 发送get请求。 节点使用文档的_id 确定文档属于分片0 。分片0 对应的复制分片在三个节点上都有。此时，它转发请求到 Node 2 。 Node 2 返回文档(document)给Node 1 然后返回给客户端。对于读请求，为了平衡负载，请求节点会为每个请求选择不同的分片——它会循环所有分片副本。可能的情况是，一个被索引的文档已经存在于主分片上却还没来得及同步到复制分片上。这时复制分片会报告文档未找到，主分片会成功返回文档。一旦索引请求成功返回给用户，文档则在主分片和复制分片都是可用的。 分布式文档全文搜索搜索，分为2个阶段， 搜索（query） 取回（fetch） 搜索（query）查询阶段包含以下三步： 客户端发送一个search（搜索） 请求给Node 3 , Node 3 创建了一个长度为from+size 的空优先级队 Node 3 转发这个搜索请求到索引中每个分片的原本或副本。每个分片在本地执行这个查询并且结果将结果到 一个大小为from+size 的有序本地优先队列里去。 每个分片返回document的ID和它优先队列里的所有document的排序值给协调节点Node 3 。Node 3 把这些 值合并到自己的优先队列里产生全局排序结果。 取回（fetch）分发阶段由以下步骤构成： 协调节点辨别出哪个document需要取回，并且向相关分片发出GET 请求。 每个分片加载document并且根据需要丰富（enrich）它们，然后再将document返回协调节点。 一旦所有的document都被取回，协调节点会将结果返回给客户端。","categories":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/tags/ELK/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://shizhonggan.github.io/tags/Elasticsearch/"}]},{"title":"Python 自动化运维(4)--Zabbix","slug":"DevOps/Zabbix","date":"2021-09-27T03:03:04.000Z","updated":"2022-10-13T02:46:42.893Z","comments":true,"path":"2021/09/27/DevOps/Zabbix/","link":"","permalink":"http://shizhonggan.github.io/2021/09/27/DevOps/Zabbix/","excerpt":"","text":"基础设施监控 基础设施监控 服务器温度、风扇转速 ipmitool命令 存储监控(df,fdisk,iotop) cpu (lscpu, uptime, top, htop, glances) 内存情况 (free) 网络(iftop) 应用监控 mysql redis nginx php-fpm python 安全监控 nginx+lua编要给WAF通过kibana可以图形化站式不同的攻击类型统计 用户登录数，passwd文件变化，本地所有文件改动 网络监控 端口，IDC带宽网络流量，网络流入流出速率，网络入/出流量，网络使用率，SMTP, POP3 完善理想的监控系统特点 监控系统能够自定义监控内容，自己通过脚本采集所需的数据 数据存入到数据库，日后对该数据进行分析计算 监控系统可以简易，快速的部署到服务器 数据可视化只管清晰 异常警告通知 可以定义复杂度告警逻辑，做到监控项之间的关联警告，例如程序之间的依赖检测，而不是之单独检测某个指标 警告可以确认响应，让运维组内的人知道已经有人处理警告问题 报警方式可以字定义，如短信，邮件，以及微信，钉钉等 告警内容可以字定义，能够写入一些简单的饭呢西，便于运维人员只管了解数据，否则还得去服务器查看 报警后，可以预处理一些任务，如自我修复，重启，采集数据 协同工作 监控系统有强大的API，提供给研发同学调用或其他系统调用 监控数据开发性，数据结构主流，便于分析 监控可视化可以建议的插件使用，而非复杂的JS文件 zabbix优点 支持自定义监控脚本，提供需要输出的值即可 zabbix存储的数据库表结构稍有复杂但是逻辑清晰 zabbix存在模板概念，可以方便的将一组监控进行部署 每一个item就是监控项，可以看到历史记录，且web界面友好 zabbix有强大的Trigger(触发器)定义规则，可以定义复杂的报警逻辑 zabbix提供了ack报警确认机制 zabbix支持邮件，短信，微信等告警 zabbix在触发告警后，可以远程执行系统命令 zabbix有原生的php绘图模块 zabbix5.0 安装 5.0版本要求php版本最低7.2.0，对php扩展组件版本也有要求,具体参见【官方文档】 准备机器，环境初始化 123456ifconfig eth0 |awk &#x27;NR==2&#123;print $2&#125;&#x27; # 输出IP,如果没有制表符，则第二列不好输出## 关闭防火墙systemctl disable --now firewalldgetenforce # 查看是否关闭iptables -L # 查看流量是否允许过来free -m # 内存大点，至少两个G, 4G最好 获取zabbix的下载源 123456789apt install rpmrpm -Uvh https://mirrors.aliyun.com/zabbix/zabbix/5.0/rhel/7/x86_64/zabbix-release-5.0-1.el7.noarch.rpm # 获得镜像源ls /etc/yum.repos.d/ # 可以查看到zabbix.repo文件## 修改zabbix.repo的镜像源为阿里的sed -i &#x27;s#http://repo.zabbix.com#https://mirrors.aliyun.com/zabbix#&#x27; /etc/yum.repos.d/zabbix.repo[zabbix-frontend]...enabled=1 # 0改为1， 官方文档给的 清空缓存，安装zabbix server和 agent 1234yum clean all yum makecacheyum install zabbix-server-mysql zabbix-agent2 -y 安装software collections, 便于后续安装高版本的php, yum默认安装5.4过低。SCL(Software Colletions) 可以让你在同一个操作系统上安装和使用多个版本的软件，而不会影响系统的安装包。软件包会安装在/opt/rh目录下。为了避免系统广泛冲突， /opt/rh包安装在目录中。例如，这允许你在centOS 7安装python3.5,而不会删除或干扰/etc/opt/rh/软件包的所有配置文件都存储在目录中，SCL包提供了定义使用所包含应用程序所需的环境变量的shell脚本。 1yum install centos-release-scl -y 安装前端环境 1yum install zabbix-web-mysql-scl zabbix-apache-conf-scl -y 安装zabbix所需的数据库 1yum install mariadb-server -y 配置数据库，设置开机启动 12345678910111213141516systemctl enable --now mariadb## 初始化数据库systemctl status mariadb # 先查看状态netstat -tunlp # 查看3306端口mysql_secure_installation # 初始化Enter current password for root (enter for none):OK, successfully used password, moving on...Set root password? [Y/n] yRemove anonymous users? [Y/n] yDisallow root login remotely? [Y/n] nRemove test database and access to it? [Y/n] yReload privilege tables now? [Y/n] y#################mysql -uroot -p1234 #成功登录 添加数据库用户，以及zabbix所需的数据库信息 1234create database zabbix character set utf8 collate utf8_bin; # 创建数据库create user zabbix@localhost identified by &#x27;1234&#x27;; # 创建用户grant all privileges on zabbix.* to zabbix@localhost; # 授权zabbix数据库下的所有表给zabbix这个用户flush privileges; # 刷新 使用zabbix-mysql命令导入数据库信息 123456789ls /usr/share/doc/zabbix-server-mysql*/create.sql.gz # 先查看以下 /usr/share/doc/zabbix-server-mysql-5.0.22/create.sql.gz ## mysql -u用户名 -p 数据库名zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbixmysql -uzabbix -p1234 # 登录查看show databases;use zabbix;show tables; # 可以查看很多表 修改zabbix server配置文件，修改数据库密码 12345678910vi /etc/zabbix/zabbix_server.conf### Option: DBPassword# Database password.# Comment this line if no password is used.## Mandatory: no# Default:DBPassword=1234################grep &#x27;^DBPass&#x27; /etc/zabbix/zabbix_server.conf # 查看是否修改成功 修改php配置文件 12vi /etc/opt/rh/rh-php72/php-fpm.d/zabbix.conf php_value[date.timezone] = Asia/Shanghai # 修改时区，取消注释 启动zabbix相关服务器 12systemctl restart zabbix-server zabbix-agent2 httpd rh-php72-php-fpmsystemctl enable zabbix-server zabbix-agent2 httpd rh-php72-php-fpm 登录访问web 网址: ip/zabbix 用户：Admin 密码：zabbix zabbix客户端部署zabbix5.0版本 agent2新版本采用golang语言开发，性能更高 由于是go语言开发，部署很方便，与之前的程序部署形式不一样 agent2 默认10050端口，客户端的端口。两个版本不能共存 旧版本客户端，zabbix-agent go语言新版本， zabbix-agent2 12345678910111213141516171819202122232425262728293031323334353637383940414243################# centosgetenforce # 查看防火墙是否关闭# 1. 时间同步yum install ntpdate -yntpdate -u ntp.aliyun.com# 2. 时区统一mv /etc/localtime&#123;,.bak&#125;ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime# 3. 安装zabbix agent2,rpm -Uvh https://mirrors.aliyun.com/zabbix/zabbix/5.0/rhel/7/x86_64/zabbix-release-5.0-1.el7.noarch.rpm # 获得镜像源sed -i &#x27;s#http://repo.zabbix.com#https://mirrors.aliyun.com/zabbix#&#x27; /etc/yum.repos.d/zabbix.repo #修改zabbix.repo的镜像源为阿里的yum install zabbix-agent2 -y # 安装agent2# 4. 查看配置文件和启动命令vi /etc/zabbix/zabbix_agent2.confls -l /usr/sbin/zabbix_agent2# 5. 启动客户端systemctl enable --now zabbix-agent2netstat -tnlp |grep zabbix # 查看端口# 修改配置文件hostnamectl set-hostname agent1 # 修改主机名grep -Ev &#x27;^#|^$&#x27; /etc/zabbix/zabbix_agent2.conf # 查看过滤掉注释和空行的配置文件cat /var/run/zabbix/zabbix_agent2.pid # 查看进程号ps -ef |grep zabbix # 看进程号是否一致vi /etc/zabbix/zabbix_agent2.conf PidFile=/var/run/zabbix/zabbix_agent2.pid LogFile=/var/log/zabbix/zabbix_agent2.log LogFileSize=0 Server=127.0.0.1 # 192.168.0.8 ServerActive=127.0.0.1 # 192.168.0.8 Hostname=agent1 # zbx-agent01 Include=/etc/zabbix/zabbix_agent2.d/*.conf ControlSocket=/tmp/agent.sock# 7. 重启agent2systemctl restart zabbix-agent2#################### ubuntusudo ufw status 验证 zabbix-agent2的连通性123# 1. 在服务端上通过命令主动获取数据yum install zabbix-get -y # 可以主动去客户端拿数据zabbix_get -s &#x27;192.168.0.13&#x27; -p 10050 -k &#x27;agent.ping&#x27; zabbix-server web 乱码问题12yum install wqy-microhei-fonts -y\\cp /usr/share/fonts/wqy-microhei/wqy-microhei.ttc /usr/share/fonts/dejavu/DejaVuSans.ttf 自定义监控内容例1 自定义监控服务器登录人数，限制登陆人数不超过三个 命令行方法1234567891011121314151617##################### 客户端操作# 1. 明确要执行的linux命令who | wc -l# 2. 手动创建zabbix的配置文件，用于定义key/etc/zabbix/zabbix_agent2.conf# 3. 创建配置文件，内容如下cd /etc/zabbix/zabbix_agentd.d/vi getusernum.confUserParameter=login.user,who|wc -l# 重启systemctl restart zabbix-agent2systemctl status zabbix-agent2######################## 服务端操作# 检查 zabbix_get -s &#x27;192.168.0.13&#x27; -p 10050 -k &#x27;login.user&#x27; # 可以看到返回值 web页面添加zabbix-server的自定义监控模板 创建模板 ： 名称Template Login User Number 创建应用集 创建监控项，自定义item，具体想监控的内容 创建触发器，当监控获取到值的时候，进行触发器比较、判断，决定是否报警 创建图像 将具体的主机和该模板连接，关联 邮件报警全网监控方案自动快速添加主机，思路 克隆监控模板 自动注册和自动发现 使用zabbix的api接口，利用curl语言，或者开发自己的变成脚本如python等 1curl -i -X POST -H &#x27;Content-Type:application/json&#x27; -d&#x27;&#123;&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;method&quot;:&quot;user.login&quot;,&quot;params&quot;:&#123;&quot;user&quot;:&quot;Admin&quot;,&quot;password&quot;:&quot;zabbix&quot;&#125;,&quot;auth&quot;:null,&quot;id&quot;:0&#125;&#x27; &quot;http://119.255.249.177/zabbix/api_jsonrpc.php&quot; 监控实施方案 硬件监控 应用服务监控 rsync服务监控 监控服务器的873端口是否存活 有关端口的监控，使用zabbix自带的key net.tcp.port[,873] 进行数据推拉，检测效果 监控NFC服务是否正常 通过key检测111端口 net.tcp.port[,111] showmount -e ip | wc -l 监控mysql数据库是否正常 通过端口 net.tcp.port[,3306] zabbix自带mysql监控模板，直接添加主板和mysql的主机关联即可 web 服务监控 net.tcp.port[,80] zabbix也提供了web服务器的监控模板 监控服务的具体方案12345678910111213141516# 端口检测的命令, 结合grep查看端口是否存活netstat sslsof## 例如：netstat -tunlp|grep httpdzabbix_get -s &#x27;127.0.0.1&#x27; -p 10050 -k &#x27;net.tcp.port[,80]&#x27; pkill httpd # 关闭进程，再查看# 查询进程信息ps# 通过客户端连接## 1. curl 查询web服务器## 2. mysql，用mysql语句连接验证## 3. 缓存数据库服务，数据读写验证 自动发现（被动）与自动注册（主动）主机1234567891011121314151617181920212223# 1. 准备一台机器,安装好agent2systemctl is-active zabbix-agent2 # 检查是否安装好# 2. 配置host解析ip zabbix_server_nameip zabbix_agent_name###### 自动发现模式【配置-自动发现，然后通过动作选项加入主机】【略】###### 自动注册模式# 3. 修改配置文件grep -Ev &#x27;^#|^$&#x27; /etc/zabbix/zabbix_agent2.confPidFile=/var/run/zabbix/zabbix_agentd.pidLogFile=/var/log/zabbix-agent/zabbix_agentd.logLogFileSize=0Server=119.255.249.177ServerActive=119.255.249.177Hostname=ganHostnameItem=system.hostname # 多设置的一项Include=/etc/zabbix/zabbix_agentd.conf.d/*.conf# 4. 验证连通性telnet 119.254.169.244 10050zabbix_get -s &#x27;119.254.169.244&#x27; -p 10050 -k &#x27;agent.ping&#x27;# 配置-动作-创建动作-修改条件-操作添加主机-添加主机群主-添加链接到模板 分布式监控12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364# 环境准备119.255.243.31 zabbix-proxy119.254.173.203 zabbix-agent2# 关闭防火墙iptables -Lgetenforcesystemctl stop zabbix-agent2netstat -tunlp# 自动发现与自动注册功能关闭# zabbix-server 已经安装无需变动# 准备好客户端机器，agent2机器# 配置代理服务器，并且部署数据库，用于存储agent2发来的数据，最终发给zabbix-server# ubuntu16 不支持zabbix5.0# wget https://repo.zabbix.com/zabbix/5.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_5.0-1+bionic_all.deb# sudo dpkg -i zabbix-release_5.0-1+bionic_all.deb# sudo sed -i.bak &#x27;s#http://repo.zabbix.com#https://mirrors.aliyun.com/zabbix#&#x27; /etc/apt/sources.list.d/zabbix.list # apt update# apt upgradesudo apt install zabbix-proxy-mysql zabbix-get -y # get可能安装不上，就不安装了apt-get install mariadb-server python-pymysqlservice mysql restartvi /etc/mysql/my.cnf [mysqld] collation-server = utf8_unicode_ci init-connect=&#x27;SET NAMES utf8&#x27; character-set-server = utf8mysql_secure_installation # 加强MariaDB的安全设置：create database zabbix_proxy character set utf8 collate utf8_bin;create user zabbix@localhost identified by &#x27;1234&#x27;;grant all privileges on zabbix_proxy.* to zabbix@localhost; # 授权zabbix数据库下的所有表给zabbix这个用户grant all on zabbix_proxy.* to &#x27;zabbix&#x27;@&#x27;localhost&#x27; identified by &#x27;zabbix&#x27; with grant option; # 如果报错用该命令flush privileges; # 刷新# 导入数据dpkg -L zabbix-proxy-mysql # 查看安装过程中数据库的位置 /usr/share/zabbix-proxy-mysql/schema.sql.gzzcat /usr/share/zabbix-proxy-mysql/schema.sql.gz | mysql -uzabbix -p zabbix_proxy# 修改配置文件vi /etc/zabbix/zabbix_proxy.confsed -i.ori &#x27;162a DBPassword=zabbix&#x27; /etc/zabbix/zabbix_proxy.conf # 修改162行,并做了.ori的备份文件sed -i &#x27;s#Server=127.0.0.1#Server=119.255.249.177#&#x27; /etc/zabbix/zabbix_proxy.confsed -i &#x27;s#Hostname=Zabbix proxy#Hostname=ryu#&#x27; /etc/zabbix/zabbix_proxy.conf# 检查代理服务器配置文件grep &#x27;^[a-Z]&#x27; /etc/zabbix/zabbix_proxy.conf Server=119.255.249.177 Hostname=ryu # 代理服务器名 LogFile=/var/log/zabbix-proxy/zabbix_proxy.log PidFile=/var/run/zabbix/zabbix_proxy.pid DBName=zabbix_proxy DBUser=zabbix DBPassword=zabbix FpingLocation=/usr/bin/fping Fping6Location=/usr/bin/fping6 Include=/etc/zabbix/zabbix_proxy.conf.d/*.conf# 启动service zabbix-proxy status# 在服务端添加代理服务器 参考：https://blog.csdn.net/weixin_62466637/article/details/123269890123456789101112131415161718192021222324252627282930313233343536373839## 设置zabbix的下载源，安装zabbix-proxyrpm -ivh https://mirrors.aliyun.com/zabbix/zabbix/5.0/rhel/7/x86_64/zabbix-release-5.0-1.el7.noarch.rpm cd /etc/yum.repos.dsed -i &#x27;s#http://repo.zabbix.com#https://mirrors.aliyun.com/zabbix#&#x27; /etc/yum.repos.d/zabbix.repo yum install -y zabbix-proxy-mysql zabbix-get## 安装 zabbix 所需的数据库yum install -y mariadb-server mariadb systemctl enable --now mariadb mysql_secure_installation #初始化数据库，并设置密码，如 abc123## 添加数据库用户，以及 zabbix 所需的数据库信息mysql -u root -p CREATE DATABASE zabbix_proxy character set utf8 collate utf8_bin;create user zabbix@localhost identified by &#x27;1234&#x27;; grant all privileges on zabbix_proxy.* to zabbix@localhost;flush privileges;## 导入数据库信息rpm -ql zabbix-proxy-mysql #查询 sql 文件的位置 zcat /usr/share/doc/zabbix-proxy-mysql-5.0.24/schema.sql.gz | mysql -uroot -p zabbix_proxy## 修改 zabbix-proxy 配置文件vim /etc/zabbix/zabbix_proxy.confServer=192.168.80.20 #30行，指定 zabbix 服务端的 IP 地址Hostname=zbx-proxy #49行，指定当前 zabbix 代理服务器的主机名DBPassword=zabbix #196行，指定当前数据库 zabbix 用户的密码## 启动 zabbix-proxysystemctl start zabbix-proxysystemctl enable zabbix-proxy ubuntu 完整安装zabbix123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# 1. 安装zabbix 库wget https://repo.zabbix.com/zabbix/5.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_5.0-1+focal_all.debdpkg -i zabbix-release_5.0-1+focal_all.debapt update# 2. 安装 zabbix-server, frontend, agentapt install zabbix-server-mysql zabbix-frontend-php zabbix-apache-conf zabbix-agent 1.查看安装的所有软件 dpkg -l 例如：dpkg -l | grep ftp 2.查看软件安装的路径 dpkg -L | grep ftp 也可以用 whereis ftp 3.查看软件版本 aptitude show# 3. 初始化 数据库# mysql -uroot -ppasswordmysql&gt; create database zabbix character set utf8 collate utf8_bin;mysql&gt; create user zabbix@localhost identified by &#x27;Ghxw_0603&#x27;;mysql&gt; grant all privileges on zabbix.* to zabbix@localhostgrant all privileges on zabbix.* to&#x27;zabbix&#x27;@&#x27;%&#x27; identified by &#x27;Ghxw_0603&#x27;;mysql&gt; quit;zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbixls /usr/share/doc/zabbix-server-mysql*/create.sql.gz # 先查看以下 /usr/share/doc/zabbix-server-mysql-5.0.22/create.sql.gz ## mysql -u用户名 -p 数据库名# 4. 修改配置文件/etc/zabbix/zabbix_server.conf DBPassword=password# 4. 修改配置文件/etc/zabbix/apache.confphp_value date.timezone Asia/ShangHai# 4. 修改 apache 端口 /etc/apache2/ports.confListen 8088sudo /etc/init.d/apache2 restart# 5. 重启 systemctl restart zabbix-server zabbix-agent apache2systemctl enable zabbix-server zabbix-agent apache2# 6. ubuntu 20 语言设置locales -a # 查看本地语言，没有zh-*语言包dpkg-reconfigure locales # 拉到最后，空格选择zh-*, enter 确认，重启生效，同时可以选择默认语言apt install ttf-wqy-microhei ttf-wqy-zenhei xfonts-intl-chinese # 重启后中文地方乱码，需要安装字体支持中文yum install wqy-microhei-fonts -y\\cp /usr/share/fonts/wqy-microhei/wqy-microhei.ttc /usr/share/fonts/dejavu/DejaVuSans.ttf","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/tags/DevOps/"},{"name":"zabbix","slug":"zabbix","permalink":"http://shizhonggan.github.io/tags/zabbix/"}]},{"title":"基于Vue.js + django 的工单流程系统","slug":"Django/workflow","date":"2021-09-27T03:03:04.000Z","updated":"2022-08-05T12:34:58.229Z","comments":true,"path":"2021/09/27/Django/workflow/","link":"","permalink":"http://shizhonggan.github.io/2021/09/27/Django/workflow/","excerpt":"","text":"准备123456789101112131415## 数据库版本要高10.x.xcreate database sinnetflow character set utf8 collate utf8_bin; # 创建数据库create user sinnet@&#x27;%&#x27; identified by &#x27;Ghxw_0603&#x27;; # 创建用户grant all privileges on sinnetflow.* to &#x27;sinnet&#x27;@&#x27;%&#x27;; # 授权zabbix数据库下的所有表给zabbix这个用户flush privileges; # 刷新create database test character set utf8 collate utf8_bin; # 创建数据库grant all privileges on test.* to &#x27;sinnet&#x27;@&#x27;%&#x27;; # 授权zabbix数据库下的所有表给zabbix这个用户flush privileges; # 刷新create database loontest character set utf8 collate utf8_bin;grant all privileges on loontest.* to &#x27;sinnet&#x27;@&#x27;%&#x27;; flush privileges; mysql -uroot shutongflow &lt; shutongflow.sql vue cli 安装部署1234567891011121314# https：//nodejs.org/zh-cn/ # 下载安装 node.js 修改安装目录修改目录：npm install -g cnpm --registry=https://registry.npm.taobao.org ## 下载 中国版的 npm将 /path/nodejs/node_global/ 添加到环境变量# https://cli.vuejs.org/zh/guide/installation.html # 官网参考安装 vue cli 方法cnpm install -g @vue/cli # cnpm比npm快 Vue 创建模板项目12vue init webpack sinnetflow Vue 组件12345678components# router 路由npm install vue-router@2 # echarts.js 表格# swiper 1","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/tags/DevOps/"},{"name":"zabbix","slug":"zabbix","permalink":"http://shizhonggan.github.io/tags/zabbix/"}]},{"title":"基于docker容器部署zabbix5.2","slug":"DevOps/zabbix_docker","date":"2021-09-27T03:03:04.000Z","updated":"2022-05-07T10:07:50.304Z","comments":true,"path":"2021/09/27/DevOps/zabbix_docker/","link":"","permalink":"http://shizhonggan.github.io/2021/09/27/DevOps/zabbix_docker/","excerpt":"","text":"安装docker[略]12345678官方源比较慢，改用国内镜像源：阿里云$ sudo yum-config-manager --add-repo \\http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo或：清华大学源$ sudo yum-config-manager --add-repo \\https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.repo 镜像准备1234567docker pull mysql:5.7# 拉取zabbix/zabbix-java-gateway:centos-5.4-latest镜像docker pull zabbix/zabbix-java-gateway:centos-5.4-latest# 拉取zabbix/zabbix-server-mysql:centos-5.4-latest镜像docker pull zabbix/zabbix-server-mysql:centos-5.4-latest# 拉取zabbix/zabbix-web-nginx-mysql:centos-5.4-latest镜像docker pull zabbix/zabbix-web-nginx-mysql:centos-5.4-latest 不要下载最新版本的mysql，不然后面server 无法在mysql上进行注册，会报 “MySQL server is not available. ” 错误 配置网络 https://stackoverflow.com/questions/56013245/docker-on-centos-7-will-not-pull-containers 12ip link set dev ens33 mtu 900 # centos7 貌似不生效，需要手动修改docker network create --opt com.docker.network.driver.mtu=1400 --subnet 172.18.0.0/16 -d bridge zabbix_net 以下配置，注意路径映射和密码修改mysql容器12345678910111213docker run --name mysql-server -dit \\--network zabbix_net --ip 172.18.0.2 \\-v /home/ec2-user/work/zabbix_docker/mysql/conf:/etc/mysql \\-v /home/ec2-user/work/zabbix_docker/mysql/logs:/var/log/mysql \\-v /home/ec2-user/work/zabbix_docker/mysql/data:/var/lib/mysql \\-v /etc/localtime:/etc/localtime \\ -e MYSQL_DATABASE=&quot;zabbix&quot; \\ -e MYSQL_USER=&quot;zabbix&quot; \\ -e MYSQL_PASSWORD=&quot;Ghxw_0603&quot; \\ -e MYSQL_ROOT_PASSWORD=&quot;Ghxw_0603&quot; \\ --restart=always \\ mysql:5.7 \\ --character-set-server=utf8 --collation-server=utf8_bin #注：–restart=always写在-d mysql:5.7的前面，要不然容器启动后自动关闭。–restart=always跟随Docker启动 java-gateway 容器12345docker run --name zabbix-java-gateway -dit \\--network zabbix_net --ip 172.18.0.5 \\-v /etc/localtime:/etc/localtime \\--restart=always \\ zabbix/zabbix-java-gateway:centos-5.4-latest 5、安装zabbix-server-mysql12345678910docker run -dit -p 10051:10051 --mount source=zabbix-server-vol,target=/home/ec2-user/work/zabbix_docker/zabbix \\-v /etc/localtime:/etc/localtime \\-v /home/ec2-user/work/zabbix_docker/alertscripts:/usr/lib/zabbix/alertscripts \\--name=zabbix-server-mysql --restart=always --network zabbix_net --ip 172.18.0.6 \\-e DB_SERVER_HOST=&quot;mysql-server&quot; \\-e MYSQL_DATABASE=&quot;zabbix&quot; \\-e MYSQL_USER=&quot;zabbix&quot; \\-e MYSQL_PASSWORD=&quot;Ghxw_0603&quot; \\-e MYSQL_ROOT_PASSWORD=&quot;Ghxw_0603&quot; \\-e ZBX_JAVAGATEWAY=&quot;zabbix-java-gateway&quot; zabbix/zabbix-server-mysql:centos-5.4-latest 6、安装zabbix-nginx12345678910docker run -dit -p 8088:8080 -v &#x2F;etc&#x2F;localtime:&#x2F;etc&#x2F;localtime \\--name zabbix-web-nginx-mysql \\--restart&#x3D;always --network zabbix_net --ip 172.18.0.3 \\-e DB_SERVER_HOST&#x3D;&quot;mysql-server&quot; \\-e MYSQL_DATABASE&#x3D;&quot;zabbix&quot; \\-e MYSQL_USER&#x3D;&quot;zabbix&quot; \\-e MYSQL_PASSWORD&#x3D;&quot;Ghxw_0603&quot; \\-e MYSQL_ROOT_PASSWORD&#x3D;&quot;Ghxw_0603&quot; \\-e PHP_TZ&#x3D;&quot;Asia&#x2F;Shanghai&quot; \\-e ZBX_SERVER_HOST&#x3D;&quot;zabbix-server-mysql&quot; zabbix&#x2F;zabbix-web-nginx-mysql:centos-5.4-latest 7、部署zabbix-agent端(指定zabbix-server地址或者ip地址) 1234567docker run -d --name zabbix-agent \\ -e ZBX_HOSTNAME&#x3D;&quot;119.255.249.177&quot; \\ -e ZBX_SERVER_HOST&#x3D;&quot;119.255.249.177&quot; \\ -p 10050:10050 \\ zabbix&#x2F;zabbix-agent:centos-5.4-latestdocker run -dit --name zabbix-agent -e ZBX_HOSTNAME&#x3D;&quot;zabbix-server-mysql&quot; --restart&#x3D;always --link zabbix-server-mysql --network zabbix_net --ip 172.18.0.4 -e ZBX_SERVER_HOST&#x3D;&quot;zabbix-server-mysql&quot; -p 10050:10050 --privileged -e ZBX_SERVER_PORT&#x3D;10051 -d zabbix&#x2F;zabbix-agent:centos-5.4-latest 8、登陆zabbix web http://宿主机IP:8888/ 用户：Admin 密码: zabbix 12345CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES5fb0132fe0c2 zabbix&#x2F;zabbix-web-nginx-mysql:centos-5.4-latest &quot;docker-entrypoint.sh&quot; 16 minutes ago Up 3 minutes 8443&#x2F;tcp, 0.0.0.0:8088-&gt;8080&#x2F;tcp zabbix-web-nginx-mysql0cf37fc88c5a zabbix&#x2F;zabbix-server-mysql:centos-5.4-latest &quot;&#x2F;usr&#x2F;bin&#x2F;tini -- &#x2F;u…&quot; 16 minutes ago Up 16 minutes 0.0.0.0:10051-&gt;10051&#x2F;tcp zabbix-server-mysqle58dde5fa6ab zabbix&#x2F;zabbix-java-gateway:centos-5.4-latest &quot;docker-entrypoint.s…&quot; 19 minutes ago Up 19 minutes 10052&#x2F;tcp zabbix-java-gateway77d09e257a8d mysql:5.7 &quot;docker-entrypoint.s…&quot; 19 minutes ago Up 19 minutes 3306&#x2F;tcp, 33060&#x2F;tcp mysql-server 参考：https://www.zabbix.com/documentation/5.4/en/manual/installation/containers 中文乱码修改拷贝windows下的微软雅黑字体到zabbix-web-nginx-mysql下 1234docker cp /data/MSYH.TTC 36:/usr/share/zabbix/assets/fonts/docker exec -it -u root zabbix-nginx /bin/bashmv DejaVuSans.ttf DejaVuSans.ttf_bakln -s MSYH.TTC DejaVuSans.ttf 监控Zabbix Server错误现象 Zabbix agent is not available (for 3m) Get value from agent failed: cannot connect to [[127.0.0.1]:10050]: [111] Connection refused 默认安装好Zabbix之后自带一个监视本地系统的配置“Zabbix Server”,无法被检测到。 主要原因就是我们是将Zabbix服务器和Zabbix客户端都安装到了Docker上 解决方法： 打开配置-主机，接口那的ip为127.0.0.1，这个IP是宿主机的IP，需要修改为 zabbix-agent 容器的IP","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/tags/DevOps/"},{"name":"zabbix","slug":"zabbix","permalink":"http://shizhonggan.github.io/tags/zabbix/"},{"name":"docker","slug":"docker","permalink":"http://shizhonggan.github.io/tags/docker/"}]},{"title":"Python 自动化运维(3)--Nagios配置","slug":"DevOps/Nagios2","date":"2021-09-18T03:03:04.000Z","updated":"2022-05-07T10:07:50.302Z","comments":true,"path":"2021/09/18/DevOps/Nagios2/","link":"","permalink":"http://shizhonggan.github.io/2021/09/18/DevOps/Nagios2/","excerpt":"","text":"Nagios配置文件 nagios.cfg 主配置文件,进程运行状态的配置文件，其他配置文件主要是基于此配置文件选择 cgi.cfg 控制cgi访问的配置文件，网络访问协议,web访问配置 resource.cfg 资源文件，在此文件中定义的变量可以再其他配置文件中引用 objects/*.cfg 监控相关的配置文件,用于定义nagios对象 commands.cfg 定义命令的配置文件，可以被其他文件应用 contacts.cfg 定义联系人和联系人组，用于接收警报消息 localhosts.cfg 定义监控本机的配置文件，不局限于local,可以是其配置文件 printer.cfg 定义打印机配置文件默认不启用 switch.cfg 监控路由器的配置文件，默认不启用 templates.cfg 模板配置文件 timeperiods.cfg 定义监控时间段的配置文件 windows.cfg 监控windows主机的一个配置文件模板，默认不启用 Nagios主配置文件对象配置文件模块： 定义主机、主机组、联系人、联系人组、服务等 cfg_file指明配置文件分开定义 Nagios将会读取并处理所有这些配置文件 对象配置文件 #cfg_dir=/usr/local/nagios/etc/servers #cfg_dir=/usr/local/nagios/etc/printers #cfg_dir=/usr/local/nagios/etc/switches #cfg_dir=/usr/local/nagios/etc/routers 对象缓存文件这些选项将决定当Nagios启动或重启时，对象定义将被缓存在什么地方。CGI将从这个对象文件中读取对象的定义，而不是在之前的对象配置文件路径中去找。这样做是为了避免修改Nagios配置文件后引起的不一致问题。 状态文件这个文件保存着目前检测到的服务和主机数据信息。这个文件当中的内容是被CGI读取并处理的，而它也是每次Nagios重新启动的时候被删除。 status_file=/var/log/nagios/stauts.dat Nagios进程运行用户和用户组 nagios_user = nagios nagios_nagios = nagios 外部命令行 check_external_commands = 1 , 这个选项允许用户指定是否Nagios应对外部的命令进行检查 command_check_interval = 15s , 外部命令检查时间间隔 command_file=/var/log/nagios/rw/nagios.cmd , 这事Nagios用力啊检查外部命令请求的文件。这个文件同样也是用户操作提交于CGI命令写入的地。 external_command_buffer_slot = 4096 , 外部命令缓冲 运行文件 downtime_file=/var/log/nagios/downtime.dat, 这是Nagios用来记录主机和服务故障停机时间数据的文件 lock_file=/var/run/nagios.pid , 设定Nagios的PID文件 temp_file=/var/log/nagios/nagios.tmp , 设定临时文件的路径 日志 log_file : 设定Nagios的主日志文件的路径(需修改，负责会出现权限问题) log_rotation_method : 写主日志记录是的循环记录方式 log_archive_path : 设定日志归档路径 use_syslog : 默认设定Nagios信息加入系统日志 log_notifications : 默认设定Nagios的通知是记录的 log_service_retries: 默认设定记录服务重启信息 log_host_retries : 默认设定记录主机重启信息 log_event_handlers : 默认启用记录事件处理程序信息 log_initial_states : 默认不记录初始化状态信息(最好开启) log_external_commands : 默认设定记录外部命令信息 log_passive_checks : 默认设定记录被动检查信息 主服务间内部检查之间延时的方式 service_inter_check_delay_method : 默认设定服务间检查间隔采用smart算法 值n表示none,不做任何延迟 值d表示dump, 表示在两个相邻的检查之间做1s的延迟 值s表示smart, 表示默认精简方式安排延迟 值x.xx表示动手定制每相邻的检查之间固定的x.xx秒延迟","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/tags/DevOps/"},{"name":"Nagios","slug":"Nagios","permalink":"http://shizhonggan.github.io/tags/Nagios/"}]},{"title":"Python 自动化运维(3)--Nagios使用","slug":"DevOps/Nagios3","date":"2021-09-18T03:03:04.000Z","updated":"2022-05-07T10:07:50.302Z","comments":true,"path":"2021/09/18/DevOps/Nagios3/","link":"","permalink":"http://shizhonggan.github.io/2021/09/18/DevOps/Nagios3/","excerpt":"","text":"添加一个监控主机 编辑 /usr/local/nagios/etc/objects/contacts.cfg 增加报警联系人信息1. 编辑 /usr/local/nagios/etc/objects/templates.cfg 增加报警策略信息 编辑 /usr/local/nagios/etc/objects/localhost.cfg 增加被监控主机信息 检测配置文件是否正确12/etc/init.d/nagios restart # 重新启动nagios -v /etc/nagios/nagios.cfg # 检查配置文件 配置文件有错的启动： Running configuration check… CONFIG ERROR! Restart aborted. Check your Nagios configuration 检测配置文件： nagios -v /etc/nagios/nagios.cfg 客户端安装nagios 在被监控的机器上安装nagios: yum install nagios 启动nrpe: systemctl start nagios 客户端进程nrpenrpe主要是用来搜集主机相关信息 在被监控的机器上安装nrpe: yum install nrpe 启动nrpe: systemctl start nrpe 修改 /usr/local/nagios/etc/cgi.cfg 配置里的use_authentication 为0 重启nagios: systemctl restart nagios 图形化工具nagios只显示当前状态，图形显示很差，可以用以下工具 nagiosQL 图形化配置管理工具 pnp4nagios 监控信息图标工具 nagiosgraph 监控信息图标工具 插件下载 https://exchange.nagios.org/ 插件使用 编辑command.cfg, 增加一个command 在hosts文件中使用这个command","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/tags/DevOps/"},{"name":"Nagios","slug":"Nagios","permalink":"http://shizhonggan.github.io/tags/Nagios/"}]},{"title":"JumpServer堡垒机","slug":"DevOps/JumpServer","date":"2021-09-16T03:03:04.000Z","updated":"2022-05-07T10:07:50.301Z","comments":true,"path":"2021/09/16/DevOps/JumpServer/","link":"","permalink":"http://shizhonggan.github.io/2021/09/16/DevOps/JumpServer/","excerpt":"","text":"介绍身份认证Authentication账号管理Accout授权控制Authorization审计AuditJumpServer安全提示JumpServer高可用部署","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"}],"tags":[{"name":"JumpServer","slug":"JumpServer","permalink":"http://shizhonggan.github.io/tags/JumpServer/"}]},{"title":"监控对比","slug":"DevOps/monitorcompared","date":"2021-09-16T03:03:04.000Z","updated":"2022-10-13T02:46:42.924Z","comments":true,"path":"2021/09/16/DevOps/monitorcompared/","link":"","permalink":"http://shizhonggan.github.io/2021/09/16/DevOps/monitorcompared/","excerpt":"","text":"zabbix 优点 报警系统 图表展示好 Creation of new alerts - either fault based or performance based. Creating an alert &amp; its trigger can be made easier. More VM-based data collection counters should be introduced to have better VM monitoring. The raw counters collection agent in every node is relatively weak. It goes down often, which needs more stability. 1docker network create --subnet 172.20.0.0&#x2F;16 --ip-range 172.20.240.0&#x2F;20 zabbix-net 创建数据库123456create database zabbix character set utf8 collate utf8_bin;create user zabbix@localhost identified by &#39;zabbix&#39;;grant all privileges on zabbix.* to zabbix@localhost;grant all privileges on zabbix.* to&#39;zabbix&#39;@&#39;%&#39; identified by &#39;zabbix&#39;;&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; zabbix 安装12345678# 准备机器，环境准备ifconfig eth0 |awk &#39;NR&#x3D;&#x3D;2&#123;print $2&#125;&#39; # 输出IP,如果没有制表符，则第二列不好输出## 关闭防火墙systemctl disable --now firewalldgetenforce # 查看是否关闭iptables -L # 查看流量是否允许过来free -m # 内存大点，至少两个G, 4G最好&gt;&gt;&gt;&gt;&gt;&gt;&gt; a578b6565373013651da4fb279b53d904030e944","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://shizhonggan.github.io/tags/zabbix/"}]},{"title":"Python 自动化运维(2)","slug":"DevOps/SaltStack","date":"2021-09-16T03:03:04.000Z","updated":"2022-05-07T10:07:50.302Z","comments":true,"path":"2021/09/16/DevOps/SaltStack/","link":"","permalink":"http://shizhonggan.github.io/2021/09/16/DevOps/SaltStack/","excerpt":"","text":"SaltStack概念 一个配置管理系统，能够维护预定义状态的远程节点 一个分布式远程执行系统，用来在远程节点上执行命令和查询数据 SaltStack特点 简单(相对于Puppet) 并行执行 基于成熟技术(ZeroMQ, AES) Python API 灵活开放 SaltStack服务架构 Master – 负责管理所有节点(可以有多个) Minion – 节点服务(客户端) ZeroMQ – 通信服务 AES – 数据加密方法 SaltStack 缺点 需要单独安装客户端 安全隐患大 ZeroMQ 简述ZeroMQ以嵌入式网络变成库的形式实现了一个并行开发框架，能够提供进程内、进程间、网络和广播方式的消息信道，并支持扇出、发布-订阅、任务分发、请求/相应等通信模式。【入门不需要深入了解】","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/tags/DevOps/"}]},{"title":"Python 自动化运维(3)--Nagios安装","slug":"DevOps/Nagios","date":"2021-09-15T03:03:04.000Z","updated":"2022-05-07T10:07:50.301Z","comments":true,"path":"2021/09/15/DevOps/Nagios/","link":"","permalink":"http://shizhonggan.github.io/2021/09/15/DevOps/Nagios/","excerpt":"","text":"Nagios一款免费的开源IT基础设施监控系统，其功能强大，灵活性强，能够监控windows、linux、VMware和Unix主机状态，交换机、路由器等网络设置等。 结构上分为两个部分： 核心功能 轻量化 插件 Nagios特性 监控网络服务(HTTP,) 监控主机资源(CPU负载、CPU使用率、进程状态等) 主动通知 web页面（发现异常报警功能） 可扩展 Nagios优点 轻量级，架构简单 容易部署 文档健全 灵活、全面（插件安装方便，可随时安装卸载，即插即用） Nagios 缺点 修改配置麻烦(只能改配置文件，不能再web页面改) 太灵活、学习成本高 监控报警缺乏历史数据(可以通过插件解决 ) 严重依赖外部插件 Nagios 原理简而言之，主机给客户机发了指令，让客户机收集相关信息，客户机把信息收集后发送给主机。 通信过程： Nagios执行安装在它里面的check_nrpe插件，并告诉check_nrpe去检测哪些服务。 Nagios执行安装在它里面的check_nrpe插件，并告诉check_nrpe去检测哪些服务 NRPE运行本地的各种插件区检测本地的服务和状态(check_disk,..etc) 最后，NRPE把检测的结果传给主机端的check_nrpe,check_nrpe再把结果送到Nagios状态队列中。 Nagios依次读取队列中的信息，再把结果显示出来。 Nagios 安装12345678910111213cd /etc/yum.repos.d/mv CentOS-Base.repo CentOS-Base.repo.bakwget http://mirrors.163.com/.help/CentOS7-Base-163.repoyum makecacheyum -y update# Install the required packagesyum install gcc glibc glibc-common wget gd gd-devel perl postfix unzip zip httpd php # php安装后可访问web页面# Download and Install Nagios Corecd /tmpwget https://assets.nagios.com/downloads/nagioscore/releases/nagios-4.4.3.tar.gztar xzf nagios-4.4.3.tar.gz./configure 12345678910111213141516171819useradd nagiosgroupadd nagcmdusermod -a -G nagcmd nagiosusermod -a -G nagcmd apache # 得安装httpd才有./configure --with-nagios-group=nagios --with-command-group=nagcmdmake allmake installmake install-init# Next, run the following command to install the Nagios sample configuration filesmake install-config# To, install the initialization script which can be used to manage your Nagios service, run the following commandmake install-daemoninit# Run the following command to install and configure the external command file to make Nagios Core to work from the command line:make install-commandmode# The following command will install the Apache web server configuration filesmake install-webconf# After all the installations are complete, restart your apache service with:systemctl restart httpd 1234567891011121314151617181920212223242526# Create nagiosadmin User Accounthtpasswd -c /usr/local/nagios/etc/htpasswd.users nagiosadmin #password 1234####### Install Nagios Plugins ######yum install gcc glibc glibc-common make gettext automake autoconf wget openssl-devel net-snmp net-snmp-utils epel-release perl-Net-SNMP wget https://nagios-plugins.org/download/nagios-plugins-2.2.1.tar.gztar -zxvf nagios-plugins-2.2.1.tar.gzcd /tmp/nagios-plugins-2.2.1/# Compile and install the Nagios plugins../configure --with-nagios-user=nagios --with-nagios-group=nagiosmakemake install# 最后将 Nagios 和 Apache 设置为开机启动，并重启 Nagios 服务以使配置修改内容生效，最后打开防火墙，放行HTTP服务：systemctl enable nagiossystemctl enable httpdsystemctl restart nagiosfirewall-cmd --add-service=http --zone=public --permanentfirewall-cmd --reload# Accessing Nagios Core/usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/nagios.cfgsystemctl start nagioshttp://119.255.249.177/nagios/ 参考： https://linuxhostsupport.com/blog/how-to-install-nagios-core-on-centos-7/ https://www.itzgeek.com/how-tos/linux/centos-how-tos/monitor-centos-7-rhel-7-using-nagios-4-0-7.html","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/tags/DevOps/"},{"name":"Nagios","slug":"Nagios","permalink":"http://shizhonggan.github.io/tags/Nagios/"}]},{"title":"Python 自动化运维(1)","slug":"DevOps/Ansible","date":"2021-09-12T03:03:04.000Z","updated":"2022-05-07T10:07:50.301Z","comments":true,"path":"2021/09/12/DevOps/Ansible/","link":"","permalink":"http://shizhonggan.github.io/2021/09/12/DevOps/Ansible/","excerpt":"","text":"介绍运维自动化是一组将静态的设备结构转化为根据IT服务需求动态弹性响应的策略，目的就是实现IT运维的质量，降低成本。 优点：高效利、平台化、标准化、流程化 自动化运维工具： 部署类： jenkins 环境类： ansible 监控类： ngios 运维包括：监控、持续集成、运维等 运维自动化设计思想： 管理体系化、工作流程化、人员专业化、任务自动化（环境定义自动化、部署自动化、监控自动化） 关心的问题：自动化、易实现、跨平台、轻量级 缺点： 数据无法共享、无法主动式发现问题[不能预测]、部署成本高、标准不统一 云运维： 资源数据共享、主动发现问题、统一标准、批量推送成本低 ansibleAnsible是一个自动化管理IT资源的工具 功能： 系统环境配置 安装软件 持续集成 热回滚 优点： 无客户端 推送式 丰富module 基于YAML的Playbook 商业化支持 缺点： 效率低、易挂起，串行的， 与其他软件对比： Ansible教程准备环境 pyhon setuptools 参考:https://www.cnblogs.com/effortsing/p/10012070.html 快速安装： 12345678sudo apt install python-setuptoolssudo apt install python3-pippython3 -m pip install ansible ## 这个方式好，能产生ansible.cfgsudo apt-get install -y python-software-properties software-properties-commonsudo add-apt-repository -y ppa:ansible/ansible; sudo apt-get updatesudo apt-get install -y ansible Ansible源码安装, 主要是因为自定义了系统、软件环境 获取源码 解压源码 进入目录 运行source ./hacking/env-setup Ansible系统源安装: Centos yum install ansible Ubuntu apt-get install software-prperties-common apt-get-repository ppa:ansible/ansible apt-get update apt-get install ansible ansible是基于ssh通信的，所以不需要后台起服务 Ansible配置文件路径 export ANSIBLE_CONFIG # 首先，Ansible命令会检查环境变量，及这个环境变量将指向的配置文件 ./ansible.cfg # 其次，将会检查当前目录下的ansible.cfg配置文件 ~/.ansible.cfg # 再次，将会检查当前用户home目录下的.ansible.cfg配置文件 /etc/ansible/ansible.cfg # 最后，将会检查在用软件包管理工具安装Ansible时自动产生的配置文件 如果以上目录都没有，则自己新建，只能有一个配置文件，不然会被覆盖 AnsibleAnsible命令格式： ansible all -m ping ansible 命令主题： ansible/ansible-playbook 被操作的目标机器的正则表达式： all 指定使用的模块： -m ping （command shell 命令） 传入参数: -a 传入的参数，例：ansible all -a ‘ls’ 命令详解：|optional arguments|detail||-|-|-a | 指定传入模块的参数-C -D | 两个一起使用，检查hosts规则文件的修改-l | 限制匹配规则的主机数-list-hosts | 显示所有匹配规则的主机数-m -M | 指定所用的模块和模块路径–syntax-check | 检查语法-v | 显示详细日志 添加一台主机 编辑/etc/ansible/hosts, 如果没有可以手动添加，其他位置创建也可以 添加本地public SSH key 到目标机器的authorized_keys 添加本机的密钥到Ansible 运行ansible all -m ping 测试添加是否成功 Inventory（分组） Patterns ( ) Ad-Hoc () Playbook 是一种简单的配置管理系统与多机器部署系统的基础。与现有的其他系统有不同之处，且非常适合于复杂应用的部署。 Playbooks可用于声明配置，更强大的地方在于，playbooks中以编排有序的执行过程，甚至于做到在多组机器间，来回有序的执行带别指定的步骤，且可以同步或异步的发起任务。 Ansible APIAPI提供的功能： 调用Ansible模块 引入Ansible runner库 初始化runner对象， 传入相关参数 运行runner对象的runner函数 12345678import ansible.runnerrunner = ansible.runner.Runner( module_name = &#x27;ping&#x27;, module_args = &#x27;&#x27;, # 参数 pattern = &#x27;web*&#x27;, # 匹配的机器 forks = 10, # 进程数)datastructure = runner.run() ansible2.0版本前后，差异很大，以上示例不适用于2.0后，以下是Ansible2.0 API使用方法 定义一个结果对象 初始化ansible节点对象 初始化结果对象 创建一个任务 1# 后续学 开发动态的Inventory数据源 更好的控制playbook等功能的运行 编写ansible module 字定义Ansible Plugin","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/tags/DevOps/"},{"name":"Ansilbe","slug":"Ansilbe","permalink":"http://shizhonggan.github.io/tags/Ansilbe/"}]},{"title":"Spinnaker入门笔记(1)","slug":"DevOps/Spinnaker/spinnaker","date":"2021-09-12T03:03:04.000Z","updated":"2022-11-06T09:58:33.031Z","comments":true,"path":"2021/09/12/DevOps/Spinnaker/spinnaker/","link":"","permalink":"http://shizhonggan.github.io/2021/09/12/DevOps/Spinnaker/spinnaker/","excerpt":"","text":"介绍Spinnaker 是一个开源，多云持续交付平台，可帮助您快速而稳定地发布软件更改。Spinnaker 提供了两组核心的功能： 应用管理与应用程序部署。Spinnaker 应用程序对此概念进行了建模。应用程序、集群和服务器组是 Spinnaker 用来描述服务的关键概念。负载均衡器和防火墙描述了服务如何向用户公开。 Spinnaker 11 个微服务 Desk: 前端web页面 端口9000 Gate: API 网关，所有程序通过 gate 与 spinnaker 通信； 端口8084 Orca: 编排引擎， 定义管道或任务，并管理阶段和任务，协调其他Spinnaker服务，端口8083 Clouddriver: 云厂商适配器，负责对云厂商的变更资源调用， 端口7002 适配阿里、亚马逊、微软、华为、K8s Front50: 用于保存应用程序、管道、项目和通知的元数据，端口8080 Rosco: 为各种运营供应商生成不可变的VM镜像， 端口8087 Igor: 持续集成、系统集成，触发管道，端口8088 Echo: 消息通知，负责发送通知，端口8089 Fiat: 认证授权服务，端口7003 Kayenta: 自动化的金丝雀分析，端口8090 Halyard: Spinnaker 生命周期配置管理工具，端口8064 部署比较复杂，参考： https://github.com/zeyangli/spinnaker-cd-install 流水线配置部署继承 Jenkins1234567891011hal config ci jenkins enable # 开启CI## 配置Jenkins, 需要用到账号和密码hal config ci jenkins master add my-jenkins-master-01 \\ --address http:&#x2F;&#x2F;jenkins.idvops.site \\ --username admin \\ --password admin## NOTE: 如果启用了SSO、gitlab or github 可以用tocken## 启用 CSRFhal config ci jenkins master edit my-jenkins-master-01 --csrf true","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"}],"tags":[{"name":"Spinnaker","slug":"Spinnaker","permalink":"http://shizhonggan.github.io/tags/Spinnaker/"}]},{"title":"AWS","slug":"Note/AWS","date":"2021-09-07T08:36:04.000Z","updated":"2022-10-13T02:46:43.009Z","comments":true,"path":"2021/09/07/Note/AWS/","link":"","permalink":"http://shizhonggan.github.io/2021/09/07/Note/AWS/","excerpt":"","text":"AWS KMSAWS KMS 是一项托管式服务，让您能够轻松地创建和控制用于加密操作的密钥。该服务为您提供可用性高的密钥生成、存储、管理和审计解决方案，让您可以在自己的应用程序内加密您的数据或以数字方式对数据签名，并在 AWS 服务之间对数据的加密进行控制。 https://aws.amazon.com/cn/kms/faqs/ Amazon CognitoAmazon Cognito 为您的 Web 和移动应用程序提供身份验证、授权和用户管理。您的用户可使用用户名和密码直接登录，也可以通过第三方（例如 Facebook、Amazon、Google 或 Apple）登录。 Amazon Cognito 的两个主要组件是用户池和身份池。用户池是为您的应用程序提供注册和登录选项的用户目录。使用身份池，您可以授予用户访问其他 AWS 服务的权限。您可以单独或配合使用身份池和用户池。 https://docs.aws.amazon.com/zh_cn/cognito/latest/developerguide/what-is-amazon-cognito.html AWS Lambdahttps://docs.aws.amazon.com/zh_cn/lambda/latest/dg/welcome.html AWS KinesisAmazon Kinesis 可让您轻松收集、处理和分析实时流数据，以便您及时获得见解并对新信息快速做出响应。Amazon Kinesis 提供多种核心功能，可以经济高效地处理任意规模的流数据，同时具有很高的灵活性，让您可以选择最符合应用程序需求的工具。借助 Amazon Kinesis，您可以获取视频、音频、应用程序日志和网站点击流等实时数据，也可以获取用于机器学习、分析和其他应用程序的 IoT 遥测数据。借助 Amazon Kinesis，您可以即刻对收到的数据进行处理和分析并做出响应，无需等到收集完全部数据后才开始进行处理。 https://aws.amazon.com/cn/kinesis/ https://blog.csdn.net/Trigl/article/details/80475966# T401: https://docs.databricks.com/administration-guide/cloud-configurations/aws/iam-kinesis.html Kinesis 是 AWS 的一项用于收集实时流数据的云服务，类似于 Kafka。Kinesis 收集到的数据可以用于多个方面，例如存到 S3，发到 EMR 作进一步数据分析等等。 AWS CloudFormationAWS CloudFormation 是一项服务，可帮助您对 AWS 资源进行建模和设置，以便能花较少的时间管理这些资源，而将更多的时间花在运行于 AWS 中的应用程序上。您创建一个描述您所需的所有 AWS 资源（如 Amazon EC2 实例或 Amazon RDS 数据库实例）的模板，并且 CloudFormation 将负责为您设置和配置这些资源。您无需单独创建和配置 AWS 资源并了解 what; CloudFormation 句柄处理该工作时所依赖的内容 https://docs.aws.amazon.com/zh_cn/AWSCloudFormation/latest/UserGuide/Welcome.html AWS X-RayAWS X-Ray是一项服务，用来收集您应用程序所服务的请求的相关数据，并提供用于查看、筛选和获取数据洞察力的工具，以确定问题和发现优化机会。对于任何被跟踪的对您应用程序的请求，您不仅可以查看请求和响应的详细信息，还可以查看您的应用程序对下游进行的调用的详细信息。AWS资源、微服务、数据库和 Web API。 https://docs.aws.amazon.com/zh_cn/xray/latest/devguide/aws-xray.html AWS CloudFront WebAmazon CloudFront 是一项加快将静态和动态 Web 内容（例如 .html、.css、.js 和图像文件）分发给用户的速度的 Web 服务。CloudFront 通过全球数据中心（称作边缘站点）网络传输内容。当用户请求您用 CloudFront 提供的内容时，请求被路由到提供最低延迟（时间延迟）的边缘站点，从而以尽可能最佳的性能传送内容。 https://docs.aws.amazon.com/zh_cn/AmazonCloudFront/latest/DeveloperGuide/Introduction.html AWS Elastic Beanstalk借助 Elastic Beanstalk，您可以在AWS云中快速部署和管理应用程序，而不必了解运行这些应用程序的基础设施。Elastic Beanstalk 可降低管理的复杂性，但不会影响选择或控制。您只需上传应用程序，Elastic Beanstalk 将自动处理有关容量预配置、负载均衡、扩展和应用程序运行状况监控的部署细节。 https://docs.aws.amazon.com/zh_cn/elasticbeanstalk/latest/dg/Welcome.html AWS CodeArtifactCodeArtifact 是一项完全托管的工件存储库服务，使组织可以轻松安全地存储和共享用于应用程序开发的软件包。 Amazon EventBridge亚马逊 EventBridge 是一种无服务器事件总线服务，让您可以轻松地将应用程序与来自多种来源的数据相连接。 EventBridge 从应用程序、软件即服务 (SaaS) 应用程序传输实时数据流，以及AWS对目标的服务，例如AWS Lambda函数、使用 API 目标的 HTTP 调用终端节点或其他AWS账户。 AWS serverless 服务： https://aws.amazon.com/cn/serverless/?nc=sn&amp;loc=0 计算 AWS Lambda 是一项事件驱动、随用随付的计算服务，无需预置或管理服务器即可运行代码 AWS Fargate 是一种无服务器计算引擎，可与Amazon Elastic Container Service(ECS)和Amazon Elastic Kubernetes Service(EKS)一起使用 应用程序集成 Amazon EventBridge 是一种无服务事件总线，可跨AWS和现有大规模构建事件驱动的应用程序 AWS Step Functions 是一种直观的工作流编排工具，可轻松将多个AWS服务按顺序安排到业务关键型应用程序中 Amazon Simple Queue Service(SQS) 是一种消息队列服务，可分离和扩展微服务、分布式系统和无服务器应用程序 Amazon Simple Notification Service(SNS) 是一项用于应用与应用之间的(A2A)以及应用与人之间(A2P)通信的完全托管式消息收发服务 Amazon API Gateway 是一种完全托管式服务，可以轻松创建、发布任意规模的API AWS AppSync 是一项完全托管式服务，可通过可扩展的GraphQL API加速应用程序开发 数据存储 Amazon Simple Strorage Service(Amazon S3) 是一项对象存储服务，旨在存储和保护任意量的数据 Amazon DynamoDB 是一个键/值和文档数据库，可以在任何规模的环境中提供个位数的毫秒级性能 Amazon RDS Proxy是Amazon Relational Database Service(RDS)的托管式数据库代理，可提高应用程序的可扩展性和安全性 Amazon Aurora Serverless 是一种兼容MySQL和PostgreSQL的关系数据库，可根据应用程序自动扩展容量 无服务器服务：https://aws.amazon.com/cn/serverless/getting-started/?serverless.sort-by=item.additionalFields.createdDate&amp;serverless.sort-order=desc Amazon API Gateway 是一种完全托管的服务，可以帮助开发人员轻松创建、发布、维护、监控和保护任意规模的 API。 Amazon EventBridge 是一种无服务器事件总线，支持您使用自己的应用程序、软件即服务 (SaaS) 应用程序和 AWS 服务的数据轻松将应用程序连接到一起。 Amazon Simple Notification Service (Amazon SNS) ，Amazon SNS 是一种高度可用、持久、安全且完全托管的发布/订阅消息收发服务，可以让您轻松解耦微服务、分布式系统和无服务器应用程序。 Amazon Simple Queue Service (Amazon SQS), Amazon SQS 是一种完全托管的消息队列服务，让您可以解耦和扩展微服务、分布式系统和无服务器应用程序。 AWS Fargate 是一种适用于 Amazon ECS 的计算引擎，让您无需管理服务器或集群即可运行容器。 AWS Lambda 使您几乎可以为任何类型的应用程序或后端服务运行代码，而且完全无需管理。 AWS Serverless Application Model (AWS SAM), 是一种使用简洁语法、用于构建无服务器应用程序的开源框架。 AWS Serverless Application Repository (AWS SAR), 使团队、组织和各个开发人员能够存储和共享可重用的应用程序，并轻松组装和部署无服务器架构。 AWS Step Functions 让您将多个 AWS 服务协调为无服务器工作流，以便您可以快速构建和更新应用程序。 从可简化无服务器应用程序开发和部署的各种 AWS 框架、开源框架以及第三方 Web 框架中进行选择。这些常用框架支持多种语言。 AWS Serverless Application Model (AWS SAM) 是一种用于构建无服务器应用程序的开源框架。它提供了表示函数、API、数据库和事件源映射的简写语法。 AWS Cloud Development Kit (AWS CDK) 是一种开源软件开发框架，可让您使用熟悉的编程语言来定义云应用程序资源。 无服务器框架 - 无服务器框架由一个开源 CLI 和一个托管控制面板组成。它们一起为您提供了完整的无服务器应用程序生命周期管理。 Chalice是在 Python 中编写无服务器应用程序的一种框架。通过它，您可以快速创建和部署使用 AWS Lambda 的应用程序。 Arc.codes 提供了构建大规模可扩展无服务器应用所需的一切，具有低代码、清晰简洁的配置和零仪式。 Claudia.js 可用于轻松将 Node.js 项目部署到 AWS Lambda 和 API Gateway。 您可以使用 AWS 开发人员工具和第三方工具为您的无服务器应用程序构建持续集成和持续部署(CI/CD) 流程。 AWS CodeCommit 是一项安全、高度可扩展的托管式源代码控制服务，可用于托管私有 Git 存储库。 AWS CodePipeline 是一种完全托管的持续交付服务，可以帮助您实现发布管道的自动化，从而实现快速而可靠的应用程序和基础设施更新。 AWS CodeBuild 是一项完全托管的持续集成服务，可编译源代码、运行测试以及生成可供部署的软件包。 AWS CodeDeploy 是一项完全托管的部署服务，它可以将软件自动部署到各种计算服务，如 Amazon EC2、AWS Fargate、AWS Lambda 和本地服务器。 AWS CodeArtifact 是一项完全托管式构件存储库服务，借助它，各种规模的组织都可以轻松安全地存储、发布和分享其软件开发过程中所使用的软件程序包。 Stackery 是一个无服务器平台，可用于设计、开发和交付现代化应用程序。 监控、日志记录和诊断您可以使用 AWS 服务和第三方工具监控无服务器应用程序和 AWS Lambda 函数的性能，并对其进行故障排除。 AWS X-Ray 可以帮助开发人员分析与调试分布式生产应用程序，例如使用微服务架构构建的应用程序。 Amazon CloudWatch 是一种面向开发运维工程师、开发人员、站点可靠性工程师 (SRE) 和 IT 经理的监控和可观测性服务。 AppDynamics - AWS Lambda 监控扩展从 Amazon CloudWatch 中捕获 Lambda 统计数据，并将其显示在 AppDynamics 指标浏览器中。 Dashbird - AWS Lambda 应用程序的端到端可观察性和实时错误跟踪。 DataDog - 检测和解决您的无服务器应用程序中的性能问题。 Epsagon 在您最复杂的无服务器环境中提供自动分布式跟踪，为服务和基础设施组件提供单一窗格，很少或不需要进行代码更改。 Lumigo - 无服务器和微服务的监控和调试平台。 New Relic - 使用 New Relic 无服务器对 AWS Lambda 函数进行监控、可视化、问题排查和提醒。 Splunk - 在一个平台中对您的整个堆栈进行监控、探索和问题排查。 Thundra - 调试、测试、交付和监控 AWS 云上的现代微服务。 编写和开发您可以使用 IDE 插件在您现有的集成开发环境 (IDE) 中撰写 AWS Lambda 函数代码。 IDE 工具包 - 在 AWS 上使用您选择的编程语言轻松开发应用程序。 AWS SAM CLI 提供一个类似于 Lambda 的执行环境，允许您在本地构建、测试、调试和部署 SAM 模板定义的应用程序。 AWS Cloud9 是一种基于云的集成开发环境 (IDE)，您只需要一个浏览器，即可编写、运行和调试代码。它包括一个代码编辑器、调试程序和终端。 PowerShell 工具使开发人员和管理人员可以在 PowerShell 脚本环境中管理他们的 AWS 服务和资源。","categories":[{"name":"AWS","slug":"AWS","permalink":"http://shizhonggan.github.io/categories/AWS/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://shizhonggan.github.io/tags/AWS/"}]},{"title":"AWS 学习（2）","slug":"Note/aws_example","date":"2021-09-07T08:36:04.000Z","updated":"2022-10-13T02:46:43.009Z","comments":true,"path":"2021/09/07/Note/aws_example/","link":"","permalink":"http://shizhonggan.github.io/2021/09/07/Note/aws_example/","excerpt":"","text":"https://docs.aws.amazon.com/zh_cn/codedeploy/latest/userguide/reference-appspec-file.html https://docs.aws.amazon.com/zh_cn/lambda/latest/dg/with-s3-example.html https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.rolling-version-deploy.html https://docs.aws.amazon.com/zh_cn/elasticbeanstalk/latest/dg/using-features.rolling-version-deploy.html 部署策略 一次部署全部(All at once): Elastic Beanstalk 将环境的 Amazon EC2 实例拆分为各个批，并将新版本的应用程序一次部署到一个批中。运行旧版应用程序的环境中的其余实例将会保留。在滚动部署期间，一些实例通过旧版本的应用程序处理请求，而已完成批次中的实例通过新版本处理其他请求。 滚动部署(Rolling)：Elastic Beanstalk 将环境的 Amazon EC2 实例拆分为各个批，并将新版本的应用程序一次部署到一个批中。运行旧版应用程序的环境中的其余实例将会保留。在滚动部署期间，一些实例通过旧版本的应用程序处理请求，而已完成批次中的实例通过新版本处理其他请求。 额外批量滚动(Rolling with additional batch)：要在部署期间保持完整容量，可以配置环境以启动新的实例批次，然后再禁用任何实例。 不可变的(Immutable)： 启动在单独的 Auto Scaling 组中运行新版本应用程序的一组完整的新实例，以及运行旧版本的实例。不可变的部署会阻止由部分完成的滚动部署导致的问题。如果新实例未通过运行状况检查，则 Elastic Beanstalk 将终止这些实例，并使原始实例保持不变。 流量拆分(Traffic splitting)：允许您在应用程序部署过程中执行 Canary 测试。在流量拆分部署中，Elastic Beanstalk 启动一整套新实例，就像在不可变部署期间一样。然后，它在指定的评估期内将指定百分比的传入客户端流量转发到新的应用程序版本。如果新实例保持正常状态，则 Elastic Beanstalk 会将所有流量转发给它们并终止旧实例。如果新实例未通过运行状况检查，或者您选择中止部署，则 Elastic Beanstalk 会将流量移回旧实例并终止新实例。从不会有任何服务中断。","categories":[{"name":"AWS","slug":"AWS","permalink":"http://shizhonggan.github.io/categories/AWS/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://shizhonggan.github.io/tags/AWS/"}]},{"title":"Django RESTful API 学习笔记","slug":"Python/django_RESTful","date":"2021-09-07T08:36:04.000Z","updated":"2022-05-07T10:07:50.318Z","comments":true,"path":"2021/09/07/Python/django_RESTful/","link":"","permalink":"http://shizhonggan.github.io/2021/09/07/Python/django_RESTful/","excerpt":"","text":"https://www.bilibili.com/video/BV1k5411p7Kp?p=3&amp;spm_id_from=pageDriver 1 web应用模式 前后端分离 juery – ajax vue – axios 前后端不分离，后端渲染好页面或重定向到其他页面 2 RESTful风格统一了CURD, 增删改查。REST(Representational State Transfer) 设计方法： 域名 专属域名 https://api.xxx.com https://xxx.com/api/ 版本 版本号放入域名https://xxx.com/api/1.0/foo 放入HTTP头部信息中，Accept: vnd.example-com.foo+json; version=1.0 路径 资源作为网址，只能是名词，不能有动词，往往与数据库的表明对应 https://xxx.api/1.0/books/name API的mincing应使用附属 HTTP动词 GET(SELECT) POST(CREATE) PUT(UPDATE) DELETE(DELETE) PATCH(UPDATE)局部更新 HEAD 元数据 OPTIONS 无害请求 过滤信息(Filtering) 状态码(Status Codes) 错误处理 返回结果json格式 3 RESTful案例","categories":[{"name":"Django","slug":"Django","permalink":"http://shizhonggan.github.io/categories/Django/"}],"tags":[{"name":"Django","slug":"Django","permalink":"http://shizhonggan.github.io/tags/Django/"},{"name":"RESTful API","slug":"RESTful-API","permalink":"http://shizhonggan.github.io/tags/RESTful-API/"}]},{"title":"opendaylight下发流表--想象不到的坑(1)","slug":"SDN/odl_error1","date":"2021-08-17T09:07:04.000Z","updated":"2022-05-07T10:07:50.326Z","comments":true,"path":"2021/08/17/SDN/odl_error1/","link":"","permalink":"http://shizhonggan.github.io/2021/08/17/SDN/odl_error1/","excerpt":"","text":"这两天在云平台部署了Carbon版本的opendaylight, 通过界面下发流表过程中，万万没想到遇到了这样的坑，如下图所示。 讲道理，在填入正确的node id之后（table id 在openflow1.0版本设置为0），即可展开flow list，填写相关参数，然后发送请求。然而，如图上所示，无法展开，没有展开按钮，没有网上各种资料所说的”+”图标。于是，反反复复、一步一步、仔仔细细地检查了各个操作步骤是否准确，貌似并没有什么错误。 这两天用谷歌搜索也不能解决问题，遍读官方文档也没有解决方法，苦苦盯着屏幕开始自我怀疑，是我环境没有部署好？是我操作不当？是我对网络的理解不够深刻？是我对计算机一窍不通？。。。。。。 正当放弃的时候，突然灵光一现，我把鼠标轻轻地挪到了flow list 圆圈A后方这个位置，如下图所示，鼠标放在红色的箭头位置时，上方突然跳出一个add list iterm，这不就是我苦苦寻找的东西么！ 至此，这个隐藏的按钮终于被找到了，问题也就解决了。点击展开如下，flow[0]后的删除按钮也无法显示，显然这是软件的问题。 下图是其他平台正常界面显示结果，如下所示，红色框框中的图标按钮是我这几天苦苦追寻的东西。此坑完结。。。。。 问题解决了，原因找到了，坑了我两天的问题，绝对不能这样放过，必须深究一下本质原因，查看界面html源码如下面三张图所示。先找到这个位置所需要的icon，找到icon对应的位置，发现该位置下貌似没有所需要的icon。这几天胸口郁结之气终于散了！","categories":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/categories/SDN/"}],"tags":[{"name":"OpenDaylight","slug":"OpenDaylight","permalink":"http://shizhonggan.github.io/tags/OpenDaylight/"},{"name":"那些坑","slug":"那些坑","permalink":"http://shizhonggan.github.io/tags/%E9%82%A3%E4%BA%9B%E5%9D%91/"}]},{"title":"Mininet MAC地址学习","slug":"SDN/mininet02","date":"2021-08-12T05:07:04.000Z","updated":"2022-05-07T10:07:50.325Z","comments":true,"path":"2021/08/12/SDN/mininet02/","link":"","permalink":"http://shizhonggan.github.io/2021/08/12/SDN/mininet02/","excerpt":"","text":"MAC地址学习MAC地址是识别LAN节点的标识。MAC对设备（通常是网卡）接口是全球统一的，MAC地址为48bit，用12个十六进制数表示。前6个十六进制数字由IEEE管理，用来识别生产商或者厂商，构成组织唯一识别符（OUI， Organization Unique Identifier）。后6个包括网卡序列号，或者特定硬件厂商的设定值。对于一个网卡来说，MAC地址是它的物理地址，是不可变的，而IP地址是它对应的逻辑地址，是可以更改的。在交换机中有一张记录局域网主机MAC地址与交换机接口对应关系的表，交换机根据这张表负责将数据帧传输到指定的主机上。交换机在接收到数据帧以后，首先将数据帧中的源MAC地址和对应的接口记录到MAC表中，接着检查自己的MAC表中是否有数据帧中目标MAC地址的信息，如果有，则根据MAC表中记录的对应接口将数据帧发送出去（也就是单播），如果没有，则将该数据帧从非接收口发送出去（也就是广播）。 实验12345678910111213141516171819202122232425262728293031323334353637$ sudo mn --topo linear --mac --switch ovsk --controller=none # 没有指定控制器，交换机中没有流表的存在，无法进行转发操作，主机h1和h2无法通信。mininet&gt; pingall # 此时无法ping通*** Ping: testing ping reachabilityh1 -&gt; Xh2 -&gt; X*** Results: 100% dropped (0/2 received)$ sudo ovs-ofctl dump-flows s1 # 也无流表存在NXST_FLOW reply (xid=0x4):mininet&gt; nodesavailable nodes are:h1 h2 s1 s2mininet&gt; neth1 h1-eth0:s1-eth1h2 h2-eth0:s2-eth1s1 lo: s1-eth1:h1-eth0 s1-eth2:s2-eth2s2 lo: s2-eth1:h2-eth0 s2-eth2:s1-eth2mininet&gt; dump&lt;Host h1: h1-eth0:10.0.0.1 pid=7448&gt;&lt;Host h2: h2-eth0:10.0.0.2 pid=7451&gt;&lt;OVSSwitch s1: lo:127.0.0.1,s1-eth1:None,s1-eth2:None pid=7457&gt;&lt;OVSSwitch s2: lo:127.0.0.1,s2-eth1:None,s2-eth2:None pid=7460&gt;$ sudo ovs-vsctl del-fail-mode s1 # 打开交换机s1的二层，执行该命令后s1变成普通的二层交换机$ sudo ovs-vsctl del-fail-mode s2 # 同上mininet&gt; h1 ping h2 # 执行上述步骤，即可ping通PING 10.0.0.2 (10.0.0.2) 56(84) bytes of data.64 bytes from 10.0.0.2: icmp_seq=1 ttl=64 time=0.750 ms64 bytes from 10.0.0.2: icmp_seq=2 ttl=64 time=0.038 ms64 bytes from 10.0.0.2: icmp_seq=3 ttl=64 time=0.044 ms$ sudo ovs-ofctl dump-flows s1 # 可以看到两条数据帧转发表，这表明交换机已进行过MAC地址学习NXST_FLOW reply (xid=0x4): cookie=0x0, duration=63.612s, table=0, n_packets=10, n_bytes=756, idle_age=48, priority=0 actions=NORMAL$ sudo ovs-ofctl dump-flows s2NXST_FLOW reply (xid=0x4): cookie=0x0, duration=64.392s, table=0, n_packets=10, n_bytes=756, idle_age=51, priority=0 actions=NORMAL","categories":[{"name":"Mininet","slug":"Mininet","permalink":"http://shizhonggan.github.io/categories/Mininet/"}],"tags":[{"name":"网络架构","slug":"网络架构","permalink":"http://shizhonggan.github.io/tags/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/"},{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/tags/SDN/"},{"name":"OVS","slug":"OVS","permalink":"http://shizhonggan.github.io/tags/OVS/"}]},{"title":"Ansible学习笔记","slug":"Ansible/install","date":"2021-08-12T02:24:04.000Z","updated":"2022-05-07T10:07:50.297Z","comments":true,"path":"2021/08/12/Ansible/install/","link":"","permalink":"http://shizhonggan.github.io/2021/08/12/Ansible/install/","excerpt":"","text":"参考资料 https://www.w3cschool.cn/automate_with_ansible/ https://www.bilibili.com/video/BV18t411f7CN?from=search&amp;seid=5997156070713703834&amp;spm_id_from=333.337.0.0 运维自动化发展历程及技术应用本地部署(On-Premises) -&gt; 基础设施即服务(IaaS) -&gt; 平台即服务(PaaS) -&gt; 软件即服务(SaaS) 自动化运维应用场景 文件传输 命令执行 应用部署 配置管理 任务流编排 企业实际应用场景分析 1 Dev开发环境 使用者：程序员 功能：程序员开发软件，测试BUG的环境 管理者：程序员 2 测试环境 使用者：QA测试工程师 功能：测试经过Dev环境测试通过的软件的功能 管理者：运维 说明：测试环境往往有多套,测试环境满足测试功能即可，不宜过多 1、测试人员希望测试环境有多套,公司的产品多产品线并发，即多个版本，意味着多个版本同步测试 2、通常测试环境有多少套和产品线数量保持一样 3 发布环境：代码发布机，有些公司为堡垒机（安全屏障） 使用者：运维 功能：发布代码至生产环境 管理者：运维（有经验） 发布机：往往需要有2台（主备） 4 生产环境 使用者：运维，少数情况开放权限给核心开发人员，极少数公司将权限完全 开放给开发人员并其维护 功能：对用户提供公司产品的服务 5 管理者：只能是运维 生产环境服务器数量：一般比较多，且应用非常重要。往往需要自动工具协助部署配置应用 6 灰度环境（生产环境的一部分） 使用者：运维 功能：在全量发布代码前将代码的功能面向少量精准用户发布的环境,可基于主机或用户执行灰度发布 案例：共100台生产服务器，先发布其中的10台服务器，这10台服务器就是灰度服务器 管理者：运维 灰度环境：往往该版本功能变更较大，为保险起见特意先让一部分用户优化体验该功能，待这部分用户使用没有重大问题的时候，再全量发布至所有服务器 程序发布 程序发布要求： 不能导致系统故障或造成系统完全不可用 不能影响用户体验 预发布验证： 新版本的代码先发布到服务器（跟线上环境配置完全相同，只是未接入到调度器） 灰度发布： 基于主机，用户，业务 发布路径： /webapp/tuangou /webapp/tuangou-1.1 /webapp/tuangou-1.2 发布过程：在调度器上下线一批主机(标记为maintanance状态) –&gt; 关闭服务 –&gt; 部署新版本的应用程序 --&gt; 启动服务 --&gt; 在调度器上启用这一批服务器 自动化灰度发布：脚本、发布平台 常用自动化运维工具 Ansible：python，Agentless，中小型应用环境，使用ssh协议 Saltstack：python，一般需部署agent(麻烦)，执行效率更高 Puppet：ruby, 功能强大，配置复杂，重型,适合大型环境，需要agent端配合 Fabric：python，agentless Chef：ruby，国内应用少 Cfengine func 可以ansible部署saltstack；ansible无主无从架构，开箱即用，用完即扔。 运维自动化场景： 操作系统预备自动化：PXE, Kickstart, Cobbler 配置自动化: Ansible 监控自动化: 系统与应用监控: Zabbix 日志监控: ELK 代码持续继承与代码持续发布自动化: git, Docker, Jenkins, github Ansible 特性 模块化：调用特定的模块，完成特定任务 Paramiko（python对ssh的实现），PyYAML，Jinja2（模板语言）三个关键模块 支持自定义模块 基于Python语言实现 部署简单，基于python和SSH(默认已安装)，agentless= 安全，基于OpenSSH 支持playbook编排任务 幂等性：一个任务执行1遍和执行n遍效果一样，不因重复执行带来意外情况 无需代理不依赖PKI（无需ssl） 可使用任何编程语言写模块 YAML格式，编排任务，支持丰富的数据结构 较强大的多层解决方案 Ansible主要组成部分 ANSIBLE PLAYBOOKS：任务剧本（任务集），编排定义Ansible任务集的配置文件， 由Ansible顺序依次执行，通常是JSON格式的YML文件 INVENTORY：Ansible管理主机的清单 /etc/anaible/hosts MODULES： Ansible执行命令的功能模块，多数为内置核心模块，也可自定义 PLUGINS： 模块功能的补充，如连接类型插件、循环插件、变量插件、过滤插件等，该功能不常用 API： 供第三方程序调用的应用程序编程接口 ANSIBLE： 组合INVENTORY、API、MODULES、PLUGINS的绿框，可以理解为是ansible命令工具，其为核心执行工具 Ansible命令执行来源： USER，普通用户，即SYSTEM ADMINISTRATOR CMDB（配置管理数据库） API 调用 PUBLIC/PRIVATE CLOUD API调用 (公有私有云的API接口调用) USER-&gt; Ansible Playbook -&gt; Ansibile​利用ansible实现管理的方式： Ad-Hoc 即ansible单条命令，主要用于临时命令使用场景 Ansible-playbook 主要用于长期规划好的，大型项目的场景，需要有前期的规划过程 Ansible-playbook（剧本）执行过程 将已有编排好的任务集写入Ansible-Playbook 通过ansible-playbook命令分拆任务集至逐条ansible命令，按预定规则逐条执行​Ansible主要操作对象 HOSTS主机 NETWORKING网络设备​注意事项: 执行ansible的主机一般称为主控端，中控，master或堡垒机 主控端Python版本需要2.6或以上 被控端Python版本小于2.4需要安装python-simplejson 被控端如开启SELinux需要安装libselinux-python windows不能做为主控端 ansible不是服务,不会一直启动,只是需要的时候启动安装 12345678910111213141516171819202122232425262728293031323334353637383940## rpm包安装: EPEL源yum -y install epel-releaseyum install ansible## 编译安装:yum -y install python-jinja2 PyYAML python-paramiko python-babelpython-cryptotar xf ansible-1.5.4.tar.gzcd ansible-1.5.4python setup.py buildpython setup.py installmkdir /etc/ansiblecp -r examples/* /etc/ansible## Git方式:git clone git://github.com/ansible/ansible.git --recursivecd ./ansiblesource ./hacking/env-setup## pip安装： pip是安装Python包的管理器，类似yumyum install python-pip python-develyum install gcc glibc-devel zibl-devel rpm-bulid openssl-develpip install --upgrade pippip install ansible --upgrade## 确认安装：[root@master ec2-user]# ansible --versionansible 2.9.25 config file = /etc/ansible/ansible.cfg configured module search path = [u&#x27;/root/.ansible/plugins/modules&#x27;, u&#x27;/usr/share/ansible/plugins/modules&#x27;] ansible python module location = /usr/lib/python2.7/site-packages/ansible executable location = /bin/ansible python version = 2.7.5 (default, Nov 16 2020, 22:23:17) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)][ec2-user@master ~]$ file /usr/bin/ansible/usr/bin/ansible: symbolic link to `/usr/bin/ansible-2.7&#x27;[ec2-user@master ~]$ ll /usr/bin/ansiblelrwxrwxrwx 1 root root 20 Nov 18 16:29 /usr/bin/ansible -&gt; /usr/bin/ansible-2.7 相关文件1234567891011121314rpm -ql ansible |less # 查看详细路径## 配置文件/etc/ansible/ansible.cfg # 主配置文件,配置ansible工作特性(一般无需修改)/etc/ansible/hosts # 主机清单(将被管理的主机放到此文件)/etc/ansible/roles/ # 存放角色的目录​## 程序/usr/bin/ansible # 主程序，临时命令执行工具/usr/bin/ansible-doc # 查看配置文档，模块功能查看工具/usr/bin/ansible-galaxy # 下载/上传优秀代码或Roles模块的官网平台/usr/bin/ansible-playbook # 定制自动化任务，编排剧本工具/usr/bin/ansible-pull # 远程执行命令的工具/usr/bin/ansible-vault # 文件加密工具/usr/bin/ansible-console # 基于Console界面与用户交互的执行工具 Ansible 简单应用案例使用ansible ping 模块实现测试主机互通性集群免密登录方法： shell写个循环 密码设置相同，然后-k 登录即可 12345678## 第一步：实现多主机间免密登录# 在ansible controller 生成密钥ssh-keygen -t rsa -f /root/.ssh/id_rsa -N &#x27;&#x27; # -N 免密操作ssh-copy-id IP # 同用户下操作## 第二部：修改/etc/ansible/hosts文件，添加需要操作的主机## 第三步：使用ping模块ansible all -m ping # 如果有hosts文件，首先识别该文件，其他host无效 在使用ansible连接之前，必须首先登录一下，保持know_hosts有连接记录，负责无法连接 ansible的ping不是基于ssh协议的 报错: ssh免密登录设置无法生效，具体如下： 123456789101112131415161718ssh 192.169.0.13 -v # 可查看具体报错原因##### 返回如下############## debug1: key_load_public: No such file or directorydebug1: identity file /home/ec2-user/.ssh/id_rsa-cert type -1...debug1: No valid Key exchange contextdebug1: Next authentication method: gssapi-with-micdebug1: Unspecified GSS failure. Minor code may provide more informationNo Kerberos credentials available (default cache: KEYRING:persistent:1000)debug1: Unspecified GSS failure. Minor code may provide more informationNo Kerberos credentials available (default cache: KEYRING:persistent:1000)################### 解决方法如下，修改文件权限su ec2-userchmod 700 /home/ec2-user/chmod 700 /home/ec2-user/.sshchmod 644 /home/ec2-user/.ssh/authorized_keyschmod 600 /home/ec2-user/.ssh/id_rsa 使用ansible cron 模块实现配置多主机时间同步12345678910111213141516171819202122232425262728## 第一步：选择时钟源服务器- 国内建议使用阿里时钟源 time1.aliyun.com- 国际建议使用微软时钟源 time.windows.com# ntpdate -u ntp.aliyun.com# mv /etc/localtime&#123;,.bak&#125;# ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime## 第二步：cron模块应用sudo yum install ntpdate -yansible 主机清单IP或分组名称 -m 模块 -a &quot;参数&quot;ansible 192.168.0.15 -m cron -a &#x27;name=&quot;test cron1&quot; job=&quot;sudo ntpdate ntp.aliyun.com&quot; minute=0 hour=*/1&#x27; # 每一小时更新一次 192.168.0.15 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot; &#125;, &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;test cron1&quot; ] &#125;## 远程主机查看结果crontab -lansible 192.168.0.15 -m command -a &#x27;crontab -l&#x27; 192.168.0.15 | CHANGED | rc=0 &gt;&gt; #Ansible: test cron1 0 */1 * * * sudo ntpdate ntp.aliyun.com 使用ansible copy 模块实现多主机配置文件同步1234## 第一步：准备本地域名解析文件119.255.249.177## 第二部：copy模块应用ansible 192.168.0.15 -m copy -a &quot;src=/etc/hosts dest=/etc/hosts&quot; 如果需要root权限，可以在root用户下执行操作，同时确保主机开启rootssh登录，方式如下：【此处是不成熟的解决办法，采用ansible -b参数，可以在连接后切换到root用户下】 12345678910111213141516## 开启rootssh登录最近使用这个工具，普通用户可以登录root用户不可以登录。将vi /etc/ssh/sshd_config按照下述配置解决问题修改sshd配置文件：vi /etc/ssh/sshd_configPermitRootLogin yesPubkeyAuthentication noPasswordAuthentication yesUseLogin yes## 两者命令都可以查看 是否开启cat /etc/ssh/sshd_config |grep PermitRootLogin |grep -Ev &#x27;^#&#x27;grep -Ev &#x27;^#|^$&#x27; /etc/ssh/sshd_config |grep PermitRootLoginsudo sed -i &quot;s#PermitRootLogin no#PermitRootLogin yes#&quot; /etc/ssh/sshd_configansible all -m command -a &#x27;sudo cat /etc/ssh/sshd_config |grep PermitRootLogin |grep -Ev &quot;^#&quot;&#x27;ansible all -m command -a &#x27;sudo sed -i &quot;s#PermitRootLogin no#PermitRootLogin yes#&quot; /etc/ssh/sshd_config&#x27; Ansible 配置文件Ansible 配置文件/etc/ansible/ansible.cfg （一般保持默认） 1234567891011121314151617vim /etc/ansible/ansible.cfg[defaults]#inventory = /etc/ansible/hosts # 主机列表配置文件#library = /usr/share/my_modules/ # 库文件存放目录#remote_tmp = $HOME/.ansible/tmp # 临时py命令文件存放在远程主机目录#local_tmp = $HOME/.ansible/tmp # 本机的临时命令执行目录 #forks = 5 # 默认并发数,同时可以执行5次#sudo_user = root # 默认sudo 用户#ask_sudo_pass = True # 每次执行ansible命令是否询问ssh密码#ask_pass = True # 每次执行ansible命令是否询问ssh口令#remote_port = 22 # 远程主机的端口号(默认22)## 建议优化项： host_key_checking = False # 检查对应服务器的host_key，建议取消注释log_path=/var/log/ansible.log # 日志文件,建议取消注释module_name = command # 默认模块 Ansible命令123456789101112131415Ansible系列命令 ansible ansible-doc ansible-playbook ansible-vault ansible-console ansible-galaxy ansible-pullansible-doc: 显示模块帮助 ansible-doc [options] [module...] -a 显示所有模块的文档 -l, --list 列出可用模块 -s, --snippet 显示指定模块的playbook片段(简化版,便于查找语法)示例： ansible-doc -l 列出所有模块 ansible-doc ping 查看指定模块帮助用法 ansible-doc -s ping 查看指定模块帮助用法 ansible 命令ansible通过ssh实现配置管理、应用部署、任务执行等功能，建议配置ansible端能基于密钥认证的方式联系各被管理节点 1234567891011121314151617181920212223242526ansible &lt;host-pattern&gt; [-m module_name] [-a args]ansible +被管理的主机(ALL) +模块 +参数 --version 显示版本 -m module 指定模块，默认为command -v **详细过程 –vv -vvv更详细** --list-hosts 显示主机列表，可简写 --list -k, --ask-pass 提示输入ssh连接密码,默认Key验证 -C, --check 检查，并不执行 -T, --timeout&#x3D;TIMEOUT 执行命令的超时时间,默认10s -u, --user&#x3D;REMOTE_USER 执行远程执行的用户 -b, --become 代替旧版的sudo切换 --become-user&#x3D;USERNAME 指定sudo的runas用户,默认为root -K, --ask-become-pass 提示输入sudo时的口令ansible all --list 列出所有主机ping模块: 探测网络中被管理主机是否能够正常使用 走ssh协议 如果对方主机网络正常,返回pongansible-doc -s ping 查看ping模块的语法 检测所有主机的网络状态1&gt; 默认情况下连接被管理的主机是ssh基于key验证,如果没有配置key,权限将会被拒绝 因此需要指定以谁的身份连接,输入用户密码,必须保证被管理主机用户密码一致 ansible all -m ping -k2&gt; 或者实现基于key验证 将公钥ssh-copy-id到被管理的主机上 , 实现免密登录 ansible all -m ping ansible的Host-pattern12345678910111213141516171819202122匹配主机的列表 All ：表示所有Inventory中的所有主机 ansible all –m ping * :通配符 ansible &quot;*&quot; -m ping (*表示所有主机) ansible 192.168.1.* -m ping ansible &quot;*srvs&quot; -m ping 或关系 &quot;:&quot; ansible &quot;websrvs:internal&quot; -m ping ansible “192.168.1.10:192.168.1.20” -m ping 逻辑与 &quot;:&amp;&quot; ansible &quot;websrvs:&amp;dbsrvs&quot; –m ping 在websrvs组并且在dbsrvs组中的主机 逻辑非 &quot;:!&quot; ansible &#x27;websrvs:!dbsrvs&#x27; –m ping 在websrvs组，但不在dbsrvs组中的主机 注意：此处为单引号 综合逻辑 ansible &#x27;websrvs:dbsrvs:&amp;internal:!ftpsrvs&#x27; –m ping 正则表达式 ansible &quot;websrvs:&amp;dbsrvs&quot; –m ping ansible &quot;~(web|db).*\\.magedu\\.com&quot; –m ping ansible命令执行过程 加载自己的配置文件 默认/etc/ansible/ansible.cfg 加载自己对应的模块文件，如command 通过ansible将模块或命令生成对应的临时py文件，并将该文件传输至远程服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件 给文件+x执行 执行并返回结果 删除临时py文件，sleep 0退出 执行状态： 绿色：执行成功并且不需要做改变的操作 黄色：执行成功并且对目标主机做变更 红色：执行失败 Ansible常用模块详解模块文档：https://docs.ansible.com/ansible/latest/modules/modules_by_category.html command在远程主机执行命令，默认模块，可忽略-m选项 123456789101112ansible all -m command -a &#x27;service vsftpd start&#x27;ansible all -m command -a &#x27;echo adong |passwd --stdin 123456&#x27;ansible all -a &quot;removes=/home/aa/tt cat /home/aa/tt&quot; -b # remove表示如果不存在该文件，则不执行，反之执行ansible all -a &quot;creates=/home/aa/tt df -h&quot; -b # creates表示如果存在该文件，则不执行，反之执行ansible all -a &quot;chdir=/home/aa/ cat tt&quot; # chdir 表示切换到该目录下之后执行命令ansible all -a &quot;/data/f1.sh&quot; -b # 此处.sh脚本开头必须有“#!/bin/bash”，得规范## 创建一个账号ansible all -a &quot;useradd test1&quot; -b ansible all -a &quot;getent passwd test1&quot; # 查看用户是否存在ansible all -m shell -a &quot;echo magedu|passwd --stdin test1&quot; # 添加口令才能登陆，不能成功ansible all -m shell -a &quot;echo $HOSTNAME&quot; ## 此命令不支持 $VARNAME &lt; &gt; | ; &amp; * 等特殊符号,用shell模块实现 注意：ubuntu和centos的命令不尽一样，所以以下命令能在centos上运行成功，再ubuntu上不一定能成功 Shell和command相似，用shell执行命令,上述无法执行的命令可以通过该模块执行。因此，使用shell模块即可。同时，针对不同的应用场景，尽量采用相应的模块进行处理，例如，“rm -rf /file” 删除文件命令可以采用 file 模块进行处理。 1234567891011ansible all -m shell -a &#x27;getenforce&#x27; 查看SELINUX状态ansible all -m shell -a &quot;sed -i &#x27;s/SELINUX=.*/SELINUX=disabled&#x27; /etc/selinux/config&quot;ansible all -m shell -a &#x27;echo magedu|passwd --stdin test1&#x27; 调用bash执行命令 类似 cat /tmp/stanley.md | awk -F&#x27;|&#x27; &#x27;&#123;print $1,$2&#125;&#x27; &amp;&gt; /tmp/example.txt 这些复杂命令，即使使用shell也可能会失败， 解决办法：写到脚本时，copy到远程执行，再把需要的结果拉回执行命令的机器 修改配置文件,使shell作为默认模块 vim /etc/ansible/ansible.cfg module_name = shell Script在远程主机上运行ansible服务器上的脚本 1ansible all -m script -a /data/test.sh Copy从主控端复制文件到远程主机 src : 源文件 指定拷贝文件的本地路径 (如果有/ 则拷贝目录内容,比拷贝目录本身) dest: 指定目标路径 mode: 设置权限 backup: 备份源文件 content: 代替src 指定本机文件内容,生成目标主机文件 12ansible all -m copy -a &quot;src=/root/test1.sh dest=/tmp/test2.sh owner=root mode=600 backup=yes&quot; # 如果目标存在，默认覆盖，此处指定先备份ansible all -m copy -a &quot;content=&#x27;test content\\nxxx&#x27; dest=/tmp/test.txt&quot; # 指定内容，直接生成目标文件 Fetch从远程主机提取文件至主控端，copy相反，目前不支持目录,可以先打包,再提取文件 1234ansible all -m fetch -a &#x27;src=/root/test.sh dest=/data/scripts&#x27; # 会生成每个被管理主机不同编号的目录,不会发生文件名冲突 ## 对于抓多个文件，可以先压缩，再抓取ansible all -m shell -a &#x27;tar jxvf test.tar.gz /root/test.sh&#x27;ansible all -m fetch -a &#x27;src=/root/test.tar.gz dest=/data/&#x27; File：设置文件属性 path: 要管理的文件路径 (强制添加) recurse: 递归,文件夹要用递归 src: 创建硬链接,软链接时,指定源目标,配合’state=link’ ‘state=hard’ 设置软链接,硬链接 state: 状态 absent 缺席,删除 12345ansible all -m file -a &#x27;path=/app/test.txt state=touch&#x27; 创建文件ansible all -m file -a &quot;path=/data/testdir state=directory&quot; 创建目录ansible all -m file -a &quot;path=/data/testdir state=absent&quot; 删除ansible all -m file -a &quot;path=/root/test.sh owner=wang mode=755&quot; 设置权限755ansible all -m file -a &#x27;src=/data/testfile dest=/data/testfile-link state=link&#x27; 创建软链接 unarchive：解包解压缩，有两种用法：1、将ansible主机上的压缩包传到远程主机后解压缩至特定目录，设置copy=yes.2、将远程主机上的某个压缩包解压缩到指定路径下，设置copy=no 常见参数： copy：默认为yes，当copy=yes，拷贝的文件是从ansible主机复制到远程主机上，如果设置为copy=no，会在远程主机上寻找src源文件 src： 源路径，可以是ansible主机上的路径，也可以是远程主机上的路径，如果是远程主机上的路径，则需要设置copy=no dest：远程主机上的目标路径 mode：设置解压缩后的文件权限 123ansible all -m unarchive -a &#x27;src=foo.tgz dest=/var/lib/foo&#x27; #默认copy为yes ,将本机目录文件解压到目标主机对应目录下ansible all -m unarchive -a &#x27;src=/tmp/foo.zip dest=/data copy=no mode=0777&#x27; # 解压被管理主机的foo.zip到data目录下, 并设置权限777ansible all -m unarchive -a &#x27;src=https://example.com/example.zip dest=/data copy=no&#x27; Archive：打包压缩 path: 指定路径 dest: 指定目标文件 format: 指定打包格式 owner: 指定所属者 mode: 设置权限 1ansible all -m archive -a &#39;path&#x3D;&#x2F;etc&#x2F;sysconfig dest&#x3D;&#x2F;data&#x2F;sysconfig.tar.bz2 format&#x3D;bz2 owner&#x3D;wang mode&#x3D;0777&#39; #将远程主机目录打包 Hostname：管理主机名12ansible group -m hostname -a &quot;name=app.adong.com&quot; 更改一组的主机名ansible 192.168.38.103 -m hostname -a &quot;name=app2.adong.com&quot; 更改单个主机名 Cron：计划任务1234## 支持时间：minute,hour,day,month,weekdayansible all -m cron -a &#x27;minute=*/5 job=&quot;/usr/sbin/ntpdate 172.16.0.1 &amp;&gt;/dev/null&quot; name=Synctime&#x27; # 创建任务ansible all -m cron -a &#x27;state=absent name=Synctime&#x27; # 删除任务ansible all -m cron -a &#x27;minute=*/10 job=&quot;/usr/sbin/ntpdate 172.30.0.100&quot; name=synctime disabled=true&#x27; #注释任务,不在生效，必须有 name, job,disabled=&quot;true/yes/false/no&quot; 三个参数 Yum：管理包1234567ansible all -m yum -a &#x27;list=httpd&#x27; # 查看程序列表ansible all -m yum -a &#x27;name=httpd state=present&#x27; # 安装ansible all -m yum -a &#x27;name=httpd,vsftpd state=absent&#x27; # 删除 可以同时安装多个程序包ansible all -m copy -a &#x27;src=/data/software.rpm dest=/dir/&#x27; # 拷贝软件ansible all -m yum -a &#x27;name=dstat update_cache=yes&#x27; # 避免缓存造成的影响ansible all -m yum -a &#x27;name=/dir/software.rpm disable_gpg_check=yes&#x27; # Service：管理服务1234ansible all -m service -a &#x27;name=httpd state=stopped&#x27; 停止服务ansible all -m service -a &#x27;name=httpd state=started enabled=yes&#x27; 启动服务,并设为开机自启ansible all -m service -a &#x27;name=httpd state=reloaded&#x27; 重新加载ansible all -m service -a &#x27;name=httpd state=restarted&#x27; 重启服务 User：管理用户 home 指定家目录路径 system 指定系统账号 group 指定组 remove 清除账户 shell 指定shell类型 12345678910ansible all -m user -a &#x27;name=nginx shell=/sbin/nologin system=yes home=/var/nginx groups=root,bin uid=80 comment=&quot;nginx service&quot;&#x27; # 源码编译都需要创建用户，yum安装的就自动创建了ansible all -m user -a &#x27;name=nginx state=absent remove=yes&#x27; # 删除用户ansible all -a &#x27;ls /var/ -l&#x27; # 查看用户目录已经被删除ansible all -a &#x27;getent passwd nginx&#x27; # 账号也删除了ansible all -m user -a &#x27;name=user1 comment=&quot;test user&quot; uid=2048 home=/app/user1 group=root&#x27;ansible all -m user -a &#x27;name=sysuser1 system=yes home=/app/sysuser1&#x27;ansible all -m user -a &#x27;name=user1 state=absent remove=yes&#x27; 清空用户所有数据ansible all -m user -a &#x27;name=app uid=88 system=yes home=/app groups=root shell=/sbin/nologin password=&quot;$1$zfVojmPy$ZILcvxnXljvTI2PhP2Iqv1&quot;&#x27; 创建用户ansible all -m user -a &#x27;name=app state=absent&#x27; 不会删除家目录 安装mkpasswd yum insatll expect mkpasswd 生成口令 openssl passwd -1 生成加密口令 删除用户及家目录等数据 Group：管理组12ansible all -m group -a &quot;name=testgroup system=yes&quot; 创建组ansible all -m group -a &quot;name=testgroup state=absent&quot; 删除组 Ansible系列命令ansible-galaxy 连接 https://galaxy.ansible.com 下载相应的roles(角色) 列出所有已安装的galaxy ansible-galaxy list 安装galaxy ansible-galaxy install geerlingguy.redis 删除galaxy ansible-galaxy remove geerlingguy.redis ansible-pull 推送命令至远程，效率无限提升，对运维要求较高 ansible-playbook 可以引用按照标准的yml语言写的脚本 执行playbook 1234567891011### 示例：ansible-playbook hello.ymlcat hello.yml#hello world yml file##################### 开始--- # 标准格式，可以没有，表示开始- hosts: internal remote_user: ec2-user tasks: - name: hello world command: /usr/bin/wall hello world################### 结束 ansible-vault (了解) 1234567### 功能：管理加密解密yml文件ansible-vault [create|decrypt|edit|encrypt|rekey|view]ansible-vault encrypt hello.yml 加密ansible-vault view hello.yml 查看ansible-vault edit hello.yml 编辑加密文件ansible-vault rekey hello.yml 修改口令ansible-vault create new.yml 创建新文件 Ansible-console：2.0+新增，可交互执行命令，支持tab (了解) 123456789[ec2-user@master ~]$ ansible-consoleWelcome to the ansible console.Type help or ? to list commands.ec2-user@all (3)[f:5]$ cd internal # 切换组ec2-user@internal (2)[f:5]$ forks 10 # 设置并发数ec2-user@internal (2)[f:10]$ list # 看主机清单ec2-user@internal (2)[f:10]$ ? 或 help # 列出所有内置命令，模块ec2-user@internal (2)[f:10]$ command hostname YAML语法简介特性: YAML的可读性好 YAML和脚本语言的交互性好 YAML使用实现语言的数据类型 YAML有一个一致的信息模型 YAML易于实现 YAML可以基于流来处理 YAML表达能力强，扩展性好 规则 在单一档案中，可用连续三个连字号(——)区分多个档案。另外，还有选择性的连续三个点号( … )用来表示档案结尾 次行开始正常写Playbook的内容，一般建议写明该Playbook的功能 使用#号注释代码 缩进必须是统一的，不能空格和tab混用 缩进的级别也必须是一致的，同样的缩进代表同样的级别，程序判别配置的级别是通过缩进结合换行来实现的 YAML文件内容是区别大小写的，k/v的值均需大小写敏感 多个k/v可同行写也可换行写，同行使用:分隔 v可是个字符串，也可是另一个列表[] 一个完整的代码块功能需最少元素需包括 name 和 task 一个name只能包括一个task YAML文件扩展名通常为yml或yaml playbook playbook是由一个或多个”play”组成的列表 play的主要功能在于将预定义的一组主机，装扮成事先通过ansible中的task定义好的角色。Task实际是调用ansible的一个module，将多个play组织在一个playbook中，即可以让它们联合起来，按事先编排的机制执行预定义的动作 Playbook采用YAML语言编写 Playbook核心元素 Hosts 执行的远程主机列表(应用在哪些主机上) Tasks 任务集 Variables 内置变量或自定义变量在playbook中调用 Templates模板 可替换模板文件中的变量并实现一些简单逻辑的文件 Handlers和notify结合使用，由特定条件触发的操作，满足条件方才执行，否则不执行 tags标签 指定某条任务执行，用于选择运行playbook中的部分代码。ansible具有幂等性，因此会自动跳过没有变化的部分，即便如此，有些代码为测试其确实没有发生变化的时间依然会非常地长。此时，如果确信其没有变化，就可以通过tags跳过此些代码片断 ansible-playbook -t tagsname useradd.yml playbook基础组件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162Hosts： &gt; playbook中的每一个play的目的都是为了让特定主机以某个指定的用户身份执行任务。 hosts用于指定要执行指定任务的主机，须事先定义在主机清单中 &gt; 可以是如下形式： one.example.com one.example.com:two.example.com 192.168.1.50 192.168.1.* &gt; Websrvs:dbsrvs 或者，两个组的并集 &gt; Websrvs:&amp;dbsrvs 与，两个组的交集 &gt; webservers:!phoenix 在websrvs组，但不在dbsrvs组 示例: - hosts: websrvs：dbsrvsremote_user: 可用于Host和task中。 也可以通过指定其通过sudo的方式在远程主机上执行任务，其可用于play全局或某任务； 此外，甚至可以在sudo时使用sudo_user指定sudo时切换的用户 - hosts: websrvs remote_user: root (可省略,默认为root) 以root身份连接 tasks: 指定任务 - name: test connection ping: remote_user: magedu sudo: yes 默认sudo为root sudo_user:wang sudo为wang task列表和action 任务列表task:由多个动作,多个任务组合起来的,每个任务都调用的模块,一个模块一个模块执行 1&gt; play的主体部分是task list，task list中的各任务按次序逐个在hosts中指定的所有主机上执行， 即在所有主机上完成第一个任务后，再开始第二个任务 2&gt; task的目的是使用指定的参数执行模块，而在模块参数中可以使用变量。 模块执行是幂等的，这意味着多次执行是安全的，因为其结果均一致 3&gt; 每个task都应该有其name，用于playbook的执行结果输出，建议其内容能清晰地描述任务执行步骤。 如果未提供name，则action的结果将用于输出tasks：任务列表两种格式： (1) action: module arguments (2) module: arguments 建议使用 模块: 参数 注意：shell和command模块后面跟命令，而非key=value某任务的状态在运行后为changed时，可通过&quot;notify&quot;通知给相应的handlers任务可以通过&quot;tags&quot;打标签，可在ansible-playbook命令上使用-t指定进行调用示例：tasks: - name: disable selinux 描述 command: /sbin/setenforce 0 模块名: 模块对应的参数如果命令或脚本的退出码不为零，可以使用如下方式替代tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand || /bin/true 转错为正 如果命令失败则执行 true或者使用ignore_errors来忽略错误信息tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand ignore_errors: True 忽略错误 样例12345678910111213141516---- hosts: internal remote_user: ec2-user become: yes tasks: - name: create new File file: name=/home/ec2-user/newfile state=touch - name: create new user user: name=test2 shell=/sbin/nologin - name: install package yum: name=httpd - name: copy file copy: src=a.txt dest=/home/ec2-user/ - name: start service service: name=httpd state=started enabled=yes 12345ansible internal -a &#x27;getent passwd test2&#x27;# 查看用户列表ansible internal -a &#x27;rpm -q httpd&#x27; # 查看是否安装ansible internal -m file -a &#x27;path=/home/ec2-user/a.txt state=touch&#x27; # 创建文件ansible internal -a &#x27;ls /home/ec2-user/ -l&#x27; # 查看文件是否创建成功ansible internal -m shell -a &#x27;netstat -tln|grep :80&#x27; Playbook选项 运行playbook的方式 ansible-playbook &lt;filename.yml&gt; … [options]1234567891011121314常见选项 --check -C 只检测可能会发生的改变，但不真正执行操作 (只检查语法,如果执行过程中出现问题,-C无法检测出来) (执行playbook生成的文件不存在,后面的程序如果依赖这些文件,也会导致检测失败) --list-hosts 列出运行任务的主机 --list-tags 列出tag (列出标签) --list-tasks 列出task (列出任务) --limit 主机列表 只针对主机列表中的主机执行 -v -vv -vvv 显示过程示例 ansible-playbook hello.yml --check 只检测 ansible-playbook hello.yml --list-hosts 显示运行任务的主机 ansible-playbook hello.yml --limit websrvs 限制主机 playbook 与 shellscripts(安装httpd)123456789#!/bin/bash# 安装Apacheyum install --quiet -y httpd# 复制配置文件cp /tmp/httpd.conf /etc/httpd/conf/httpd.confcp/tmp/vhosts.conf /etc/httpd/conf.d/# 启动Apache，并设置开机启动service httpd startchkconfig httpd on 12345678910111213---- hosts: all remote_user: root tasks: - name: &quot;安装Apache&quot; yum: name=httpd yum模块:安装httpd - name: &quot;复制配置文件&quot; copy: src=/tmp/httpd.conf dest=/etc/httpd/conf/ copy模块: 拷贝文件 - name: &quot;复制配置文件&quot; copy: src=/tmp/vhosts.conf dest=/etc/httpd/conf.d/ - name: &quot;启动Apache，并设置开机启动&quot; service: name=httpd state=started enabled=yes service模块: 启动服务 示例:Playbook 创建用户 12345678910### 示例：sysuser.yml---- hosts: all remote_user: root tasks: - name: create mysql user user: name=mysql system=yes uid=36 - name: create a group group: name=httpd system=yes Playbook示例 安装httpd服务1234567891011### 示例：httpd.yml- hosts: websrvs remote_user: root tasks: - name: Install httpd yum: name=httpd state=present - name: Install configure file copy: src=files/httpd.conf dest=/etc/httpd/conf/ - name: start service service: name=httpd state=started enabled=yes Playbook示例 安装nginx服务12345678910111213### 示例 nginx.yml- hosts: all remote_user: root tasks: - name: add group nginx user: name=nginx state=present - name: add user nginx user: name=nginx state=present group=nginx - name: Install Nginx yum: name=nginx state=present - name: Start Nginx service: name=nginx state=started enabled=yes handlers和notify结合使用触发条件 Handlers 实际上就是一个触发器 是task列表，这些task与前述的task并没有本质上的不同,用于当关注的资源发生变化时，才会采取一定的操作 Notify此action可用于在每个play的最后被触发，这样可避免多次有改变发生时每次都执行指定的操作，仅在所有的变化发生完成后一次性地执行指定操作。在notify中列出的操作称为handler，也即notify中调用handler中定义的操作 Playbook中handlers使用123456789101112131415- hosts: websrvs remote_user: root tasks: - name: Install httpd yum: name=httpd state=present - name: Install configure file copy: src=files/httpd.conf dest=/etc/httpd/conf/ notify: restart httpd ## 如果copy文件有变化，则调用对应的触发器 - name: ensure apache is running service: name=httpd state=started enabled=yes handlers: - name: restart ht tpd service: name=httpd state=restarted 12345678910111213141516171819202122- hosts: websrvs remote_user: root tasks: - name: add group nginx tags: user user: name=nginx state=present - name: add user nginx user: name=nginx state=present group=nginx - name: Install Nginx yum: name=nginx state=present - name: config copy: src=/root/config.txt dest=/etc/nginx/nginx.conf notify: - Restart Nginx - Check Nginx Process handlers: - name: Restart Nginx service: name=nginx state=restarted enabled=yes - name: Check Nginx process shell: killall -0 nginx &gt; /tmp/nginx.log Playbook中tags使用tage: 添加标签可以指定某一个任务添加一个标签,添加标签以后,想执行某个动作可以做出挑选来执行多个动作可以使用同一个标签 12345678910111213141516## 示例：httpd.yml- hosts: websrvs remote_user: root tasks: - name: Install httpd yum: name=httpd state=present tage: install - name: Install configure file copy: src=files/httpd.conf dest=/etc/httpd/conf/ tags: conf - name: start httpd service tags: service service: name=httpd state=started enabled=yesansible-playbook –t install,conf httpd.yml ## 指定执行install,conf 两个标签 123456789101112131415161718192021222324252627282930313233343536## heartbeat.yaml- hosts: hbhosts remote_user: root tasks: - name: ensure heartbeat latest version yum: name=heartbeat state=present - name: authkeys configure file copy: src=/root/hb_conf/authkeys dest=/etc/ha.d/authkeys - name: authkeys mode 600 file: path=/etc/ha.d/authkeys mode=600 notify: - restart heartbeat - name: ha.cf configure file copy: src=/root/hb_conf/ha.cf dest=/etc/ha.d/ha.cf notify: - restart heartbeat handlers: - name: restart heartbeat service: name=heartbeat state=restarted## Playbook中tags使用- hosts: testsrv remote_user: root tags: inshttpd ## 针对整个playbook添加tage tasks: - name: Install httpd yum: name=httpd state=present - name: Install configure file copy: src=files/httpd.conf dest=/etc/httpd/conf/ tags: rshttpd notify: restart httpd handlers: - name: restart httpd service: name=httpd status=restarted ansible-playbook –t rshttpd httpd2.yml Playbook中变量的使用变量名：仅能由字母、数字和下划线组成，且只能以字母开头 变量来源： ansible setup facts 远程主机的所有变量都可直接调用 (系统自带变量)setup模块可以实现系统中很多系统信息的显示可以返回每个主机的系统信息包括:版本、主机名、cpu、内存1234567891011121314151617ansible all -m setup -a &#x27;filter=&quot;ansible_nodename&quot;&#x27; # 查询主机名ansible all -m setup -a &#x27;filter=&quot;ansible_memtotal_mb&quot;&#x27; # 查询主机内存大小ansible all -m setup -a &#x27;filter=&quot;ansible_distribution_major_version&quot;&#x27; # 查询系统版本ansible all -m setup -a &#x27;filter=&quot;ansible_processor_vcpus&quot;&#x27; # 查询主机cpu个数``` 2. 在/etc/ansible/hosts(主机清单)中定义变量 - 普通变量：主机组中主机单独定义，优先级高于公共变量(单个主机 ) - 公共(组)变量：针对主机组中所有主机定义统一变量(一组主机的同一类别) 3. 通过命令行指定变量，优先级最高 - ansible-playbook –e varname=value 4. 在playbook中定义```ymlvars: - var1: value1 - var2: value2 在独立的变量YAML文件中定义 在role中定义 变量命名: 变量名仅能由字母、数字和下划线组成，且只能以字母开头 变量定义：key=value, 示例：http_port=80 变量调用方式： 通过 调用变量，且变量名前后必须有空格，有时用“”才生效 ansible-playbook –e 选项指定 ansible-playbook test.yml -e “hosts=www user=magedu” 在主机清单中定义变量,在ansible中使用变量 1234# vim /etc/ansible/hosts[internal]192.168.38.17 http_port=817 name=www192.168.38.27 http_port=827 name=web 调用变量ansible internal -m hostname -a’name=‘ 更改主机名为各自被定义的变量 针对一组设置变量[internal:vars]make=”-“ ansible internal -m hostname -a ‘name=‘ ansible调用变量 将变量写进单独的配置文件中引用vim vars.ymlpack: vsftpdservice: vsftpd 引用变量文件vars_files: vars.yml Ansible基础元素Facts：是由正在通信的远程目标主机发回的信息，这些信息被保存在ansible变量中。要获取指定的远程主机所支持的所有facts，可使用如下命令进行 ansible websrvs -m setup 通过命令行传递变量,在运行playbook的时候也可以传递一些变量供playbook使用,示例： ansible-playbook test.yml -e “hosts=www user=magedu” register把任务的输出定义为变量，然后用于其他任务 示例: 1234tasks:- shell: /usr/bin/foo register: foo_result ignore_errors: True 示例：使用setup变量123456## 示例：var.yml- hosts: websrvs remote_user: root tasks: - name: create log file file: name=/var/log/ &#123;&#123; ansible_fqdn &#125;&#125; state=touch ansible-playbook var.yml 示例：变量12345678## 示例：var.yml- hosts: websrvs remote_user: root tasks: - name: install package yum: name=&#123;&#123; pkname &#125;&#125; state=present ansible-playbook –e pkname=httpd var.yml 示例：变量1234567891011121314## 示例：var.yml- hosts: websrvs remote_user: rootvars: - username: user1 - groupname: group1tasks: - name: create group group: name=&#123;&#123; groupname &#125;&#125; state=present - name: create user user: name=&#123;&#123; username &#125;&#125; state=presentansible-playbook var.ymlansible-playbook -e &quot;username=user2 groupname=group2” var2.yml 变量 主机变量: 可以在inventory中定义主机时为其添加主机变量以便于在playbook中使用 示例： 123[websrvs]www1.magedu.com http_port&#x3D;80 maxRequestsPerChild&#x3D;808www2.magedu.com http_port&#x3D;8080 maxRequestsPerChild&#x3D;909 组变量: 组变量是指赋予给指定组内所有主机上的在playbook中可用的变量 示例： 1234567[websrvs]www1.magedu.comwww2.magedu.com[websrvs:vars]ntp_server=ntp.magedu.comnfs_server=nfs.magedu.com 示例：变量 普通变量 123[websrvs]192.168.99.101 http_port=8080 hname=www1192.168.99.102 http_port=80 hname=www2 公共（组）变量 1234567[websvrs:vars]http_port=808mark=&quot;_&quot;[websrvs]192.168.99.101 http_port=8080 hname=www1192.168.99.102 http_port=80 hname=www2ansible websvrs –m hostname –a ‘name=&#123;&#123; hname &#125;&#125;&#123;&#123; mark &#125;&#125;&#123;&#123; http_port &#125;&#125;’ 命令行指定变量： 1ansible websvrs –e http_port=8000 –m hostname –a&#x27;name=&#123;&#123; hname &#125;&#125;&#123;&#123; mark &#125;&#125;&#123;&#123; http_port &#125;&#125;&#x27; 使用变量文件 1234567891011121314151617# cat vars.ymlvar1: httpdvar2: nginx#cat var.yml- hosts: web remote_user: root vars_files: - vars.yml tasks: - name: create httpd log file: name=/app/&#123;&#123; var1 &#125;&#125;.log state=touch - name: create nginx log file: name=/app/&#123;&#123; var2 &#125;&#125;.log state=touch hostname app_81.magedu.com hostname 不支持&quot;_&quot;,认为&quot;_&quot;是非法字符hostnamectl set-hostname app_80.magedu.com 可以更改主机名 变量 组嵌套: inventory中，组还可以包含其它的组，并且也可以向组中的主机指定变量。这些变量只能在ansible-playbook中使用，而ansible命令不支持 示例： 1234567891011121314[apache]httpd1.magedu.comhttpd2.magedu.com[nginx]ngx1.magedu.comngx2.magedu.com[websrvs:children]apachenginx[webservers:vars]ntp_server=ntp.magedu.com invertory参数 invertory参数：用于定义ansible远程连接目标主机时使用的参数，而非传递给playbook的变量1234567891011 ansible_ssh_host ansible_ssh_port ansible_ssh_user ansible_ssh_pass ansbile_sudo_pass示例： cat /etc/ansible/hosts [websrvs] 192.168.0.1 ansible_ssh_user=root ansible_ssh_pass=magedu 192.168.0.2 ansible_ssh_user=root ansible_ssh_pass=magedu invertory参数 inventory参数: ansible基于ssh连接inventory中指定的远程主机时，还可以通过参数指定其交互方式；这些参数如下所示：12345678910111213141516171819202122232425262728293031323334353637383940414243ansible_ssh_hostThe name of the host to connect to, if different from the alias you wishto give to it.ansible_ssh_portThe ssh port number, if not 22ansible_ssh_userThe default ssh user name to use.ansible_ssh_passThe ssh password to use (this is insecure, we strongly recommendusing --ask-pass or SSH keys)ansible_sudo_passThe sudo password to use (this is insecure, we strongly recommendusing --ask-sudo-pass)ansible_connectionConnection type of the host. Candidates are local, ssh or paramiko.The default is paramiko before Ansible 1.2, and &#x27;smart&#x27; afterwards whichdetects whether usage of &#x27;ssh&#x27; would be feasible based on whetherControlPersist is supported.ansible_ssh_private_key_filePrivate key file used by ssh. Useful if using multiple keys and you don&#x27;t want to use SSH agent.ansible_shell_typeThe shell type of the target system. By default commands are formattedusing &#x27;sh&#x27;-style syntax by default. Setting this to &#x27;csh&#x27; or &#x27;fish&#x27; will causecommands executed on target systems to follow those shell&#x27;s syntax instead.ansible_python_interpreterThe target host python path. This is useful for systems with morethan one Python or not located at &quot;/usr/bin/python&quot; such as \\*BSD, or where /usr/bin/pythonis not a 2.X series Python. We do not use the &quot;/usr/bin/env&quot; mechanism as that requires the remote user&#x27;spath to be set right and also assumes the &quot;python&quot; executable is named python,where the executable mightbe named something like &quot;python26&quot;.ansible\\_\\*\\_interpreterWorks for anything such as ruby or perl and works just like ansible_python_interpreter.This replaces shebang of modules which will run on that host. ansible配置不同系统的nginx进程数 要求：根据系统CPU核数修改nginx进程数（默认auto） 1lscpu #可以查看系统cpu核数 模板 templates 文本文件，嵌套有脚本（使用模板编程语言编写） 借助模板生成真正的文件 Jinja2语言，使用字面量，有下面形式 字符串：使用单引号或双引号 数字：整数，浮点数 列表：[item1, item2, …] 元组：(item1, item2, …) 字典：{key1:value1, key2:value2, …} 布尔型：true/false 算术运算：+, -, *, /, //, %, ** 比较操作：==, !=, &gt;, &gt;=, &lt;, &lt;= 逻辑运算：and，or，not 流表达式：For，If，When Jinja2相关字面量 表达式最简单的形式就是字面量。字面量表示诸如字符串和数值的 Python对象。如“Hello World”双引号或单引号中间的一切都是字符串。 无论何时你需要在模板中使用一个字符串（比如函数调用、过滤器或只是包含或继承一个模板的参数），如4242.23 数值可以为整数和浮点数。如果有小数点，则为浮点数，否则为整数。在Python 里， 42 和 42.0 是不一样的 逻辑运算符1234567891011121314151617181920212223242526272829对于 if 语句，在 for 过滤或 if 表达式中，它可以用于联合多个表达式and 如果左操作数和右操作数同为真，返回 trueor 如果左操作数和右操作数有一个为真，返回 truenot 对一个表达式取反（见下）(expr) 表达式组你可以容易地在 for循环中用列表和元组创建一个链接的列表 &lt;ul&gt; &#123;% for href, caption in [(&#x27;index.html&#x27;, &#x27;Index&#x27;), (&#x27;about.html&#x27;, &#x27;About&#x27;), (&#x27;downloads.html&#x27;,&#x27;Downloads&#x27;)] %&#125; &lt;li&gt;&lt;a href=&quot;&#123;&#123; href &#125;&#125;&quot;&gt;&#123;&#123; caption &#125;&#125;&lt;/a&gt;&lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt; (&#x27;tuple&#x27;, &#x27;of&#x27;, &#x27;values&#x27;):元组与列表类似，只是你不能修改元组。如果元组中只有一个项，你需要以逗号结尾它。元组通常用于表示两个或更多元素的项。更多细节见上面的例子 &#123;&#x27;dict&#x27;: &#x27;of&#x27;, &#x27;key&#x27;: &#x27;and&#x27;, &#x27;value&#x27;: &#x27;pairs&#x27;&#125;:Python 中的字典是一种关联键和值的结构。键必须是唯一的，并且键必须只有一个 值。字典在模板中很少使用，罕用于诸如 xmlattr() 过滤器之类 true / false: true 永远是 true ，而 false 始终是 false template 的使用template功能：根据模块文件动态生成对应的配置文件 123456789101112131415161718 &gt; template文件必须存放于templates目录下，且命名为 .j2 结尾 &gt; yaml/yml 文件需和templates目录平级，目录结构如下： ./ ├── temnginx.yml └── templates └── nginx.conf.j2``` ### template示例示例：利用template 同步nginx配置文件```yml## 准备templates/nginx.conf.j2文件# vim temnginx.yml- hosts: websrvs remote_user: root tasks: - name: template config to remote hosts template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf ansible-playbook temnginx. Playbook中template变更替换修改文件nginx.conf.j2 下面行为 12345678worker_processes &#123;&#123; ansible_processor_vcpus &#125;&#125;;cat temnginx2.yml- hosts: websrvs remote_user: root tasks: - name: template config to remote hosts template: src&#x3D;nginx.conf.j2 dest&#x3D;&#x2F;etc&#x2F;nginx&#x2F;nginx.conf ansible-playbook temnginx2.yml Playbook中template算术运算算法运算：示例： 123# vim nginx.conf.j2worker_processes &#123;&#123; ansible_processor_vcpus**2 &#125;&#125;;worker_processes &#123;&#123; ansible_processor_vcpus+2 &#125;&#125;; when 实现条件判断条件测试:如果需要根据变量、facts或此前任务的执行结果来做为某task执行与否的前提时要用到条件测试,通过when语句实现，在task中使用，jinja2的语法格式 when语句 在task后添加when子句即可使用条件测试；when语句支持Jinja2表达式语法 示例：1234tasks: - name: &quot;shutdown RedHat flavored systems&quot; command: /sbin/shutdown -h now when: ansible_os_family == &quot;RedHat&quot; 当系统属于红帽系列,执行command模块 when语句中还可以使用Jinja2的大多”filter”，例如要忽略此前某语句的错误并基于其结果(failed或者success)运行后面指定的语句，可使用类似如下形式：12345678910tasks: - command: /bin/false register: result ignore_errors: True - command: /bin/something when: result|failed - command: /bin/something_else when: result|success - command: /bin/still/something_else when: result|skipped 此外，when语句中还可以使用facts或playbook中定义的变量示例：when条件判断12345678910111213- hosts: websrvs remote_user: root tasks: - name: add group nginx tags: user user: name=nginx state=present - name: add user nginx user: name=nginx state=present group=nginx - name: Install Nginx yum: name=nginx state=present - name: restart Nginx service: name=nginx state=restarted when: ansible_distribution_major_version == &quot;6&quot; 示例：when条件判断1234567tasks: - name: install conf file to centos7 template: src=nginx.conf.c7.j2 dest=/etc/nginx/nginx.conf when: ansible_distribution_major_version == &quot;7&quot; - name: install conf file to centos6 template: src=nginx.conf.c6.j2 dest=/etc/nginx/nginx.conf when: ansible_distribution_major_version == &quot;6&quot; 迭代：with_items迭代：当有需要重复性执行的任务时，可以使用迭代机制 对迭代项的引用，固定变量名为”item” 要在task中使用with_items给定要迭代的元素列表 列表格式： 字符串 字典 示例 123456# 示例： 创建用户- name: add several users user: name=&#123;&#123; item &#125;&#125; state=present groups=wheel #&#123;&#123; item &#125;&#125; 系统自定义变量 with_items: # 定义&#123;&#123; item &#125;&#125; 的值和个数 - testuser1 - testuser2 上面语句的功能等同于下面的语句： 1234- name: add user testuser1 user: name=testuser1 state=present groups=wheel- name: add user testuser2 user: name=testuser2 state=present groups=wheel with_items中可以使用元素还可为hashes123456## 示例：- name: add several users user: name=&#123;&#123; item.name &#125;&#125; state=present groups=&#123;&#123; item.groups &#125;&#125; with_items: - &#123; name: &#x27;testuser1&#x27;, groups: &#x27;wheel&#x27; &#125; - &#123; name: &#x27;testuser2&#x27;, groups: &#x27;root&#x27; &#125; ansible的循环机制还有更多的高级功能，具体请参见官方文档http://docs.ansible.com/playbooks_loops.html 示例：迭代示例：将多个文件进行copy到被控端 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148---- hosts: testsrv remote_user: root tasks - name: Create rsyncd config copy: src=&#123;&#123; item &#125;&#125; dest=/etc/&#123;&#123; item &#125;&#125; with_items: - rsyncd.secrets - rsyncd.conf## 示例：迭代- hosts: websrvs remote_user: root tasks: - name: copy file copy: src=&#123;&#123; item &#125;&#125; dest=/tmp/&#123;&#123; item &#125;&#125; with_items: - file1 - file2 - file3 - name: yum install httpd yum: name=&#123;&#123; item &#125;&#125; state=present with_items: - apr - apr-util - httpd## 示例：迭代- hosts：websrvs remote_user: root tasks - name: install some packages yum: name=&#123;&#123; item &#125;&#125; state=present with_items: - nginx - memcached - php-fpm## 示例：迭代嵌套子变量- hosts：websrvs remote_user: root tasks: - name: add some groups group: name=&#123;&#123; item &#125;&#125; state=present with_items: - group1 - group2 - group3 - name: add some users user: name=&#123;&#123; item.name &#125;&#125; group=&#123;&#123; item.group &#125;&#125; state=present with_items: - &#123; name: &#x27;user1&#x27;, group: &#x27;group1&#x27; &#125; - &#123; name: &#x27;user2&#x27;, group: &#x27;group2&#x27; &#125; - &#123; name: &#x27;user3&#x27;, group: &#x27;group3&#x27; &#125;## with_itmes 嵌套子变量示例---- hosts: testweb remote_user: root tasks: - name: add several users user: name=&#123;&#123; item.name &#125;&#125; state=present groups=&#123;&#123; item.groups &#125;&#125; with_items: - &#123; name: &#x27;testuser1&#x27; , groups: &#x27;wheel&#x27;&#125; - &#123; name: &#x27;testuser2&#x27; , groups: &#x27;root&#x27;&#125;## Playbook字典 with_items- name: 使用ufw模块来管理哪些端口需要开启 ufw: rule: “&#123;&#123; item.rule &#125;&#125;” port: “&#123;&#123; item.port &#125;&#125;” proto: “&#123;&#123; item.proto &#125;&#125;” with_items: - &#123; rule: &#x27;allow&#x27;, port: 22, proto: &#x27;tcp&#x27; &#125; - &#123; rule: &#x27;allow&#x27;, port: 80, proto: &#x27;tcp&#x27; &#125; - &#123; rule: &#x27;allow&#x27;, port: 123, proto: &#x27;udp&#x27; &#125;- name: 配置网络进出方向的默认规则 ufw: direction: &quot;&#123;&#123; item.direction &#125;&#125;&quot; policy: &quot;&#123;&#123; item.policy &#125;&#125;&quot; state: enabled with_items: - &#123; direction: outgoing, policy: allow &#125; - &#123; direction: incoming, policy: deny &#125;## Playbook中template for if when循环&#123;% for vhost in nginx_vhosts %&#125;server &#123; #重复执行server代码listen &#123;&#123; vhost.listen | default(&#x27;80 default_server&#x27;) &#125;&#125;;&#123;% if vhost.server_name is defined %&#125;server_name &#123;&#123; vhost.server_name &#125;&#125;;&#123;% endif %&#125;&#123;% if vhost.root is defined %&#125;root &#123;&#123; vhost.root &#125;&#125;;&#123;% endif %&#125;&#123;% endfor %&#125;### 示例 temnginx.yml---- hosts: testweb remote_user: root vars: # 调用变量 nginx_vhosts: - listen: 8080 #列表 键值对## templates/nginx.conf.j2&#123;% for vhost in nginx_vhosts %&#125; server &#123; listen &#123;&#123; vhost.listen &#125;&#125;&#125;&#123;% endfor %&#125;## 生成的结果server &#123; listen 8080&#125;### 示例 temnginx.yml---- hosts: mageduweb remote_user: root vars: nginx_vhosts: - web1 - web2 - web3 tasks: - name: template config template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf## templates/nginx.conf.j2&#123;% for vhost in nginx_vhosts %&#125;server &#123; listen &#123;&#123; vhost &#125;&#125;&#125;&#123;% endfor %&#125;## 生成的结果：server &#123; listen web1&#125;server &#123; listen web2&#125;server &#123; listen web3&#125;","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://shizhonggan.github.io/categories/Ansible/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://shizhonggan.github.io/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"Mininet安装与使用问题","slug":"SDN/mininet01","date":"2021-08-12T02:24:04.000Z","updated":"2022-05-07T10:07:50.325Z","comments":true,"path":"2021/08/12/SDN/mininet01/","link":"","permalink":"http://shizhonggan.github.io/2021/08/12/SDN/mininet01/","excerpt":"","text":"安装12345678910111213141516# 升级pip3,避免后续安装报错吗，高版本的pip放弃了对2.7和3.5版本的支持，因此需要降级wget https://bootstrap.pypa.io/pip/3.5/get-pip.pypython3 get-pip.py git clone git://github.com/mininet/mininetcd mininet git tag # list available versionsgit checkout -b mininet-2.3.0 2.3.0 # cd ..mininet/util/install.sh -s mydir -amininet/util/install.sh [options] -a 全部安装 -nfv 仅安装mininet, OpenFlow, OVS -s mydir 将source/build放在指定目录 指定python版本Mininet 2.3.0 及更高版本支持 Python 3 和 Python 2 12sudo PYTHON=python2 mininet/util/install.sh -n # install Python 2 Mininetsudo PYTHON=python3 mininet/util/install.sh -n # install Python 3 Mininet 查看mininet对应的python版本 1234echo py sys.version | sudo mn -v output mininet&gt; 3.5.2 (default, Jan 26 2021, 13:30:48) [GCC 5.4.0 20160609] mininet&gt; 可能存在的报错通过mininet面板设计拓扑，保存为py脚本时会报错，如下所示： 1234567mininet&gt; Exception in Tkinter callbackTraceback (most recent call last): File &quot;/usr/lib/python3.5/tkinter/__init__.py&quot;, line 1553, in __call__ return self.func(*args) File &quot;miniedit.py&quot;, line 1707, in exportScript f.write(&quot;#!/usr/bin/env python\\n&quot;)TypeError: a bytes-like object is required, not &#x27;str&#x27; 只需修改miniedit.py脚本的第1702行，f=open(“fileName”,”wb”) 改成 f=open(“fileName”,”w”) 连接远程控制器，没有流表初次安装使用mininet启动基本拓扑，都会生成默认流表，网络时全连通的。但在后续的使用过程中，对流表进行添加、删除等操作，会导致再次启动新的默认网络拓扑不再有默认的全连通网络。此时，需要手动添加 123456789101112131415## 为所有交换机添加端口1和端口2的操作---两个交换机公共操作dpctl add-flow in_port=1,actions=output:2 dpctl add-flow in_port=2,actions=output:1## 为交换机之间端口提供交互---只操作s1(因为只有s1有端口3)sh ovs-ofctl add-flow s1 in_port=1,actions=output:2,3sh ovs-ofctl add-flow s1 in_port=3,actions=output:1,2sh ovs-ofctl add-flow s1 in_port=2,actions=output:1,3## mininet命令mininet&gt; dpctl add-flow in_port=1,actions=output:2,3mininet&gt; dpctl add-flow in_port=2,actions=output:1,3mininet&gt; dpctl add-flow in_port=3,actions=output:1,2## 为交换机2添加丢弃流表，使得两个交换机不可通信（在前面互通基础上实现）mininet&gt; sh ovs-ofctl del-flows s2 in_port=1 删除原有流表mininet&gt; sh ovs-ofctl add-flow s2 in_port=1,actions=drop 添加丢弃流表 MININET OpenFlow13协议支持问题Steps to Reproduce: set OpenFlow protocol to 1.3 on bridge br0 (done during boot in OpenShift) 12# ovs-vsctl set bridge br0 protocols=OpenFlow13# sudo mn --switch=ovs,protocols=OpenFlow13 # 启动网络之前提前设置协议参数 try to dump flows 1# ovs-ofctl dump-flows br0 123456789101112## 报错Actual results:2015-11-04T17:45:56Z|00001|vconn|WARN|unix:/var/run/openvswitch/br0.mgmt: version negotiation failed (we support version 0x01, peer supports version 0x04)ovs-ofctl: br0: failed to connect to socket (Broken pipe)Expected results:OFPST_FLOW reply (OF1.3) (xid=0x2): cookie=0x0, duration=1299.155s, table=0, n_packets=0, n_bytes=0, dl_src=01:00:00:00:00:00/01:00:00:00:00:00 actions=drop ...Additional info:this currently works when specifying the version 1# ovs-ofctl dump-flows br0 --protocols=OpenFlow13 原因： ovs-ofctl allows you to set many protocols on the command line, like –protocols=OpenFlow10,OpenFlow13. That will work for bridges that only support OpenFlow13. The problem with using any version by default is that mod-flow has different semantics depending on the version. So, instead of behaving differently whenever you use ovs-ofctl mod-flow, the tool defaults to OpenFlow10 only. Why not use an alias like ovs-ofctl13=’ovs-ofctl –protocols=OpenFlow13’? 个人总结：即使采用 mn –protocols=OpenFlow10,OpenFlow13 这种方式也会出现上述报错问。可以先不指定协议直接启动一个网络拓扑，此时OpenFlow协议默认的1.0。然后再mininet命令行中输入命令进行协议修改，如： mininet&gt; dpctl dump-flows -O OpenFlow13 。","categories":[{"name":"Mininet","slug":"Mininet","permalink":"http://shizhonggan.github.io/categories/Mininet/"}],"tags":[{"name":"网络架构","slug":"网络架构","permalink":"http://shizhonggan.github.io/tags/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/"},{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/tags/SDN/"},{"name":"OVS","slug":"OVS","permalink":"http://shizhonggan.github.io/tags/OVS/"}]},{"title":"网络技术基础知识[持续更新]","slug":"SDN/basicnetwork","date":"2021-07-01T08:18:00.000Z","updated":"2022-05-07T10:07:50.325Z","comments":true,"path":"2021/07/01/SDN/basicnetwork/","link":"","permalink":"http://shizhonggan.github.io/2021/07/01/SDN/basicnetwork/","excerpt":"","text":"IPv4192.168.1.1 由32位点分十进制表示，如下图所示： IP地址由两部分组成： 网络ID和主机ID 网络ID：用于区分不同的子网 主机ID：用于区分同一子网得不同主机 掩码：用于区分网络ID和主机ID,前24位是1可以表示为/24,如下图所示： 使用方法： 网络地址 All Hosts=0广播地址 All Hosts=1主机地址数量 2^n-2(n=32-掩码)&lt;网络地址+1，广播地址-1&gt; IPv4即将枯竭，解决方法： VLSM可变长子网掩码 私网IP NAT 最终解决方法IPv6 例题：10.102.22.9/22 网络地址：10.102.20.0 广播地址：10.102.23.255 主机地址范围：&lt;10.102.20.1, 10.102.23.254&gt; 5G 技术特点网络通信包括：无线通信（wifi, 2G-5G） 和 有线通信（双绞线, 光纤等）。由于不同的传播介质，有线的通信能力远远大于无线通信。 光速=波长×频率 5G特点 高频段（毫米波）：频率越高，越趋向直线传播，传输过程衰减越大，覆盖范围越小，成本越高 微基站：辐射更小，天线长度与波长成正比（天线长度 = 波长/10~波长/4），因此5G天线非常小。可以实现MASSIVE MIMO，5G天线阵列可以实现。 波束赋形，将光源聚集到一个设备上的技术。波束赋形的物理学原理，其实就是波的干涉现象。百度百科上定义如下：频率相同的两列波叠加，使某些区域的振动加强，某些区域的振动减弱，而且振动加强的区域和振动减弱的区域相互隔开。 D2D(device to device)以往信令包和数据包都是通过基站，5G是信令包通过基站数据再设备中间互相传输。 BGP协议[学了还是不懂啥玩意]基本概念BGP概述 外部网关协议 使用TCP作为传输层协议 支持CIDR 增量更新 路径矢量路由协议 无环路 路由策略丰富 可防止路由震荡 易于扩展 自治系统AS: 由同一个技术管理机构管理、使用统一选路策略的一些路由器的集合。 工作原理-报文类型 Open报文： 协商BGP参数 Update报文： 交换路由信息 Keepalive报文：保持邻居关系 Notification报文：差错通知 Route-Refresh报文：用于改变路由策略后请求对等体重新发送路由信息 工作原理-状态机 视频学习链接 SDN Underlay 与 OverlayUnderlay: 现实的物理基础层网络设备。-数据中心基础转发架构的网络。 以太网最初设计的时候就是一个分布式的网络架构，没有中心控制节点，网络中的节点通过协议传递学习网络的可达性信息。 underlay就是数据中心场景的基础物理设施，保证任何两个点路由可达，其中包含了传统的网络技术。 Overlay: 一个基于物理网络之上构建的逻辑网络。 verlay是在网络技术领域指的是一种网络架构上叠加的虚拟化技术模式，Overlay网络也是一个网络，不过是建立在Underlay网络之上的网络。 overlay网络节点通过虚拟或者逻辑链路进行通信，其实现基于ip技术的基础网络为主。 Overlay网络技术多种多样，一般采用TRILL、VxLan、GRE、NVGRE等隧道技术。 underlay和overlay是互相独立的，其中underlay为overlay提供基础承载； underlya和overlay是相对而言的，谁为对方提供基础网络架构，谁就是underlay，相反另外的一方则为overlay； 提到overlay是近几年数据中心为网络兴起的概念，但是对于传统网络而言实际上早一些类似概念。 传统网络：l2vpn、l3vpn、qinq、macinmac等隧道技术就是传统的overlay网络技术；数据中心网络：以vxlan、gre、nvgre、trill等新兴隧道技术为基础构建出来的vpc网络；2 当前网络架构主流技术对比flexe是一种在ip传送网借鉴otn网络的一种无ip交换的更快的1层网络技术，可以理解成把多个节点调度打通看做一根光纤，无ip交换自然更快；mpls和sr这些基于二三层之间的隧道技术，个人理解可以理解成逻辑接口，提供的是一个跨多个节点的专线管道；vxlan、gre、nvgre、trill是基于ip技术打造新兴隧道技术，本质而言，他们对于每个具体的设备仍然是一个逻辑接口；数据中心场景下基于vxlan、gre等不同底层承载新建的逻辑网络，也就是我们常说的vpc网络，是真正意义的逻辑network；l2vpn和l3vpn网路构建出来的也是一个逻辑network,通常承载在mpls的运营商传统网络场景，但是sdwan的出现改变了这一个格局。 路由器硬件设计要考虑八个方面： FIB表容量 协议特性 高可靠性 快速收敛 QOS 吞吐量 低功耗 带宽 RFC1925: Good, fast, cheap, pick any two, but you can’t have all three 网络传输中的三张表，MAC地址表、ARP缓存表以及路由表 路由表：目的地址、网络掩码、下一条ip地址、出接口、优先级、cost路由开销 arp表：ip地址、对应的mac地址、ip地址类型 mac表：mac地址、出端口 详细参考：https://www.cnblogs.com/dapaitou2006/p/6391472.html","categories":[{"name":"网络","slug":"网络","permalink":"http://shizhonggan.github.io/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://shizhonggan.github.io/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"软件定义网络（SDN）学习笔记(6)--Floodlight","slug":"SDN/SDN07_Floodlight","date":"2021-06-03T05:11:04.000Z","updated":"2022-05-07T10:07:50.324Z","comments":true,"path":"2021/06/03/SDN/SDN07_Floodlight/","link":"","permalink":"http://shizhonggan.github.io/2021/06/03/SDN/SDN07_Floodlight/","excerpt":"","text":"安装123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051## 通用版本java 卸载dpkg -l |grep -i jdkapt-get purge openjdk*apt-get purge icedtea-* openjdk-*## 安装1（此方法不行）sudo apt-get install build-essential ant python-devsudo add-apt-repository ppa:webupd8team/javasudo apt-get updatesudo apt-get install oracle-java8-installer## 安装2sudo mkdir /usr/lib/jvmsudo tar -zxvf jdk-8u181-linux-x64.tar.gz -C /usr/lib/jvm# sudo vim ~/.bashrcsudo vim /etc/profile #set oracle jdk environment export JAVA_HOME=/home/ec2-user/jdk/jdk1.8.0_211 ## 这里要注意目录要换成自己解压的jdk 目录 export JRE_HOME=$&#123;JAVA_HOME&#125;/jre export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH source /etc/profile ## 设置默认jdk(可不操作)sudo update-alternatives --install /usr/bin/java java /usr/lib/jvm/jdk1.8.0_181/bin/java 300 sudo update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/jdk1.8.0_181/bin/javac 300 sudo update-alternatives --install /usr/bin/jar jar /usr/lib/jvm/jdk1.8.0_181/bin/jar 300 sudo update-alternatives --install /usr/bin/javah javah /usr/lib/jvm/jdk1.8.0_181/bin/javah 300 sudo update-alternatives --install /usr/bin/javap javap /usr/lib/jvm/jdk1.8.0_181/bin/javap 300## 执行sudo update-alternatives --config java## 检查java -versionjavac -version## Floodlightsudo apt-get install build-essential default-jdk ant python-devsudo apt-get install gitgit clone -b v1.1 git://github.com/floodlight/floodlight.git cd floodlight# git pull origin master # git submodule init # git submodule update antant eclipse## 启动java -jar target/floodlight.jar","categories":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/categories/SDN/"}],"tags":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/tags/SDN/"},{"name":"Floodlight","slug":"Floodlight","permalink":"http://shizhonggan.github.io/tags/Floodlight/"}]},{"title":"软件定义网络（SDN）学习笔记(5)--OpenDaylight控制器","slug":"SDN/SDN05_OpenDaylight","date":"2021-05-31T05:11:04.000Z","updated":"2022-05-07T10:07:50.324Z","comments":true,"path":"2021/05/31/SDN/SDN05_OpenDaylight/","link":"","permalink":"http://shizhonggan.github.io/2021/05/31/SDN/SDN05_OpenDaylight/","excerpt":"","text":"SDN学习目录 SDN学习笔记(0)–wireshark抓包分析 SDN学习笔记(1)–iPerf和Netperf性能测试 SDN学习笔记(2)–Scapy交互式数据处理与Postman HTTP请求测试 SDN学习笔记(3)–OVS系统架构 SDN学习笔记(5)–OpenDaylight控制器 1 OpenDaylight介绍控制器是给交换机下发流表的设备，最常见的控制器是OpenDaylight，简称ODL，下面首先安装一个ODL控制器，看看控制器给交换机下发的原汁原味的流表是怎么样的。 心得：控制器还是属ODL好安装啊…界面丰富，新手上路不需要担心太多东西，就是软件太大。 2 ODL控制器安装123456789101112131415161718192021222324252627282930313233343536## 安装JAVAapt install openjdk-8-jdk## 配置环境vim /etc/environment # 进入环境变量配置文件，在第二行加入java的环境变量。 JAVA_HOME=&quot;/usr/lib/jvm/java-8-openjdk-amd64&quot;## 下载ODL编译好的文件wget https://nexus.opendaylight.org/content/groups/public/org/opendaylight/integration/distribution-karaf/0.6.4-Carbon/distribution-karaf-0.6.4-Carbon.tar.gz## 解压文件tar zvxf distribution-karaf-0.6.4-Carbon.tar.gz## 配置文件/etc/org.apache.karaf.management.cfg # Host for RMI registry rmiRegistryHost = 0.0.0.0 # Port number for RMI server connection rmiServerPort = 44444 # Host for RMI server rmiServerHost = 0.0.0.0## tmux 启动 odltmux unset TMOUT./bin/karaffeature:install odl-l2switch-switch-ui odl-openflowplugin-flow-services-ui odl-mdsal-apidocs odl-dluxapps-applications odl-faas-all## 上面就行，下面这个或许也可以，同时要遵守顺序feature:install odl-restconffeature:install odl-l2switch-switchfeature:install odl-openflowplugin-allfeature:install odl-dlux-allfeature:install odl-mdsal-allfeature:install odl-adsal-northbound ODL命令： 1234567log:display|more # 控制台查看日志feature:list # 列出所有组件feature:list -i # 列出已经安装的feature:list -i|grep odl-restconf # 确认某个组件安装# rm -rf data # 删除data目录，并# ./bin/karaf clean # 清除组件重新进入karaf控制台 验证OpenDaylight基本功能 12# mn --controller=remote,ip=119.255.243.31,port=6633mininet&gt;pingall 登录web界面，查看是否有拓扑http://:8181/index.html 用户名：admin 密码：admin 下发流表YANG UI是OpenDaylight中一款基于DLUX的应用，旨在简化、激励应用的开发与测试。YANG UI通过动态封装、调用YANG模型和相关REST APIs，生成并展示一个简单的UI界面。开发人员可以通过API请求获取交换机信息，并且以JSON格式展示。YANG UI主要面向上层应用开发，为应用开发人员提供了很多相关工具，有效的节约了开发人员的时间。 OpenFlow1.0协议处理数据包的流程相对简单，因为1.0版本只支持单流表。交换机接收到数据包后解析数据包，数据包解析后就开始匹配，从table 0 开始匹配，如果匹配成功则对该数据包执行相应的动作，更新相应的计数器。如果没有找到匹配项则将数据包交给控制器。 OpenFlow1.3协议支持多流表匹配，即一个交换机只会有多个流表，因此数据包处理过程相对复杂。首先解析进入设备的报文，然后从table 0开始匹配，按照优先级高低依次匹配该流表中的流表项，一个报文在一个流表中只会匹配上一条流表项。通常根据报文的类型，报文头的字段例如源MAC地址、目的MAC地址、源IP地址、目的IP地址等进行匹配，大部分匹配还支持掩码进行更精确、灵活的匹配。也可以通过报文的入端口或元数据信息来进行报文的匹配，一个流表项中可以同时存在多个匹配项，一个报文需要同时匹配流表项中所有匹配项才能匹配该流表项。报文匹配按照现有的报文字段进行，比如前一个流表通过apply actions改变了该报文的某个字段，则下一个表项按修改后的字段进行匹配。如果匹配成功，则按照指令集里的动作更新动作集，或更新报文/匹配集字段，或更新元数据和计数器。根据指令是否继续前往下一个流表，不继续则终止匹配流程执行动作集，如果指令要求继续前往下一个流表则继续匹配，下一个流表的ID需要比当前流表ID大。当报文匹配失败了，如果存在无匹配流表项（table miss）就按照该表项执行指令，一般是将报文转发给控制器、丢弃或转发给其他流表。如果没有table miss表项则默认丢弃该报文。 YANG UI是OpenDaylight中一款基于DLUX的应用，旨在简化、激励应用的开发与测试。YANG UI通过动态封装、调用YANG模型和相关REST APIs，生成并展示一个简单的UI界面。开发人员可以通过API请求获取交换机信息，并且以JSON格式展示。YANG UI主要面向上层应用开发，为应用开发人员提供了很多相关工具，有效的节约了开发人员的时间。 OpenFlow1.0协议处理数据包的流程相对简单，因为1.0版本只支持单流表。交换机接收到数据包后解析数据包，数据包解析后就开始匹配，从table 0 开始匹配，如果匹配成功则对该数据包执行相应的动作，更新相应的计数器。如果没有找到匹配项则将数据包交给控制器。 OpenFlow1.3协议支持多流表匹配，即一个交换机只会有多个流表，因此数据包处理过程相对复杂。首先解析进入设备的报文，然后从table 0开始匹配，按照优先级高低依次匹配该流表中的流表项，一个报文在一个流表中只会匹配上一条流表项。通常根据报文的类型，报文头的字段例如源MAC地址、目的MAC地址、源IP地址、目的IP地址等进行匹配，大部分匹配还支持掩码进行更精确、灵活的匹配。也可以通过报文的入端口或元数据信息来进行报文的匹配，一个流表项中可以同时存在多个匹配项，一个报文需要同时匹配流表项中所有匹配项才能匹配该流表项。报文匹配按照现有的报文字段进行，比如前一个流表通过apply actions改变了该报文的某个字段，则下一个表项按修改后的字段进行匹配。如果匹配成功，则按照指令集里的动作更新动作集，或更新报文/匹配集字段，或更新元数据和计数器。根据指令是否继续前往下一个流表，不继续则终止匹配流程执行动作集，如果指令要求继续前往下一个流表则继续匹配，下一个流表的ID需要比当前流表ID大。当报文匹配失败了，如果存在无匹配流表项（table miss）就按照该表项执行指令，一般是将报文转发给控制器、丢弃或转发给其他流表。如果没有table miss表项则默认丢弃该报文。 在Open vSwitch中，流表项作为ovs-ofctl的参数，采用“字段=值”的格式。如果有多个字段，可以用逗号分开，一些常见字段如下： 字段名称 说明 in_port=port 传递数据包的端口的OpenFlow端口编号 dl_vlan=vlan 数据包的VLAN Tag值，范围是0-4095，0xffff代表不包含VLAN Tag的数据包 dl_src=&lt;MAC&gt; dl_dst= &lt;MAC&gt; 匹配源或者目标的MAC地址 01:00:00:00:00:00/01:00:00:00:00:00 代表广播地址 00:00:00:00:00:00/01:00:00:00:00:00 代表单播地址 dl_type=ethertype 匹配以太网协议类型，其中： dl_type=0x0800 代表IPv4协议； dl_type=0x086dd 代表IPv6协议； dl_type=0x0806 代表ARP协议； nw_src=ip[/netmask] nw_dst=ip[/netmask] 当 dl_typ=0x0800 时，匹配源或者目标的IPv4地址，可以使IP地址或者域名 table=number 指定要使用的流表的编号，范围是0-254。在不指定的情况下，默认值为0。通过使用流表编号，可以创建或者修改多个Table中的Flow。 步骤一 通过miniedit.py 快速设计网络拓扑，并保存为topo1_1_3.py文件，如下图所示 步骤二 python3 topo1_1_3.py 执行文件，打开opendaylight web页面，可查看网络拓扑图如下所示 单机左侧，可查看Nodes 节点信息， Node id在下发流表过程中需要。点击Node Connectors可查看具体节点连接信息 展开“opendaylight-inventory rev.2013-08-19”,选择“config-&gt;nodes-&gt;node{id}-&gt;table{id}-&gt;flow{id}” 参数填写 “match&gt;ethernet-match&gt;ethernet-type”, 填写”type”为”0x0800”; “layer-3-match”选择”ipv4=match”使用IP匹配; 展开”layer-3-match”填写源IP地址和目的IP地址，如下图： “instuctions”后单击添加，选择”apply-actions-case”; “apply-actions”后单击添加，选择“drop-action-case”; 以上两个order都设置为0，如下图所示： 设置”priority”为27, “idle-timeout”为0, “hard-timeout”为0, “cookie”为100000000, “table_id”为0，如下图所示： 选择PUT，点击Send, 若发送成功，如下图所示： 执行命令查看流表 1sudo ovs-ofctl dump-flows s1 登录主机h1，执行如下命令向主机h2、h3发送数据包，测试连通性： 123scapy&gt;&gt;&gt; result,unanswered=sr(IP(dst=&quot;10.0.0.2&quot;,ttl=(3,10))/ICMP())&gt;&gt;&gt; result,unanswered=sr(IP(dst=&quot;10.0.0.3&quot;,ttl=(3,10))/ICMP()) 12scapy&gt;&gt;&gt; result,unanswered=sr(IP(dst=&quot;10.0.0.1&quot;,ttl=(3,10))/ICMP()) 12# ovs-ofctl del-flows s1 dl_type=0x0800,nw_src=10.0.0.1,nw_dst=10.0.0.2 # 删除下发的流表# ovs-ofctl dump-flows s1 # 可以查看流表已被删除","categories":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/categories/SDN/"}],"tags":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/tags/SDN/"},{"name":"OVS","slug":"OVS","permalink":"http://shizhonggan.github.io/tags/OVS/"},{"name":"OpenDaylight","slug":"OpenDaylight","permalink":"http://shizhonggan.github.io/tags/OpenDaylight/"}]},{"title":"AWS云平台SDK boto3(python)--自动化创建实例、创建挂载卷以及远程操作","slug":"Python/aws_boto3_paramiko","date":"2021-05-26T00:36:04.000Z","updated":"2022-05-07T10:07:50.316Z","comments":true,"path":"2021/05/26/Python/aws_boto3_paramiko/","link":"","permalink":"http://shizhonggan.github.io/2021/05/26/Python/aws_boto3_paramiko/","excerpt":"","text":"1 介绍Boto3是AWS python版的SDK，可以向python开发者在编写程序过程中使用Amazon S3和 Amazon EC2等服务。 Boto提供了简单的面向对象的API和基本的AWS相关服务。Boto3是最新版本，老版本例如boto2不建议使用。 这篇文章介绍了如何在本地windows环境下，进行AWS云服务的一些基本操作，例如创建实例创建、卷创建和挂载、资源状态查询、资源使用后的清理回收，以及通过paramiko远程操作实例。 2 安装环境 安装AWS CLI(Command Line Interface)AWS命令行接口(CLI)是一个统一的工具来管理的AWS服务。只需下载并完成配置，便可以从命令行控制多个AWS服务，并通过脚本实现对AWS云服务的自动化操作。 下载链接：https://aws.amazon.com/cli/ 可参考 https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html#guide-configuration 主要配置修改： 12345678## 修改 ~/.aws/credentials[default]aws_access_key_id = YOUR_KEY # 你的aws_secret_access_key = YOUR_SECRET## 修改 ~/.aws/config[default]region=cn-north-1a # 安装Boto3 12## python3pip install boto3 3 基本命令3.1 操作流程基本操作流程示例： 创建实例 查询实例状态 创建卷 查看卷状态 若实例与卷均已创建完成并可以使用，挂载卷到已创建的云主机 资源使用完毕，清理回收3.2 客户端和资源 boto3.client(“ec2”) 该命令主要可以进行EC2客户端的一些基本操作。例如：关联、挂载、创建、查询，取消、删除、修改等。 boto3.resource(“ec2”) 该命令主要可以进行EC2云服务中的各类资源的相关操作。该命令与client有交集的部分也有独立的一部分。 3.3 控制AWS代码123456789101112131415161718192021222324252627282930313233343536373839404142434445import boto3# 先调用以下两个ec2 = boto3.client(&quot;ec2&quot;) ec2_resource = boto3.resource(&quot;ec2&quot;) ## 创建实例，返回的是实例的详细信息createInstance = ec2_resource.create_instances( Placement=&#123; &quot;AvailabilityZone&quot;: &quot;cn-north-1b&quot;, &#125;, ImageId=&quot;ami-0c52e2685c7218558&quot;, # 可先从AWS console上查看 InstanceType=&quot;t2.micro&quot;, MaxCount=1, # 可同时创建多个, MinCount=1, KeyName=&quot;gsz&quot;, # 实现创建好的key pairs)instanceID = createInstance[0].id # 从返回的数据中得到实例的ID## 状态查询,是为了等待创建成功，状态可使用情况下进行下一步操作instance_state = ec2_resource.Instance(instanceID).state[&quot;Name&quot;] # 根据实例ID查询状态## 创建卷，此处貌似&quot;ec2&quot;和&quot;ec2_resource&quot;都具有创建卷的方法snap2vol = ec2.create_volume( AvailabilityZone= &quot;cn-north-1b&quot;, # 要与创建的实例相同 Encrypted=True, Size = 100, # 单位GiBs SnapshotId = &quot;snap-096b5af48e45fe262&quot; # 通过某个快照ID创建，如无则为常规卷)## 挂载卷volID = create_vol[&#x27;VolumeId&#x27;] # 获取卷IDattach_vol2 = ec2.attach_volume( ice=Device2, # 挂载路径 /dev/sdf InstanceId=InstanceID, # 实例ID VolumeId=volID, #卷ID)attach_state = ec2_resource.Volume(datavolID).attachments[0][&#x27;State&#x27;]## 删除资源instance = ec2_resource.Instance(instanceID)instance.terminate()volume = ec2_resource.Volume(vol_id)volume.delete() 3.4 远程操作云主机123456789101112131415161718import paramiko## 实例化SSHClinetsshc = paramiko.SSHClient()sshc.set_missing_host_key_policy(paramiko.AutoAddPolicy())sshc.connect(host, username=username,port=port,pkey=key)## 传文件sftp = sshc.open_sftp()localfile1 = &quot;path to your locoal file&quot;remotepath1 = &quot;path/file.name&quot;sftp.put(localfile1, remotepath1)sftp.close()commands = [ &quot;shell command list&quot;]for command in commands: stdin, stdout, stderr = sshc.exec_command(command) 参考资料Paramiko: https://www.cnblogs.com/xiao-apple36/p/9144092.html Boto3: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ec2.html#ec2","categories":[{"name":"AWS","slug":"AWS","permalink":"http://shizhonggan.github.io/categories/AWS/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://shizhonggan.github.io/tags/AWS/"},{"name":"boto3","slug":"boto3","permalink":"http://shizhonggan.github.io/tags/boto3/"},{"name":"paramiko","slug":"paramiko","permalink":"http://shizhonggan.github.io/tags/paramiko/"}]},{"title":"PyQt5 GUI应用程序开发常见问题","slug":"Python/PyQt5","date":"2021-05-20T01:39:04.000Z","updated":"2022-05-07T10:07:50.316Z","comments":true,"path":"2021/05/20/Python/PyQt5/","link":"","permalink":"http://shizhonggan.github.io/2021/05/20/Python/PyQt5/","excerpt":"","text":"安装设置12345678QtDesignerD:\\Programs\\anaconda3\\Library\\bin\\designer.exe$ProjectFileDir$pyUICD:\\Programs\\anaconda3\\Scripts\\pyuic5.exe$FileName$ -o $FileNameWithoutExtension$.py$FileDir$ 尺寸策略 sizePolicysizeHint (期望尺寸)对于大多数控件来说，sizeHint的值是只读的 1234self.textEdit.sizeHint().widght()self.pushButton.sizeHint().height()self.textEdit.minimumSizeHint().widght()self.textEdit.minimumSizeHint().height() Qlabel与伙伴关系信号与槽 signal &amp; slot信号：是由对象或控件发射出去的消息 按钮的单击事件 当单击按钮时，按钮就会向外部发送单击的消息，这些发送出去的信号需要一些代码来拦截，这些代码就是槽 槽：本质上是一个函数或方法 信号可以理解为事件，槽可以理解为事件函数 需要将信号和槽绑定 常见问题解决办法12# error: from PyQt5.QtWebEngineWidgets import *：ImportError: DLL load failedpip install PyQtWebEngine #","categories":[{"name":"开发","slug":"开发","permalink":"http://shizhonggan.github.io/categories/%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"PyQt5","slug":"PyQt5","permalink":"http://shizhonggan.github.io/tags/PyQt5/"},{"name":"python","slug":"python","permalink":"http://shizhonggan.github.io/tags/python/"}]},{"title":"Paramiko执行后台命令报错","slug":"Python/paramiko","date":"2021-05-20T01:39:04.000Z","updated":"2022-05-07T10:07:50.319Z","comments":true,"path":"2021/05/20/Python/paramiko/","link":"","permalink":"http://shizhonggan.github.io/2021/05/20/Python/paramiko/","excerpt":"","text":"1. 报错关键字 paramiko Exception ignored in: &lt;function BufferedFile.__del__ at 0x000001E62C28A048&gt; TypeError: ‘NoneType’ object is not callable 2. 代码12345import paramikosshc = paramiko.SSHClient()sshc.set_missing_host_key_policy(paramiko.AutoAddPolicy())sshc.connect(host, username=username,port=port,pkey=key)stdin1, stdout1, stderr1 = sshc.exec_command(&quot;setsid ...(省略)... &amp;&quot;) setsid是linux系统命令，如果再window下写的代码此处必然无法运行。可以先将setsid相关代码通过sshc.open_sftp()上传到服务端，然后通过sshc.exec_command(“python setsid.py”)运行脚本。 nohup 与 setsid 区别参考：http://www.tang-lei.com/2019/03/04/linux-nohup-setsid-使用区别/ nohup nohup命令的功能就是使用当前进程忽略hangup信号，从而继续执行。默认的标准输入输出都会被重定向到当前目录下的nohup.out文件里。一般我们配置在命令的末尾加上 &amp; 来配合使用。 可以通过 &gt;filename 2&gt;&amp;1 来重定向默认的输入输出, 如：”nohup minio server :9001 /mnt/test/ &gt; /var/log/minio_test.log 2&gt;&amp;1 &amp;”, 通过jobs 可以看到该进程的父进程是当前shell的进程号 作用说明：进程在后台执行；忽略hangup信号；重定向日志输出 &amp; &amp; 代表后台运行程序。如果终端退出，则该进程会结束。通常配合nohup和setsid使用 setsid setsid 就是set session id 的意思。表示该命令运行的进程是一个新的session。因此其父进程不属于当前终端。实际上setsid运行的进程，其父进程id(ppid)为1(init进程的id)。 如：”setsid minion server :9001 /mnt/test/ &gt; /var/log/minio_test.log &amp;”。注意：setsid输出重定向必须手动指定。 结论 由于nohup的父进程与当前的worker有关，当我们Ctrl+C的时候，也会把其给kill掉。而setsid的父进程是init,所以当我们退出worker的时候，并不会kill掉该服务 3. 输出123456789Exception ignored in: &lt;function BufferedFile.__del__ at 0x000001E62C28A048&gt;Traceback (most recent call last): File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paramiko\\file.py&quot;, line 66, in __del__ File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paramiko\\channel.py&quot;, line 1392, in close File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paramiko\\channel.py&quot;, line 991, in shutdown_write File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paramiko\\channel.py&quot;, line 963, in shutdown File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paramiko\\channel.py&quot;, line 1246, in _send_eof File &quot;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paramiko\\message.py&quot;, line 232, in add_intTypeError: &#x27;NoneType&#x27; object is not callable 报错原因 windows回车和linux回车存在差异,如下图是windows的回车，二linux不是。 nohup &amp; 命令执行完没有完全退出 shell命令存在错误 4. 解决方法1234567891011121314151617181920212223## main.pyimport paramikosshc = paramiko.SSHClient()sshc.set_missing_host_key_policy(paramiko.AutoAddPolicy())sshc.connect(host, username=username,port=port,pkey=key)sftp = sshc.open_sftp()localfile = &quot;cmd.py&quot;remotepath = &quot;/path/cmd.py&quot;sftp.put(localfile, remotepath)stdin, stdout1, stderr = sshc.exec_command(&quot;python &quot;+&quot;cmd.py&quot;) sshc.close()## cmd.pyimport osimport sysSnapID = &quot;snap-096b5af48e45fe262&quot;datapath = &quot;/mnt/snap/8572302701/hda/data.gz.aes&quot;opensslcmd = os.popen( # 此处选用os.popen，主要是怀疑paramiko存在问题&quot;setsid ...(your shell commands)... &amp;&quot;)# 此处可以多添加几个无用命令sys.exit() 将代码最后添加一个sys.exit()程序恢复正常,其实主要ssh返回的结果缓冲释放过快未读完，就产生报错了。也有说，加一个sleep 1秒也可以解决。 也可能是shell脚本问题，需仔细检查;windows于linux 回车差异需要注意。","categories":[{"name":"运维","slug":"运维","permalink":"http://shizhonggan.github.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/tags/DevOps/"},{"name":"python","slug":"python","permalink":"http://shizhonggan.github.io/tags/python/"},{"name":"paramiko","slug":"paramiko","permalink":"http://shizhonggan.github.io/tags/paramiko/"}]},{"title":"tkinter快速入门","slug":"Python/tkinter","date":"2021-05-20T01:39:04.000Z","updated":"2022-05-07T10:07:50.320Z","comments":true,"path":"2021/05/20/Python/tkinter/","link":"","permalink":"http://shizhonggan.github.io/2021/05/20/Python/tkinter/","excerpt":"","text":"窗口12345importinit_window = tk.Tk()init_window.title(&quot;test&quot;)init_window.geometry(&quot;500x400&quot;)init_window.mainloop() 标签和按钮 Label &amp; Button1234567891011121314def hit_me(): global on_hit if on_hit == False: var.set(&quot;you hit me&quot;) on_hit = True else: on_hit = False var.set(&quot;&quot;)label = tk.Label(init_window, text=&quot;OMG&quot;, bg=&quot;green&quot;, font=(&quot;Arial&quot;,12), width=15, height=2)label = tk.Label(init_window, textvariable=var, bg=&quot;green&quot;, font=(&quot;Arial&quot;, 12), width=15, height=2)label.pack()button = tk.Button(init_window, text=&quot;hit me&quot;, width=15, height=2, command=hit_me)button.pack() 输入和文本框 Entry &amp; Text12345678910111213e = tk.Entry(init_window, show=&#x27;*&#x27;)e.pack()var = tk.StringVar()on_hit = Falsebutton1 = tk.Button(init_window, text=&quot;insert point&quot;, width=15, height=2, command=insert_point)button1.pack()button2 = tk.Button(init_window, text=&quot;insert end&quot;, width=15, height=2, command=insert_end)button2.pack()t = tk.Text(init_window, height=2)t.pack() 列表部件 Listbox123456789101112131415161718var2 = tk.StringVar()var2.set((11,22,33,44)) #为变量设置值#创建Listboxlb = tk.Listbox(window, listvariable=var2) #将var2的值赋给Listbox#创建一个list并将值循环添加到Listbox控件中list_items = [1,2,3,4]for item in list_items: lb.insert(&#x27;end&#x27;, item) #从最后一个位置开始加入值lb.insert(1, &#x27;first&#x27;) #在第一个位置加入&#x27;first&#x27;字符lb.insert(2, &#x27;second&#x27;) #在第二个位置加入&#x27;second&#x27;字符lb.delete(2) #删除第二个位置的字符lb.pack()#显示主窗口window.mainloop() Radiobutton 选择按钮123456789var = tk.StringVar()var.set(0) # 默认空，选项按钮没有被勾选l = tk.Label(window, bg=&#x27;yellow&#x27;, width=20, text=&#x27;empty&#x27;)l.pack()r1 = tk.Radiobutton(window, text=&#x27;Option A&#x27;, variable=var, value=&#x27;A&#x27;, command=print_selection)r1.pack() Scale 尺度123456789s = tk.Scale(window, label=&#x27;try me&#x27;, from_=5, to=11, orient=tk.HORIZONTAL, length=200, showvalue=0, tickinterval=2, resolution=0.01, command=print_selection)s.pack()## 触发l = tk.Label(window, bg=&#x27;yellow&#x27;, width=20, text=&#x27;empty&#x27;)l.pack()def print_selection(v): l.config(text=&#x27;you have selected &#x27; + v) Checkbutton 勾选项123456789101112131415var1 = tk.IntVar()c1 = tk.Checkbutton(window, text=&#x27;Python&#x27;, variable=var1, onvalue=1, offvalue=0, command=print_selection)c1.pack()## 触发def print_selection(): if (var1.get() == 1) &amp; (var2.get() == 0): #如果选中第一个选项，未选中第二个选项 l.config(text=&#x27;I love only Python &#x27;) elif (var1.get() == 0) &amp; (var2.get() == 1): #如果选中第二个选项，未选中第一个选项 l.config(text=&#x27;I love only C++&#x27;) elif (var1.get() == 0) &amp; (var2.get() == 0): #如果两个选项都未选中 l.config(text=&#x27;I do not love either&#x27;) else: l.config(text=&#x27;I love both&#x27;) #如果两个选项都选中 Canvas 画布123456789101112131415canvas = tk.Canvas(window, bg=&#x27;blue&#x27;, height=100, width=200)canvas.pack()image_file = tk.PhotoImage(file=&#x27;ins.gif&#x27;)image = canvas.create_image(10, 10, anchor=&#x27;nw&#x27;, image=image_file)x0, y0, x1, y1= 50, 50, 80, 80line = canvas.create_line(x0, y0, x1, y1)oval = canvas.create_oval(x0, y0, x1, y1, fill=&#x27;red&#x27;) #创建一个圆，填充色为`red`红色arc = canvas.create_arc(x0+30, y0+30, x1+30, y1+30, start=0, extent=180) #创建一个扇形rect = canvas.create_rectangle(100, 30, 100+20, 30+20) #创建一个矩形def moveit(): canvas.move(rect, 0, 2) Menubar 菜单123456789101112131415161718192021222324252627282930##创建一个菜单栏，这里我们可以把他理解成一个容器，在窗口的上方menubar = tk.Menu(window)##定义一个空菜单单元filemenu = tk.Menu(menubar, tearoff=0)##将上面定义的空菜单命名为`File`，放在菜单栏中，就是装入那个容器中menubar.add_cascade(label=&#x27;File&#x27;, menu=filemenu)##在`File`中加入`New`的小菜单，即我们平时看到的下拉菜单，每一个小菜单对应命令操作。##如果点击这些单元, 就会触发`do_job`的功能filemenu.add_command(label=&#x27;New&#x27;, command=do_job)filemenu.add_command(label=&#x27;Open&#x27;, command=do_job)##同样的在`File`中加入`Open`小菜单filemenu.add_command(label=&#x27;Save&#x27;, command=do_job)##同样的在`File`中加入`Save`小菜单filemenu.add_separator()##这里就是一条分割线##同样的在`File`中加入`Exit`小菜单,此处对应命令为`window.quit`filemenu.add_command(label=&#x27;Exit&#x27;, command=window.quit)submenu = tk.Menu(filemenu)##和上面定义菜单一样，不过此处实在`File`上创建一个空的菜单filemenu.add_cascade(label=&#x27;Import&#x27;, menu=submenu, underline=0)##给放入的菜单`submenu`命名为`Import`submenu.add_command(label=&quot;Submenu1&quot;, command=do_job)##这里和上面也一样，在`Import`中加入一个小菜单命令`Submenu1`counter = 0def do_job(): global counter l.config(text=&#x27;do &#x27;+ str(counter)) counter+=1 Frame 框架1234567891011121314151617181920###定义一个`label`显示`on the window`tk.Label(window, text=&#x27;on the window&#x27;).pack()###在`window`上创建一个`frame`frm = tk.Frame(window)frm.pack()###在刚刚创建的`frame`上创建两个`frame`，我们可以把它理解成一个大容器里套了一个小容器，即`frm`上有两个`frame` ，`frm_l`和`frm_r`frm_l = tk.Frame(frm)frm_r = tk.Frame(frm)###这里是控制小的`frm`部件在大的`frm`的相对位置，此处`frm_l`就是在`frm`的左边，`frm_r`在`frm`的右边frm_l.pack(side=&#x27;left&#x27;)frm_r.pack(side=&#x27;right&#x27;)###这里的三个label就是在我们创建的frame上定义的label部件，还是以容器理解，就是容器上贴了标签，来指明这个是什么，解释这个容器。tk.Label(frm_l, text=&#x27;on the frm_l1&#x27;).pack()##这个`label`长在`frm_l`上，显示为`on the frm_l1`tk.Label(frm_l, text=&#x27;on the frm_l2&#x27;).pack()##这个`label`长在`frm_l`上，显示为`on the frm_l2`tk.Label(frm_r, text=&#x27;on the frm_r1&#x27;).pack()##这个`label`长在`frm_r`上，显示为`on the frm_r1` messagebox 弹窗123456789101112import tkinter as tkfrom tkinter import messageboxtk.Button(init_window, text=&quot;hit me&quot;, command=hit_me).pack()def hit_me(): # tk.messagebox.showinfo(title=&quot;Hi&quot;, message=&quot;hahahaha&quot;) # messagebox.showwarning(title=&quot;Hi&quot;, message=&quot;nonono&quot;) # tk.messagebox.showerror(title=&quot;Hi&quot;, message=&quot;no!never&quot;) # print(messagebox.askquestion(title=&quot;hi&quot;, message=&quot;hhhaaaa&quot;)) # print(messagebox.askyesno(title=&quot;hi&quot;, message=&quot;hhhaaaa&quot;)) # print(messagebox.askretrycancel(title=&quot;hi&quot;, message=&quot;hhhaaaa&quot;)) print(messagebox.askokcancel(title=&quot;hi&quot;, message=&quot;hhhaaaa&quot;)) pack grid place 放置位置12345678910tk.Label(window, text=&#x27;1&#x27;).pack(side=&#x27;top&#x27;)#上tk.Label(window, text=&#x27;1&#x27;).pack(side=&#x27;bottom&#x27;)#下tk.Label(window, text=&#x27;1&#x27;).pack(side=&#x27;left&#x27;)#左tk.Label(window, text=&#x27;1&#x27;).pack(side=&#x27;right&#x27;)#右for i in range(4): for j in range(3): tk.Label(window, text=1).grid(row=i, column=j, padx=10, pady=10)tk.Label(window, text=1).place(x=20, y=10, anchor=&#x27;nw&#x27;)","categories":[{"name":"python","slug":"python","permalink":"http://shizhonggan.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://shizhonggan.github.io/tags/python/"},{"name":"tkinter","slug":"tkinter","permalink":"http://shizhonggan.github.io/tags/tkinter/"}]},{"title":"学术论文免费下载方法","slug":"Tips/PaperDownload","date":"2021-05-18T13:44:23.000Z","updated":"2022-05-07T10:07:50.329Z","comments":true,"path":"2021/05/18/Tips/PaperDownload/","link":"","permalink":"http://shizhonggan.github.io/2021/05/18/Tips/PaperDownload/","excerpt":"","text":"本文仅测试了IEEE论文的下载，亲测有效。 打开网址scihubtw.tw，网站如下： IEEE搜索你需要下载的文章，打开文章所在页面如下图所示，其中红色框内的链接和DOI编号都可以在SCI-HUB中搜索，然后即可下载。 温馨提示：SCI-HUB网址会经常变更，需要多加留意啊~","categories":[{"name":"Tips","slug":"Tips","permalink":"http://shizhonggan.github.io/categories/Tips/"}],"tags":[]},{"title":"Docker 常用命令方法","slug":"Docker/basic_method","date":"2021-04-28T03:03:04.000Z","updated":"2022-05-07T10:07:50.306Z","comments":true,"path":"2021/04/28/Docker/basic_method/","link":"","permalink":"http://shizhonggan.github.io/2021/04/28/Docker/basic_method/","excerpt":"","text":"镜像搜索、拉取和使用123456docker search ubuntudocker pull ubuntudocker run -it --name test ubuntu /bin/bashdocker start testdocker restart testdocker stop test 将容器保存为镜像，便于重复使用12345apt-get install net-toolsapt-get install -y inetutils-pingapt-get install iproute2docker commit -a &quot;作者名&quot; -m &quot;镜像描述&quot; 容器ID 新镜像命名docker commit -a &quot;paxton&quot; -m &quot;ubuntu with modified apt source.list&quot; ovs1 mdubuntu 自定义网络 docker的网络通信基于安装时新建的docker0网桥，可以与外网，本虚拟机以及其他虚拟机通信 在两台虚拟机上创建自定义网络，并为新建容器分配自定义网络下的ip地址，两台虚拟机分配不同网段，配置操作如下： 虚拟机1-ip：192.168.255.129 容器网段 10.0.30.0/24 容器ip：10.0.30.10 虚拟机1操作如下： 创建自定义网络，ifconfig可发现多出一个网桥 123456## h0docker network create --subnet=10.0.30.0/24 --opt com.docker.network.driver.mtu=1450 docker-br0 docker run -itd --net docker-br0 --ip 10.0.30.10 --name h0 mdubuntu /bin/bash## h1docker network create --subnet=10.0.50.0/24 --opt com.docker.network.driver.mtu=1450 docker-br1 docker run -itd --net docker-br1 --ip 10.0.50.10 --name h1 ubuntu /bin/bash 此时，新建的两个虚拟机相互无法ping通。可以通过增加路由的方式解决： 1234ip route show # 查看一下当前路由docker network connect docker-br0 h1 # 将h1加入到h0所在的自定义网络docker-br0中，进入h1可ping通h0，h0不可ping通h1 https://www.cnblogs.com/tengj/p/5357879.htmlhttps://blog.csdn.net/Silvester123/article/details/80867168","categories":[{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/tags/Docker/"}]},{"title":"Docker 容器内网络无法连接","slug":"Docker/netdisconnected","date":"2021-04-27T08:09:04.000Z","updated":"2022-05-07T10:07:50.307Z","comments":true,"path":"2021/04/27/Docker/netdisconnected/","link":"","permalink":"http://shizhonggan.github.io/2021/04/27/Docker/netdisconnected/","excerpt":"","text":"操作系统ubuntu16docker 参照官方教程安装最新版本 问题描述最近迷恋上了docker，因为官方提供的ubuntu镜像只有64M!!!十分轻便。然而基于该镜像生成的容器无法联网，参见下面代码错误，然后试了试其它镜像，依旧无法联网。 12345678910111213141516171819202122root@gan# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEubuntu latest a2a15febcdf3 7 days ago 64.2MBroot@e6a2c5bec004:/# apt updateErr:1 http://security.ubuntu.com/ubuntu bionic-security InRelease Connection failed [IP: 91.189.88.162 80]Err:2 http://archive.ubuntu.com/ubuntu bionic InRelease Connection failed [IP: 91.189.88.149 80]Err:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease Connection failed [IP: 91.189.88.24 80]Err:4 http://archive.ubuntu.com/ubuntu bionic-backports InRelease Connection failed [IP: 91.189.88.149 80]Reading package lists... DoneBuilding dependency treeReading state information... DoneAll packages are up to date.W: Failed to fetch http://archive.ubuntu.com/ubuntu/dists/bionic/InRelease Conn ection failed [IP: 91.189.88.149 80]W: Failed to fetch http://archive.ubuntu.com/ubuntu/dists/bionic-updates/InRelea se Connection failed [IP: 91.189.88.24 80]W: Failed to fetch http://archive.ubuntu.com/ubuntu/dists/bionic-backports/InRel ease Connection failed [IP: 91.189.88.149 80]W: Failed to fetch http://security.ubuntu.com/ubuntu/dists/bionic-security/InRel ease Connection failed [IP: 91.189.88.162 80]W: Some index files failed to download. They have been ignored, or old ones used instead. 解决办法例如：Docker容器内不能联网的6种解决方案stack overflow中的高分回复 Docker apt-get update fails中文这六种解决方法，不要轻易动用，除非你之前做过大量的网络设置，负责这些问题基本不会出现。 第一步：首先查看docker虚拟网卡，查看mtu值，如果是1500(默认，或者更大)，则需要修改为1450或者更小，/etc/docker/daemon.json 。此外，可以在daemon.json中修改镜像的存储路径，以免占用太多的系统内存；修改mtu值便可以联网了；dns根据情况修改，可以不加吧。12345678910111213141516171819202122232425262728293031root@gan:/etc/docker# ifconfigdocker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1450 inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255 inet6 fe80::42:7eff:fee3:87ab prefixlen 64 scopeid 0x20&lt;link&gt; ether 02:42:7e:e3:87:ab txqueuelen 0 (Ethernet) RX packets 4518 bytes 281479 (281.4 KB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 5733 bytes 17386562 (17.3 MB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0root@gan# vim /etc/docker/daemon.json&#123; &quot;data-root&quot;: &quot;/home/ec2-user/software/docker-data&quot;, &quot;storage-driver&quot;: &quot;overlay2&quot;, &quot;mtu&quot;: 1450, &quot;dns&quot;: [&quot;you_server_dns&quot;,&quot;8.8.8.8&quot;]&#125;##启动 systemctl start docker## 守护进程重启sudo systemctl daemon-reload## 重启docker服务sudo systemctl restart docker## 关闭dockersudo systemctl stop docker## 重启docker服务sudo service docker restart## 关闭dockersudo service docker stop 第二步：再按照其它方法慢慢修改吧总结有时候搜索不到答案，就细致读一下官方文档，按照官方文档操作一般不会遇到问题，否则就是这个软件的BUG了。 MTU [百度百科]通信术语 最大传输单元（Maximum Transmission Unit，MTU）是指一种通信协议的某一层上面所能通过的最大数据包大小（以字节为单位）。最大传输单元这个参数通常与通信接口有关（网络接口卡、串口等）。 因为协议数据单元的包头和包尾的长度是固定的，MTU越大，则一个协议数据单元的承载的有效数据就越长，通信效率也越高。MTU越大，传送相同的用户数据所需的数据包个数也越低。 MTU也不是越大越好，因为MTU越大， 传送一个数据包的延迟也越大；并且MTU越大，数据包中 bit位发生错误的概率也越大。 MTU越大，通信效率越高而传输延迟增大，所以要权衡通信效率和传输延迟选择合适的MTU。","categories":[{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/tags/Docker/"}]},{"title":"Ubuntu安装Docker与最常用配置","slug":"Docker/docker_install","date":"2021-04-26T02:54:04.000Z","updated":"2022-05-07T10:07:50.306Z","comments":true,"path":"2021/04/26/Docker/docker_install/","link":"","permalink":"http://shizhonggan.github.io/2021/04/26/Docker/docker_install/","excerpt":"","text":"1 docker 介绍Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源。 Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。 容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低。 Docker 从 17.03 版本之后分为 CE（Community Edition: 社区版） 和 EE（Enterprise Edition: 企业版），我们用社区版就可以了。 Docker的应用场景 Web 应用的自动化打包和发布。 自动化测试和持续集成、发布。 在服务型环境中部署和调整数据库或其他的后台应用。 从头编译或者扩展现有的 OpenShift 或 Cloud Foundry 平台来搭建自己的 PaaS 环境。 Docker 的优点 Docker 是一个用于开发，交付和运行应用程序的开放平台。Docker 使您能够将应用程序与基础架构分开，从而可以快速交付软件。借助 Docker，您可以与管理应用程序相同的方式来管理基础架构。通过利用 Docker 的方法来快速交付，测试和部署代码，您可以大大减少编写代码和在生产环境中运行代码之间的延迟。 快速，一致地交付您的应用程序 Docker 允许开发人员使用您提供的应用程序或服务的本地容器在标准化环境中工作，从而简化了开发的生命周期。 容器非常适合持续集成和持续交付（CI / CD）工作流程，请考虑以下示例方案： 您的开发人员在本地编写代码，并使用 Docker 容器与同事共享他们的工作。 他们使用 Docker 将其应用程序推送到测试环境中，并执行自动或手动测试。 当开发人员发现错误时，他们可以在开发环境中对其进行修复，然后将其重新部署到测试环境中，以进行测试和验证。 测试完成后，将修补程序推送给生产环境，就像将更新的镜像推送到生产环境一样简单。 响应式部署和扩展 Docker 是基于容器的平台，允许高度可移植的工作负载。Docker 容器可以在开发人员的本机上，数据中心的物理或虚拟机上，云服务上或混合环境中运行。 Docker 的可移植性和轻量级的特性，还可以使您轻松地完成动态管理的工作负担，并根据业务需求指示，实时扩展或拆除应用程序和服务。 在同一硬件上运行更多工作负载 Docker 轻巧快速。它为基于虚拟机管理程序的虚拟机提供了可行、经济、高效的替代方案，因此您可以利用更多的计算能力来实现业务目标。Docker 非常适合于高密度环境以及中小型部署，而您可以用更少的资源做更多的事情。 安装ubuntu16.04安装成功；ubuntu14.04安装失败【各种报错啊，有耐心的可以慢慢去解决】。 123456789101112131415161718192021$ sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak$ sudo rm /etc/apt/sources.list$ sudo vi /etc/apt/sources.listecho \\&quot;deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse&quot; \\&gt;&gt; /etc/apt/sources.list$ sudo apt-get update$ sudo apt-get upgrade 12$ sudo apt-get remove docker docker-engine docker.io containerd runc # 如果存在旧版本地docker产品先卸载$ Install using the repository1234567$ sudo apt-get update$ sudo apt-get install apt-transport-https ca-certificates curl gnupg lsb-release$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg$ sudo apt-key fingerprint 0EBFCD88$ echo \\ &quot;deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null INSTALL DOCKER CE123$ sudo apt-get update$ sudo apt-get install docker-ce docker-ce-cli containerd.io$ sudo docker run hello-world docker 更改工作存储路径【可选操作】1$ sudo systemctl stop docker Runtime directory and storage driver You may want to control the disk space used for Docker images, containers, and volumes by moving it to a separate partition.To accomplish this, set the following flags in the daemon.json file:1234&#123; &quot;data-root&quot;: &quot;/mnt/docker-data&quot;, ## 修改成你自己的目录 &quot;storage-driver&quot;: &quot;overlay2&quot;&#125; 123$ sudo service docker start # 重启$ sudo systemctl start dockersystemctl enable docker Docker 更改容器日志文件大小【可选操作】 docker容器的日志文件会不断挤占系统资源内存，因此需要限定docker日志文件大小，实现docker日志定期处理，具体方法如下： 123456789# 查看文件夹子文件所占内存大小du -h --max-depth=1 /home/ec2-user/dirname/# vim /etc/docker/daemon.json &#123; &quot;log-driver&quot;:&quot;json-file&quot;, &quot;log-opts&quot;: &#123;&quot;max-size&quot;:&quot;500m&quot;, &quot;max-file&quot;:&quot;1&quot;&#125; # max-size=500m，意味着一个容器日志大小上限是500M，max-file=3，意味着一个容器有三个日志，分别是id+.json、id+1.json、id+2.json。&#125; ## 重启docker守护进程 # systemctl daemon-reload 、# systemctl restart docker","categories":[{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/tags/Docker/"}]},{"title":"面向对象编程(python)","slug":"Python/ObjectOrientedPrograming","date":"2021-04-26T02:54:04.000Z","updated":"2022-05-07T10:07:50.316Z","comments":true,"path":"2021/04/26/Python/ObjectOrientedPrograming/","link":"","permalink":"http://shizhonggan.github.io/2021/04/26/Python/ObjectOrientedPrograming/","excerpt":"","text":"与面向过程相比，面向对象优缺点如下： 优点：易维护、易复用、易扩展，由于面向对象有封装、继承、多态性的特性，可以设计出低耦合的系统，使系统 更加灵活、更加易于维护 数据抽象的概念可以在保持外部接口不变的情况下改变内部实现，从而减少甚至避免对外界的干扰； 通过继承大幅减少冗余的代码，并可以方便地扩展现有代码，提高编码效率，也减低了出错概率，降低软件维护的难度； 结合面向对象分析、面向对象设计，允许将问题域中的对象直接映射到程序中，减少软件开发过程中中间环节的转换过程； 通过对对象的辨别、划分可以将软件系统分割为若干相对独立的部分，在一定程度上更便于控制软件复杂度； 以对象为中心的设计可以帮助开发人员从静态（属性）和动态（方法）两个方面把握问题，从而更好地实现系统； 通过对象的聚合、联合可以在保证封装与抽象的原则下实现对象在内在结构以及外在功能上的扩充，从而实现对象由低到高的升级。 缺点：性能比面向过程低 自己写","categories":[{"name":"Python","slug":"Python","permalink":"http://shizhonggan.github.io/categories/Python/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://shizhonggan.github.io/tags/OOP/"}]},{"title":"软件定义网络（SDN）学习笔记(3)--OVS系统架构","slug":"SDN/SDN03_ovs","date":"2021-04-21T13:31:04.000Z","updated":"2022-05-07T10:07:50.322Z","comments":true,"path":"2021/04/21/SDN/SDN03_ovs/","link":"","permalink":"http://shizhonggan.github.io/2021/04/21/SDN/SDN03_ovs/","excerpt":"","text":"SDN学习目录 SDN学习笔记(0)–wireshark抓包分析 SDN学习笔记(1)–iPerf和Netperf性能测试 SDN学习笔记(2)–Scapy交互式数据处理与Postman HTTP请求测试 SDN学习笔记(3)–OVS系统架构 SDN学习笔记(5)–OpenDaylight控制器 1 基本概念1.1 交换机交换机（Switch）是一种在通信系统中完成信息交换功能的设备。它可以为接入交换机的任意两个网络节点提供独享的电信号通路。最常见的交换机是以太网交换机。其他常见的还有电话语音交换机、光纤交换机等。目前，二层交换技术发展比较成熟，二层交换机（Layer 2 switches）是指只支持OSI第二层（数据链路层）交换技术的交换机。 1.2 工作原理交换机拥有一条很高带宽的背部总线和内部交换矩阵。交换机的所有的端口都挂接在这条背部总线上，控制电路收到数据包以后，处理端口会查找内存中的地址对照表以确定目的MAC（网卡的硬件地址）的NIC（网卡）挂接在哪个端口上，通过内部交换矩阵迅速将数据包传送到目的端口，目的MAC若不存在，广播到所有的端口，接收端口回应后交换机会“学习”新的MAC地址，并把它添加入内部MAC地址表中，并刷新CAM表，表中有MAC地址，对应的端口号，端口所属的VLAN信息，交换机在二层转发数据时根据CAM表查找出端口。使用交换机也可以把网络“分段”，通过对照IP地址表，交换机只允许必要的网络流量通过交换机。通过交换机的过滤和转发，可以有效的减少冲突域，但不能划分广播域。交换机在同一时刻可进行多个端口对之间的数据传输。每一端口都可视为独立的网段，连接在其上的网络设备独自享有全部的带宽，无须同其他设备竞争使用。当节点A向节点D发送数据时，节点B可同时向节点C发送数据，而且这两个传输都享有网络的全部带宽，有着自己的虚拟连接。 1.3 作用与功能交换机的常见功能如下： MAC地址学习：以太网交换机了解每一端口相连设备的MAC地址，并将地址同相应的端口映射起来存放在交换机缓存中的MAC地址表中。 转发/过滤：当一个数据帧的目的地址在MAC地址表中有映射时，它被转发到连接目的节点的端口而不是所有端口（如该数据帧为广播/组播帧则转发至所有端口）。 消除回路：当交换机包括一个冗余回路时，以太网交换机通过生成树协议避免回路的产生，同时允许存在后备路径。 2 Open vSwitch (OVS)在网络中，交换机和桥概念类似，Open vSwitch是一个虚拟交换软件，也就是说，Open vSwitch实现了网桥的功能。学习Open vSwitch的第一步要弄清楚网桥的概念。网桥是连接两个局域网的设备，工作在数据链路层，根据MAC地址来转发帧。在Open vSwitch中创建一个网桥后，此时网络功能不受影响，但是会产生一个虚拟网卡，之所以会产生一个虚拟网卡，是为了实现接下来的网桥（交换机）功能。有了这个网桥以后，还需要为这个网桥增加端口（port），一个端口就是一个物理网卡，当网卡加入到这个网桥之后，其工作方式就和普通交换机的一个端口的工作方式类似了。以下是一个网桥的具体信息： Open vSwitch（OVS）是一个高质量的、多层虚拟交换机。OVS遵循开源Apache2.0许可，通过可编程扩展，OVS可以实现大规模网络的自动化（配置、管理、维护），同时支持现有标准管理接口和协议（比如NetFlow、sFlow、SPAN、RSPAN、CLI、LACP、802.1ag等）。此外OVS支持多种Linux虚拟化技术，包括Xen/XenServer，KVM，和VirtualBox等。虽然是虚拟交换机，但是其工作原理与物理交换机类似。在虚拟交换机的实现中，其两端分别连接着物理网卡和多块虚拟网卡，同时虚拟交换机内部会维护一张映射表，根据MAC地址寻找对应的虚拟机链路进而完成数据转发。 OVS交换机有两种工作模式 一种为SDN交换机，另一种为普通交换机。作为SDN交换机时，显示Fail_mode为Secure，在这种模式下OVS交换机需要控制器发送转发规则，指挥交换机去工作 作为普通交换机时，显示Fail_mode是Standalone。其和物理交换机工作模式一样，记录端口号和MAC地址的对应关系，基于对应关系转发数据帧。交换机默认状态是SDN交换机。 OVS 架构分为三个部分: 内核空间：包含了流表（Flow Table）和Datapath模块（类似于网桥，主要负责对数据分组进行操作）。 用户空间：运行着OVS的守护进程(Open vSwitch Daemon, vswitchd)和数据库(Open vSwitch Database, ovsdb)，他们是ovs的核心功能模块。 vswitchd类似于OVS的心脏，维持OVS的声明周期。可以配置一系列特性： 基于MAC地址学习的二层交换 支持IEEE802.1Q VLAN sFlow监测 连接OpenFlow控制器 通过Netlink协议与内核模块Datapath直接通信 ovsdb相当于OVS的大脑，存储OVS的配置信息和数据流信息。 配置管理层：包括ovs-dpctl, ovs-ofctl, ovs-appctl, ovs-vsctl和ovsdb-tool等，主要用于和vswitchd,ovsdb之间进行交互操作以及ovs的安装配置和部署 3. OVS安装使用OVS可以运行在任何基于Linux的虚拟化平台，包括KVM, VirtualBox, Xen等，其代码都是基于C编写，所以易于移植到其他环境。安装有两种方法：一种通过二进制文件安装apt-get；另外一种是源码安装。 3.1 ovs安装docker 安装参见【Ubuntu安装Docker与最常用配置】 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950docker pull ubuntudocker run -it --name ovs1 ubuntu /bin/bash apt install pythonapt install python-pipwget https://www.openvswitch.org/releases/openvswitch-2.13.3.tar.gz参考：https://www.cnblogs.com/goldsunshine/p/10331606.htmlapt list --upgradable # 查看可以升级的包apt install pythonapt install python-pip wget https://www.openvswitch.org/releases/openvswitch-2.13.3.tar.gztar -zxf openvswitch-2.13.3.tar.gz## 以下需root用户下执行./configuremake make installmake modules_install /sbin/modprobe openvswitch export PATH=$PATH:/usr/local/share/openvswitch/scriptsovs-ctl start export PATH=$PATH:/usr/local/share/openvswitch/scriptsovs-ctl --no-ovs-vswitchd startexport PATH=$PATH:/usr/local/share/openvswitch/scriptsovs-ctl --no--ovsdb-server startmkdir -p /usr/local/etc/openvswitchovsdb-tool create /usr/local/etc/openvswitch/conf.db \\ vswitchd/vswitch.ovsschemamkdir -p /usr/local/var/run/openvswitchovsdb-server --remote=punix:/usr/local/var/run/openvswitch/db.sock \\ --remote=db:Open_vSwitch,Open_vSwitch,manager_options \\ --private-key=db:Open_vSwitch,SSL,private_key \\ --certificate=db:Open_vSwitch,SSL,certificate \\ --bootstrap-ca-cert=db:Open_vSwitch,SSL,ca_cert \\ --pidfile --detach --log-fileovs-vsctl --no-wait initovs-vswitchd --pidfile --detach --log-file note:进入容器后，若发现无法联网请参见文章【Docker容器内网络无法连接】 3.2 ovs-vsctl 命令使用ovs-ovsctl命令是对交换机上网桥和端口等信息进行配置的命令。获取或者更改ovs-vswitchd的配置信息，此工具操作的时候会更新ovsdb-server中的数据库。下面的操作需要连接控制器，控制器的安装可以参考【OpenDaylight安装】 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950## 查看网桥ovs-vsctl show393b60ce-7d82-41e0-bd78-2aa47e54c8d5 ovs_version: &quot;2.13.3&quot;## 添加网桥ovs-vsctl add-br br-test393b60ce-7d82-41e0-bd78-2aa47e54c8d5 Bridge br-test Port br-test Interface br-test type: internal ovs_version: &quot;2.13.3&quot;## 绑定网卡，创建网桥后会默认创建同名的port，可以绑定机器存在的网卡ovs-vsctl add-port br-test ens8393b60ce-7d82-41e0-bd78-2aa47e54c8d5 Bridge br-test Port ens8 Interface ens8 Port br-test Interface br-test type: internal ovs_version: &quot;2.13.3&quot;## 删除port绑定的网卡ovs-vsctl del-port br-test ens8## 删除网桥ovs-vsctl add-br br-test## 网桥连接控制器ovs-vsctl set-controller br-test tcp:x.x.x.x:6633## 设置协议,否则web界面无法显示ovs-vsctl set bridge br-test protocols=OpenFlow10393b60ce-7d82-41e0-bd78-2aa47e54c8d5 Bridge br-test Controller &quot;tcp:x.x.x.x:6633&quot; is_connected: true Port ens8 Interface ens8 Port br-test Interface br-test type: internal ovs_version: &quot;2.13.3&quot;## 网桥端开连接控制器ovs-vsctl del-controller br-test ovs连接控制器成功后，可在opendaylight界面看到： ovs连接本地docker容器后，可以在OpenDaylight界面看到： 12345678910## 查看docker容器的网卡物理地址docker exec -it h0 bashroot@8cfaf3984bdf:/# ifconfigeth0 flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1450 inet 10.0.50.10 netmask 255.255.255.0 broadcast 10.0.50.255 ether 02:42:0a:00:32:0a txqueuelen 0 (Ethernet) RX packets 2873 bytes 319842 (319.8 KB) RX errors 0 dropped 2736 overruns 0 frame 0 TX packets 29 bytes 1666 (1.6 KB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ovs连接容器方法有诸多坑存在，将单独整理一篇文章讲解 上面说到，创建桥的时候会创建一个和桥名字一样的接口，并自动作为该桥的一个端口，那么这个虚拟接口的作用，一方面是可以作为交换机的管理端口，另一方面也是基于这个虚拟接口实现了桥的功能。Open vSwitch的内核模块实现了多个“数据路径”，每个都可以有多个vports。每个数据路径也通过关联流表（flow table）来设置操作，而这些流表中的流都是用户空间在报文头和元数据的基础上映射的关键信息，一般的操作都是将数据包转发到另一个vport。当一个数据包到达一个vport，内核模块所做的处理是提取其流的关键信息并在流表中查找这些关键信息，当有一个匹配的流时它执行对应的操作，如果没有匹配，它会将数据包送到用户空间的处理队列中，作为处理的一部分，用户空间可能会设置一个流用于以后碰到相同类型的数据包可以在内核中执行操作。ovs-vsctl关于网桥管理的常用命令如下： 命令 含义 init 初始化数据库（前提数据分组为空） show 打印数据库信息摘要 add-br BRIDGE 添加新的网桥 del-br BRIDGE 删除网桥 list-br 打印网桥摘要信息 list-ports BRIDGE 打印网桥中所有port摘要信息 add-port BRIDGE PORT 向网桥中添加端口 del-port [BRIDGE] PORT 删除网桥上的端口 get-controller BRIDGE 获取网桥的控制器信息 del-controller BRIDGE 删除网桥的控制器信息 set-controller BRIDGE TARGET 向网桥添加控制器 3.3 ovs-ofctl 命令使用ovs-ofctl 命令是对流表的操作，包括对流表的增，删，改，查等命令。简单来说流表类似于交换机的MAC地址表，路由器的路由表，是ovs交换机指挥流量转发的表。 OpenFlow是用于管理交换机流表的协议，ovs-ofctl是Open vSwitch提供的命令行工具。在没有配置OpenFlow控制器的模式下，用户可以使用ovs-ofctl命令通过OpenFlow协议连接Open vSwitch来创建、修改或删除Open vSwitch中的流表项，并对Open vSwitch的运行状况进行动态监控。ovs-ofctl关于流表管理的常用命令如下表所示： 对于add-flow、add-flows和mod-flows这3个命令，还需要指定要执行的动作actions=[target],[target]…，一个流规则中可能有多个动作，按照指定的先后顺序执行。常见的流表操作如下表所示 在OpenFlow白皮书中，Flow被定义为某个特定的网络流量。例如，一个TCP连接就是一个Flow，或者从某个IP地址发出来的数据包，都可以被认为是一个Flow。支持OpenFlow协议的交换机应该包括一个或多个流表，流表中的条目包含：数据包头的信息、匹配成功后要执行的指令和统计信息。当数据包进入OVS后，会将数据包和流表中的流表项进行匹配，如果发现了匹配的流表项，则执行该流表项中的指令集。相反，如果数据包在流表中没有发现任何匹配，OVS会通过控制通道把数据包发到OpenFlow控制器中。在OVS中，流表项作为ovs-ofctl的参数，采用如下的格式：字段=值，如果有多个字段，可以用逗号或空格分开，一些常用的字段列举如下表所示。","categories":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/categories/SDN/"}],"tags":[{"name":"网络架构","slug":"网络架构","permalink":"http://shizhonggan.github.io/tags/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/"},{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/tags/SDN/"},{"name":"OVS","slug":"OVS","permalink":"http://shizhonggan.github.io/tags/OVS/"}]},{"title":"软件定义网络（SDN）学习笔记(4)--Mininet","slug":"SDN/SDN04_Mininet","date":"2021-04-21T13:31:04.000Z","updated":"2022-05-07T10:07:50.324Z","comments":true,"path":"2021/04/21/SDN/SDN04_Mininet/","link":"","permalink":"http://shizhonggan.github.io/2021/04/21/SDN/SDN04_Mininet/","excerpt":"","text":"Mininet简洁Mininet是基于Linux C ontainer架构开发的一个进程虚拟化网络仿真工具，可以创建一个含有主机、交换机、控制器和链路的虚拟网络，其交换机支持OpenFlow，具有高度灵活的自定义软件定义网络。Mininet可以用一个命令在一台主机上（虚拟机、云或者本地）以秒级创建一个虚拟网络，并在上面运行真正的内核、交换机和应用程序代码。Mininet能实现如下功能： 为OpenFlow应用程序提供一个简单、便宜的网络测试平台 启用复杂的拓扑测试，无需连接物理网络 具有拓扑感知和OpenFlow感知的CLI，用于调试或运行网络范围的测试 支持任意自定义拓扑，主机数可达4096，并包括一组基本的参数化拓扑 提供用于网络创建和实验的可扩展Python API Miniedit可视化，直接在界面上编辑任意拓扑，生成python自定义拓扑脚本，使用Mininet可视化界面方便了用户自定义拓扑创建，为不熟悉python脚本的使用者创造了更简单的环境，界面直观，可操作性强。 Mininet 2.2.0+内置miniedit 。在mininet/examples下提供miniedit.py脚本，执行脚本后显示可视化界面，可自定义拓扑及配置属性。MiniEdit使用主要分三个步骤：Miniedit启动→自定义创建拓扑，设置设备信息→运行拓扑并生成拓扑脚本。 Mininet 安装与卸载123456789101112131415sudo apt-get updategit clone http://github.com/mininet/mininet.gitcd mininet ``cat INSTALL|morecd util/## 安装./install.sh -a## 检查是否成功mn --test pingall## 查看版本mn --version## 卸载sudo rm -rf /usr/local/bin/mn /usr/local/bin/mnexec /usr/local/lib/python*/*/*mininet* /usr/local/bin/ovs-* /usr/local/sbin/ovs-*sudo apt-get remove mininet 1234567891011121314151617181920# dpkg 报错 参考：https://www.bbsmax.com/A/MyJx7MvVzn/sudo mv /var/lib/dpkg/info/ /var/lib/dpkg/info_old/sudo mkdir /var/lib/dpkg/info/sudo apt-get updatesudo apt-get -f installsudo mv /var/lib/dpkg/info/* /var/lib/dpkg/info_old/sudo rm -rf /var/lib/dpkg/infosudo mv /var/lib/dpkg/info_old/ /var/lib/dpkg/info/sudo apt-get update sudo apt-get upgrade ## 或者 这个方法不行，但有说成功的... # https://blog.csdn.net/ljf_study/article/details/81591036sudo apt-get autoremovesudo apt-get --purge remove &amp;&amp; sudo apt-get autocleansudo apt-get -f installsudo apt-get updatesudo apt-get upgrade &amp;&amp; sudo apt-get dist-upgradesudo dpkg-reconfigure -asudo dpkg --configure -a Mininet拓朴构建与命令使用topo：用于指定网络拓扑，Mininet支持创建的网络拓扑为：minimal、single、linear和tree。 minimal：创建一个交换机和两个主机相连的简单拓扑。默认无—topo参数的情况下就是这样。其内部实现就是调用了single,2对应的函数。 single,n：设置一个交换机和n个主机相连的拓扑。 linear,n：创建n个交换机，每个交换机只连接一个主机，并且所有交换机成线型排列。 tree,depth=n,fanout=m：创建深度为n，每层树枝为m的树型拓扑。因此形成的拓扑的交换机个数为（mn-1）/（m-1），主机个数为mn。 –custom：在上述已有拓扑的基础上，Mininet支持自定义的拓扑，使用一个简单的Python API即可。—custom需和—topo一起使用，如mn —custom file.py -topo mytopo。 网络构建参数使用12345678910111213141516# 创建single拓扑sudo mn --topo=single,3exit # 退出 # 创建linear线性拓扑sudo mn --topo=linear,3# 创建tree树形拓扑，深度2，每个交换机下挂两个设备sudo mn --topo=tree,depth=2,fanout=2# 创建custom自定义拓扑cd /home/openlab/openlab/mininet/customsudo mn --custom topo-2sw-2host.py --topo mytopo#自定义（custom）拓扑指python编写文件file.py，执行此脚本即可创建定义的拓扑，—custom与—topo联用，在custom目录下存在topo-2sw-2host.py文件，本例调用此文件构建拓扑。## 设置交换机--switch=Switch # 默认ovsk，还包括user,ovsbr,ovsk,ivs和lxbr## 配置MAC地址， 内部交互命令使用1234567net # 显示链接信息nodes # 查看节点信息links # 查看链路健壮性信息pingall # 验证所有主机间通信并查看结果xterm h1 h2 # 开启xterm进入设备可视化操作界面exit # 退出mn -c # 清除释放Mininet构造配置的交换机及主机 可视化构建网络拓扑 启动 12cd mininet/examples # 进入该目录下sudo ./miniedit.py # 启动可视化界面 Miniedit拓扑建立：选择左侧的网络组件，在空白区域单击鼠标左键即可添加网络组件，可选择的组件主要有主机、OpenFlow交换机、传统交换机，传统路由器、链路、控制器。 Miniedit拓扑建立：选择左侧的网络组件，在空白区域单击鼠标左键即可添加网络组件，可选择的组件主要有主机、OpenFlow交换机、传统交换机，传统路由器、链路、控制器。 Miniedit全局配置：Miniedit左上角“Edit”中可以剪切删除设备，及对整个网络进行全局配置 Miniedit运行：点击左下角“run”，即可运行设置好的网络拓扑，同时在后台可以看到相应的配置信息。运行后对交换机、主机进行右击长按，可查看交换机的bridge信息及打开Host的终端 Miniedit保存脚本：miniedit设置好拓扑后，可通过选择File-Export Level 2 Script，将其保存为python脚本，默认在mininet/examples目录下，通过chmod给此脚本权限后，直接运行即可重现拓扑 Miniedit脚本执行 1234# 通过后台查看保存的sdnlab.py脚本文件，并给脚本赋予权限：chmod –R 777 sdnlab.py# 执行sdnlab.py脚本：./sdnlab.py Mininet 调用API扩展自定义拓扑123456789101112cd mininet/custom sudo mn --custom topo-2sw-2host.py --topo mytopo # 执行py net.addHost(&#x27;h3&#x27;) # 添加主机h3py net.addLink(s3,net.get(&#x27;h3&#x27;)) # 添加s3与h3之间的链路py s3.attach(&#x27;s3-eth3&#x27;) # s3添加接口py net.get(&#x27;h3&#x27;).cmd(&#x27;ifconfig h3-eth0 10.3&#x27;) # 配置h3的IP地址## 查看节点信息dumpnodes ## 检查连通性h1 ping h3pingall Mininet可视化构建网络拓扑1234## 报错 MoTTY X11 proxy: Unsupported authorisation protocol## 需要普通用户下执行cd mininet/mininet/examplessudo ./miniedit.py 在控制器上进行鼠标右击长按，选择Properties即可对控制器进行配置，如下所示 在交换机上进行鼠标右击长按，选择Properties即可对交换机进行配置，交换机属性需配置16位的DPID，如下所示: 在主机上进行鼠标右击长按，选择Properties即可对主机进行配置，主机属性需配置IP地址，如下所示。 也可对链路进行属性配置，主要配置带宽、时延、丢包率等，此项可配置亦可不配置，如下所示: Miniedit全局配置。Miniedit左上角“Edit”中可以剪切删除设备，及对整个网络进行全局配置，如下所示。 Miniedit运行。 单击左下角“run”，即可运行设置好的网络拓扑，同时在后台可以看到相应的配置信息。 运行后对交换机、主机进行右击长按，可查看交换机的bridge信息及打开Host的终端，交换机信息如下： Miniedit保存脚本。Miniedit设置好拓扑后，可通过选择“File &gt; Export Level 2 Script”，将其保存为python脚本，默认在mininet/examples目录下。 Miniedit脚本执行。 通过后台查看保存的sdnlab.py脚本文件，并给脚本赋予权限： 1sudo chmod -R 777 sdnlab.py Mininet流表应用1——手动添加流表创建拓扑12345678910111213141516171819202122232425262728vim ./custom/exper1.py#!/usr/bin/pythonfrom mininet.topo import Topofrom mininet.net import Mininetfrom mininet.node import RemoteControllerfrom mininet.link import TCLinkfrom mininet.util import dumpNodeConnectionsclass MyTopo( Topo ): &quot;Simple topology example.&quot; def __init__( self ): &quot;Create custom topo.&quot; # Initialize topology Topo.__init__( self ) # Add hosts and switches Host1 = self.addHost( &#x27;h1&#x27; ) Host2 = self.addHost( &#x27;h2&#x27; ) Host3 = self.addHost( &#x27;h3&#x27; ) Switch1 = self.addSwitch( &#x27;s1&#x27; ) Switch2 = self.addSwitch( &#x27;s2&#x27; ) # Add links self.addLink( Host1, Switch1 ) self.addLink( Host2, Switch1 ) self.addLink( Host3, Switch2 ) self.addLink( Switch1, Switch2 )topos = &#123; &#x27;mytopo&#x27;: ( lambda: MyTopo() ) &#125;## # 运行自定义脚本，并指定一个不存在的控制器，是交换机不受控制器控制sudo mn --custom exper1.py --topo mytopo --controller=remote,ip=127.0.0.1,port=6633 测试流表状态下的通信12345678910111213141516171819xterm h1 h2 h3 # 打开可视化终端dpctl dump-flows # 查看交换机的flow table信息，可以看到没有流表mininet&gt; dpctl dump-flows*** s1 -------------------------*** s2 -------------------------## 在主机h2中执行命令tcpdump -n -i h2-eth0抓取网卡h2-eth0上的数据包root@sdntest:~/mininet/custom# tcpdump -n -i h2-eth0tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on h2-eth0, link-type EN10MB (Ethernet), capture size 262144 bytes## 在主机h3中执行命令tcpdump -n -i h3-eth0抓取网卡h2-eth0上的数据包,结果同上## 在主机h1中执行如下命令分别ping主机h2和h3，结果如下：PING 10.0.0.2 (10.0.0.2) 56(84) bytes of data.From 10.0.0.1 icmp_seq=1 Destination Host UnreachableFrom 10.0.0.1 icmp_seq=2 Destination Host UnreachableFrom 10.0.0.1 icmp_seq=3 Destination Host Unreachable--- 10.0.0.2 ping statistics ---3 packets transmitted, 0 received, +3 errors, 100% packet loss, time 1999mspipe 3 添加流表并测试主机间的通信123456# 步骤1 执行如下命令添加交换机端口流表使主机h1和h2通信mininet&gt; dpctl add-flow in_port=1,actions=output:2dpctl add-flow in_port=2,actions=output:1# 步骤2 执行如下命令查看交换机流表，两条flow entry添加成功mininet&gt; dpctl dump-flows# 步骤3 在主机h1中执行如下命令分别ping主机h2和h3 可以看到主机h1成功ping通h2，且h3没收到任何ping包。原理解析：用dpctl对交换机添加flow，让交换机从s1-eth1这个端口接收到的所有traffic都从s1-eth2这个端口发出去。用dpctl给交换机添加双向流表，因为ping包除了echo request还有echo reply。所以还需要用dpctl对交换机添加flow，让交换机从s1-eth2这个端口接收到的所有traffic都从s1-eth1这个端口发出去。添加这两条flow后，h1能够ping通h2，但是并没有为h1和h3之间添加对应的端口流表，所以h1与h3不通。 添加协议流表使h1/h2通信1234567891011# 步骤1 执行如下命令删除之前通过端口添加的流表并查看流表，确保交换机flow table为空dpctl del-flowsdpctl dump-flows# 步骤2 执行如下命令添加两条traffic类型为IPv4（0x0800）协议相关的flow entry，并查看下发的流表。dpctl add-flow dl_type=0x0800,nw_dst=10.0.0.2,actions=output:2dpctl add-flow dl_type=0x0800,nw_dst=10.0.0.1,actions=output:1dpctl dump-flows# 步骤3 在主机h1中执行如下命令分别ping主机h2和h3ping -c 3 10.0.0.2ping -c 3 10.0.0.3# 步骤4 在主机h2和h3 上查看tcpdump抓包结果 原理解析：用dpctl对交换机添加flow，让交换机把所有EtherType为0x0800（IPv4）并且destiation IP为10.0.0.2的traffic从s1-eth2这个端口发出去。用dpctl对交换机添加flow，让交换机把所有EtherType为0x0800（IPv4）并且destiation IP为10.0.0.1的traffic从s1-eth1这个端口发出去。但处在同一网段下的主机，它们之间的交流是L2 forwarding，需要靠ARP来解析MAC地址，之前只匹配了0x0800(IPv4)协议，并没有匹配到0x0806(ARP)，这样当交换机收到h1的ARP包后，因为没有控制器，flow table里面也没有相应的flow告诉它如何转发这个ARP包，交换机只能将它丢弃，从而导致h1 ping h2失败，所以需要添加ARP协议的流表来使通信。 1234# 步骤5 执行命令添加ARP（0x0806）协议相关的流表，让交换机以NORMAL形式（即广播）将所有ARP包从各个端口广播出去dpctl add-flow dl_type=0x0806,actions=NORMALdpctl dump-flows## 然后 h1可以ping通h2 Mininet流表应用实战2123456789101112131415161718192021# 步骤1 登录OpenDaylight虚拟机，执行如下命令查看OpenDaylight的启动情况，端口监听情况如下所示netstat -anput|grep 6653netstat -anput|grep 8181./bin/karaffeature:install odl-l2switch-switch-ui odl-openflowplugin-flow-services-ui odl-mdsal-apidocs odl-dluxapps-applications odl-faas-allfeature:install odl-restconffeature:install odl-l2switch-switch-uifeature:install odl-openflowplugin-flow-services-uifeature:install odl-mdsal-apidocsfeature:install odl-dluxapps-applicationsfeature:install odl-faas-all# 步骤2 mininet虚拟机打开wireshark进行抓包，监听网卡anysudo wireshark# 步骤3 sudo mn --custom exper1.py --topo mytopo --controller=remote,ip=119.255.243.31,port=6633 --switch ovs,protocols=OpenFlow13 # 这个1.3协议得设置 不然总失败，或1.1# 步骤4 执行命令pingall验证Mininet中虚拟主机的连通性# 步骤5 执行命令dpctl dump-flows查看交换机上的流表 123error: ovs-ofctl：version negotiation failed (we support version 0x01, peer supports version 0x04) 查看ovs中的流表时报错。原因是ovs-ofctl dump-flows命令默认是1.0版本，需要在命令中指定OpenFlow版本sudo ovs-ofctl dump-flows -O OpenFlow13 s1 # ovs 12# 步骤6 停止Wireshark抓包并查看抓包结果，筛选出openflow_v4协议数据包，如下图# 步骤7 打开odl控制器可以看到拓扑图如下 OpenFlow协议解析 步骤1 首先发送HELLO消息，建立初始化连接，协商使用的OpenFlow协议版本。由下图可知，ODL与Mininet之间应用的是OpenFlow1.0版本协议。 步骤2 OpenFlow版本协商完成后，控制器发送一条features_request消息获取交换机的特性信息，包括交换机的ID（DPID）、缓冲区数量、端口及端口属性等等。相应的，交换机回复features_reply消息。ofpt_feature_reply数据包详情如下，交换机的DPID是数据通道独一无二的标识符。本实验中交换机缓冲区数量（n_buffers）为256，交换机支持的流表数量（n_tables）为254，交换机所支持的功能，如下所示。 步骤3 stats reply消息用于回应stats request信息，主要是交换机回应给控制器的状态信息 步骤4 当交换机收到数据包后查找流表无匹配项时，将数据包封装在packet_in消息发给控制器，由控制器通过packet_out消息下发决策，使发送和接收数据包的两主机间进行通信。 步骤5 flow mod消息涉及流表项的下发匹配信息，下图显示的是flow mod匹配项的类型信息。 Mininet 多数据中心网络拓扑流量带宽实验实验内容 通过Mininet模拟搭建基于不同数据中心的网络拓扑。 通过程序生成真实网络流量。 实验原理数据中心基础数据中心不仅是一个网络概念，还是一个服务概念，它构成了网络基础资源的一部分，提供了一种高端的数据传输服务和高速接入服务。数据中心提供给用户综合全面的解决方法，为政府上网、企业上网、企业IT管理提供专业服务，使企业和个人能够迅速借助网络开展业务，把精力集中在其核心业务策划和网站建设上，而减少IT方面的后顾之忧。 使用mininet中的iperf工具在网络中生成UDP流量，iperf客户端传送数据流到iperf的服务端，由服务端接收并记录相关信息。网络性能评估中一个巨大的挑战就是如何生成真实的网络流量，可以通过程序来创造人工的网络流量，通过建立测试环境来模拟真实的状况。此应用主要以数据中心网络为目标场景，在mininet仿真环境中尽可能地还原数据中心内部的真实流量情况。Mininet数据中心应用价值： 树状拓扑结构容错能力强 降低数据中心成本消耗 提供重新排列的全带宽无阻碍路径 提高带宽利用率 分析数据中心网络流量性能 为真实数据中心和仿真测试床提供有用信息 在mininet中进行自定义命令iperfmulti功能拓展主要分为4步： 修改mininet/net.py 修改mininet/cli.py 修改bin/mn 重新安装Mininet核心文件：~/mininet/util/install.sh -n 操作步骤一、编写网络测试程序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081## 执行命令sudo vi openlab/mininet/mininet/net.py打开net.py文件,添加定义iperf_single()函数，实现在两个主机间进行iperf udp测试，并且在server端记录，具体代码如下，建议将代码放置在“def iperf”下 def iperf_single( self,hosts=None, udpBw=&#x27;10M&#x27;, period=60, port=5001): &quot;&quot;&quot;Run iperf between two hosts using UDP. hosts: list of hosts; if None, uses opposite hosts returns: results two-element array of server and client speeds&quot;&quot;&quot; if not hosts: return else: assert len( hosts ) == 2 client, server = hosts filename = client.name[1:] + &#x27;.out&#x27; output( &#x27;*** Iperf: testing bandwidth between &#x27; ) output( &quot;%s and %s\\n&quot; % ( client.name, server.name ) ) iperfArgs = &#x27;iperf -u &#x27; bwArgs = &#x27;-b &#x27; + udpBw + &#x27; &#x27; print &quot;***start server***&quot; server.cmd( iperfArgs + &#x27;-s -i 1&#x27; + &#x27; &gt; /home/sdnlab/log/&#x27; + filename + &#x27;&amp;&#x27;) print &quot;***start client***&quot; client.cmd( iperfArgs + &#x27;-t &#x27;+ str(period) + &#x27; -c &#x27; + server.IP() + &#x27; &#x27; + bwArgs +&#x27; &gt; /home/sdnlab/log/&#x27; + &#x27;client&#x27; + filename +&#x27;&amp;&#x27;)## 添加自定义命令iperfmulti()函数，iperfmulti函数主要是实现依次为每一台主机随机选择另一台主机作为iperf的服务器端，通过调用iperf_single，自身以客户端身份按照指定参数发送UDP流，服务器生成的报告以重定向的方式输出到文件中，使用iperfmulti命令，主机随机地向另一台主机发起一条恒定带宽的UDP数据流。具体代码如下所示,建议将代码放置在“def iperf_single”下 def iperfMulti(self, bw, period=60): base_port = 5001 server_list = [] client_list = [h for h in self.hosts] host_list = [] host_list = [h for h in self.hosts] cli_outs = [] ser_outs = [] _len = len(host_list) for i in xrange(0, _len): client = host_list[i] server = client while( server == client ): server = random.choice(host_list) server_list.append(server) self.iperf_single(hosts = [client, server], udpBw=bw, period= period, port=base_port) sleep(.05) base_port += 1 sleep(period) print &quot;test has done&quot;## sudo vi openlab/mininet/mininet/cli.py,添加如下代码，注册iperfmulti命令 ## isReadable缩进有问题？ def isReadable( poller ): &quot;Check whether a Poll object has a readable fd.&quot; for fdmask in poller.poll( 0 ): mask = fdmask[ 1 ] if mask &amp; POLLIN: return True return False def do_iperfmulti( self, line ): &quot;&quot;&quot;Multi iperf UDP test between nodes&quot;&quot;&quot; args = line.split() if len(args) == 1: udpBw = args[ 0 ] self.mn.iperfMulti(udpBw) elif len(args) == 2: udpBw = args[ 0 ] period = args[ 1 ] err = False self.mn.iperfMulti(udpBw, float(period)) else: error(&#x27;invalid number of args: iperfmulti udpBw period\\n&#x27; + &#x27;udpBw examples: 1M 120\\n&#x27;)## 执行命令sudo vi openlab/mininet/bin/mn打开mn文件，在mn中加入iperfmulti可执行命令，如下所示TESTS = &#123; name: True for name in ( &#x27;pingall&#x27;, &#x27;pingpair&#x27;, &#x27;iperf&#x27;, &#x27;iperfudp&#x27;, &#x27;iperfmulti&#x27; ) &#125;ALTSPELLING = &#123; &#x27;pingall&#x27;: &#x27;pingAll&#x27;, &#x27;pingpair&#x27;: &#x27;pingPair&#x27;, &#x27;iperfudp&#x27;: &#x27;iperfUdp&#x27;,&#x27;iperfMulti&#x27;:&#x27;iperfMulti&#x27; &#125;## 执行如下命令，重新编译Mininet。$ cd openlab/mininet/util$./install.sh -n## sudo mn命令创建一个topo，查看是否存在iperfmulti命令，以此验证iperfmulti是否成功 二、构建多数据中心网络拓扑12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758## 执行如下命令，创建多数据中心拓扑创建脚本。$ cd /home/openlab/openlab/mininet/custom$ sudo vi fattree.py#!/usr/bin/python&quot;&quot;&quot;Custom topology exampleAdding the &#x27;topos&#x27; dict with a key/value pair to generate our newly definedtopology enables one to pass in &#x27;--topo=mytopo&#x27; from the command line.&quot;&quot;&quot;from mininet.topo import Topofrom mininet.net import Mininetfrom mininet.node import RemoteController,CPULimitedHostfrom mininet.link import TCLinkfrom mininet.util import dumpNodeConnectionsclass MyTopo( Topo ): &quot;Simple topology example.&quot; def __init__( self ): &quot;Create custom topo.&quot; # Initialize topology Topo.__init__( self ) L1 = 2 L2 = L1 * 2 L3 = L2 c = [] a = [] e = [] # add core ovs for i in range( L1 ): sw = self.addSwitch( &#x27;c&#123;&#125;&#x27;.format( i + 1 ) ) c.append( sw ) # add aggregation ovs for i in range( L2 ): sw = self.addSwitch( &#x27;a&#123;&#125;&#x27;.format( L1 + i + 1 ) ) a.append( sw ) # add edge ovs for i in range( L3 ): sw = self.addSwitch( &#x27;e&#123;&#125;&#x27;.format( L1 + L2 + i + 1 ) ) e.append( sw ) # add links between core and aggregation ovs for i in range( L1 ): sw1 = c[i] for sw2 in a[i/2::L1/2]: # self.addLink(sw2, sw1, bw=10, delay=&#x27;5ms&#x27;, loss=10, max_queue_size=1000, use_htb=True) self.addLink( sw2, sw1 ) # add links between aggregation and edge ovs for i in range( 0, L2, 2 ): for sw1 in a[i:i+2]: for sw2 in e[i:i+2]: self.addLink( sw2, sw1 ) #add hosts and its links with edge ovs count = 1 for sw1 in e: for i in range(2): host = self.addHost( &#x27;h&#123;&#125;&#x27;.format( count ) ) self.addLink( sw1, host ) count += 1topos = &#123; &#x27;mytopo&#x27;: ( lambda: MyTopo() ) &#125; Mininet创建网络拓扑的代码中，可以通过改变代码中定义的L1变量来设置核心交换机的数量，并通过添加额外的交换机和链路来构成更复杂的数据中心网络拓扑。随着边缘交换机的增加，主机个数也随之增长，利用Mininet的易用性和扩展性，可以创建基于多种数据中心场景下的网络拓扑，达到更好更全面的实验效果。说明：为方便用户实验，该段代码在/home/ftp/fattree.py文件中已预置。 12## 切换到Mininet主机，执行如下命令，启动Mininet，生成测试拓扑结构。sudo mn --custom fattree.py --topo mytopo --controller=remote,ip=119.255.243.31,port=6633 --switch ovs,protocols=OpenFlow13","categories":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/categories/SDN/"}],"tags":[{"name":"网络架构","slug":"网络架构","permalink":"http://shizhonggan.github.io/tags/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/"},{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/tags/SDN/"},{"name":"OVS","slug":"OVS","permalink":"http://shizhonggan.github.io/tags/OVS/"}]},{"title":"软件定义网络（SDN）学习笔记(3)--Scapy交互式数据处理与Postman HTTP请求测试","slug":"SDN/SDN02_Scapy_Postman","date":"2021-04-20T01:15:22.000Z","updated":"2022-05-07T10:07:50.322Z","comments":true,"path":"2021/04/20/SDN/SDN02_Scapy_Postman/","link":"","permalink":"http://shizhonggan.github.io/2021/04/20/SDN/SDN02_Scapy_Postman/","excerpt":"","text":"SDN学习目录 SDN学习笔记(0)–wireshark抓包分析 SDN学习笔记(1)–iPerf和Netperf性能测试 SDN学习笔记(2)–Scapy交互式数据处理与Postman HTTP请求测试 SDN学习笔记(3)–OVS系统架构 SDN学习笔记(5)–OpenDaylight控制器 ScapyScapy 是基于python编写的交互式数据包处理程序，使用pyhon解释器作为命令面板。可以用来发送、嗅探、解析和伪造网络数据包，通常用于网络攻击和测试。 Scapy 不仅可以实现扫描、路由跟踪、探测、单元测试、攻击和发现网络等传统功能，也可以代替hping、arpspoof、arp-sk、arping、p0f,实现部分Namp、Tcpdump和tshark的功能。 它能够伪造或解码大量的网络协议数据包，能够发送、捕捉、匹配请求和回复包等。 它还可以发送无效数据帧、诸如修改的802.11数据帧、在WEP熵解码加密通道(VOIP)、ARP缓存攻击(VLAN)等，这是其他工具无法完成的。 Scapy主要负责定义、发送和接收报文。 Postman 进行SDN流表下发任务Postman是google开发的一款强大的王爷调试、发送网页HTTP请求，并能运行测试用例的Chrome插件。","categories":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/categories/SDN/"}],"tags":[{"name":"Scapy","slug":"Scapy","permalink":"http://shizhonggan.github.io/tags/Scapy/"},{"name":"Postman","slug":"Postman","permalink":"http://shizhonggan.github.io/tags/Postman/"}]},{"title":"Spark学习(1)","slug":"BigData/Spark01","date":"2021-04-17T07:54:23.000Z","updated":"2022-05-07T10:07:50.298Z","comments":true,"path":"2021/04/17/BigData/Spark01/","link":"","permalink":"http://shizhonggan.github.io/2021/04/17/BigData/Spark01/","excerpt":"","text":"Spark框架概述Spark是基于内存的运算，效率更高，语句更加简洁。 RDD 弹性分布式数据集，以实现通用性。 安装部署 运行环境与安装包不匹配的时候，就要对源代码进行编译或生成（SBT或Maven编译）。 make-distribution.sh option param –hadoop VERSION Hadoop版本号，默认1.0.4 –with-yarn 是否支持Hadoop YARN –with-hive 是否在Spark SQL中支持hive –skip-java-test 是否编译过程中略过java测试 –with-tachyon 是否支持文件系统Tachyon –tgz 在根目录生成spark-$VERSION-bin.tgz的部署包, 若无此参数则只生成dist目录 – name 在根目录生成spark-$VERSION-bin-$NAME.tgz的部署包，与–tgz组合使用 例如： 生成支持yarn、hadoop2.2.0的部署包： ./make-distribution.sh –hadoop 2.2.0 –with-yarn –tgz 生成支持yarn、hive的部署包 ./make-distribution.sh –hadoop 2.2.0 –with-yarn –with-hive –tgz Spark Standalone 集群部署 Java 的安装 ssh 无密码登录 Spark 安装包解压 Spark配置文件配置 文件 conf/slave hadoop1 hadoop2 hadoop3 文件 conf/spark-env.sh export SPARK_MASTER_IP=hadoop1 export SPARK_MASTER_PORT=7077 export SPARK_WORKER_CORES=1 export SPARK_WORKER_INSTANCES=1 export SPARK_MEMORY=3g Spark Standalone HA 部署 基于文件系统的HA[有问题] spark.deploy.recoveryMode 设置城FILESYSTEM spark.deploy.recoveryDirectory Spark保存恢复状态的目录 Spark-env.sh里对SPARK_DAEMON_JAVA_OPTS 设置 export SPARK_DAEMON_JAVA_OPTS=”-Dspark.deploy.recoverMode=FILESYSTEM -D spark.deploy.recoveryDirectory=/app/hadoop/spark/spark100/recovery” 基于zookeeper的HA 参考博客 spark.deploy.recoveryMode 设置成ZOOKEEPER spark.deploy.zookeeper.url ZooKeeper URL spark.deploy.zookeeper.dir Zookeeper保存恢复状态的目录，缺省为/spark spark-env里对SPARK_DAEMON_JAVA_OPTS设置 export SPARK_DAEMON_JAVA_OPTS=”-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=hadoop1:2181,hadoop2:2181,hadoop3:2181 -Dspark.deploy.zookeeper.dir=/spark” Spark Standalone 伪分布式部署Spark工具介绍 Spark 交互工具spark-shell Spark 应用程序部署工具spark-submit 参数说明 J 1","categories":[{"name":"BigData","slug":"BigData","permalink":"http://shizhonggan.github.io/categories/BigData/"}],"tags":[]},{"title":"Keras学习准备[待续...]","slug":"DeepLeaning/Keras/KerasBase","date":"2021-04-17T07:54:23.000Z","updated":"2022-05-07T10:07:50.300Z","comments":true,"path":"2021/04/17/DeepLeaning/Keras/KerasBase/","link":"","permalink":"http://shizhonggan.github.io/2021/04/17/DeepLeaning/Keras/KerasBase/","excerpt":"","text":"1. 安装12345pip install tensorflowpip install tensorflow-gpupip install keras## 其他pip install pydot pydot_ng vizgraph python3-tk matplotlib 2. 主要模型 MLP(多层感知机) 全连接网络，也成为深度前馈网络或前馈神经网络。常用于简单的逻辑和线性回归问题。处理序列数据和多维数据欠佳。 CNN(卷积神经网络) 主要应用与图像或视频的分类、分割和生成等。也可用于时序数据网络 RNN(循环神经网络) 主要应用于序列数据的预测 3. 代码流程3.1 加载数据集数据集常用MNIST手写体 3. MLP 数据集 MNIST手写体 代码：https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras","categories":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://shizhonggan.github.io/categories/Deep-Learning/"}],"tags":[]},{"title":"软件定义网络（SDN）学习笔记(1)--iPerf和Netperf性能测试","slug":"SDN/SDN01_iPerf_Netperf","date":"2021-04-15T08:15:22.000Z","updated":"2022-05-07T10:07:50.322Z","comments":true,"path":"2021/04/15/SDN/SDN01_iPerf_Netperf/","link":"","permalink":"http://shizhonggan.github.io/2021/04/15/SDN/SDN01_iPerf_Netperf/","excerpt":"","text":"SDN学习目录 SDN学习笔记(0)–wireshark抓包分析 SDN学习笔记(1)–iPerf和Netperf性能测试 SDN学习笔记(2)–Scapy交互式数据处理与Postman HTTP请求测试 SDN学习笔记(3)–OVS系统架构 SDN学习笔记(5)–OpenDaylight控制器 1. iPerf and NetperfiPerf是网络性能测试工具，可以测试主机之间的吞吐量。iPerf具有多种参数和特性，支持协议、定时、缓冲区等参数的配置调整，能够测试TCP/UDP的最大带宽、延迟抖动、数据包丢失等统计信息。iPerf基于Server/Client的工作模式,客户端向服务端发送一定量的数据，服务端统计并计算带宽、延时和抖动等信息。 命令格式： iperf [-s|-c host] [options] Netperf也是网络性能测试工具，主要用于测试TCP或UDP和Berkeley套接字接口的批量数据传输(Bulk Data Transfer)和请求/应答(Request/Reponse)性能。Netperf工具以Client/Server方式工作，服务端是netServer，用来侦听来自客户端的连接，客户端时NetPerf，用来向服务发起网络测试。在客户端与服务端之间，首先建立一个控制连接，传递有关测试配置的信息，以及测试的结果。在控制连接建立并传递了测试配置信息以后，客户端与服务之间建立一个测试连接，用于来回传递特殊的流量，已测试网络性能。 命令格式：netperf [global options] –[test-specific options] 2. 性能测试指标 网络吞吐量：单位时间内通过某个网络(信道或接口)的数据量，吞吐量受网络的带宽或网络的额定速率限制，单位bit/s 网络延时：一个数据包从用户的计算机发送到网站服务器，然后立即从网站服务器返回用户计算机的来回时间。影响网络演示的主要因素：路由的跳数和网络的流量。交换机延时(Latency)是指从交换机接收到数据包到开始向目的端口复制数据包之间的时间间隔。有许多因素会影响交换机演示大小，如转发技术等。 抖动：用于描述包在网络中的传输延时变化，抖动越小，说明网络质量越稳定、越好。 丢包率：理想状态下发送多少数据包就能接收到多少数据包。但由于信号衰减、网络质量等诸多因素的影响并不能达到理想状态。丢包率是指测试中多丢失的数据包数量占所有发送数据包的比率。 3. iPerf和Netperf比较 比较项 iPerf Netperf 支持多线程 是 是 可以设置服务器关闭之前保持的连接数 是 否 支持组播 是 否 支持除TCP,UDP之外的协议 否 是 支持IPv6 一定程度上 是 可以输出TCP MSS指 是 否 设置测试分组大小 否 是 支持多种测试范式 否 是 4. 测试命令4.1 iPerf一、TCP测试1234567## 主机一 10.0.0.8# iperf -s # 作为服务端## 主机二# iperf -c 10.0.0.8# iperf -c 10.0.0.8 -t 32 -i 8 # 测试时间32s,输出频率8s# iperf -c 10.0.0.8 -n 2000M -i 5 # 数据包为2000M,输出频率5s## 主机三 与主机二 分别执行上述命令，可以观察主机一的测试结果， 不同时段的带宽相差比较大 二、UDP测试123## 主机一 10.0.0.8 停止iPerf TCP服务# iperf -s -u # UDP测试# iperf -c 10.0.0.8 -u -b 2000M -i 5 -l 1380 # -b 2000M 2000Mbit/s发送速率， -i 5 表示输出频率5s -l 1380表示数据包的大小为1380个字节 note: 若发现Server接收不到Client 端发来的包，即没有任何输出，请检查是不是Client 端发的数据包大小大于Server端网卡设置的MTU值。当不设置-l的时候，Client端默认发送的数据包大小为1470. 4.2 Netperf一、TCP测试12345## 主机一# netserver -p 9991 # 指定端口## 主机二# netperf -H 10.0.0.8 -p 9991 # 缺省TCP批量传输，即 -t TCP_STREAM# netperf -H 10.0.0.8 -p 9991 -- -m 1024 二、UDP 测试1# netperf -t UDP_STREAM -H 10.0.0.8 -p 9991 -- -m 1024 note: 不同于iPerf, Netperf测试UDP数据包无需在服务器端指定参数，所以，不用重启服务器，只需要在客户端上加上 -t UDP_STREAM","categories":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/categories/SDN/"}],"tags":[{"name":"性能测试","slug":"性能测试","permalink":"http://shizhonggan.github.io/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"},{"name":"iPerf","slug":"iPerf","permalink":"http://shizhonggan.github.io/tags/iPerf/"},{"name":"Netperf","slug":"Netperf","permalink":"http://shizhonggan.github.io/tags/Netperf/"}]},{"title":"[阅读] Few-Shot Adversarial Domain Adaptation","slug":"Paper/Few-ShotAdversarialDomainAdaptation","date":"2021-04-14T13:54:23.000Z","updated":"2022-05-07T10:07:50.316Z","comments":true,"path":"2021/04/14/Paper/Few-ShotAdversarialDomainAdaptation/","link":"","permalink":"http://shizhonggan.github.io/2021/04/14/Paper/Few-ShotAdversarialDomainAdaptation/","excerpt":"","text":"参考资料： Github Code: https://github.com/Coolnesss/fada-pytorch[作者源程序] Github Code: https://github.com/xzsl/FewShotPapers[源程序，包含数据源，参考文献] http://blog.leanote.com/post/wuvin/1f36d3173608 https://blog.csdn.net/Adupanfei/article/details/85164925 https://github.com/topics/domain-adaptation","categories":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://shizhonggan.github.io/categories/Deep-Learning/"}],"tags":[{"name":"Few-shot Learning","slug":"Few-shot-Learning","permalink":"http://shizhonggan.github.io/tags/Few-shot-Learning/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"http://shizhonggan.github.io/tags/Semi-Supervised-Learning/"}]},{"title":"软件定义网络（SDN）学习笔记(0)--wireshark抓包分析","slug":"SDN/SDN00_wireshark","date":"2021-04-09T07:36:22.000Z","updated":"2022-05-07T10:07:50.322Z","comments":true,"path":"2021/04/09/SDN/SDN00_wireshark/","link":"","permalink":"http://shizhonggan.github.io/2021/04/09/SDN/SDN00_wireshark/","excerpt":"","text":"SDN学习目录 SDN学习笔记(0)–wireshark抓包分析 SDN学习笔记(1)–iPerf和Netperf性能测试 SDN学习笔记(2)–Scapy交互式数据处理与Postman HTTP请求测试 SDN学习笔记(3)–OVS系统架构 SDN学习笔记(5)–OpenDaylight控制器 简单网络命令1. ifconfigifconfig用于显示、设置、启动和停止网络设备。通过此命令能够显示出正在使用的计算机的IP地址、子网掩码和默认网关等。当网络环境发生改变时可通过此命令对网络进行相应的配置。ifconfig命令的格式和参数解释如下： 命令格式：ifconfig [网络设备] [参数] 命令参数如下表所示： 1234567891011121314151617181920212223242526272829303132333435# ifconfig # 查看网络设备信息eth0 Link encap:Ethernet HWaddr fa:16:3e:22:f1:7c inet addr:30.0.0.96 Bcast:30.0.0.255 Mask:255.255.255.0 inet6 addr: fe80::f816:3eff:fe22:f17c/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1450 Metric:1 RX packets:2402 errors:0 dropped:0 overruns:0 frame:0 TX packets:2390 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:190993 (190.9 KB) TX bytes:4116702 (4.1 MB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:16 errors:0 dropped:0 overruns:0 frame:0 TX packets:16 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:880 (880.0 B) TX bytes:880 (880.0 B)eth0表示第一块网卡。HWaddr表示网卡的物理地址即MAC地址。inet addr表示网卡的IPv4地址。inet6 addr表示网卡的IPv6地址。Bcast表示网卡的广播地址。Mask表示子网掩码地址。UP表示网卡开启状态。RUNNING表示网卡的网线被接上。MULTICAST表示支持组播。MTU表示最大传输单元。RX packets、TX packets表示接收、发送数据包情况统计。RX byte、TX bytes表示接收、发送数据字节数统计信息。lo表示主机的回环地址。一般是用来测试一个网络程序时又不想让局域网或外网的用户能够查看，只能在此台主机上运行和查看所用的网络接口，比如把httpd服务器指定到回坏地址后，在浏览器输入127.0.0.1就能看到你所架WEB网站，但只有您能看得到，局域网的其它主机或用户无从知道。# ifconfig eth0 down # 关闭网卡# ifconfig eth0 up # 开启网卡# ifconfig eth0 192.168.2.10 netmask 255.255.255.0 broadcast 192.168.2.255 # 配置IP地址等信息 note: 机器重启后，配置的IP地址就失效了，若想将配置信息永久地存的电脑里，需要修改网卡的配置文件。 2. pingping命令用于检查网络是否通畅和网络连接速度。简单地说，网络上的机器都有唯一确定的IP地址，给目标IP地址发送一个数据包，就会返回一个同样大小的数据包，根据返回的数据包可以确定目标主机是否存在，可以初步判断网络是否通畅以及连接速度等信息。根据数据包返回时间和丢包率，可以大致判断出网络是否稳定。Ping的返回异常信息有“Request Timed Out”、“Destination Net Unreachable”、“Bad IP address”和“Source quench received”：（1） Request Timed Out表示对方主机可以到达但是连接超时，这种情况通常是对方拒绝接收你发给它的数据包而造成的数据包丢失。原因可能是对方装有防火墙。（2） Destination Net Unreachable表示对方主机不存在或者没有跟对方建立连接。（3） Bad IP address表示可能没有连接到DNS服务器所以无法解析这个IP地址，也可能是IP地址不存在。（4） Source quench received表示对方或中途的服务器繁忙无法回应。说明：“destination host unreachable”和“time out”的区别：如果所经过的路由器的路由表中具有到达目标的路由，而目标因为其它原因不可到达，这时候会出现“time out”，如果路由表中连到达目标的路由都没有，那就会出现“destination host unreachable”。ping命令的格式和参数解释如下： 命令格式：ping [参数] [主机名或IP地址] 命令参数如下表所示： 12# ping 127.0.0.1 ## ping -c 5 www.xxx.com # -c 5表示在发送5个数据包后停止。 note1: ping本网网关或本网IP地址，可以检查硬件设备是否有问题，也可以检查本机与本地网络连接是否正常（在非局域网中这一步骤可以忽略）。 3. traceroute命令traceroute是用来显示源主机到目标主机之间所经过的网关的命令。traceroute命令用IP生存时间（TTL）字段和ICMP错误消息来确定从一个主机到网络上其他主机的路由。首先，traceroute发送一个TTL是1的IP数据包到目的地，当路径上的第一个路由器收到这个数据包时，TTL将会减1。此时，TTL变为0，所以该路由器会将此数据包丢掉，并返回一个ICMP time exceeded消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址）。traceroute收到这个消息后，便知道这个路由器存在于路径上，接着traceroute再发送一个TTL是2的数据包，继而发现第2个路由器。依此规律，traceroute每次将发送的数据包的TTL加1来发现下一个路由器，一直持续到某个数据包抵达目的地。当数据包到达目的地后，该主机则不会返回ICMP time exceeded消息，此时traceroute通过UDP数据包向不常见端口（30000以上）发送数据包，因此会收到ICMP port unreachable消息，故可判断到达目的地。traceroute命令的格式和参数解释如下： 命令格式：traceroute [参数] [主机] 命令参数如下表所示： 12345# sudo su# apt-get install traceroute # 安装# traceroute www.baidu.com # 追踪网络数据包的路由途径，执行结果如下图所示# traceroute -m 10 www.baidu.com # 设置路由追踪10条，即只发回通过10个网关的信息# traceroute -w 3 www.baidu.com # 把对外发探测包的等待响应时间设置为3秒 4. route命令route用于显示和操作IP路由表，它的主要作用是创建静态路由。在Linux系统中，设置路由通常是为了解决以下问题：Linux系统在一个局域网中，局域网中有一个网关，若要让机器访问Internet，那么就需要将网关的IP地址设置为Linux机器的默认路由。route命令的格式和参数解释如下： 命令格式：route [-f] [-p] [command] [destination] [mask netmask] [gateway] [metric] [if interface] 命令参数如下表所示: 12345678# routeopenlab@openlab:~/Desktop$ routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Ifacedefault 30.0.0.1 0.0.0.0 UG 0 0 0 eth0default 30.0.0.1 0.0.0.0 UG 100 0 0 eth030.0.0.0 * 255.255.255.0 U 0 0 0 eth0169.254.169.254 30.0.0.1 255.255.255.255 UGH 0 0 0 eth0 Destination：表示目标网段或主机。 Gateway：表示网关地址，“*”表示目标是本主机所属的网络，不需要路由。 Genmask：表示网络掩码。 Flags：表示标记。常用标记如下： U表示路由是活动的 H表示目标是一个主机 G表示路由指向网关 R表示恢复动态路由产生的表项 D表示由路由的后台程序动态地安装 M表示由路由的后台程序修改 ！表示拒绝路由。 Metric：表示路由距离，到达指定网络所需的中转数（Linux内核中没有使用）。 Ref：表示路由项引用次数（Linux内核中没有使用）。 Use：表示此路由项被路由软件查找的次数。 Iface：表示该路由表项对应的输出接口。123456# route add -net 224.0.0.0 netmask 240.0.0.0 dev eth0 # 添加网关# route del -net 224.0.0.0 netmask 240.0.0.0# route add -net 192.168.62.0 netmask 255.255.255.0 gw 192.168.1.1 # 添加一条路由(发往192.168.62这个网段的全部要经过网关192.168.1.1)# route del -net 192.168.122.0 netmask 255.255.255.0 # 删除一条路由 删除的时候不用写网关 5. IPip命令用来显示或操纵Linux主机的路由、网络设备、策略路由和隧道，是Linux下较新的功能强大的网络配置工具。它能够替代一些传统的网络管理工具，例如ifconfig、route等，使用权限为超级用户，ip命令的格式和参数解释如下： 命令格式：ip [OPTIONS] OBJECT [COMMAND [ARGUMENTS]] 命令参数：OPTIONS是一些修改ip行为或者改变其输出的选项。所有的选项都是以-字符开头，分为长、短两种形式。12345# ip link list # 查看网络设备的运行状态1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000 link/ether fa:16:3e:50:89:7f brd ff:ff:ff:ff:ff:ff lo表示主机的回环地址。 eth0表示第一块网卡。 UP表示网卡开启状态。 MULTICAST表示支持组播。 mtu表示最大传输单元。 link/ether表示MAC地址。12345678910111213# ip -s link list # 查看更加详细的网络设备信息1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 RX: bytes packets errors dropped overrun mcast 880 16 0 0 0 0 TX: bytes packets errors dropped carrier collsns 880 16 0 0 0 0 2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000 link/ether fa:16:3e:50:89:7f brd ff:ff:ff:ff:ff:ff RX: bytes packets errors dropped overrun mcast 378682 3605 0 0 0 0 TX: bytes packets errors dropped carrier collsns 2422264 2317 0 0 0 0 RX packets、TX packets表示接收、发送数据包情况统计。 RX bytes、TX bytes表示接收、发送数据字节数统计信息。1234# ip addr list # 查看ip信息# ip link set eth0 down # ip link list命令# ip link set eth0 up # 开启eth0网卡# route add default gw 30.0.1.1 # 设置网关 inet表示网卡的IPv4地址。 inet6表示网卡的IPv6地址。 note: 使用ip命令关闭网卡后，默认路由也被删除了，而使用ip命令启用网卡时，并不会配置路由，所以将无法ping通公网地址，故需要配置路由。 6. netstat命令netstat是一个监控TCP/IP网络的非常有用的命令，它可以显示路由表、实际的网络连接以及每一个网络接口设备的状态信息。它用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。另外它还能列出处于监听状态（即等待接入请求）的套接字。如果你想确认系统上的Web服务有没有起来，你可以查看80端口有没有打开。netstat命令的格式和参数解释如下： 命令格式：netstat [-acCeFghilMnNoprstuvVwx][-A&lt;网络类型&gt;][—ip] 命令参数如下表所示：1234# netstat -a # 查看所有端口信息# netstat -at # 查看TCP连接# netstat -l # 查看所有处于监听状态的Sockets# netstat -ap | grep ssh # 查看程序运行的端口 7. tcpdump命令tcpdump是根据使用者的定义对网络上的数据包进行截获的包分析工具。tcpdump凭借强大的功能和灵活的截取策略，成为类UNIX系统下用于网络分析和问题排查的首选工具。tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、网络或端口的过滤。 命令格式：tcpdump [ -adeflnNOpqStvx ] [ -c 数量 ] [ -F 文件名 ][ -i 网络接口 ] [ -r 文件名] [ -s snaplen ][ -T 类型 ] [ -w 文件名 ] [表达式 ] 命令参数： tcpdump命令常用参数如下： 123456# tcpdump -i eth0 # 进行抓包# ping www.xxxx.com # 在打开一个窗口进行网络请求,可看到抓包信息# tcpdump -i eth0 tcp port 80 # 抓取端口为80的TCP协议的数据信息# tcpdump-i eth0 tcp # 抓取TCP协议的数据信息，并访问网址：www.xxx.com# tcpdump -i eth0 -w tcpdump_package.pcap # 该命令作用是将tcupdump抓到的网络包保存到tcpdump_package.pcap文件中，命名规则为：文件名.pcap。# tcpdump -r tcpdump_package.pcap # 该命令作用是将保存在tcpdump_package.pacp中的抓包信息读取出来。 练习题下面（B）命令用于测试网络是否连通。 A. ifconfig B. ping C. ftp D. route 下列相关route命令的使用错误的是（B） A. 添加路由：route add-net 192.168.1.0 netmask - 255.255.255.0 gw 192.168.1.1 B. 删除路由：route del-net 192.168.1.0 C. 添加默认网关：route add default gw 192.168.120.240 D. 添加路由：route add-net 192.168.1.0/24 dev eth0 下面输出信息解释错误的是（D） A. HWaddr表示网卡的物理地址即MAC地址。 B. inet addr表示网卡的IP地址。 C. MTU表示最大传输单元。 D. RX packets、TX packets表示接收、发送数据字节数统计信息。 判断： 使用ifconfig命令配置主机信息后，信息将永久保存在电脑里。× 判断： traceroute -m 4 www.xxx.com表示只发回通过4个网关的信息。√ 下列关于ip命令理解错误的是（B） A. ip命令用来显示或操纵Linux主机的路由、网络设备、策略路由和隧道，它能够替代一些传统的网络管理工具，例如ifconfig、route等。 B. ip命令支持的操作有add、delete、show和link。 C. 可以使用ip addr add 192.168.17.30/24 dev eth0命令给主机配置IP地址。 D. 使用ip命令的neighbour选项，可以查看接入你所在的局域网的设备的MAC地址。 关于tcpdump命令理解错误的是（B） A. tcpdump支持对网络层、协议、主机、网络或端口的过滤。 B. tcpdump -i eth1 ‘((tcp) and (port 80) and ((dst host 192.168.1.254) or (dst host 192.168.1.200)))’，表示抓取所有经过eth1，目的地址是192.168.1.254和192.168.1.200，端口是80的TCP数据。 C. 不带任何选项的tcpdump，默认会抓取第一个网络接口，且只有将tcpdump进程终止才会停止抓包。 D. 表达式单元之间可以使用操作符” and / &amp;&amp; / or / || / not / ! “进行连接，从而组成复杂的条件表达式。 下面对netstat的输出结果理解正确的是（D） A. Active Internet connections表示TCP连接；Active UNIX domain sockets表示Unix域套接口。 B. State：表示连接状态，LISTENING表示正在侦听端口，等待建立连接。 C. Proto：表示使用的通信协议。 D. 以上均正确 判断： netstat是一个网络连接端扫描软件，用来扫描电脑上开放的端口，确定哪些服务运行在哪些端口，并且推断出计算机运行的操作系统。× 判断： 使用括号”()”可以改变tcpdump的表达式的优先级 √ Wireshark抓包分析工具Wireshark是一个免费开源的网络数据包分析软件。用于截取网络数据包并尽可能显示出最为详细的网络数据包数据。为了安全考虑，Wireshark只能查看封包，而不能修改封包的内容，或者发送封包。Wireshark能够对大部分局域网协议进行解析，具有界面简单、操作方便、实时显示捕获数据的优点。Wireshark不是入侵侦测系统，对于网络上的异常流量行为，Wireshark不会产生警示或是任何提示。然而，仔细分析Wireshark撷取的封包能够帮助使用者对于网络行为有更清楚的了解。Wireshark的用途很广，网络管理员可以使用Wireshark来检测网络问题，网络安全工程师可以使用Wireshark来检查资讯安全相关问题，开发者可以使用Wireshark来为新的通讯协议除错，普通使用者可以使用Wireshark来学习网络协议的相关知识。在使用Wireshark工具时，可以按如下流程进行： 确定Wireshark的位置。即在哪执行wireshark命令，如果没有一个正确的位置，启动Wireshark后会花费很长的时间捕获一些与自己无关的数据。 选择捕获接口。一般都是选择连接到Internet网络的接口，这样才可以捕获到与网络相关的数据。否则，捕获到的其它数据对自己也没有任何帮助。 使用捕获过滤器。通过设置捕获过滤器，可以避免产生过大的捕获文件。这样用户在分析数据时，也不会受其它数据干扰。而且，还可以为用户节约大量的时间。 使用显示过滤器。通常使用捕获过滤器过滤后的数据，往往还是很复杂。为了使过滤的数据包再更细致，此时使用显示过滤器进行过滤。 使用着色规则。通常使用显示过滤器过滤后的数据，都是有用的数据包。如果想更加突出的显示某个会话，可以使用着色规则高亮显示。 构建图表。如果用户想要更明显的看出一个网络中数据的变化情况，使用图表的形式可以很方便的展现数据分布情况。 重组数据。Wireshark的重组功能，可以重组一个会话中不同数据包的信息，或者是一个重组一个完整的图片或文件。由于传输的文件往往较大，所以信息分布在多个数据包中。为了能够查看到整个图片或文件，这时候就需要使用重组数据的方法来实现。环境 控制器：Ubuntu14.03桌面版,Floodlight1.0;CPU:1,内存:2GB,磁盘:20GB 交换机：Ubuntu14.03桌面版,OVS2.3.1;CPU:1,内存:2GB,磁盘:20GB 基本使用步骤12# apt-get install wireshark # root用户下安装$ sudo wireshark # 普通用户下打开wireshark主界面，这里权限的问题，root打不开，普通用户无法获得网卡 步骤 1 选择需要抓包的网卡Wireshark是捕获机器上的某一块网卡的网络包，当你的机器上有多块网卡的时候，你需要选择一个网卡，请按下面的方式选择网卡： 方式一：选择网卡“eth0”，单击开始按钮 方式二：1)在菜单栏选择”Capture -&gt; Interfaces”，进入选择网卡的页面;2)选择网卡“eth0”，单击“Start”，进入抓包页面 步骤 2 单击浏览器图标，打开浏览器，在浏览器上访问www.sina.com.cn，进行抓包步骤 3 单击红色停止按钮停止抓包，抓包结果如下图所示 图中四个区域分别为： 为DISPLAY FILTER（显示过滤器），显示过滤器用于查找捕捉记录中的内容。 为PACKET LIST PANE（封包列表），封包列表中显示所有已经捕获的封包。可以看到发送或接收方的MAC/IP地址、TCP/UDP端口号、协议或封包的内容。 为PACKET DETAILS PANE（封包详细信息）：这里显示的是在封包列表中被选中项目的详细信息。 为DISSECTOR PANE（16进制数据）：“解析器”在Wireshark中也被叫做“16进制数据查看面板”。这里显示的内容与“封包详细信息”中相同，只是改为以16进制的格式表述。 步骤 4 根据抓包结果，分析抓包数据 在封包列表部分选择一条TCP协议数据，如下图所示。 在封包列表部分选择一条TCP协议数据，如下图所示。 图中： Frame：表示物理层数据帧概况。 Ethernet II：表示数据链路层以太网帧头部信息。 Internet Protocol Version 4：表示互联网IP包头信息。 Transmission Control Protocol：表示传输层数据段头部信息，此处为TCP。 图中： 数据链路层显示有源MAC地址，目的MAC地址。 网络层IP的版本信息显示为IPv4。协议为TCP。源IP地址30.0.0.93即本机IP地址，目的IP地址10.168.16.15即远端服务器地址。 源端口为5901，目的端口为52356。 步骤 5 过滤报文信息 过滤源IP地址 如查找源地址为30.0.0.93的报文，则在过滤框中输入ip.src==30.0.0.93进行过滤 过滤目的IP地址 如查找目的地址为10.168.16.15的报文，则在过滤框中输入ip.dst==10.168.16.15进行过滤 过滤端口 如过滤52356端口，则在过滤框中输入tcp.port==52356||udp.port==52356 过滤协议 如过滤TCP的协议，则在过滤框中输入协议名tcp进行过滤 使用连接符and过滤。 过滤两种条件时，使用and连接，如过滤ip为30.0.0.93并且为TCP协议的报文，则在过滤框中输入ip.src==30.0.0.93 and tcp进行过滤，如下图所示。步骤 6 保存Wireshark抓包数据。 捕获的数据信息可以保存在文件中，这样就可以随时在Wireshark中打开此文件进行分析，而无需再次捕获同样的数据。关闭数据捕获屏幕或退出Wireshark时，系统会提示你保存信息 练习题下面关于Wireshark说法错误的是（D） A. 捕获过滤器用来过滤捕获的封包，以免捕获太多的记录。 B. 封包列表中显示所有已经捕获的封包。可以看到发送或接收方的MAC/IP地址、TCP/UDP端口号、协议或封包的内容。 C. 显示过滤器用来告诉Wireshark只显示那些符合过滤条件的数据包。 D. Wireshark能够对大部分局域网协议进行解析，能够查看、修改封包的内容，具有界面简单、操作方便、实时显示捕获数据的优点。 下面关于Wireshark的过滤表达式描述错误的是（B） A. 过滤ip为10.0.1.1并且为http协议的报文，表达式为：ip.src==10.0.1.1 and http。 B. 如果没有特别指明来源或目的地，则默认使用源地址进行过滤。 C. 否(“not”)具有最高的优先级，或(“or”)和与(“and”)具有相同的优先级，运算时从左至右进行。 D. 对目的地址为192.168.0.1的包的过滤，表达式为：ip.dst eq 192.168.0.1。 判断：封包列表的面板中显示：编号、时间戳、源地址、目标地址、协议、长度以及封包信息，不同的协议用了不同的颜色显示，也可以自己修改这些显示的颜色规则。 √ 判断：Wireshark的捕捉过滤器支持协议过滤和内容过滤。×","categories":[{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/categories/SDN/"}],"tags":[{"name":"性能测试","slug":"性能测试","permalink":"http://shizhonggan.github.io/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"},{"name":"网络","slug":"网络","permalink":"http://shizhonggan.github.io/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"Hexo markdown 插入图片解决方法","slug":"HexoStudy/HexoImageFile","date":"2021-04-07T12:41:21.000Z","updated":"2022-05-07T10:07:50.314Z","comments":true,"path":"2021/04/07/HexoStudy/HexoImageFile/","link":"","permalink":"http://shizhonggan.github.io/2021/04/07/HexoStudy/HexoImageFile/","excerpt":"","text":"前言官方解决办法： https://hexo.io/zh-cn/docs/asset-folders.html 我尝试了一下这个官方办法，并未成功。于是，不得不尝试大家推荐的“图床”办法。 “图床”即第三方存储图片的地方，并能支持http/https协议以提供图片访问链接。减轻本地服务器空间，加快图片打开速度。 提供图床的第三方网站众多。出于对安全、网站服务能力的考量，建议采用gitee 作为图片托管仓库。 具体方法 新建仓库 仓库下新建index.html，此时service 里便出现gitee pages功能 点击gitee pages进入设置，直接默认确定即可，然后出现该网页链接地址 url 克隆到本地,然后将你需要的图片放到该目录下 push到仓库 于是，可以通过url+path的方式访问图片 markdown可以直接使用 温馨提示1：图要加水印 温馨提示2：gitee每次更新都要进入service-&gt;gitee page-&gt;update","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://shizhonggan.github.io/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://shizhonggan.github.io/tags/Hexo/"},{"name":"前端","slug":"前端","permalink":"http://shizhonggan.github.io/tags/%E5%89%8D%E7%AB%AF/"}]},{"title":"Gitalk 评论登录出现403 解决方法","slug":"HexoStudy/Gitalk403Solution","date":"2021-04-07T11:22:12.000Z","updated":"2022-05-07T10:07:50.313Z","comments":true,"path":"2021/04/07/HexoStudy/Gitalk403Solution/","link":"","permalink":"http://shizhonggan.github.io/2021/04/07/HexoStudy/Gitalk403Solution/","excerpt":"","text":"起因网络受限 本篇文章参考：https://cuiqingcai.com/30010.html 问题二Related Issues not found Please contact @ShizhongGan to initialize the comment 解决方法 用代理啊 换其他的","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://shizhonggan.github.io/categories/Hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://shizhonggan.github.io/tags/hexo/"},{"name":"gitalk","slug":"gitalk","permalink":"http://shizhonggan.github.io/tags/gitalk/"}]},{"title":"vs code 实用扩展插件","slug":"Tips/vscode_tips","date":"2021-04-07T06:32:06.000Z","updated":"2022-05-07T10:07:50.329Z","comments":true,"path":"2021/04/07/Tips/vscode_tips/","link":"","permalink":"http://shizhonggan.github.io/2021/04/07/Tips/vscode_tips/","excerpt":"","text":"Angular 8 and TypeScript/HTML VS Code Snippets Awesome Flutter Snippets Chinese (Simplified) Language Pack for Visual Studio Code Code Runner Code Spell Checker Dart Docker Draw.io Integration Flutter Graphviz Interactive Preview HTML Boilerplate Jupyter LaTeX Workshop Live Server Markdown All in One Markdown Mind Map Preview Markdown PDF Markdown+Math Office Viewer open in browser PlantUML python reStructuredText","categories":[{"name":"Tips","slug":"Tips","permalink":"http://shizhonggan.github.io/categories/Tips/"}],"tags":[{"name":"vs code插件","slug":"vs-code插件","permalink":"http://shizhonggan.github.io/tags/vs-code%E6%8F%92%E4%BB%B6/"}]},{"title":"Gitee部署Hexo 博客","slug":"HexoStudy/HexoGiteeDeploy","date":"2021-04-07T01:21:46.000Z","updated":"2022-05-07T10:07:50.313Z","comments":true,"path":"2021/04/07/HexoStudy/HexoGiteeDeploy/","link":"","permalink":"http://shizhonggan.github.io/2021/04/07/HexoStudy/HexoGiteeDeploy/","excerpt":"","text":"前言由于网络限制，Github部署Hexo博客加载速度慢，因此建议采用gitee进行部署。 部署方法 注册gitee账号 新建公开仓库 访问地址不带二级目录设置：如果你想你的 pages 首页访问地址不带二级目录，如ipvb.gitee.io，你需要建立一个与自己个性地址同名的项目，如 gitee.com/ipvb 这个用户，想要创建一个自己的站点，但不想以子目录的方式访问，想以ipvb.oschina.io直接访问，那么他就可以创建一个名字为ipvb的项目 gitee.com/ipvb/ipvb 部署完成后，就可以以 ipvb.gitee.io 进行访问了。 设置hexo _config.yml文件，绑定该新建的仓库 hexo d部署 该仓库的service出现gitee page功能，点击进去默认确定即可 然后通过ipvb.gitee.io即可访问 温馨提示：每次hexo d部署完，都要进入gitee page功能中update，否则无法看到网页变化。github不需要。","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://shizhonggan.github.io/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://shizhonggan.github.io/tags/Hexo/"},{"name":"Gitee","slug":"Gitee","permalink":"http://shizhonggan.github.io/tags/Gitee/"}]},{"title":"Hexo 快速搭建静态博客","slug":"HexoStudy/HexoStudy","date":"2021-04-06T02:26:34.000Z","updated":"2022-05-07T10:07:50.314Z","comments":true,"path":"2021/04/06/HexoStudy/HexoStudy/","link":"","permalink":"http://shizhonggan.github.io/2021/04/06/HexoStudy/HexoStudy/","excerpt":"","text":"环境准备12# 设置npm环境npm config set registry https://registry.npm.taobao.org 1ssh-keygen -t rsa -C &quot;gan_shizhong@163.com&quot; 12345678910# install pluginnpm install hexo-wordcount --savenpm install hexo-generator-json-content --savenpm install hexo-generator-feed --savenpm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --savenpm install hexo-neat --save# npm install hexo-translate-title --save 12345安装Hexonpm install -g hexo-clinpm install hexonpm install hexo-deployer-git --save 发布文章1hexo new page &quot;文件名&quot;","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://shizhonggan.github.io/categories/Hexo/"}],"tags":[{"name":"前端","slug":"前端","permalink":"http://shizhonggan.github.io/tags/%E5%89%8D%E7%AB%AF/"},{"name":"hexo","slug":"hexo","permalink":"http://shizhonggan.github.io/tags/hexo/"},{"name":"gitalk","slug":"gitalk","permalink":"http://shizhonggan.github.io/tags/gitalk/"}]}],"categories":[{"name":"Python","slug":"Python","permalink":"http://shizhonggan.github.io/categories/Python/"},{"name":"Linux","slug":"Linux","permalink":"http://shizhonggan.github.io/categories/Linux/"},{"name":"React","slug":"React","permalink":"http://shizhonggan.github.io/categories/React/"},{"name":"python","slug":"python","permalink":"http://shizhonggan.github.io/categories/python/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://shizhonggan.github.io/categories/Kubernetes/"},{"name":"Git","slug":"Git","permalink":"http://shizhonggan.github.io/categories/Git/"},{"name":"Networking","slug":"Networking","permalink":"http://shizhonggan.github.io/categories/Networking/"},{"name":"Django","slug":"Django","permalink":"http://shizhonggan.github.io/categories/Django/"},{"name":"Shell","slug":"Shell","permalink":"http://shizhonggan.github.io/categories/Shell/"},{"name":"BigData","slug":"BigData","permalink":"http://shizhonggan.github.io/categories/BigData/"},{"name":"Spark","slug":"BigData/Spark","permalink":"http://shizhonggan.github.io/categories/BigData/Spark/"},{"name":"Hadoop","slug":"BigData/Hadoop","permalink":"http://shizhonggan.github.io/categories/BigData/Hadoop/"},{"name":"SQL","slug":"SQL","permalink":"http://shizhonggan.github.io/categories/SQL/"},{"name":"Ansible","slug":"Ansible","permalink":"http://shizhonggan.github.io/categories/Ansible/"},{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/categories/Docker/"},{"name":"Nvidia","slug":"Nvidia","permalink":"http://shizhonggan.github.io/categories/Nvidia/"},{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/categories/ELK/"},{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/categories/DevOps/"},{"name":"AWS","slug":"AWS","permalink":"http://shizhonggan.github.io/categories/AWS/"},{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/categories/SDN/"},{"name":"Mininet","slug":"Mininet","permalink":"http://shizhonggan.github.io/categories/Mininet/"},{"name":"网络","slug":"网络","permalink":"http://shizhonggan.github.io/categories/%E7%BD%91%E7%BB%9C/"},{"name":"开发","slug":"开发","permalink":"http://shizhonggan.github.io/categories/%E5%BC%80%E5%8F%91/"},{"name":"运维","slug":"运维","permalink":"http://shizhonggan.github.io/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Tips","slug":"Tips","permalink":"http://shizhonggan.github.io/categories/Tips/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://shizhonggan.github.io/categories/Deep-Learning/"},{"name":"Hexo","slug":"Hexo","permalink":"http://shizhonggan.github.io/categories/Hexo/"}],"tags":[{"name":"Jupyter","slug":"Jupyter","permalink":"http://shizhonggan.github.io/tags/Jupyter/"},{"name":"io multiplexing","slug":"io-multiplexing","permalink":"http://shizhonggan.github.io/tags/io-multiplexing/"},{"name":"select","slug":"select","permalink":"http://shizhonggan.github.io/tags/select/"},{"name":"poll","slug":"poll","permalink":"http://shizhonggan.github.io/tags/poll/"},{"name":"epoll","slug":"epoll","permalink":"http://shizhonggan.github.io/tags/epoll/"},{"name":"React","slug":"React","permalink":"http://shizhonggan.github.io/tags/React/"},{"name":"python","slug":"python","permalink":"http://shizhonggan.github.io/tags/python/"},{"name":"classmethod","slug":"classmethod","permalink":"http://shizhonggan.github.io/tags/classmethod/"},{"name":"DNS server","slug":"DNS-server","permalink":"http://shizhonggan.github.io/tags/DNS-server/"},{"name":"Centos","slug":"Centos","permalink":"http://shizhonggan.github.io/tags/Centos/"},{"name":"bind chroot","slug":"bind-chroot","permalink":"http://shizhonggan.github.io/tags/bind-chroot/"},{"name":"Flask","slug":"Flask","permalink":"http://shizhonggan.github.io/tags/Flask/"},{"name":"gunicorn","slug":"gunicorn","permalink":"http://shizhonggan.github.io/tags/gunicorn/"},{"name":"nginx","slug":"nginx","permalink":"http://shizhonggan.github.io/tags/nginx/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://shizhonggan.github.io/tags/Kubernetes/"},{"name":"gitlab","slug":"gitlab","permalink":"http://shizhonggan.github.io/tags/gitlab/"},{"name":"docker","slug":"docker","permalink":"http://shizhonggan.github.io/tags/docker/"},{"name":"ci/cd","slug":"ci-cd","permalink":"http://shizhonggan.github.io/tags/ci-cd/"},{"name":"Networking","slug":"Networking","permalink":"http://shizhonggan.github.io/tags/Networking/"},{"name":"Django","slug":"Django","permalink":"http://shizhonggan.github.io/tags/Django/"},{"name":"Docker","slug":"Docker","permalink":"http://shizhonggan.github.io/tags/Docker/"},{"name":"Mysql","slug":"Mysql","permalink":"http://shizhonggan.github.io/tags/Mysql/"},{"name":"Shell","slug":"Shell","permalink":"http://shizhonggan.github.io/tags/Shell/"},{"name":"Spark","slug":"Spark","permalink":"http://shizhonggan.github.io/tags/Spark/"},{"name":"YARN","slug":"YARN","permalink":"http://shizhonggan.github.io/tags/YARN/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://shizhonggan.github.io/tags/Zookeeper/"},{"name":"游标","slug":"游标","permalink":"http://shizhonggan.github.io/tags/%E6%B8%B8%E6%A0%87/"},{"name":"Ansible","slug":"Ansible","permalink":"http://shizhonggan.github.io/tags/Ansible/"},{"name":"devops","slug":"devops","permalink":"http://shizhonggan.github.io/tags/devops/"},{"name":"python3","slug":"python3","permalink":"http://shizhonggan.github.io/tags/python3/"},{"name":"django","slug":"django","permalink":"http://shizhonggan.github.io/tags/django/"},{"name":"RESTful","slug":"RESTful","permalink":"http://shizhonggan.github.io/tags/RESTful/"},{"name":"API","slug":"API","permalink":"http://shizhonggan.github.io/tags/API/"},{"name":"thread","slug":"thread","permalink":"http://shizhonggan.github.io/tags/thread/"},{"name":"process","slug":"process","permalink":"http://shizhonggan.github.io/tags/process/"},{"name":"coroutine","slug":"coroutine","permalink":"http://shizhonggan.github.io/tags/coroutine/"},{"name":"后端","slug":"后端","permalink":"http://shizhonggan.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"运维","slug":"运维","permalink":"http://shizhonggan.github.io/tags/%E8%BF%90%E7%BB%B4/"},{"name":"Shell commands","slug":"Shell-commands","permalink":"http://shizhonggan.github.io/tags/Shell-commands/"},{"name":"Nvidia","slug":"Nvidia","permalink":"http://shizhonggan.github.io/tags/Nvidia/"},{"name":"ELK","slug":"ELK","permalink":"http://shizhonggan.github.io/tags/ELK/"},{"name":"Nginx","slug":"Nginx","permalink":"http://shizhonggan.github.io/tags/Nginx/"},{"name":"Logstash","slug":"Logstash","permalink":"http://shizhonggan.github.io/tags/Logstash/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://shizhonggan.github.io/tags/Elasticsearch/"},{"name":"DevOps","slug":"DevOps","permalink":"http://shizhonggan.github.io/tags/DevOps/"},{"name":"zabbix","slug":"zabbix","permalink":"http://shizhonggan.github.io/tags/zabbix/"},{"name":"Nagios","slug":"Nagios","permalink":"http://shizhonggan.github.io/tags/Nagios/"},{"name":"JumpServer","slug":"JumpServer","permalink":"http://shizhonggan.github.io/tags/JumpServer/"},{"name":"Ansilbe","slug":"Ansilbe","permalink":"http://shizhonggan.github.io/tags/Ansilbe/"},{"name":"Spinnaker","slug":"Spinnaker","permalink":"http://shizhonggan.github.io/tags/Spinnaker/"},{"name":"AWS","slug":"AWS","permalink":"http://shizhonggan.github.io/tags/AWS/"},{"name":"RESTful API","slug":"RESTful-API","permalink":"http://shizhonggan.github.io/tags/RESTful-API/"},{"name":"OpenDaylight","slug":"OpenDaylight","permalink":"http://shizhonggan.github.io/tags/OpenDaylight/"},{"name":"那些坑","slug":"那些坑","permalink":"http://shizhonggan.github.io/tags/%E9%82%A3%E4%BA%9B%E5%9D%91/"},{"name":"网络架构","slug":"网络架构","permalink":"http://shizhonggan.github.io/tags/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/"},{"name":"SDN","slug":"SDN","permalink":"http://shizhonggan.github.io/tags/SDN/"},{"name":"OVS","slug":"OVS","permalink":"http://shizhonggan.github.io/tags/OVS/"},{"name":"网络","slug":"网络","permalink":"http://shizhonggan.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Floodlight","slug":"Floodlight","permalink":"http://shizhonggan.github.io/tags/Floodlight/"},{"name":"boto3","slug":"boto3","permalink":"http://shizhonggan.github.io/tags/boto3/"},{"name":"paramiko","slug":"paramiko","permalink":"http://shizhonggan.github.io/tags/paramiko/"},{"name":"PyQt5","slug":"PyQt5","permalink":"http://shizhonggan.github.io/tags/PyQt5/"},{"name":"tkinter","slug":"tkinter","permalink":"http://shizhonggan.github.io/tags/tkinter/"},{"name":"OOP","slug":"OOP","permalink":"http://shizhonggan.github.io/tags/OOP/"},{"name":"Scapy","slug":"Scapy","permalink":"http://shizhonggan.github.io/tags/Scapy/"},{"name":"Postman","slug":"Postman","permalink":"http://shizhonggan.github.io/tags/Postman/"},{"name":"性能测试","slug":"性能测试","permalink":"http://shizhonggan.github.io/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"},{"name":"iPerf","slug":"iPerf","permalink":"http://shizhonggan.github.io/tags/iPerf/"},{"name":"Netperf","slug":"Netperf","permalink":"http://shizhonggan.github.io/tags/Netperf/"},{"name":"Few-shot Learning","slug":"Few-shot-Learning","permalink":"http://shizhonggan.github.io/tags/Few-shot-Learning/"},{"name":"Semi-Supervised Learning","slug":"Semi-Supervised-Learning","permalink":"http://shizhonggan.github.io/tags/Semi-Supervised-Learning/"},{"name":"Hexo","slug":"Hexo","permalink":"http://shizhonggan.github.io/tags/Hexo/"},{"name":"前端","slug":"前端","permalink":"http://shizhonggan.github.io/tags/%E5%89%8D%E7%AB%AF/"},{"name":"hexo","slug":"hexo","permalink":"http://shizhonggan.github.io/tags/hexo/"},{"name":"gitalk","slug":"gitalk","permalink":"http://shizhonggan.github.io/tags/gitalk/"},{"name":"vs code插件","slug":"vs-code插件","permalink":"http://shizhonggan.github.io/tags/vs-code%E6%8F%92%E4%BB%B6/"},{"name":"Gitee","slug":"Gitee","permalink":"http://shizhonggan.github.io/tags/Gitee/"}]}